diff -Naur chromium-67.0.3396.62/base/numerics/safe_math_shared_impl.h chromium-67.0.3396.62.patched/base/numerics/safe_math_shared_impl.h
--- chromium-67.0.3396.62/base/numerics/safe_math_shared_impl.h	2018-05-30 11:43:03.000000000 +0300
+++ chromium-67.0.3396.62.patched/base/numerics/safe_math_shared_impl.h	2018-06-06 10:06:12.361134439 +0300
@@ -21,8 +21,7 @@
 #if !defined(__native_client__) &&                         \
     ((defined(__clang__) &&                                \
       ((__clang_major__ > 3) ||                            \
-       (__clang_major__ == 3 && __clang_minor__ >= 4))) || \
-     (defined(__GNUC__) && __GNUC__ >= 5))
+       (__clang_major__ == 3 && __clang_minor__ >= 4))))
 #include "base/numerics/safe_math_clang_gcc_impl.h"
 #define BASE_HAS_OPTIMIZED_SAFE_MATH (1)
 #else
diff -Naur chromium-67.0.3396.62/cc/paint/raw_memory_transfer_cache_entry.cc chromium-67.0.3396.62.patched/cc/paint/raw_memory_transfer_cache_entry.cc
--- chromium-67.0.3396.62/cc/paint/raw_memory_transfer_cache_entry.cc	2018-05-30 11:43:03.000000000 +0300
+++ chromium-67.0.3396.62.patched/cc/paint/raw_memory_transfer_cache_entry.cc	2018-06-06 10:06:12.365134376 +0300
@@ -3,7 +3,7 @@
 // found in the LICENSE file.
 
 #include "cc/paint/raw_memory_transfer_cache_entry.h"
-
+#include <memory.h>
 #include <string.h>
 
 namespace cc {
diff -Naur chromium-67.0.3396.62/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix chromium-67.0.3396.62.patched/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix
--- chromium-67.0.3396.62/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix	2018-05-30 11:43:03.000000000 +0300
@@ -0,0 +1,53 @@
+// Copyright (c) 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "cc/paint/raw_memory_transfer_cache_entry.h"
+
+#include <string.h>
+
+namespace cc {
+
+ClientRawMemoryTransferCacheEntry::ClientRawMemoryTransferCacheEntry(
+    std::vector<uint8_t> data)
+    : id_(s_next_id_.GetNext()), data_(std::move(data)) {}
+ClientRawMemoryTransferCacheEntry::~ClientRawMemoryTransferCacheEntry() =
+    default;
+
+// static
+base::AtomicSequenceNumber ClientRawMemoryTransferCacheEntry::s_next_id_;
+
+size_t ClientRawMemoryTransferCacheEntry::SerializedSize() const {
+  return data_.size();
+}
+
+uint32_t ClientRawMemoryTransferCacheEntry::Id() const {
+  return id_;
+}
+
+bool ClientRawMemoryTransferCacheEntry::Serialize(
+    base::span<uint8_t> data) const {
+  if (data.size() != data_.size())
+    return false;
+
+  memcpy(data.data(), data_.data(), data.size());
+  return true;
+}
+
+ServiceRawMemoryTransferCacheEntry::ServiceRawMemoryTransferCacheEntry() =
+    default;
+ServiceRawMemoryTransferCacheEntry::~ServiceRawMemoryTransferCacheEntry() =
+    default;
+
+size_t ServiceRawMemoryTransferCacheEntry::CachedSize() const {
+  return data_.size();
+}
+
+bool ServiceRawMemoryTransferCacheEntry::Deserialize(
+    GrContext* context,
+    base::span<const uint8_t> data) {
+  data_ = std::vector<uint8_t>(data.begin(), data.end());
+  return true;
+}
+
+}  // namespace cc
diff -Naur chromium-67.0.3396.62/chrome/browser/first_run/first_run_internal_linux.cc chromium-67.0.3396.62.patched/chrome/browser/first_run/first_run_internal_linux.cc
--- chromium-67.0.3396.62/chrome/browser/first_run/first_run_internal_linux.cc	2018-05-30 11:43:06.000000000 +0300
+++ chromium-67.0.3396.62.patched/chrome/browser/first_run/first_run_internal_linux.cc	2018-06-06 10:06:12.325135014 +0300
@@ -19,9 +19,9 @@
 
 base::FilePath MasterPrefsPath() {
   // The standard location of the master prefs is next to the chrome binary.
+  // ...but we patch it to use /etc/chromium
   base::FilePath master_prefs;
-  if (!PathService::Get(base::DIR_EXE, &master_prefs))
-    return base::FilePath();
+  master_prefs = base::FilePath("/etc/chromium");
   return master_prefs.AppendASCII(installer::kDefaultMasterPrefs);
 }
 
diff -Naur chromium-67.0.3396.62/chrome/browser/first_run/first_run_internal_linux.cc.etc chromium-67.0.3396.62.patched/chrome/browser/first_run/first_run_internal_linux.cc.etc
--- chromium-67.0.3396.62/chrome/browser/first_run/first_run_internal_linux.cc.etc	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/chrome/browser/first_run/first_run_internal_linux.cc.etc	2018-05-30 11:43:06.000000000 +0300
@@ -0,0 +1,29 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "chrome/browser/first_run/first_run_internal.h"
+
+#include "base/base_paths.h"
+#include "base/files/file_path.h"
+#include "base/path_service.h"
+#include "chrome/installer/util/master_preferences.h"
+
+namespace first_run {
+namespace internal {
+
+bool IsOrganicFirstRun() {
+  // We treat all installs as organic.
+  return true;
+}
+
+base::FilePath MasterPrefsPath() {
+  // The standard location of the master prefs is next to the chrome binary.
+  base::FilePath master_prefs;
+  if (!PathService::Get(base::DIR_EXE, &master_prefs))
+    return base::FilePath();
+  return master_prefs.AppendASCII(installer::kDefaultMasterPrefs);
+}
+
+}  // namespace internal
+}  // namespace first_run
diff -Naur chromium-67.0.3396.62/chrome/test/data/webui_test_resources.grd chromium-67.0.3396.62.patched/chrome/test/data/webui_test_resources.grd
--- chromium-67.0.3396.62/chrome/test/data/webui_test_resources.grd	2018-05-30 11:43:09.000000000 +0300
+++ chromium-67.0.3396.62.patched/chrome/test/data/webui_test_resources.grd	2018-06-06 10:06:12.313135206 +0300
@@ -8,7 +8,6 @@
   </outputs>
   <release seq="1">
     <includes>
-      <include name="IDR_WEBUI_TEST_I18N_PROCESS_CSS_TEST" file="webui/i18n_process_css_test.html" flattenhtml="true" allowexternalscript="true" type="BINDATA" />
     </includes>
   </release>
 </grit>
diff -Naur chromium-67.0.3396.62/chrome/test/data/webui_test_resources.grd.notest chromium-67.0.3396.62.patched/chrome/test/data/webui_test_resources.grd.notest
--- chromium-67.0.3396.62/chrome/test/data/webui_test_resources.grd.notest	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/chrome/test/data/webui_test_resources.grd.notest	2018-05-30 11:43:09.000000000 +0300
@@ -0,0 +1,14 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<grit latest_public_release="0" current_release="1" output_all_resource_defines="false">
+  <outputs>
+    <output filename="test/data/grit/webui_test_resources.h" type="rc_header">
+      <emit emit_type='prepend'></emit>
+    </output>
+    <output filename="webui_test_resources.pak" type="data_package" />
+  </outputs>
+  <release seq="1">
+    <includes>
+      <include name="IDR_WEBUI_TEST_I18N_PROCESS_CSS_TEST" file="webui/i18n_process_css_test.html" flattenhtml="true" allowexternalscript="true" type="BINDATA" />
+    </includes>
+  </release>
+</grit>
diff -Naur chromium-67.0.3396.62/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc chromium-67.0.3396.62.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc
--- chromium-67.0.3396.62/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc	2018-05-30 11:43:10.000000000 +0300
+++ chromium-67.0.3396.62.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc	2018-06-06 10:06:12.325135014 +0300
@@ -156,6 +156,14 @@
 }
 
 void NaClSandbox::CheckForExpectedNumberOfOpenFds() {
+  // Whatever logic this code is using is wrong more often than it is right.
+  // If you set expected_num_fds to 6, it finds 7.
+  // If you set expected_num_fds to 7, it finds 6.
+  // Code like this makes a packager drink. And not the good stuff either.
+  // Instead, we're just going to smile and tell it to never care about the
+  // number of FDs open. Stupid code. We hates it.
+
+#if 0  
   // We expect to have the following FDs open:
   //  1-3) stdin, stdout, stderr.
   //  4) The /dev/urandom FD used by base::GetUrandomFD().
@@ -174,6 +182,8 @@
   }
 
   CHECK_EQ(expected_num_fds, sandbox::ProcUtil::CountOpenFds(proc_fd_.get()));
+#endif
+
 }
 
 void NaClSandbox::InitializeLayerTwoSandbox(bool uses_nonsfi_mode) {
diff -Naur chromium-67.0.3396.62/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count chromium-67.0.3396.62.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count
--- chromium-67.0.3396.62/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count	2018-05-30 11:43:10.000000000 +0300
@@ -0,0 +1,249 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/nacl/loader/sandbox_linux/nacl_sandbox_linux.h"
+
+#include <errno.h>
+#include <fcntl.h>
+#include <stdint.h>
+#include <sys/prctl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+#include <limits>
+#include <memory>
+#include <utility>
+
+#include "base/callback.h"
+#include "base/command_line.h"
+#include "base/compiler_specific.h"
+#include "base/files/scoped_file.h"
+#include "base/logging.h"
+#include "base/posix/eintr_wrapper.h"
+#include "build/build_config.h"
+#include "components/nacl/common/nacl_switches.h"
+#include "components/nacl/loader/nonsfi/nonsfi_sandbox.h"
+#include "components/nacl/loader/sandbox_linux/nacl_bpf_sandbox_linux.h"
+#include "content/public/common/content_switches.h"
+#include "sandbox/linux/seccomp-bpf/sandbox_bpf.h"
+#include "sandbox/linux/services/credentials.h"
+#include "sandbox/linux/services/namespace_sandbox.h"
+#include "sandbox/linux/services/proc_util.h"
+#include "sandbox/linux/services/resource_limits.h"
+#include "sandbox/linux/services/thread_helpers.h"
+#include "sandbox/linux/suid/client/setuid_sandbox_client.h"
+#include "services/service_manager/sandbox/switches.h"
+
+namespace nacl {
+
+namespace {
+
+// This is a simplistic check of whether we are sandboxed.
+bool IsSandboxed() {
+  int proc_fd = open("/proc/self/exe", O_RDONLY);
+  if (proc_fd >= 0) {
+    PCHECK(0 == IGNORE_EINTR(close(proc_fd)));
+    return false;
+  }
+  return true;
+}
+
+bool MaybeSetProcessNonDumpable() {
+  const base::CommandLine& command_line =
+      *base::CommandLine::ForCurrentProcess();
+  if (command_line.HasSwitch(
+          service_manager::switches::kAllowSandboxDebugging)) {
+    return true;
+  }
+
+  if (prctl(PR_SET_DUMPABLE, 0, 0, 0, 0) != 0) {
+    PLOG(ERROR) << "Failed to set non-dumpable flag";
+    return false;
+  }
+
+  return prctl(PR_GET_DUMPABLE) == 0;
+}
+
+void RestrictAddressSpaceUsage() {
+#if defined(ADDRESS_SANITIZER) || defined(MEMORY_SANITIZER) || \
+    defined(THREAD_SANITIZER)
+  // Sanitizers need to reserve huge chunks of the address space.
+  return;
+#endif
+
+  // Add a limit to the brk() heap that would prevent allocations that can't be
+  // indexed by an int. This helps working around typical security bugs.
+  // This could almost certainly be set to zero. GLibc's allocator and others
+  // would fall-back to mmap if brk() fails.
+  const rlim_t kNewDataSegmentMaxSize = std::numeric_limits<int>::max();
+  CHECK(sandbox::ResourceLimits::Lower(RLIMIT_DATA, kNewDataSegmentMaxSize));
+
+#if defined(ARCH_CPU_64_BITS)
+  // NaCl's x86-64 sandbox allocated 88GB address of space during startup:
+  // - The main sandbox is 4GB
+  // - There are two guard regions of 40GB each.
+  // - 4GB are allocated extra to have a 4GB-aligned address.
+  // See https://crbug.com/455839
+  //
+  // Set the limit to 128 GB and have some margin.
+  const rlim_t kNewAddressSpaceLimit = 1UL << 37;
+#else
+  // Some architectures such as X86 allow 32 bits processes to switch to 64
+  // bits when running under 64 bits kernels. Set a limit in case this happens.
+  const rlim_t kNewAddressSpaceLimit = std::numeric_limits<uint32_t>::max();
+#endif
+  CHECK(sandbox::ResourceLimits::Lower(RLIMIT_AS, kNewAddressSpaceLimit));
+}
+
+}  // namespace
+
+NaClSandbox::NaClSandbox()
+    : layer_one_enabled_(false),
+      layer_one_sealed_(false),
+      layer_two_enabled_(false),
+      layer_two_is_nonsfi_(false),
+      proc_fd_(-1),
+      setuid_sandbox_client_(sandbox::SetuidSandboxClient::Create()) {
+  proc_fd_.reset(
+      HANDLE_EINTR(open("/proc", O_DIRECTORY | O_RDONLY | O_CLOEXEC)));
+  PCHECK(proc_fd_.is_valid());
+}
+
+NaClSandbox::~NaClSandbox() {
+}
+
+bool NaClSandbox::IsSingleThreaded() {
+  CHECK(proc_fd_.is_valid());
+  return sandbox::ThreadHelpers::IsSingleThreaded(proc_fd_.get());
+}
+
+bool NaClSandbox::HasOpenDirectory() {
+  CHECK(proc_fd_.is_valid());
+  return sandbox::ProcUtil::HasOpenDirectory(proc_fd_.get());
+}
+
+void NaClSandbox::InitializeLayerOneSandbox() {
+  // Check that IsSandboxed() works. We should not be sandboxed at this point.
+  CHECK(!IsSandboxed()) << "Unexpectedly sandboxed!";
+
+  if (setuid_sandbox_client_->IsSuidSandboxChild()) {
+    setuid_sandbox_client_->CloseDummyFile();
+
+    // Make sure that no directory file descriptor is open, as it would bypass
+    // the setuid sandbox model.
+    CHECK(!HasOpenDirectory());
+
+    // Get sandboxed.
+    CHECK(setuid_sandbox_client_->ChrootMe());
+    CHECK(MaybeSetProcessNonDumpable());
+    CHECK(IsSandboxed());
+    layer_one_enabled_ = true;
+  } else if (sandbox::NamespaceSandbox::InNewUserNamespace()) {
+    CHECK(sandbox::Credentials::MoveToNewUserNS());
+    CHECK(sandbox::Credentials::DropFileSystemAccess(proc_fd_.get()));
+
+    // We do not drop CAP_SYS_ADMIN because we need it to place each child
+    // process in its own PID namespace later on.
+    std::vector<sandbox::Credentials::Capability> caps;
+    caps.push_back(sandbox::Credentials::Capability::SYS_ADMIN);
+    CHECK(sandbox::Credentials::SetCapabilities(proc_fd_.get(), caps));
+
+    CHECK(IsSandboxed());
+    layer_one_enabled_ = true;
+  }
+}
+
+void NaClSandbox::CheckForExpectedNumberOfOpenFds() {
+  // We expect to have the following FDs open:
+  //  1-3) stdin, stdout, stderr.
+  //  4) The /dev/urandom FD used by base::GetUrandomFD().
+  //  5) A dummy pipe FD used to overwrite kSandboxIPCChannel.
+  //  6) The socket for the Chrome IPC channel that's connected to the
+  //     browser process, kPrimaryIPCChannel.
+  // We also have an fd for /proc (proc_fd_), but CountOpenFds excludes this.
+  //
+  // This sanity check ensures that dynamically loaded libraries don't
+  // leave any FDs open before we enable the sandbox.
+  int expected_num_fds = 6;
+  if (setuid_sandbox_client_->IsSuidSandboxChild()) {
+    // When using the setuid sandbox, there is one additional socket used for
+    // ChrootMe(). After ChrootMe(), it is no longer connected to anything.
+    ++expected_num_fds;
+  }
+
+  CHECK_EQ(expected_num_fds, sandbox::ProcUtil::CountOpenFds(proc_fd_.get()));
+}
+
+void NaClSandbox::InitializeLayerTwoSandbox(bool uses_nonsfi_mode) {
+  // seccomp-bpf only applies to the current thread, so it's critical to only
+  // have a single thread running here.
+  DCHECK(!layer_one_sealed_);
+  CHECK(IsSingleThreaded());
+  CheckForExpectedNumberOfOpenFds();
+
+  RestrictAddressSpaceUsage();
+
+  // Pass proc_fd_ ownership to the BPF sandbox, which guarantees it will
+  // be closed. There is no point in keeping it around since the BPF policy
+  // will prevent its usage.
+#if defined(OS_NACL_NONSFI)
+  CHECK(uses_nonsfi_mode);
+  layer_two_enabled_ = nacl::nonsfi::InitializeBPFSandbox(std::move(proc_fd_));
+  layer_two_is_nonsfi_ = true;
+#else
+  CHECK(!uses_nonsfi_mode);
+  layer_two_enabled_ = nacl::InitializeBPFSandbox(std::move(proc_fd_));
+#endif
+}
+
+void NaClSandbox::SealLayerOneSandbox() {
+  if (proc_fd_.is_valid() && !layer_two_enabled_) {
+    // If nothing prevents us, check that there is no superfluous directory
+    // open.
+    CHECK(!HasOpenDirectory());
+  }
+  proc_fd_.reset();
+  layer_one_sealed_ = true;
+}
+
+void NaClSandbox::CheckSandboxingStateWithPolicy() {
+  static const char kItIsDangerousMsg[] = " this is dangerous.";
+  static const char kItIsNotAllowedMsg[] =
+      " this is not allowed in this configuration.";
+
+  const bool no_sandbox_for_nonsfi_ok =
+#if defined(ADDRESS_SANITIZER) || defined(THREAD_SANITIZER) || \
+    defined(MEMORY_SANITIZER) || defined(LEAK_SANITIZER)
+      // Sanitizer tests run with --no-sandbox, but without
+      // --nacl-dangerous-no-sandbox-nonsfi. Allow that case.
+      true;
+#else
+      base::CommandLine::ForCurrentProcess()->HasSwitch(
+          switches::kNaClDangerousNoSandboxNonSfi);
+#endif
+
+  const bool can_be_no_sandbox =
+      !layer_two_is_nonsfi_ || no_sandbox_for_nonsfi_ok;
+
+  if (!layer_one_enabled_ || !layer_one_sealed_) {
+    static const char kNoSuidMsg[] =
+        "The SUID sandbox is not engaged for NaCl:";
+    if (can_be_no_sandbox)
+      LOG(ERROR) << kNoSuidMsg << kItIsDangerousMsg;
+    else
+      LOG(FATAL) << kNoSuidMsg << kItIsNotAllowedMsg;
+  }
+
+  if (!layer_two_enabled_) {
+    static const char kNoBpfMsg[] =
+        "The seccomp-bpf sandbox is not engaged for NaCl:";
+    if (can_be_no_sandbox)
+      LOG(ERROR) << kNoBpfMsg << kItIsDangerousMsg;
+    else
+      LOG(FATAL) << kNoBpfMsg << kItIsNotAllowedMsg;
+  }
+}
+
+}  // namespace nacl
diff -Naur chromium-67.0.3396.62/components/strings/components_strings_ru.xtb chromium-67.0.3396.62.patched/components/strings/components_strings_ru.xtb
--- chromium-67.0.3396.62/components/strings/components_strings_ru.xtb	2018-05-30 11:43:11.000000000 +0300
+++ chromium-67.0.3396.62.patched/components/strings/components_strings_ru.xtb	2018-06-06 10:06:12.309135269 +0300
@@ -95,7 +95,7 @@
 
       &lt;p&gt;Установите точную дату и время. Для этого откройте раздел &lt;strong&gt;Общие&lt;/strong&gt; в приложении &lt;strong&gt;Настройки&lt;/strong&gt;.&lt;/p&gt;</translation>
 <translation id="1583429793053364125">При загрузке этой страницы возникли неполадки.</translation>
-<translation id="1590457302292452960">Создайте надежный пароль…</translation>
+<translation id="1590457302292452960">Создайте надёжный пароль…</translation>
 <translation id="1592005682883173041">Доступ к данным на устройстве</translation>
 <translation id="1594030484168838125">Выбрать</translation>
 <translation id="1620510694547887537">Камера</translation>
@@ -111,7 +111,7 @@
 <translation id="1656489000284462475">Получение</translation>
 <translation id="1663943134801823270">Карты и адреса, указанные в Chrome. Вы можете изменить их на странице <ph name="BEGIN_LINK" />Настройки<ph name="END_LINK" />.</translation>
 <translation id="1676269943528358898">На сайте <ph name="SITE" /> для защиты ваших данных обычно используется шифрование. Однако учетные данные, которые мы получили от сайта <ph name="SITE" /> сейчас, отличаются от тех, которые он отправляет обычно. Вероятно, вредоносный сайт пытается выдать себя за <ph name="SITE" />, либо страница подключения к сети Wi-Fi прервала соединение. Ваша информация по-прежнему в безопасности, так как браузер Google Chrome разорвал соединение до того, как произошел обмен данными.</translation>
-<translation id="168841957122794586">Сертификат сервера содержит ненадежный криптографический ключ.</translation>
+<translation id="168841957122794586">Сертификат сервера содержит ненадёжный криптографический ключ.</translation>
 <translation id="1706954506755087368">{1,plural, =1{Не удалось подтвердить, что это сервер <ph name="DOMAIN" />. Его сертификат безопасности вступит в силу завтра. Возможно, сервер настроен неправильно или кто-то пытается перехватить ваши данные.}one{Не удалось подтвердить, что это сервер <ph name="DOMAIN" />. Его сертификат безопасности вступит в силу через # день. Возможно, сервер настроен неправильно или кто-то пытается перехватить ваши данные.}few{Не удалось подтвердить, что это сервер <ph name="DOMAIN" />. Его сертификат безопасности вступит в силу через # дня. Возможно, сервер настроен неправильно или кто-то пытается перехватить ваши данные.}many{Не удалось подтвердить, что это сервер <ph name="DOMAIN" />. Его сертификат безопасности вступит в силу через # дней. Возможно, сервер настроен неправильно или кто-то пытается перехватить ваши данные.}other{Не удалось подтвердить, что это сервер <ph name="DOMAIN" />. Его сертификат безопасности вступит в силу через # дня. Возможно, сервер настроен неправильно или кто-то пытается перехватить ваши данные.}}</translation>
 <translation id="1710259589646384581">ОС</translation>
 <translation id="1721312023322545264">Для доступа к этой странице требуется разрешение пользователя <ph name="NAME" /></translation>
@@ -497,7 +497,7 @@
 <translation id="4312866146174492540">Блокировать (по умолчанию)</translation>
 <translation id="4325863107915753736">Не удалось найти статью</translation>
 <translation id="4326324639298822553">Проверьте срок действия и повторите попытку</translation>
-<translation id="4331708818696583467">Ненадежный</translation>
+<translation id="4331708818696583467">Ненадёжный</translation>
 <translation id="4340982228985273705">По нашим данным, этот компьютер не является корпоративным, поэтому в соответствии с правилом на него можно автоматически устанавливать только расширения из Интернет-магазина Chrome. URL для обновления: <ph name="CWS_UPDATE_URL" />.</translation>
 <translation id="4346197816712207223">Кредитные карты, которые принимаются к оплате</translation>
 <translation id="4356973930735388585">Злоумышленники могут использовать этот сайт, чтобы установить на ваш компьютер вредоносное ПО, которое крадет или удаляет личную информацию (например, фотографии, пароли, сообщения и реквизиты банковских карт).</translation>
diff -Naur chromium-67.0.3396.62/device/usb/usb_context.cc chromium-67.0.3396.62.patched/device/usb/usb_context.cc
--- chromium-67.0.3396.62/device/usb/usb_context.cc	2018-05-30 11:43:14.000000000 +0300
+++ chromium-67.0.3396.62.patched/device/usb/usb_context.cc	2018-06-06 10:06:12.325135014 +0300
@@ -58,7 +58,11 @@
 
 void UsbContext::UsbEventHandler::Stop() {
   base::subtle::Release_Store(&running_, 0);
+#ifdef LIBUSB_API_VERSION >= 0x01000105
+  libusb_interrupt_event_handler(context_);
+#else
   libusb_interrupt_handle_event(context_);
+#endif
 }
 
 UsbContext::UsbContext(PlatformUsbContext context) : context_(context) {
diff -Naur chromium-67.0.3396.62/device/usb/usb_context.cc.modern-libusbx chromium-67.0.3396.62.patched/device/usb/usb_context.cc.modern-libusbx
--- chromium-67.0.3396.62/device/usb/usb_context.cc.modern-libusbx	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/device/usb/usb_context.cc.modern-libusbx	2018-05-30 11:43:14.000000000 +0300
@@ -0,0 +1,75 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "device/usb/usb_context.h"
+
+#include "base/atomicops.h"
+#include "base/logging.h"
+#include "base/macros.h"
+#include "base/threading/simple_thread.h"
+#include "device/usb/usb_error.h"
+#include "third_party/libusb/src/libusb/interrupt.h"
+#include "third_party/libusb/src/libusb/libusb.h"
+
+namespace device {
+
+// The UsbEventHandler works around a design flaw in the libusb interface. There
+// is currently no way to signal to libusb that any caller into one of the event
+// handler calls should return without handling any events.
+class UsbContext::UsbEventHandler : public base::SimpleThread {
+ public:
+  explicit UsbEventHandler(libusb_context* context);
+  ~UsbEventHandler() override;
+
+  // base::SimpleThread
+  void Run() override;
+
+  void Stop();
+
+ private:
+  base::subtle::Atomic32 running_;
+  libusb_context* context_;
+  DISALLOW_COPY_AND_ASSIGN(UsbEventHandler);
+};
+
+UsbContext::UsbEventHandler::UsbEventHandler(libusb_context* context)
+    : base::SimpleThread("UsbEventHandler"), context_(context) {
+  base::subtle::Release_Store(&running_, 1);
+}
+
+UsbContext::UsbEventHandler::~UsbEventHandler() {
+  libusb_exit(context_);
+}
+
+void UsbContext::UsbEventHandler::Run() {
+  VLOG(1) << "UsbEventHandler started.";
+
+  while (base::subtle::Acquire_Load(&running_)) {
+    const int rv = libusb_handle_events(context_);
+    if (rv != LIBUSB_SUCCESS) {
+      VLOG(1) << "Failed to handle events: "
+              << ConvertPlatformUsbErrorToString(rv);
+    }
+  }
+
+  VLOG(1) << "UsbEventHandler shutting down.";
+}
+
+void UsbContext::UsbEventHandler::Stop() {
+  base::subtle::Release_Store(&running_, 0);
+  libusb_interrupt_handle_event(context_);
+}
+
+UsbContext::UsbContext(PlatformUsbContext context) : context_(context) {
+  // Ownership of the PlatformUsbContext is passed to the event handler thread.
+  event_handler_.reset(new UsbEventHandler(context_));
+  event_handler_->Start();
+}
+
+UsbContext::~UsbContext() {
+  event_handler_->Stop();
+  event_handler_->Join();
+}
+
+}  // namespace device
diff -Naur chromium-67.0.3396.62/mojo/public/c/system/macros.h chromium-67.0.3396.62.patched/mojo/public/c/system/macros.h
--- chromium-67.0.3396.62/mojo/public/c/system/macros.h	2018-05-30 11:43:17.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/c/system/macros.h	2018-06-06 10:06:12.373134247 +0300
@@ -18,7 +18,13 @@
 #endif
 
 // Like the C++11 |alignof| operator.
-#if __cplusplus >= 201103L
+#if defined(__GNUC__) && __GNUC__ >= 8
+// GCC 8 has changed the alignof operator to return the minimal alignment
+// required by the target ABI, instead of the preferred alignment.
+// This means that on 32-bit x86, it will return 4 instead of 8.
+// Use __alignof__ instead to avoid this.
+#define MOJO_ALIGNOF(type) __alignof__(type)
+#elif __cplusplus >= 201103L
 #define MOJO_ALIGNOF(type) alignof(type)
 #elif defined(__GNUC__)
 #define MOJO_ALIGNOF(type) __alignof__(type)
diff -Naur chromium-67.0.3396.62/mojo/public/c/system/macros.h.gcc8-alignof chromium-67.0.3396.62.patched/mojo/public/c/system/macros.h.gcc8-alignof
--- chromium-67.0.3396.62/mojo/public/c/system/macros.h.gcc8-alignof	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/c/system/macros.h.gcc8-alignof	2018-05-30 11:43:17.000000000 +0300
@@ -0,0 +1,49 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MOJO_PUBLIC_C_SYSTEM_MACROS_H_
+#define MOJO_PUBLIC_C_SYSTEM_MACROS_H_
+
+#include <stddef.h>
+
+// Assert things at compile time. (|msg| should be a valid identifier name.)
+// This macro is currently C++-only, but we want to use it in the C core.h.
+// Use like:
+//   MOJO_STATIC_ASSERT(sizeof(Foo) == 12, "Foo has invalid size");
+#if defined(__cplusplus)
+#define MOJO_STATIC_ASSERT(expr, msg) static_assert(expr, msg)
+#else
+#define MOJO_STATIC_ASSERT(expr, msg)
+#endif
+
+// Like the C++11 |alignof| operator.
+#if __cplusplus >= 201103L
+#define MOJO_ALIGNOF(type) alignof(type)
+#elif defined(__GNUC__)
+#define MOJO_ALIGNOF(type) __alignof__(type)
+#elif defined(_MSC_VER)
+// The use of |sizeof| is to work around a bug in MSVC 2010 (see
+// http://goo.gl/isH0C; supposedly fixed since then).
+#define MOJO_ALIGNOF(type) (sizeof(type) - sizeof(type) + __alignof(type))
+#else
+#error "Please define MOJO_ALIGNOF() for your compiler."
+#endif
+
+// Specify the alignment of a |struct|, etc.
+// Use like:
+//   struct MOJO_ALIGNAS(8) Foo { ... };
+// Unlike the C++11 |alignas()|, |alignment| must be an integer. It may not be a
+// type, nor can it be an expression like |MOJO_ALIGNOF(type)| (due to the
+// non-C++11 MSVS version).
+#if __cplusplus >= 201103L
+#define MOJO_ALIGNAS(alignment) alignas(alignment)
+#elif defined(__GNUC__)
+#define MOJO_ALIGNAS(alignment) __attribute__((aligned(alignment)))
+#elif defined(_MSC_VER)
+#define MOJO_ALIGNAS(alignment) __declspec(align(alignment))
+#else
+#error "Please define MOJO_ALIGNAS() for your compiler."
+#endif
+
+#endif  // MOJO_PUBLIC_C_SYSTEM_MACROS_H_
diff -Naur chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_ptr_info.h chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h
--- chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_ptr_info.h	2018-05-30 11:43:17.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h	2018-06-06 10:06:12.365134376 +0300
@@ -45,7 +45,7 @@
 
   bool is_valid() const { return handle_.is_valid(); }
 
-  explicit operator bool() const { return handle_; }
+  explicit operator bool() const { return (bool) handle_; }
 
   ScopedInterfaceEndpointHandle PassHandle() {
     return std::move(handle_);
diff -Naur chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix
--- chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix	2018-05-30 11:43:17.000000000 +0300
@@ -0,0 +1,79 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_PTR_INFO_H_
+#define MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_PTR_INFO_H_
+
+#include <stdint.h>
+#include <utility>
+
+#include "base/macros.h"
+#include "mojo/public/cpp/bindings/scoped_interface_endpoint_handle.h"
+
+namespace mojo {
+
+// AssociatedInterfacePtrInfo stores necessary information to construct an
+// associated interface pointer. It is similar to InterfacePtrInfo except that
+// it doesn't own a message pipe handle.
+template <typename Interface>
+class AssociatedInterfacePtrInfo {
+ public:
+  AssociatedInterfacePtrInfo() : version_(0u) {}
+  AssociatedInterfacePtrInfo(std::nullptr_t) : version_(0u) {}
+
+  AssociatedInterfacePtrInfo(AssociatedInterfacePtrInfo&& other)
+      : handle_(std::move(other.handle_)), version_(other.version_) {
+    other.version_ = 0u;
+  }
+
+  AssociatedInterfacePtrInfo(ScopedInterfaceEndpointHandle handle,
+                             uint32_t version)
+      : handle_(std::move(handle)), version_(version) {}
+
+  ~AssociatedInterfacePtrInfo() {}
+
+  AssociatedInterfacePtrInfo& operator=(AssociatedInterfacePtrInfo&& other) {
+    if (this != &other) {
+      handle_ = std::move(other.handle_);
+      version_ = other.version_;
+      other.version_ = 0u;
+    }
+
+    return *this;
+  }
+
+  bool is_valid() const { return handle_.is_valid(); }
+
+  explicit operator bool() const { return handle_; }
+
+  ScopedInterfaceEndpointHandle PassHandle() {
+    return std::move(handle_);
+  }
+  const ScopedInterfaceEndpointHandle& handle() const { return handle_; }
+  void set_handle(ScopedInterfaceEndpointHandle handle) {
+    handle_ = std::move(handle);
+  }
+
+  uint32_t version() const { return version_; }
+  void set_version(uint32_t version) { version_ = version; }
+
+  bool Equals(const AssociatedInterfacePtrInfo& other) const {
+    if (this == &other)
+      return true;
+
+    // Now that the two refer to different objects, they are equivalent if
+    // and only if they are both invalid.
+    return !is_valid() && !other.is_valid();
+  }
+
+ private:
+  ScopedInterfaceEndpointHandle handle_;
+  uint32_t version_;
+
+  DISALLOW_COPY_AND_ASSIGN(AssociatedInterfacePtrInfo);
+};
+
+}  // namespace mojo
+
+#endif  // MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_PTR_INFO_H_
diff -Naur chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_request.h chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_request.h
--- chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_request.h	2018-05-30 11:43:17.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_request.h	2018-06-06 10:06:12.365134376 +0300
@@ -50,7 +50,7 @@
   // handle.
   bool is_pending() const { return handle_.is_valid(); }
 
-  explicit operator bool() const { return handle_; }
+  explicit operator bool() const { return (bool) handle_; }
 
   ScopedInterfaceEndpointHandle PassHandle() { return std::move(handle_); }
 
diff -Naur chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_request.h.boolfix chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_request.h.boolfix
--- chromium-67.0.3396.62/mojo/public/cpp/bindings/associated_interface_request.h.boolfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/associated_interface_request.h.boolfix	2018-05-30 11:43:17.000000000 +0300
@@ -0,0 +1,80 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_REQUEST_H_
+#define MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_REQUEST_H_
+
+#include <string>
+#include <utility>
+
+#include "base/macros.h"
+#include "mojo/public/cpp/bindings/scoped_interface_endpoint_handle.h"
+
+namespace mojo {
+
+// AssociatedInterfaceRequest represents an associated interface request. It is
+// similar to InterfaceRequest except that it doesn't own a message pipe handle.
+template <typename Interface>
+class AssociatedInterfaceRequest {
+ public:
+  // Constructs an empty AssociatedInterfaceRequest, representing that the
+  // client is not requesting an implementation of Interface.
+  AssociatedInterfaceRequest() {}
+  AssociatedInterfaceRequest(decltype(nullptr)) {}
+
+  explicit AssociatedInterfaceRequest(ScopedInterfaceEndpointHandle handle)
+      : handle_(std::move(handle)) {}
+
+  // Takes the interface endpoint handle from another
+  // AssociatedInterfaceRequest.
+  AssociatedInterfaceRequest(AssociatedInterfaceRequest&& other) {
+    handle_ = std::move(other.handle_);
+  }
+
+  AssociatedInterfaceRequest& operator=(AssociatedInterfaceRequest&& other) {
+    if (this != &other)
+      handle_ = std::move(other.handle_);
+    return *this;
+  }
+
+  // Assigning to nullptr resets the AssociatedInterfaceRequest to an empty
+  // state, closing the interface endpoint handle currently bound to it (if
+  // any).
+  AssociatedInterfaceRequest& operator=(decltype(nullptr)) {
+    handle_.reset();
+    return *this;
+  }
+
+  // Indicates whether the request currently contains a valid interface endpoint
+  // handle.
+  bool is_pending() const { return handle_.is_valid(); }
+
+  explicit operator bool() const { return handle_; }
+
+  ScopedInterfaceEndpointHandle PassHandle() { return std::move(handle_); }
+
+  const ScopedInterfaceEndpointHandle& handle() const { return handle_; }
+
+  bool Equals(const AssociatedInterfaceRequest& other) const {
+    if (this == &other)
+      return true;
+
+    // Now that the two refer to different objects, they are equivalent if
+    // and only if they are both invalid.
+    return !is_pending() && !other.is_pending();
+  }
+
+  void ResetWithReason(uint32_t custom_reason, const std::string& description) {
+    handle_.ResetWithReason(custom_reason, description);
+  }
+
+ private:
+  ScopedInterfaceEndpointHandle handle_;
+
+  DISALLOW_COPY_AND_ASSIGN(AssociatedInterfaceRequest);
+};
+
+}  // namespace mojo
+
+#endif  // MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_REQUEST_H_
diff -Naur chromium-67.0.3396.62/mojo/public/cpp/bindings/interface_request.h chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/interface_request.h
--- chromium-67.0.3396.62/mojo/public/cpp/bindings/interface_request.h	2018-05-30 11:43:17.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/interface_request.h	2018-06-06 10:06:12.365134376 +0300
@@ -54,7 +54,7 @@
   // Indicates whether the request currently contains a valid message pipe.
   bool is_pending() const { return handle_.is_valid(); }
 
-  explicit operator bool() const { return handle_.is_valid(); }
+  explicit operator bool() const { return (bool) handle_.is_valid(); }
 
   // Removes the message pipe from the request and returns it.
   ScopedMessagePipeHandle PassMessagePipe() { return std::move(handle_); }
diff -Naur chromium-67.0.3396.62/mojo/public/cpp/bindings/interface_request.h.boolfix chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/interface_request.h.boolfix
--- chromium-67.0.3396.62/mojo/public/cpp/bindings/interface_request.h.boolfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/mojo/public/cpp/bindings/interface_request.h.boolfix	2018-05-30 11:43:17.000000000 +0300
@@ -0,0 +1,166 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MOJO_PUBLIC_CPP_BINDINGS_INTERFACE_REQUEST_H_
+#define MOJO_PUBLIC_CPP_BINDINGS_INTERFACE_REQUEST_H_
+
+#include <string>
+#include <utility>
+
+#include "base/macros.h"
+#include "base/optional.h"
+#include "base/single_thread_task_runner.h"
+#include "mojo/public/cpp/bindings/disconnect_reason.h"
+#include "mojo/public/cpp/bindings/interface_ptr.h"
+#include "mojo/public/cpp/bindings/pipe_control_message_proxy.h"
+#include "mojo/public/cpp/system/message_pipe.h"
+
+namespace mojo {
+
+// Represents a request from a remote client for an implementation of Interface
+// over a specified message pipe. The implementor of the interface should
+// remove the message pipe by calling PassMessagePipe() and bind it to the
+// implementation. If this is not done, the InterfaceRequest will automatically
+// close the pipe on destruction. Can also represent the absence of a request
+// if the client did not provide a message pipe.
+template <typename Interface>
+class InterfaceRequest {
+ public:
+  // Constructs an empty InterfaceRequest, representing that the client is not
+  // requesting an implementation of Interface.
+  InterfaceRequest() {}
+  InterfaceRequest(decltype(nullptr)) {}
+
+  explicit InterfaceRequest(ScopedMessagePipeHandle handle)
+      : handle_(std::move(handle)) {}
+
+  // Takes the message pipe from another InterfaceRequest.
+  InterfaceRequest(InterfaceRequest&& other) {
+    handle_ = std::move(other.handle_);
+  }
+  InterfaceRequest& operator=(InterfaceRequest&& other) {
+    handle_ = std::move(other.handle_);
+    return *this;
+  }
+
+  // Assigning to nullptr resets the InterfaceRequest to an empty state,
+  // closing the message pipe currently bound to it (if any).
+  InterfaceRequest& operator=(decltype(nullptr)) {
+    handle_.reset();
+    return *this;
+  }
+
+  // Indicates whether the request currently contains a valid message pipe.
+  bool is_pending() const { return handle_.is_valid(); }
+
+  explicit operator bool() const { return handle_.is_valid(); }
+
+  // Removes the message pipe from the request and returns it.
+  ScopedMessagePipeHandle PassMessagePipe() { return std::move(handle_); }
+
+  bool Equals(const InterfaceRequest& other) const {
+    if (this == &other)
+      return true;
+
+    // Now that the two refer to different objects, they are equivalent if
+    // and only if they are both invalid.
+    return !is_pending() && !other.is_pending();
+  }
+
+  void ResetWithReason(uint32_t custom_reason, const std::string& description) {
+    if (!handle_.is_valid())
+      return;
+
+    Message message =
+        PipeControlMessageProxy::ConstructPeerEndpointClosedMessage(
+            kMasterInterfaceId, DisconnectReason(custom_reason, description));
+    MojoResult result = WriteMessageNew(
+        handle_.get(), message.TakeMojoMessage(), MOJO_WRITE_MESSAGE_FLAG_NONE);
+    DCHECK_EQ(MOJO_RESULT_OK, result);
+
+    handle_.reset();
+  }
+
+ private:
+  ScopedMessagePipeHandle handle_;
+
+  DISALLOW_COPY_AND_ASSIGN(InterfaceRequest);
+};
+
+// Creates a new message pipe over which Interface is to be served. Binds the
+// specified InterfacePtr to one end of the message pipe, and returns an
+// InterfaceRequest bound to the other. The InterfacePtr should be passed to
+// the client, and the InterfaceRequest should be passed to whatever will
+// provide the implementation. The implementation should typically be bound to
+// the InterfaceRequest using the Binding or StrongBinding classes. The client
+// may begin to issue calls even before an implementation has been bound, since
+// messages sent over the pipe will just queue up until they are consumed by
+// the implementation.
+//
+// Example #1: Requesting a remote implementation of an interface.
+// ===============================================================
+//
+// Given the following interface:
+//
+//   interface Database {
+//     OpenTable(Table& table);
+//   }
+//
+// The client would have code similar to the following:
+//
+//   DatabasePtr database = ...;  // Connect to database.
+//   TablePtr table;
+//   database->OpenTable(MakeRequest(&table));
+//
+// Upon return from MakeRequest, |table| is ready to have methods called on it.
+//
+// Example #2: Registering a local implementation with a remote service.
+// =====================================================================
+//
+// Given the following interface
+//   interface Collector {
+//     RegisterSource(Source source);
+//   }
+//
+// The client would have code similar to the following:
+//
+//   CollectorPtr collector = ...;  // Connect to Collector.
+//   SourcePtr source;
+//   InterfaceRequest<Source> source_request(&source);
+//   collector->RegisterSource(std::move(source));
+//   CreateSource(std::move(source_request));  // Create implementation locally.
+//
+template <typename Interface>
+InterfaceRequest<Interface> MakeRequest(
+    InterfacePtr<Interface>* ptr,
+    scoped_refptr<base::SingleThreadTaskRunner> runner = nullptr) {
+  MessagePipe pipe;
+  ptr->Bind(InterfacePtrInfo<Interface>(std::move(pipe.handle0), 0u),
+            std::move(runner));
+  return InterfaceRequest<Interface>(std::move(pipe.handle1));
+}
+
+// Similar to the constructor above, but binds one end of the message pipe to
+// an InterfacePtrInfo instance.
+template <typename Interface>
+InterfaceRequest<Interface> MakeRequest(InterfacePtrInfo<Interface>* ptr_info) {
+  MessagePipe pipe;
+  ptr_info->set_handle(std::move(pipe.handle0));
+  ptr_info->set_version(0u);
+  return InterfaceRequest<Interface>(std::move(pipe.handle1));
+}
+
+// Fuses an InterfaceRequest<T> endpoint with an InterfacePtrInfo<T> endpoint.
+// Returns |true| on success or |false| on failure.
+template <typename Interface>
+bool FuseInterface(InterfaceRequest<Interface> request,
+                   InterfacePtrInfo<Interface> proxy_info) {
+  MojoResult result = FuseMessagePipes(request.PassMessagePipe(),
+                                       proxy_info.PassHandle());
+  return result == MOJO_RESULT_OK;
+}
+
+}  // namespace mojo
+
+#endif  // MOJO_PUBLIC_CPP_BINDINGS_INTERFACE_REQUEST_H_
diff -Naur chromium-67.0.3396.62/native_client/src/untrusted/nacl/getcwd.c chromium-67.0.3396.62.patched/native_client/src/untrusted/nacl/getcwd.c
--- chromium-67.0.3396.62/native_client/src/untrusted/nacl/getcwd.c	2018-05-30 11:44:28.000000000 +0300
+++ chromium-67.0.3396.62.patched/native_client/src/untrusted/nacl/getcwd.c	2018-06-06 10:06:12.313135206 +0300
@@ -11,6 +11,10 @@
 
 #include <errno.h>
 #include <limits.h>
+/* Needed for PATH_MAX */
+#ifndef PATH_MAX
+#define PATH_MAX 4096
+#endif
 #include <stdlib.h>
 #include <string.h>
 #include <unistd.h>
diff -Naur chromium-67.0.3396.62/native_client/src/untrusted/nacl/getcwd.c.pathmax chromium-67.0.3396.62.patched/native_client/src/untrusted/nacl/getcwd.c.pathmax
--- chromium-67.0.3396.62/native_client/src/untrusted/nacl/getcwd.c.pathmax	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/native_client/src/untrusted/nacl/getcwd.c.pathmax	2018-05-30 11:44:28.000000000 +0300
@@ -0,0 +1,53 @@
+/*
+ * Copyright 2014 The Native Client Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+/*
+ * getcwd() implementation based on the lower level
+ * __getcwd_without_malloc().
+ */
+
+#include <errno.h>
+#include <limits.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+
+#include "native_client/src/untrusted/nacl/getcwd.h"
+
+char *getcwd(char *buffer, size_t len) {
+  int allocated = 0;
+  int do_realloc = 0;
+
+  /* If buffer is NULL, allocate a buffer. */
+  if (buffer == NULL) {
+    if (len == 0) {
+      len = PATH_MAX;
+      do_realloc = 1;
+    }
+
+    buffer = (char *) malloc(len);
+    if (buffer == NULL) {
+      errno = ENOMEM;
+      return NULL;
+    }
+    allocated = 1;
+  } else if (len == 0) {
+    /* Non-NULL buffer and zero size results in EINVAL */
+    errno = EINVAL;
+    return NULL;
+  }
+
+  char *rtn = __getcwd_without_malloc(buffer, len);
+  if (allocated) {
+    if (rtn == NULL) {
+      free(buffer);
+    } else if (do_realloc) {
+      rtn = (char *) realloc(rtn, strlen(rtn) + 1);
+    }
+  }
+
+  return rtn;
+}
diff -Naur chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/path.h chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/path.h
--- chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/path.h	2018-05-30 11:43:17.000000000 +0300
+++ chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/path.h	2018-06-06 10:06:12.313135206 +0300
@@ -12,6 +12,11 @@
 
 #include "sdk_util/macros.h"
 
+/* Needed for PATH_MAX */
+#ifndef PATH_MAX
+#define PATH_MAX 4096
+#endif
+
 namespace nacl_io {
 
 class Path {
diff -Naur chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/path.h.pathmax chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/path.h.pathmax
--- chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/path.h.pathmax	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/path.h.pathmax	2018-05-30 11:43:17.000000000 +0300
@@ -0,0 +1,64 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef LIBRARIES_NACL_IO_PATH_H_
+#define LIBRARIES_NACL_IO_PATH_H_
+
+#include <limits.h>
+
+#include <string>
+#include <vector>
+
+#include "sdk_util/macros.h"
+
+namespace nacl_io {
+
+class Path {
+ public:
+  Path();
+  Path(const Path& path);
+  explicit Path(const std::string& path);
+
+  // Return true of the first path item is '/'.
+  bool IsAbsolute() const;
+
+  // Return true if this is the root path (i.e. it has no parent)
+  bool IsRoot() const;
+
+  // Return a part of the path
+  std::string Part(size_t index) const;
+
+  // Return the number of path parts
+  size_t Size() const;
+
+  // Update the path.
+  Path& Append(const Path& path);
+  Path& Append(const std::string& path);
+  Path& Set(const std::string& path);
+  Path& MakeRelative();
+
+  // Return the parent path.
+  Path Parent() const;
+  std::string Basename() const;
+
+  std::string Join() const;
+  std::string Range(size_t start, size_t end) const;
+
+  // Operator versions
+  Path& operator=(const Path& p);
+  Path& operator=(const std::string& str);
+  bool operator==(const Path& other);
+  bool operator!=(const Path& other);
+
+ private:
+  // Collapse the string list removing extraneous '.', '..' path components
+  void Normalize();
+
+  size_t len_;
+  char path_[PATH_MAX];
+};
+
+}  // namespace nacl_io
+
+#endif  // PACKAGES_LIBRARIES_NACL_IO_PATH_H_
diff -Naur chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c
--- chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c	2018-05-30 11:43:17.000000000 +0300
+++ chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c	2018-06-06 10:06:12.313135206 +0300
@@ -13,6 +13,11 @@
 
 #include "sdk_util/macros.h"
 
+/* Needed for PATH_MAX */
+#ifndef PATH_MAX
+#define PATH_MAX 4096
+#endif
+
 EXTERN_C_BEGIN
 
 #if defined(__native_client__)
diff -Naur chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax
--- chromium-67.0.3396.62/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax	2018-05-30 11:43:17.000000000 +0300
@@ -0,0 +1,131 @@
+/* Copyright 2013 The Chromium Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file. */
+
+#include <assert.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <limits.h>
+#include <stdlib.h>
+#include <string.h>
+#include <sys/stat.h>
+#include <unistd.h>
+
+#include "sdk_util/macros.h"
+
+EXTERN_C_BEGIN
+
+#if defined(__native_client__)
+
+// TODO(binji): glibc has realpath, but it fails for all tests. Investigate.
+
+char* realpath(const char* path, char* resolved_path) {
+  if (path == NULL) {
+    errno = EINVAL;
+    return NULL;
+  }
+
+  int needs_free = 0;
+  if (resolved_path == NULL) {
+    resolved_path = (char*)malloc(PATH_MAX);
+    needs_free = 1;
+  }
+
+  struct stat statbuf;
+  const char* in = path;
+  char* out = resolved_path;
+  char* out_end = resolved_path + PATH_MAX - 1;
+  int done = 0;
+
+  *out = 0;
+
+  if (*in == '/') {
+    // Absolute path.
+    strcat(out, "/");
+    in++;
+    out++;
+  } else {
+    // Relative path.
+    if (getcwd(out, out_end - out) == NULL)
+      goto fail;
+
+    out += strlen(out);
+  }
+
+  if (stat(resolved_path, &statbuf) != 0)
+    goto fail;
+
+  while (!done) {
+    const char* next_slash = strchr(in, '/');
+    size_t namelen;
+    const char* next_in;
+    if (next_slash) {
+      namelen = next_slash - in;
+      next_in = next_slash + 1;
+    } else {
+      namelen = strlen(in);
+      next_in = in + namelen;  // Move to the '\0'
+      done = 1;
+    }
+
+    if (namelen == 0) {
+      // Empty name, do nothing.
+    } else if (namelen == 1 && strncmp(in, ".", 1) == 0) {
+      // Current directory, do nothing.
+    } else if (namelen == 2 && strncmp(in, "..", 2) == 0) {
+      // Parent directory, find previous slash in resolved_path.
+      char* prev_slash = strrchr(resolved_path, '/');
+      assert(prev_slash != NULL);
+
+      out = prev_slash;
+      if (prev_slash == resolved_path) {
+        // Moved to the root. Keep the slash.
+        ++out;
+      }
+
+      *out = 0;
+    } else {
+      // Append a slash if not at root.
+      if (out != resolved_path + 1) {
+        if (out + 1 > out_end) {
+          errno = ENAMETOOLONG;
+          goto fail;
+        }
+
+        strncat(out, "/", namelen);
+        out++;
+      }
+
+      if (out + namelen > out_end) {
+        errno = ENAMETOOLONG;
+        goto fail;
+      }
+
+      strncat(out, in, namelen);
+      out += namelen;
+    }
+
+    in = next_in;
+
+    if (stat(resolved_path, &statbuf) != 0)
+      goto fail;
+
+    // If there is more to the path, then the current path must be a directory.
+    if (!done && !S_ISDIR(statbuf.st_mode)) {
+      errno = ENOTDIR;
+      goto fail;
+    }
+  }
+
+  return resolved_path;
+
+fail:
+  if (needs_free) {
+    free(resolved_path);
+  }
+  return NULL;
+}
+
+EXTERN_C_END
+
+#endif  // defined(__native_client__)
diff -Naur chromium-67.0.3396.62/printing/backend/print_backend_cups.cc chromium-67.0.3396.62.patched/printing/backend/print_backend_cups.cc
--- chromium-67.0.3396.62/printing/backend/print_backend_cups.cc	2018-05-30 11:43:19.000000000 +0300
+++ chromium-67.0.3396.62.patched/printing/backend/print_backend_cups.cc	2018-06-06 10:06:12.325135014 +0300
@@ -18,6 +18,7 @@
 #include "base/synchronization/lock.h"
 #include "base/values.h"
 #include "printing/backend/cups_helper.h"
+#include <cups/ppd.h>
 #include "printing/backend/print_backend_consts.h"
 #include "url/gurl.h"
 
diff -Naur chromium-67.0.3396.62/printing/backend/print_backend_cups.cc.cups22 chromium-67.0.3396.62.patched/printing/backend/print_backend_cups.cc.cups22
--- chromium-67.0.3396.62/printing/backend/print_backend_cups.cc.cups22	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/printing/backend/print_backend_cups.cc.cups22	2018-05-30 11:43:19.000000000 +0300
@@ -0,0 +1,286 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "printing/backend/print_backend_cups.h"
+
+#include <cups/ppd.h>
+#include <dlfcn.h>
+#include <errno.h>
+#include <pthread.h>
+
+#include <string>
+
+#include "base/files/file_util.h"
+#include "base/lazy_instance.h"
+#include "base/logging.h"
+#include "base/strings/string_number_conversions.h"
+#include "base/synchronization/lock.h"
+#include "base/values.h"
+#include "printing/backend/cups_helper.h"
+#include "printing/backend/print_backend_consts.h"
+#include "url/gurl.h"
+
+namespace printing {
+
+namespace {
+
+const char kCUPSPrinterInfoOpt[] = "printer-info";
+const char kCUPSPrinterStateOpt[] = "printer-state";
+const char kCUPSPrinterTypeOpt[] = "printer-type";
+
+bool PrinterBasicInfoFromCUPS(const cups_dest_t& printer,
+                              PrinterBasicInfo* printer_info) {
+  // CUPS can have 'printers' that are actually scanners. (not MFC)
+  // At least on Mac. Check for scanners and skip them.
+  const char* type_str =
+      cupsGetOption(kCUPSPrinterTypeOpt, printer.num_options, printer.options);
+  if (type_str) {
+    int type;
+    if (base::StringToInt(type_str, &type) && (type & CUPS_PRINTER_SCANNER))
+      return false;
+  }
+
+  printer_info->printer_name = printer.name;
+  printer_info->is_default = printer.is_default;
+
+  const char* info =
+      cupsGetOption(kCUPSPrinterInfoOpt, printer.num_options, printer.options);
+  if (info)
+    printer_info->printer_description = info;
+
+  const char* state =
+      cupsGetOption(kCUPSPrinterStateOpt, printer.num_options, printer.options);
+  if (state)
+    base::StringToInt(state, &printer_info->printer_status);
+
+  const char* drv_info = cupsGetOption(kDriverNameTagName,
+                                       printer.num_options, printer.options);
+  if (drv_info)
+    printer_info->options[kDriverInfoTagName] = *drv_info;
+
+  // Store printer options.
+  for (int opt_index = 0; opt_index < printer.num_options; ++opt_index) {
+    printer_info->options[printer.options[opt_index].name] =
+        printer.options[opt_index].value;
+  }
+  return true;
+}
+
+}  // namespace
+
+PrintBackendCUPS::PrintBackendCUPS(const GURL& print_server_url,
+                                   http_encryption_t encryption,
+                                   bool blocking)
+    : print_server_url_(print_server_url),
+      cups_encryption_(encryption),
+      blocking_(blocking) {
+}
+
+bool PrintBackendCUPS::EnumeratePrinters(PrinterList* printer_list) {
+  DCHECK(printer_list);
+  printer_list->clear();
+
+  cups_dest_t* destinations = nullptr;
+  int num_dests = GetDests(&destinations);
+  if (!num_dests && cupsLastError() > IPP_OK_EVENTS_COMPLETE) {
+    VLOG(1) << "CUPS: Error getting printers from CUPS server"
+            << ", server: " << print_server_url_
+            << ", error: " << static_cast<int>(cupsLastError());
+    return false;
+  }
+
+  for (int printer_index = 0; printer_index < num_dests; ++printer_index) {
+    const cups_dest_t& printer = destinations[printer_index];
+
+    PrinterBasicInfo printer_info;
+    if (PrinterBasicInfoFromCUPS(printer, &printer_info))
+      printer_list->push_back(printer_info);
+  }
+
+  cupsFreeDests(num_dests, destinations);
+
+  VLOG(1) << "CUPS: Enumerated printers, server: " << print_server_url_
+          << ", # of printers: " << printer_list->size();
+  return true;
+}
+
+std::string PrintBackendCUPS::GetDefaultPrinterName() {
+  // Not using cupsGetDefault() because it lies about the default printer.
+  cups_dest_t* dests;
+  int num_dests = GetDests(&dests);
+  cups_dest_t* dest = cupsGetDest(nullptr, nullptr, num_dests, dests);
+  std::string name = dest ? std::string(dest->name) : std::string();
+  cupsFreeDests(num_dests, dests);
+  return name;
+}
+
+bool PrintBackendCUPS::GetPrinterBasicInfo(const std::string& printer_name,
+                                           PrinterBasicInfo* printer_info) {
+  cups_dest_t* dest = GetNamedDest(printer_name);
+  if (!dest)
+    return false;
+
+  DCHECK_EQ(printer_name, dest->name);
+  bool ret = PrinterBasicInfoFromCUPS(*dest, printer_info);
+  cupsFreeDests(1, dest);
+  return ret;
+}
+
+bool PrintBackendCUPS::GetPrinterSemanticCapsAndDefaults(
+    const std::string& printer_name,
+    PrinterSemanticCapsAndDefaults* printer_info) {
+  PrinterCapsAndDefaults info;
+  if (!GetPrinterCapsAndDefaults(printer_name, &info) )
+    return false;
+
+  return ParsePpdCapabilities(
+      printer_name, info.printer_capabilities, printer_info);
+}
+
+bool PrintBackendCUPS::GetPrinterCapsAndDefaults(
+    const std::string& printer_name,
+    PrinterCapsAndDefaults* printer_info) {
+  DCHECK(printer_info);
+
+  VLOG(1) << "CUPS: Getting caps and defaults, printer name: " << printer_name;
+
+  base::FilePath ppd_path(GetPPD(printer_name.c_str()));
+  // In some cases CUPS failed to get ppd file.
+  if (ppd_path.empty()) {
+    LOG(ERROR) << "CUPS: Failed to get PPD, printer name: " << printer_name;
+    return false;
+  }
+
+  std::string content;
+  bool res = base::ReadFileToString(ppd_path, &content);
+
+  base::DeleteFile(ppd_path, false);
+
+  if (res) {
+    printer_info->printer_capabilities.swap(content);
+    printer_info->caps_mime_type = "application/pagemaker";
+    // In CUPS, printer defaults is a part of PPD file. Nothing to upload here.
+    printer_info->printer_defaults.clear();
+    printer_info->defaults_mime_type.clear();
+  }
+
+  return res;
+}
+
+std::string PrintBackendCUPS::GetPrinterDriverInfo(
+    const std::string& printer_name) {
+  std::string result;
+
+  cups_dest_t* dest = GetNamedDest(printer_name);
+  if (!dest)
+    return result;
+
+  DCHECK_EQ(printer_name, dest->name);
+  const char* info =
+      cupsGetOption(kDriverNameTagName, dest->num_options, dest->options);
+  if (info)
+    result = *info;
+  cupsFreeDests(1, dest);
+  return result;
+}
+
+bool PrintBackendCUPS::IsValidPrinter(const std::string& printer_name) {
+  cups_dest_t* dest = GetNamedDest(printer_name);
+  if (!dest)
+    return false;
+
+  cupsFreeDests(1, dest);
+  return true;
+}
+
+#if !defined(OS_CHROMEOS)
+scoped_refptr<PrintBackend> PrintBackend::CreateInstanceImpl(
+    const base::DictionaryValue* print_backend_settings) {
+  std::string print_server_url_str, cups_blocking;
+  int encryption = HTTP_ENCRYPT_NEVER;
+  if (print_backend_settings) {
+    print_backend_settings->GetString(kCUPSPrintServerURL,
+                                      &print_server_url_str);
+
+    print_backend_settings->GetString(kCUPSBlocking,
+                                      &cups_blocking);
+
+    print_backend_settings->GetInteger(kCUPSEncryption, &encryption);
+  }
+  GURL print_server_url(print_server_url_str);
+  return new PrintBackendCUPS(print_server_url,
+                              static_cast<http_encryption_t>(encryption),
+                              cups_blocking == kValueTrue);
+}
+#endif  // !defined(OS_CHROMEOS)
+
+int PrintBackendCUPS::GetDests(cups_dest_t** dests) {
+  if (print_server_url_.is_empty())  // Use default (local) print server.
+    return cupsGetDests(dests);
+
+  HttpConnectionCUPS http(print_server_url_, cups_encryption_);
+  http.SetBlocking(blocking_);
+  return cupsGetDests2(http.http(), dests);
+}
+
+base::FilePath PrintBackendCUPS::GetPPD(const char* name) {
+  // cupsGetPPD returns a filename stored in a static buffer in CUPS.
+  // Protect this code with lock.
+  CR_DEFINE_STATIC_LOCAL(base::Lock, ppd_lock, ());
+  base::AutoLock ppd_autolock(ppd_lock);
+  base::FilePath ppd_path;
+  const char* ppd_file_path = nullptr;
+  if (print_server_url_.is_empty()) {  // Use default (local) print server.
+    ppd_file_path = cupsGetPPD(name);
+    if (ppd_file_path)
+      ppd_path = base::FilePath(ppd_file_path);
+  } else {
+    // cupsGetPPD2 gets stuck sometimes in an infinite time due to network
+    // configuration/issues. To prevent that, use non-blocking http connection
+    // here.
+    // Note: After looking at CUPS sources, it looks like non-blocking
+    // connection will timeout after 10 seconds of no data period. And it will
+    // return the same way as if data was completely and successfully
+    // downloaded.
+    HttpConnectionCUPS http(print_server_url_, cups_encryption_);
+    http.SetBlocking(blocking_);
+    ppd_file_path = cupsGetPPD2(http.http(), name);
+    // Check if the get full PPD, since non-blocking call may simply return
+    // normally after timeout expired.
+    if (ppd_file_path) {
+      // There is no reliable way right now to detect full and complete PPD
+      // get downloaded. If we reach http timeout, it may simply return
+      // downloaded part as a full response. It might be good enough to check
+      // http->data_remaining or http->_data_remaining, unfortunately http_t
+      // is an internal structure and fields are not exposed in CUPS headers.
+      // httpGetLength or httpGetLength2 returning the full content size.
+      // Comparing file size against that content length might be unreliable
+      // since some http reponses are encoded and content_length > file size.
+      // Let's just check for the obvious CUPS and http errors here.
+      ppd_path = base::FilePath(ppd_file_path);
+      ipp_status_t error_code = cupsLastError();
+      int http_error = httpError(http.http());
+      if (error_code > IPP_OK_EVENTS_COMPLETE || http_error != 0) {
+        LOG(ERROR) << "Error downloading PPD file, name: " << name
+                   << ", CUPS error: " << static_cast<int>(error_code)
+                   << ", HTTP error: " << http_error;
+        base::DeleteFile(ppd_path, false);
+        ppd_path.clear();
+      }
+    }
+  }
+  return ppd_path;
+}
+
+cups_dest_t* PrintBackendCUPS::GetNamedDest(const std::string& printer_name) {
+  // Use default (local) print server.
+  if (print_server_url_.is_empty())
+    return cupsGetNamedDest(CUPS_HTTP_DEFAULT, printer_name.c_str(), nullptr);
+
+  HttpConnectionCUPS http(print_server_url_, cups_encryption_);
+  http.SetBlocking(blocking_);
+  return cupsGetNamedDest(http.http(), printer_name.c_str(), nullptr);
+}
+
+}  // namespace printing
diff -Naur chromium-67.0.3396.62/printing/BUILD.gn chromium-67.0.3396.62.patched/printing/BUILD.gn
--- chromium-67.0.3396.62/printing/BUILD.gn	2018-05-30 11:43:19.000000000 +0300
+++ chromium-67.0.3396.62.patched/printing/BUILD.gn	2018-06-06 10:06:12.325135014 +0300
@@ -150,12 +150,13 @@
                                  ],
                                  "trim string")
 
-      if (cups_version == "1.6" || cups_version == "1.7") {
+      if (cups_version == "1.6" || cups_version == "1.7" || cups_version == "2.2") {
         cflags += [
           # CUPS 1.6 deprecated the PPD APIs, but we will stay with this
           # API for now as supported Linux and Mac OS'es are still using
           # older versions of CUPS. More info: crbug.com/226176
           "-Wno-deprecated-declarations",
+          "-D_PPD_DEPRECATED=",
           # CUPS 1.7 deprecates httpConnectEncrypt(), see the mac section
           # below.
         ]
diff -Naur chromium-67.0.3396.62/printing/BUILD.gn.cups22 chromium-67.0.3396.62.patched/printing/BUILD.gn.cups22
diff -Naur chromium-67.0.3396.62/sandbox/linux/BUILD.gn chromium-67.0.3396.62.patched/sandbox/linux/BUILD.gn
--- chromium-67.0.3396.62/sandbox/linux/BUILD.gn	2018-05-30 11:43:19.000000000 +0300
+++ chromium-67.0.3396.62.patched/sandbox/linux/BUILD.gn	2018-06-06 10:06:12.325135014 +0300
@@ -315,11 +315,17 @@
       # For ULLONG_MAX
       "-std=gnu99",
 
+      "-fPIE",
+
       # These files have a suspicious comparison.
       # TODO fix this and re-enable this warning.
       "-Wno-sign-compare",
     ]
 
+    ldflags = [
+      "-pie",
+    ]
+
     import("//build/config/compiler/compiler.gni")
     import("//build/config/sanitizers/sanitizers.gni")
     if (is_component_build || using_sanitizer) {
@@ -329,7 +335,7 @@
       # other flags that executable_config might have.
       configs -= [ "//build/config:executable_config" ]
       if (!use_gold) {
-        ldflags = [ "-Wl,--disable-new-dtags" ]
+        ldflags += [ "-Wl,--disable-new-dtags" ]
       }
     }
 
diff -Naur chromium-67.0.3396.62/sandbox/linux/BUILD.gn.sandboxpie chromium-67.0.3396.62.patched/sandbox/linux/BUILD.gn.sandboxpie
--- chromium-67.0.3396.62/sandbox/linux/BUILD.gn.sandboxpie	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/sandbox/linux/BUILD.gn.sandboxpie	2018-05-30 11:43:19.000000000 +0300
@@ -0,0 +1,485 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/features.gni")
+import("//build/config/nacl/config.gni")
+import("//sandbox/features.gni")
+import("//testing/test.gni")
+
+if (is_android) {
+  import("//build/config/android/rules.gni")
+}
+
+declare_args() {
+  compile_suid_client = is_linux
+
+  compile_credentials = is_linux
+
+  # On Android, use plain GTest.
+  use_base_test_suite = is_linux
+}
+
+if (is_nacl_nonsfi) {
+  config("nacl_nonsfi_warnings") {
+    # There are number of platform specific functions in
+    # seccomp-bpf syscall helpers, which are not being used.
+    cflags = [ "-Wno-unused-function" ]
+  }
+}
+
+# We have two principal targets: sandbox and sandbox_linux_unittests
+# All other targets are listed as dependencies.
+# There is one notable exception: for historical reasons, chrome_sandbox is
+# the setuid sandbox and is its own target.
+
+group("sandbox") {
+  public_deps = [
+    ":sandbox_services",
+  ]
+  if (compile_suid_client || is_nacl_nonsfi) {
+    public_deps += [ ":suid_sandbox_client" ]
+  }
+  if (use_seccomp_bpf || is_nacl_nonsfi) {
+    public_deps += [ ":seccomp_bpf" ]
+  }
+  if (is_android) {
+    public_deps += [ ":seccomp_starter_android" ]
+  }
+}
+
+source_set("sandbox_linux_test_utils") {
+  testonly = true
+  sources = [
+    "tests/sandbox_test_runner.cc",
+    "tests/sandbox_test_runner.h",
+    "tests/sandbox_test_runner_function_pointer.cc",
+    "tests/sandbox_test_runner_function_pointer.h",
+    "tests/unit_tests.cc",
+    "tests/unit_tests.h",
+  ]
+
+  deps = [
+    "//testing/gtest",
+  ]
+
+  if (!is_nacl_nonsfi) {
+    sources += [
+      "tests/test_utils.cc",
+      "tests/test_utils.h",
+    ]
+  }
+
+  if (use_seccomp_bpf || is_nacl_nonsfi) {
+    sources += [
+      "seccomp-bpf/bpf_tester_compatibility_delegate.h",
+      "seccomp-bpf/bpf_tests.h",
+      "seccomp-bpf/sandbox_bpf_test_runner.cc",
+      "seccomp-bpf/sandbox_bpf_test_runner.h",
+    ]
+    deps += [ ":seccomp_bpf" ]
+  }
+
+  if (use_base_test_suite) {
+    deps += [ "//base/test:test_support" ]
+    defines = [ "SANDBOX_USES_BASE_TEST_SUITE" ]
+  }
+}
+
+# Sources for sandbox_linux_unittests.
+source_set("sandbox_linux_unittests_sources") {
+  testonly = true
+
+  sources = [
+    "services/proc_util_unittest.cc",
+    "services/resource_limits_unittests.cc",
+    "services/scoped_process_unittest.cc",
+    "services/syscall_wrappers_unittest.cc",
+    "services/thread_helpers_unittests.cc",
+    "services/yama_unittests.cc",
+    "syscall_broker/broker_file_permission_unittest.cc",
+    "syscall_broker/broker_process_unittest.cc",
+    "tests/main.cc",
+    "tests/scoped_temporary_file.cc",
+    "tests/scoped_temporary_file.h",
+    "tests/scoped_temporary_file_unittest.cc",
+    "tests/test_utils_unittest.cc",
+    "tests/unit_tests_unittest.cc",
+  ]
+
+  deps = [
+    ":sandbox",
+    ":sandbox_linux_test_utils",
+    "//base",
+    "//base/third_party/dynamic_annotations",
+    "//testing/gtest",
+  ]
+
+  if (use_base_test_suite) {
+    deps += [ "//base/test:test_support" ]
+    defines = [ "SANDBOX_USES_BASE_TEST_SUITE" ]
+  }
+
+  if (compile_suid_client) {
+    sources += [
+      "suid/client/setuid_sandbox_client_unittest.cc",
+      "suid/client/setuid_sandbox_host_unittest.cc",
+    ]
+  }
+  if (use_seccomp_bpf) {
+    sources += [
+      "bpf_dsl/bpf_dsl_unittest.cc",
+      "bpf_dsl/codegen_unittest.cc",
+      "bpf_dsl/cons_unittest.cc",
+      "bpf_dsl/dump_bpf.cc",
+      "bpf_dsl/dump_bpf.h",
+      "bpf_dsl/syscall_set_unittest.cc",
+      "bpf_dsl/test_trap_registry.cc",
+      "bpf_dsl/test_trap_registry.h",
+      "bpf_dsl/test_trap_registry_unittest.cc",
+      "bpf_dsl/verifier.cc",
+      "bpf_dsl/verifier.h",
+      "integration_tests/bpf_dsl_seccomp_unittest.cc",
+      "integration_tests/seccomp_broker_process_unittest.cc",
+      "seccomp-bpf-helpers/baseline_policy_unittest.cc",
+      "seccomp-bpf-helpers/syscall_parameters_restrictions_unittests.cc",
+      "seccomp-bpf/bpf_tests_unittest.cc",
+      "seccomp-bpf/sandbox_bpf_unittest.cc",
+      "seccomp-bpf/syscall_unittest.cc",
+      "seccomp-bpf/trap_unittest.cc",
+    ]
+    deps += [ ":bpf_dsl_golden" ]
+
+    if (is_android) {
+      sources += [ "seccomp-bpf-helpers/baseline_policy_android_unittest.cc" ]
+    }
+  }
+  if (compile_credentials) {
+    sources += [
+      "integration_tests/namespace_unix_domain_socket_unittest.cc",
+      "services/credentials_unittest.cc",
+      "services/namespace_utils_unittest.cc",
+    ]
+
+    if (use_base_test_suite) {
+      # Tests that use advanced features not available in stock GTest.
+      sources += [ "services/namespace_sandbox_unittest.cc" ]
+    }
+
+    # For credentials_unittest.cc
+    configs += [ "//build/config/linux:libcap" ]
+  }
+}
+
+action("bpf_dsl_golden") {
+  script = "bpf_dsl/golden/generate.py"
+  inputs = [
+    "bpf_dsl/golden/i386/ArgSizePolicy.txt",
+    "bpf_dsl/golden/i386/BasicPolicy.txt",
+    "bpf_dsl/golden/i386/ElseIfPolicy.txt",
+    "bpf_dsl/golden/i386/MaskingPolicy.txt",
+    "bpf_dsl/golden/i386/MoreBooleanLogicPolicy.txt",
+    "bpf_dsl/golden/i386/NegativeConstantsPolicy.txt",
+    "bpf_dsl/golden/i386/SwitchPolicy.txt",
+    "bpf_dsl/golden/x86-64/ArgSizePolicy.txt",
+    "bpf_dsl/golden/x86-64/BasicPolicy.txt",
+    "bpf_dsl/golden/x86-64/BooleanLogicPolicy.txt",
+    "bpf_dsl/golden/x86-64/ElseIfPolicy.txt",
+    "bpf_dsl/golden/x86-64/MaskingPolicy.txt",
+    "bpf_dsl/golden/x86-64/MoreBooleanLogicPolicy.txt",
+    "bpf_dsl/golden/x86-64/NegativeConstantsPolicy.txt",
+    "bpf_dsl/golden/x86-64/SwitchPolicy.txt",
+  ]
+  outputs = [
+    "$target_gen_dir/bpf_dsl/golden/golden_files.h",
+  ]
+  args =
+      rebase_path(outputs, root_build_dir) + rebase_path(inputs, root_build_dir)
+}
+
+test("sandbox_linux_unittests") {
+  deps = [
+    ":sandbox_linux_unittests_sources",
+    "//build/config:exe_and_shlib_deps",
+  ]
+  if (is_android) {
+    use_raw_android_executable = true
+  }
+}
+
+component("seccomp_bpf") {
+  sources = [
+    "bpf_dsl/bpf_dsl.cc",
+    "bpf_dsl/bpf_dsl.h",
+    "bpf_dsl/bpf_dsl_forward.h",
+    "bpf_dsl/bpf_dsl_impl.h",
+    "bpf_dsl/codegen.cc",
+    "bpf_dsl/codegen.h",
+    "bpf_dsl/cons.h",
+    "bpf_dsl/errorcode.h",
+    "bpf_dsl/linux_syscall_ranges.h",
+    "bpf_dsl/policy.cc",
+    "bpf_dsl/policy.h",
+    "bpf_dsl/policy_compiler.cc",
+    "bpf_dsl/policy_compiler.h",
+    "bpf_dsl/seccomp_macros.h",
+    "bpf_dsl/syscall_set.cc",
+    "bpf_dsl/syscall_set.h",
+    "bpf_dsl/trap_registry.h",
+    "seccomp-bpf-helpers/baseline_policy.cc",
+    "seccomp-bpf-helpers/baseline_policy.h",
+    "seccomp-bpf-helpers/baseline_policy_android.cc",
+    "seccomp-bpf-helpers/baseline_policy_android.h",
+    "seccomp-bpf-helpers/sigsys_handlers.cc",
+    "seccomp-bpf-helpers/sigsys_handlers.h",
+    "seccomp-bpf-helpers/syscall_parameters_restrictions.cc",
+    "seccomp-bpf-helpers/syscall_parameters_restrictions.h",
+    "seccomp-bpf-helpers/syscall_sets.cc",
+    "seccomp-bpf-helpers/syscall_sets.h",
+    "seccomp-bpf/die.cc",
+    "seccomp-bpf/die.h",
+    "seccomp-bpf/sandbox_bpf.cc",
+    "seccomp-bpf/sandbox_bpf.h",
+    "seccomp-bpf/syscall.cc",
+    "seccomp-bpf/syscall.h",
+    "seccomp-bpf/trap.cc",
+    "seccomp-bpf/trap.h",
+  ]
+  defines = [ "SANDBOX_IMPLEMENTATION" ]
+
+  public_deps = [
+    ":sandbox_services_headers",
+    "//sandbox:sandbox_export",
+  ]
+  deps = [
+    ":sandbox_services",
+    "//base",
+    "//base/third_party/dynamic_annotations",
+  ]
+
+  if (is_nacl_nonsfi) {
+    cflags = [ "-fgnu-inline-asm" ]
+    sources -= [
+      "bpf_dsl/bpf_dsl_forward.h",
+      "bpf_dsl/bpf_dsl_impl.h",
+      "bpf_dsl/cons.h",
+      "bpf_dsl/errorcode.h",
+      "bpf_dsl/linux_syscall_ranges.h",
+      "bpf_dsl/seccomp_macros.h",
+      "bpf_dsl/trap_registry.h",
+      "seccomp-bpf-helpers/baseline_policy.cc",
+      "seccomp-bpf-helpers/baseline_policy.h",
+      "seccomp-bpf-helpers/syscall_sets.cc",
+      "seccomp-bpf-helpers/syscall_sets.h",
+    ]
+    configs += [ ":nacl_nonsfi_warnings" ]
+  }
+}
+
+if (is_android) {
+  # This target is available even if use_seccomp_bpf is disabled, but it also
+  # works when it is enabled.
+  component("seccomp_starter_android") {
+    sources = [
+      "seccomp-bpf-helpers/seccomp_starter_android.cc",
+      "seccomp-bpf-helpers/seccomp_starter_android.h",
+    ]
+
+    defines = [ "SANDBOX_IMPLEMENTATION" ]
+
+    deps = [
+      "//base",
+      "//sandbox:sandbox_buildflags",
+    ]
+
+    if (use_seccomp_bpf) {
+      deps += [ ":seccomp_bpf" ]
+    }
+
+    visibility = [ ":*" ]
+  }
+}
+
+if (is_linux) {
+  # The setuid sandbox for Linux.
+  executable("chrome_sandbox") {
+    sources = [
+      "suid/common/sandbox.h",
+      "suid/common/suid_unsafe_environment_variables.h",
+      "suid/process_util.h",
+      "suid/process_util_linux.c",
+      "suid/sandbox.c",
+    ]
+
+    cflags = [
+      # For ULLONG_MAX
+      "-std=gnu99",
+
+      # These files have a suspicious comparison.
+      # TODO fix this and re-enable this warning.
+      "-Wno-sign-compare",
+    ]
+
+    import("//build/config/compiler/compiler.gni")
+    import("//build/config/sanitizers/sanitizers.gni")
+    if (is_component_build || using_sanitizer) {
+      # WARNING! We remove this config so that we don't accidentally
+      # pick up the //build/config:rpath_for_built_shared_libraries
+      # sub-config. However, this means that we need to duplicate any
+      # other flags that executable_config might have.
+      configs -= [ "//build/config:executable_config" ]
+      if (!use_gold) {
+        ldflags = [ "-Wl,--disable-new-dtags" ]
+      }
+    }
+
+    # We also do not want to pick up any of the other sanitizer
+    # flags (i.e. we do not want to build w/ the sanitizers at all).
+    # This is safe to delete unconditionally, because it is part of the
+    # default configs and empty when not using the sanitizers.
+    configs -= [ "//build/config/sanitizers:default_sanitizer_flags" ]
+  }
+}
+
+component("sandbox_services") {
+  sources = [
+    "services/init_process_reaper.cc",
+    "services/init_process_reaper.h",
+    "services/proc_util.cc",
+    "services/proc_util.h",
+    "services/resource_limits.cc",
+    "services/resource_limits.h",
+    "services/scoped_process.cc",
+    "services/scoped_process.h",
+    "services/syscall_wrappers.cc",
+    "services/syscall_wrappers.h",
+    "services/thread_helpers.cc",
+    "services/thread_helpers.h",
+    "services/yama.cc",
+    "services/yama.h",
+    "syscall_broker/broker_channel.cc",
+    "syscall_broker/broker_channel.h",
+    "syscall_broker/broker_client.cc",
+    "syscall_broker/broker_client.h",
+    "syscall_broker/broker_command.cc",
+    "syscall_broker/broker_command.h",
+    "syscall_broker/broker_file_permission.cc",
+    "syscall_broker/broker_file_permission.h",
+    "syscall_broker/broker_host.cc",
+    "syscall_broker/broker_host.h",
+    "syscall_broker/broker_permission_list.cc",
+    "syscall_broker/broker_permission_list.h",
+    "syscall_broker/broker_process.cc",
+    "syscall_broker/broker_process.h",
+  ]
+
+  defines = [ "SANDBOX_IMPLEMENTATION" ]
+
+  public_deps = [
+    "//sandbox:sandbox_export",
+  ]
+  deps = [
+    "//base",
+    "//base/third_party/dynamic_annotations",
+  ]
+
+  if (compile_credentials || is_nacl_nonsfi) {
+    sources += [
+      "services/credentials.cc",
+      "services/credentials.h",
+      "services/namespace_sandbox.cc",
+      "services/namespace_sandbox.h",
+      "services/namespace_utils.cc",
+      "services/namespace_utils.h",
+    ]
+
+    public_deps += [ ":sandbox_services_headers" ]
+  }
+
+  if (is_nacl_nonsfi) {
+    cflags = [ "-fgnu-inline-asm" ]
+
+    sources -= [
+      "services/init_process_reaper.cc",
+      "services/init_process_reaper.h",
+      "services/scoped_process.cc",
+      "services/scoped_process.h",
+      "services/yama.cc",
+      "services/yama.h",
+      "syscall_broker/broker_channel.cc",
+      "syscall_broker/broker_channel.h",
+      "syscall_broker/broker_client.cc",
+      "syscall_broker/broker_client.h",
+      "syscall_broker/broker_command.cc",
+      "syscall_broker/broker_command.h",
+      "syscall_broker/broker_file_permission.cc",
+      "syscall_broker/broker_file_permission.h",
+      "syscall_broker/broker_host.cc",
+      "syscall_broker/broker_host.h",
+      "syscall_broker/broker_permission_list.cc",
+      "syscall_broker/broker_permission_list.h",
+      "syscall_broker/broker_process.cc",
+      "syscall_broker/broker_process.h",
+    ]
+  } else if (!is_android) {
+    sources += [
+      "services/libc_interceptor.cc",
+      "services/libc_interceptor.h",
+    ]
+  }
+}
+
+source_set("sandbox_services_headers") {
+  sources = [
+    "system_headers/arm64_linux_syscalls.h",
+    "system_headers/arm64_linux_ucontext.h",
+    "system_headers/arm_linux_syscalls.h",
+    "system_headers/arm_linux_ucontext.h",
+    "system_headers/i386_linux_ucontext.h",
+    "system_headers/linux_filter.h",
+    "system_headers/linux_futex.h",
+    "system_headers/linux_seccomp.h",
+    "system_headers/linux_signal.h",
+    "system_headers/linux_syscalls.h",
+    "system_headers/linux_time.h",
+    "system_headers/linux_ucontext.h",
+    "system_headers/mips64_linux_syscalls.h",
+    "system_headers/mips64_linux_ucontext.h",
+    "system_headers/mips_linux_syscalls.h",
+    "system_headers/mips_linux_ucontext.h",
+    "system_headers/x86_32_linux_syscalls.h",
+    "system_headers/x86_64_linux_syscalls.h",
+    "system_headers/x86_64_linux_ucontext.h",
+  ]
+}
+
+if (compile_suid_client || is_nacl_nonsfi) {
+  component("suid_sandbox_client") {
+    sources = [
+      "suid/client/setuid_sandbox_client.cc",
+      "suid/client/setuid_sandbox_client.h",
+      "suid/client/setuid_sandbox_host.cc",
+      "suid/client/setuid_sandbox_host.h",
+      "suid/common/sandbox.h",
+      "suid/common/suid_unsafe_environment_variables.h",
+    ]
+    defines = [ "SANDBOX_IMPLEMENTATION" ]
+    public_deps = [
+      "//sandbox:sandbox_export",
+    ]
+    deps = [
+      ":sandbox_services",
+      "//base",
+      "//base/third_party/dynamic_annotations",
+    ]
+
+    if (is_nacl_nonsfi) {
+      sources -= [
+        "suid/client/setuid_sandbox_host.cc",
+        "suid/client/setuid_sandbox_host.h",
+        "suid/common/sandbox.h",
+        "suid/common/suid_unsafe_environment_variables.h",
+      ]
+    }
+  }
+}
diff -Naur chromium-67.0.3396.62/third_party/boringssl/BUILD.gn chromium-67.0.3396.62.patched/third_party/boringssl/BUILD.gn
--- chromium-67.0.3396.62/third_party/boringssl/BUILD.gn	2018-05-30 11:43:41.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/boringssl/BUILD.gn	2018-06-06 10:06:12.313135206 +0300
@@ -26,6 +26,7 @@
     "BORINGSSL_IMPLEMENTATION",
     "BORINGSSL_NO_STATIC_INITIALIZER",
     "OPENSSL_SMALL",
+    "_POSIX_C_SOURCE=200112L",
   ]
   configs = [
     # TODO(davidben): Fix size_t truncations in BoringSSL.
diff -Naur chromium-67.0.3396.62/third_party/boringssl/BUILD.gn.addrfix chromium-67.0.3396.62.patched/third_party/boringssl/BUILD.gn.addrfix
--- chromium-67.0.3396.62/third_party/boringssl/BUILD.gn.addrfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/boringssl/BUILD.gn.addrfix	2018-05-30 11:43:41.000000000 +0300
@@ -0,0 +1,294 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/android/config.gni")
+import("//build/config/arm.gni")
+import("//build/config/sanitizers/sanitizers.gni")
+import("//build_overrides/build.gni")
+import("//testing/libfuzzer/fuzzer_test.gni")
+import("BUILD.generated.gni")
+import("BUILD.generated_tests.gni")
+
+# Config for us and everybody else depending on BoringSSL.
+config("external_config") {
+  include_dirs = [ "src/include" ]
+  if (is_component_build) {
+    defines = [ "BORINGSSL_SHARED_LIBRARY" ]
+  }
+}
+
+# Config internal to this build file, shared by boringssl and boringssl_fuzzer.
+config("internal_config") {
+  visibility = [ ":*" ]  # Only targets in this file can depend on this.
+  defines = [
+    "BORINGSSL_ALLOW_CXX_RUNTIME",
+    "BORINGSSL_IMPLEMENTATION",
+    "BORINGSSL_NO_STATIC_INITIALIZER",
+    "OPENSSL_SMALL",
+  ]
+  configs = [
+    # TODO(davidben): Fix size_t truncations in BoringSSL.
+    # https://crbug.com/boringssl/22
+    "//build/config/compiler:no_size_t_to_int_warning",
+    "//build/config/sanitizers:cfi_icall_generalize_pointers",
+  ]
+  if (is_posix || is_fuchsia) {
+    cflags_c = [ "-std=c99" ]
+    defines += [ "_XOPEN_SOURCE=700" ]
+  }
+}
+
+config("no_asm_config") {
+  visibility = [ ":*" ]  # Only targets in this file can depend on this.
+  defines = [ "OPENSSL_NO_ASM" ]
+}
+
+all_sources = crypto_sources + ssl_sources
+
+# Windows' assembly is built with Yasm. The other platforms use the platform
+# assembler.
+if (is_win && !is_msan) {
+  import("//third_party/yasm/yasm_assemble.gni")
+  yasm_assemble("boringssl_asm") {
+    if (current_cpu == "x64") {
+      sources = crypto_sources_win_x86_64
+    } else if (current_cpu == "x86") {
+      sources = crypto_sources_win_x86
+    }
+  }
+} else {
+  # This has no sources on some platforms so must be a source_set.
+  source_set("boringssl_asm") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+
+    sources = []
+    asmflags = []
+    include_dirs = [ "src/include" ]
+
+    if (is_msan) {
+      public_configs = [ ":no_asm_config" ]
+    } else if (current_cpu == "x64") {
+      if (is_mac) {
+        sources += crypto_sources_mac_x86_64
+      } else if (is_linux || is_android) {
+        sources += crypto_sources_linux_x86_64
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else if (current_cpu == "x86") {
+      if (is_mac) {
+        sources += crypto_sources_mac_x86
+      } else if (is_linux || is_android) {
+        sources += crypto_sources_linux_x86
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else if (current_cpu == "arm") {
+      if (is_linux || is_android) {
+        sources += crypto_sources_linux_arm
+      } else if (is_ios) {
+        sources += crypto_sources_ios_arm
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else if (current_cpu == "arm64") {
+      if (is_linux || is_android) {
+        sources += crypto_sources_linux_aarch64
+      } else if (is_ios) {
+        sources += crypto_sources_ios_aarch64
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else {
+      public_configs = [ ":no_asm_config" ]
+    }
+  }
+}
+
+component("boringssl") {
+  sources = all_sources
+  deps = [
+    ":boringssl_asm",
+    "//third_party/boringssl/src/third_party/fiat:fiat_license",
+  ]
+
+  public_configs = [ ":external_config" ]
+  configs += [ ":internal_config" ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [ "//build/config/compiler:no_chromium_code" ]
+
+  if (is_nacl) {
+    deps += [ "//native_client_sdk/src/libraries/nacl_io" ]
+  }
+}
+
+# These targets are named "_tests" rather than "_test" to avoid colliding with a
+# historical "boringssl_ssl_test" target. This works around a bug with the iOS
+# build rules.
+
+test("boringssl_crypto_tests") {
+  sources = crypto_test_sources + test_support_sources
+  deps = [
+    ":boringssl",
+    "//testing/gtest",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    ":internal_config",
+    "//build/config/compiler:no_chromium_code",
+  ]
+
+  # Chromium infrastructure does not support GTest, only the //base wrapper.
+  if (build_with_chromium) {
+    sources -= [
+      "src/crypto/test/gtest_main.cc",
+
+      # //base includes its own conflicting malloc shim.
+      "src/crypto/test/malloc.cc",
+    ]
+    sources += [ "gtest_main_chromium.cc" ]
+    deps += [ "//base/test:test_support" ]
+  }
+}
+
+test("boringssl_ssl_tests") {
+  sources = ssl_test_sources + test_support_sources
+  deps = [
+    ":boringssl",
+    "//testing/gtest",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    ":internal_config",
+    "//build/config/compiler:no_chromium_code",
+  ]
+
+  # Chromium infrastructure does not support GTest, only the //base wrapper.
+  if (build_with_chromium) {
+    sources -= [
+      "src/crypto/test/gtest_main.cc",
+
+      # //base includes its own conflicting malloc shim.
+      "src/crypto/test/malloc.cc",
+    ]
+    sources += [ "gtest_main_chromium.cc" ]
+    deps += [ "//base/test:test_support" ]
+  }
+}
+
+if (build_with_chromium) {
+  config("fuzzer_config") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+    defines = [
+      "BORINGSSL_UNSAFE_FUZZER_MODE",
+      "BORINGSSL_UNSAFE_DETERMINISTIC_MODE",
+    ]
+  }
+
+  # The same as boringssl, but builds with BORINGSSL_UNSAFE_FUZZER_MODE.
+  component("boringssl_fuzzer") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+
+    sources = all_sources
+    deps = [
+      ":boringssl_asm",
+    ]
+
+    public_configs = [
+      ":external_config",
+      ":fuzzer_config",
+    ]
+    configs += [ ":internal_config" ]
+
+    configs -= [ "//build/config/compiler:chromium_code" ]
+    configs += [ "//build/config/compiler:no_chromium_code" ]
+
+    if (is_nacl) {
+      deps += [ "//native_client_sdk/src/libraries/nacl_io" ]
+    }
+  }
+
+  foreach(fuzzer, fuzzers) {
+    fuzzer_test("boringssl_${fuzzer}_fuzzer") {
+      sources = [
+        "src/fuzz/${fuzzer}.cc",
+      ]
+      deps = [
+        ":boringssl_fuzzer",
+      ]
+      seed_corpus = "src/fuzz/${fuzzer}_corpus"
+
+      if ("cert" == fuzzer) {
+        libfuzzer_options = [ "max_len=3072" ]
+      } else if ("client" == fuzzer) {
+        libfuzzer_options = [ "max_len=20000" ]
+      } else if ("pkcs8" == fuzzer) {
+        libfuzzer_options = [ "max_len=2048" ]
+      } else if ("privkey" == fuzzer) {
+        libfuzzer_options = [ "max_len=2048" ]
+      } else if ("read_pem" == fuzzer) {
+        libfuzzer_options = [ "max_len=512" ]
+      } else if ("session" == fuzzer) {
+        libfuzzer_options = [ "max_len=8192" ]
+      } else if ("server" == fuzzer) {
+        libfuzzer_options = [ "max_len=4096" ]
+      } else if ("spki" == fuzzer) {
+        libfuzzer_options = [ "max_len=1024" ]
+      } else if ("ssl_ctx_api" == fuzzer) {
+        libfuzzer_options = [ "max_len=256" ]
+      }
+    }
+  }
+
+  config("fuzzer_no_fuzzer_mode_config") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+    defines = [ "BORINGSSL_UNSAFE_DETERMINISTIC_MODE" ]
+  }
+
+  # The same as boringssl, but builds with BORINGSSL_UNSAFE_DETERMINISTIC_MODE.
+  component("boringssl_fuzzer_no_fuzzer_mode") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+
+    sources = all_sources
+    deps = [
+      ":boringssl_asm",
+    ]
+
+    public_configs = [
+      ":external_config",
+      ":fuzzer_no_fuzzer_mode_config",
+    ]
+    configs += [ ":internal_config" ]
+
+    configs -= [ "//build/config/compiler:chromium_code" ]
+    configs += [ "//build/config/compiler:no_chromium_code" ]
+
+    if (is_nacl) {
+      deps += [ "//native_client_sdk/src/libraries/nacl_io" ]
+    }
+  }
+
+  fuzzer_test("boringssl_client_no_fuzzer_mode_fuzzer") {
+    sources = [
+      "src/fuzz/client.cc",
+    ]
+    deps = [
+      ":boringssl_fuzzer_no_fuzzer_mode",
+    ]
+    seed_corpus = "src/fuzz/client_corpus_no_fuzzer_mode"
+  }
+
+  fuzzer_test("boringssl_server_no_fuzzer_mode_fuzzer") {
+    sources = [
+      "src/fuzz/server.cc",
+    ]
+    deps = [
+      ":boringssl_fuzzer_no_fuzzer_mode",
+    ]
+    seed_corpus = "src/fuzz/server_corpus_no_fuzzer_mode"
+  }
+}
diff -Naur chromium-67.0.3396.62/third_party/boringssl/src/crypto/x509/by_dir.c chromium-67.0.3396.62.patched/third_party/boringssl/src/crypto/x509/by_dir.c
--- chromium-67.0.3396.62/third_party/boringssl/src/crypto/x509/by_dir.c	2018-05-30 11:44:28.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/boringssl/src/crypto/x509/by_dir.c	2018-06-06 10:06:12.337134821 +0300
@@ -56,6 +56,7 @@
  * [including the GNU Public Licence.] */
 
 #include <string.h>
+#include <time.h>
 #include <sys/stat.h>
 #include <sys/types.h>
 
diff -Naur chromium-67.0.3396.62/third_party/boringssl/src/crypto/x509/by_dir.c.timefix chromium-67.0.3396.62.patched/third_party/boringssl/src/crypto/x509/by_dir.c.timefix
--- chromium-67.0.3396.62/third_party/boringssl/src/crypto/x509/by_dir.c.timefix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/boringssl/src/crypto/x509/by_dir.c.timefix	2018-05-30 11:44:28.000000000 +0300
@@ -0,0 +1,451 @@
+/* crypto/x509/by_dir.c */
+/* Copyright (C) 1995-1998 Eric Young (eay@cryptsoft.com)
+ * All rights reserved.
+ *
+ * This package is an SSL implementation written
+ * by Eric Young (eay@cryptsoft.com).
+ * The implementation was written so as to conform with Netscapes SSL.
+ *
+ * This library is free for commercial and non-commercial use as long as
+ * the following conditions are aheared to.  The following conditions
+ * apply to all code found in this distribution, be it the RC4, RSA,
+ * lhash, DES, etc., code; not just the SSL code.  The SSL documentation
+ * included with this distribution is covered by the same copyright terms
+ * except that the holder is Tim Hudson (tjh@cryptsoft.com).
+ *
+ * Copyright remains Eric Young's, and as such any Copyright notices in
+ * the code are not to be removed.
+ * If this package is used in a product, Eric Young should be given attribution
+ * as the author of the parts of the library used.
+ * This can be in the form of a textual message at program startup or
+ * in documentation (online or textual) provided with the package.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. All advertising materials mentioning features or use of this software
+ *    must display the following acknowledgement:
+ *    "This product includes cryptographic software written by
+ *     Eric Young (eay@cryptsoft.com)"
+ *    The word 'cryptographic' can be left out if the rouines from the library
+ *    being used are not cryptographic related :-).
+ * 4. If you include any Windows specific code (or a derivative thereof) from
+ *    the apps directory (application code) you must include an acknowledgement:
+ *    "This product includes software written by Tim Hudson (tjh@cryptsoft.com)"
+ *
+ * THIS SOFTWARE IS PROVIDED BY ERIC YOUNG ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * The licence and distribution terms for any publically available version or
+ * derivative of this code cannot be changed.  i.e. this code cannot simply be
+ * copied and put under another distribution licence
+ * [including the GNU Public Licence.] */
+
+#include <string.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+
+#include <openssl/buf.h>
+#include <openssl/err.h>
+#include <openssl/mem.h>
+#include <openssl/thread.h>
+#include <openssl/x509.h>
+
+#include "../internal.h"
+
+typedef struct lookup_dir_hashes_st {
+    unsigned long hash;
+    int suffix;
+} BY_DIR_HASH;
+
+typedef struct lookup_dir_entry_st {
+    char *dir;
+    int dir_type;
+    STACK_OF(BY_DIR_HASH) *hashes;
+} BY_DIR_ENTRY;
+
+typedef struct lookup_dir_st {
+    BUF_MEM *buffer;
+    STACK_OF(BY_DIR_ENTRY) *dirs;
+} BY_DIR;
+
+DEFINE_STACK_OF(BY_DIR_HASH)
+DEFINE_STACK_OF(BY_DIR_ENTRY)
+
+static int dir_ctrl(X509_LOOKUP *ctx, int cmd, const char *argp, long argl,
+                    char **ret);
+static int new_dir(X509_LOOKUP *lu);
+static void free_dir(X509_LOOKUP *lu);
+static int add_cert_dir(BY_DIR *ctx, const char *dir, int type);
+static int get_cert_by_subject(X509_LOOKUP *xl, int type, X509_NAME *name,
+                               X509_OBJECT *ret);
+static X509_LOOKUP_METHOD x509_dir_lookup = {
+    "Load certs from files in a directory",
+    new_dir,                    /* new */
+    free_dir,                   /* free */
+    NULL,                       /* init */
+    NULL,                       /* shutdown */
+    dir_ctrl,                   /* ctrl */
+    get_cert_by_subject,        /* get_by_subject */
+    NULL,                       /* get_by_issuer_serial */
+    NULL,                       /* get_by_fingerprint */
+    NULL,                       /* get_by_alias */
+};
+
+X509_LOOKUP_METHOD *X509_LOOKUP_hash_dir(void)
+{
+    return (&x509_dir_lookup);
+}
+
+static int dir_ctrl(X509_LOOKUP *ctx, int cmd, const char *argp, long argl,
+                    char **retp)
+{
+    int ret = 0;
+    BY_DIR *ld;
+    char *dir = NULL;
+
+    ld = (BY_DIR *)ctx->method_data;
+
+    switch (cmd) {
+    case X509_L_ADD_DIR:
+        if (argl == X509_FILETYPE_DEFAULT) {
+            dir = (char *)getenv(X509_get_default_cert_dir_env());
+            if (dir)
+                ret = add_cert_dir(ld, dir, X509_FILETYPE_PEM);
+            else
+                ret = add_cert_dir(ld, X509_get_default_cert_dir(),
+                                   X509_FILETYPE_PEM);
+            if (!ret) {
+                OPENSSL_PUT_ERROR(X509, X509_R_LOADING_CERT_DIR);
+            }
+        } else
+            ret = add_cert_dir(ld, argp, (int)argl);
+        break;
+    }
+    return (ret);
+}
+
+static int new_dir(X509_LOOKUP *lu)
+{
+    BY_DIR *a;
+
+    if ((a = (BY_DIR *)OPENSSL_malloc(sizeof(BY_DIR))) == NULL)
+        return (0);
+    if ((a->buffer = BUF_MEM_new()) == NULL) {
+        OPENSSL_free(a);
+        return (0);
+    }
+    a->dirs = NULL;
+    lu->method_data = (char *)a;
+    return (1);
+}
+
+static void by_dir_hash_free(BY_DIR_HASH *hash)
+{
+    OPENSSL_free(hash);
+}
+
+static int by_dir_hash_cmp(const BY_DIR_HASH **a, const BY_DIR_HASH **b)
+{
+    if ((*a)->hash > (*b)->hash)
+        return 1;
+    if ((*a)->hash < (*b)->hash)
+        return -1;
+    return 0;
+}
+
+static void by_dir_entry_free(BY_DIR_ENTRY *ent)
+{
+    if (ent->dir)
+        OPENSSL_free(ent->dir);
+    if (ent->hashes)
+        sk_BY_DIR_HASH_pop_free(ent->hashes, by_dir_hash_free);
+    OPENSSL_free(ent);
+}
+
+static void free_dir(X509_LOOKUP *lu)
+{
+    BY_DIR *a;
+
+    a = (BY_DIR *)lu->method_data;
+    if (a->dirs != NULL)
+        sk_BY_DIR_ENTRY_pop_free(a->dirs, by_dir_entry_free);
+    if (a->buffer != NULL)
+        BUF_MEM_free(a->buffer);
+    OPENSSL_free(a);
+}
+
+static int add_cert_dir(BY_DIR *ctx, const char *dir, int type)
+{
+    size_t j, len;
+    const char *s, *ss, *p;
+
+    if (dir == NULL || !*dir) {
+        OPENSSL_PUT_ERROR(X509, X509_R_INVALID_DIRECTORY);
+        return 0;
+    }
+
+    s = dir;
+    p = s;
+    do {
+        if ((*p == ':') || (*p == '\0')) {
+            BY_DIR_ENTRY *ent;
+            ss = s;
+            s = p + 1;
+            len = p - ss;
+            if (len == 0)
+                continue;
+            for (j = 0; j < sk_BY_DIR_ENTRY_num(ctx->dirs); j++) {
+                ent = sk_BY_DIR_ENTRY_value(ctx->dirs, j);
+                if (strlen(ent->dir) == len &&
+                    strncmp(ent->dir, ss, len) == 0)
+                    break;
+            }
+            if (j < sk_BY_DIR_ENTRY_num(ctx->dirs))
+                continue;
+            if (ctx->dirs == NULL) {
+                ctx->dirs = sk_BY_DIR_ENTRY_new_null();
+                if (!ctx->dirs) {
+                    OPENSSL_PUT_ERROR(X509, ERR_R_MALLOC_FAILURE);
+                    return 0;
+                }
+            }
+            ent = OPENSSL_malloc(sizeof(BY_DIR_ENTRY));
+            if (!ent)
+                return 0;
+            ent->dir_type = type;
+            ent->hashes = sk_BY_DIR_HASH_new(by_dir_hash_cmp);
+            ent->dir = OPENSSL_malloc(len + 1);
+            if (!ent->dir || !ent->hashes) {
+                by_dir_entry_free(ent);
+                return 0;
+            }
+            BUF_strlcpy(ent->dir, ss, len + 1);
+            if (!sk_BY_DIR_ENTRY_push(ctx->dirs, ent)) {
+                by_dir_entry_free(ent);
+                return 0;
+            }
+        }
+    } while (*p++ != '\0');
+    return 1;
+}
+
+/*
+ * g_ent_hashes_lock protects the |hashes| member of all |BY_DIR_ENTRY|
+ * objects.
+ */
+static struct CRYPTO_STATIC_MUTEX g_ent_hashes_lock =
+    CRYPTO_STATIC_MUTEX_INIT;
+
+static int get_cert_by_subject(X509_LOOKUP *xl, int type, X509_NAME *name,
+                               X509_OBJECT *ret)
+{
+    BY_DIR *ctx;
+    union {
+        struct {
+            X509 st_x509;
+            X509_CINF st_x509_cinf;
+        } x509;
+        struct {
+            X509_CRL st_crl;
+            X509_CRL_INFO st_crl_info;
+        } crl;
+    } data;
+    int ok = 0;
+    size_t i;
+    int j, k;
+    unsigned long h;
+    unsigned long hash_array[2];
+    int hash_index;
+    BUF_MEM *b = NULL;
+    X509_OBJECT stmp, *tmp;
+    const char *postfix = "";
+
+    if (name == NULL)
+        return (0);
+
+    stmp.type = type;
+    if (type == X509_LU_X509) {
+        data.x509.st_x509.cert_info = &data.x509.st_x509_cinf;
+        data.x509.st_x509_cinf.subject = name;
+        stmp.data.x509 = &data.x509.st_x509;
+        postfix = "";
+    } else if (type == X509_LU_CRL) {
+        data.crl.st_crl.crl = &data.crl.st_crl_info;
+        data.crl.st_crl_info.issuer = name;
+        stmp.data.crl = &data.crl.st_crl;
+        postfix = "r";
+    } else {
+        OPENSSL_PUT_ERROR(X509, X509_R_WRONG_LOOKUP_TYPE);
+        goto finish;
+    }
+
+    if ((b = BUF_MEM_new()) == NULL) {
+        OPENSSL_PUT_ERROR(X509, ERR_R_BUF_LIB);
+        goto finish;
+    }
+
+    ctx = (BY_DIR *)xl->method_data;
+
+    hash_array[0] = X509_NAME_hash(name);
+    hash_array[1] = X509_NAME_hash_old(name);
+    for (hash_index = 0; hash_index < 2; ++hash_index) {
+        h = hash_array[hash_index];
+        for (i = 0; i < sk_BY_DIR_ENTRY_num(ctx->dirs); i++) {
+            BY_DIR_ENTRY *ent;
+            size_t idx;
+            BY_DIR_HASH htmp, *hent;
+            ent = sk_BY_DIR_ENTRY_value(ctx->dirs, i);
+            j = strlen(ent->dir) + 1 + 8 + 6 + 1 + 1;
+            if (!BUF_MEM_grow(b, j)) {
+                OPENSSL_PUT_ERROR(X509, ERR_R_MALLOC_FAILURE);
+                goto finish;
+            }
+            if (type == X509_LU_CRL && ent->hashes) {
+                htmp.hash = h;
+                CRYPTO_STATIC_MUTEX_lock_read(&g_ent_hashes_lock);
+                if (sk_BY_DIR_HASH_find(ent->hashes, &idx, &htmp)) {
+                    hent = sk_BY_DIR_HASH_value(ent->hashes, idx);
+                    k = hent->suffix;
+                } else {
+                    hent = NULL;
+                    k = 0;
+                }
+                CRYPTO_STATIC_MUTEX_unlock_read(&g_ent_hashes_lock);
+            } else {
+                k = 0;
+                hent = NULL;
+            }
+            for (;;) {
+                char c = '/';
+#ifdef OPENSSL_SYS_VMS
+                c = ent->dir[strlen(ent->dir) - 1];
+                if (c != ':' && c != '>' && c != ']') {
+                    /*
+                     * If no separator is present, we assume the directory
+                     * specifier is a logical name, and add a colon.  We
+                     * really should use better VMS routines for merging
+                     * things like this, but this will do for now... --
+                     * Richard Levitte
+                     */
+                    c = ':';
+                } else {
+                    c = '\0';
+                }
+#endif
+                if (c == '\0') {
+                    /*
+                     * This is special.  When c == '\0', no directory
+                     * separator should be added.
+                     */
+                    BIO_snprintf(b->data, b->max,
+                                 "%s%08lx.%s%d", ent->dir, h, postfix, k);
+                } else {
+                    BIO_snprintf(b->data, b->max,
+                                 "%s%c%08lx.%s%d", ent->dir, c, h,
+                                 postfix, k);
+                }
+#ifndef OPENSSL_NO_POSIX_IO
+# if defined(_WIN32) && !defined(stat)
+#  define stat _stat
+# endif
+                {
+                    struct stat st;
+                    if (stat(b->data, &st) < 0)
+                        break;
+                }
+#endif
+                /* found one. */
+                if (type == X509_LU_X509) {
+                    if ((X509_load_cert_file(xl, b->data,
+                                             ent->dir_type)) == 0)
+                        break;
+                } else if (type == X509_LU_CRL) {
+                    if ((X509_load_crl_file(xl, b->data, ent->dir_type)) == 0)
+                        break;
+                }
+                /* else case will caught higher up */
+                k++;
+            }
+
+            /*
+             * we have added it to the cache so now pull it out again
+             */
+            CRYPTO_MUTEX_lock_write(&xl->store_ctx->objs_lock);
+            tmp = NULL;
+            if (sk_X509_OBJECT_find(xl->store_ctx->objs, &idx, &stmp)) {
+                tmp = sk_X509_OBJECT_value(xl->store_ctx->objs, idx);
+            }
+            CRYPTO_MUTEX_unlock_write(&xl->store_ctx->objs_lock);
+
+            /*
+             * If a CRL, update the last file suffix added for this
+             */
+
+            if (type == X509_LU_CRL) {
+                CRYPTO_STATIC_MUTEX_lock_write(&g_ent_hashes_lock);
+                /*
+                 * Look for entry again in case another thread added an entry
+                 * first.
+                 */
+                if (!hent) {
+                    htmp.hash = h;
+                    if (sk_BY_DIR_HASH_find(ent->hashes, &idx, &htmp))
+                        hent = sk_BY_DIR_HASH_value(ent->hashes, idx);
+                }
+                if (!hent) {
+                    hent = OPENSSL_malloc(sizeof(BY_DIR_HASH));
+                    if (hent == NULL) {
+                        CRYPTO_STATIC_MUTEX_unlock_write(&g_ent_hashes_lock);
+                        ok = 0;
+                        goto finish;
+                    }
+                    hent->hash = h;
+                    hent->suffix = k;
+                    if (!sk_BY_DIR_HASH_push(ent->hashes, hent)) {
+                        CRYPTO_STATIC_MUTEX_unlock_write(&g_ent_hashes_lock);
+                        OPENSSL_free(hent);
+                        ok = 0;
+                        goto finish;
+                    }
+                } else if (hent->suffix < k)
+                    hent->suffix = k;
+
+                CRYPTO_STATIC_MUTEX_unlock_write(&g_ent_hashes_lock);
+            }
+
+            if (tmp != NULL) {
+                ok = 1;
+                ret->type = tmp->type;
+                OPENSSL_memcpy(&ret->data, &tmp->data, sizeof(ret->data));
+                /*
+                 * If we were going to up the reference count, we would need
+                 * to do it on a perl 'type' basis
+                 */
+                /*
+                 * CRYPTO_add(&tmp->data.x509->references,1,
+                 * CRYPTO_LOCK_X509);
+                 */
+                goto finish;
+            }
+        }
+    }
+ finish:
+    if (b != NULL)
+        BUF_MEM_free(b);
+    return (ok);
+}
diff -Naur chromium-67.0.3396.62/third_party/BUILD.gn.jpegfix chromium-67.0.3396.62.patched/third_party/BUILD.gn.jpegfix
--- chromium-67.0.3396.62/third_party/BUILD.gn.jpegfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/BUILD.gn.jpegfix	2018-05-30 11:43:20.000000000 +0300
@@ -0,0 +1,68 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/freetype/freetype.gni")
+import("//third_party/harfbuzz-ng/harfbuzz.gni")
+import("//third_party/libjpeg.gni")
+
+assert(!is_ios, "This is not used on iOS, don't drag it in unintentionally")
+
+config("system_libjpeg_config") {
+  libs = [ "jpeg" ]
+  defines = [ "USE_SYSTEM_LIBJPEG" ]
+}
+
+config("libjpeg_turbo_config") {
+  defines = [ "USE_LIBJPEG_TURBO=1" ]
+}
+
+# This is a meta target that forwards to the system's libjpeg,
+# third_party/libjpeg, or third_party/libjpeg_turbo depending on the build args
+# declared in this file.
+group("jpeg") {
+  if (use_system_libjpeg) {
+    public_configs = [ ":system_libjpeg_config" ]
+  } else if (use_libjpeg_turbo) {
+    public_deps = [
+      "//third_party/libjpeg_turbo:libjpeg",
+    ]
+    public_configs = [ ":libjpeg_turbo_config" ]
+  } else {
+    public_deps = [
+      "//third_party/libjpeg:libjpeg",
+    ]
+  }
+}
+
+# This is a meta target that forwards include paths only to the system's
+# libjpeg, third_party/libjpeg, or third_party/libjpeg_turbo depending on the
+# build args declared in this file. This is needed, rarely, for targets that
+# need to reference libjpeg without explicitly building it.
+group("jpeg_includes") {
+  if (use_system_libjpeg) {
+    public_configs = [ ":system_libjpeg_config" ]
+  } else if (use_libjpeg_turbo) {
+    public_configs = [ "//third_party/libjpeg_turbo:libjpeg_config" ]
+  } else {
+    public_configs = [ "//third_party/libjpeg:libjpeg_config" ]
+  }
+}
+
+# FreeType and HarfBuzz libraries are dependent on each other. This component
+# will depend on the appropriate source sets or export the system packages
+# for both FreeType and HarfBuzz.
+component("freetype_harfbuzz") {
+  public_configs = []
+  public_deps = []
+  if (use_system_freetype) {
+    public_configs += [ "//build/linux:freetype_from_pkgconfig" ]
+  } else {
+    public_deps += [ "//third_party/freetype:freetype_source" ]
+  }
+  if (use_system_harfbuzz) {
+    public_configs += [ "//third_party/harfbuzz-ng:harfbuzz_from_pkgconfig" ]
+  } else {
+    public_deps += [ "//third_party/harfbuzz-ng:harfbuzz_source" ]
+  }
+}
diff -Naur chromium-67.0.3396.62/third_party/crashpad/crashpad/util/misc/capture_context_linux.S chromium-67.0.3396.62.patched/third_party/crashpad/crashpad/util/misc/capture_context_linux.S
--- chromium-67.0.3396.62/third_party/crashpad/crashpad/util/misc/capture_context_linux.S	2018-05-30 11:43:41.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/crashpad/crashpad/util/misc/capture_context_linux.S	2018-06-06 10:06:12.377134183 +0300
@@ -288,7 +288,7 @@
 #elif defined(__aarch64__)
 
   // Zero out fault_address, which is unused.
-  str x31, [x0, #0xb0]  // context->uc_mcontext.fault_address
+  str xzr, [x0, #0xb0]  // context->uc_mcontext.fault_address
 
   // Save general purpose registers in context->uc_mcontext.regs[i].
   // The original x0 can't be recovered.
diff -Naur chromium-67.0.3396.62/third_party/crashpad/crashpad/util/misc/capture_context_linux.S.crashpad-aarch64-fix chromium-67.0.3396.62.patched/third_party/crashpad/crashpad/util/misc/capture_context_linux.S.crashpad-aarch64-fix
--- chromium-67.0.3396.62/third_party/crashpad/crashpad/util/misc/capture_context_linux.S.crashpad-aarch64-fix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/crashpad/crashpad/util/misc/capture_context_linux.S.crashpad-aarch64-fix	2018-05-30 11:43:41.000000000 +0300
@@ -0,0 +1,332 @@
+// Copyright 2018 The Crashpad Authors. All rights reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+// namespace crashpad {
+// void CaptureContext(ucontext_t* context);
+// }  // namespace crashpad
+
+// The type name for a ucontext_t varies by libc implementation and version.
+// Bionic and glibc 2.25 typedef ucontext_t from struct ucontext. glibc 2.26+
+// typedef ucontext_t from struct ucontext_t. Alias the symbol names to maintain
+// compatibility with both possibilities.
+#define CAPTURECONTEXT_SYMBOL _ZN8crashpad14CaptureContextEP10ucontext_t
+#define CAPTURECONTEXT_SYMBOL2 _ZN8crashpad14CaptureContextEP8ucontext
+
+  .text
+  .globl CAPTURECONTEXT_SYMBOL
+  .globl CAPTURECONTEXT_SYMBOL2
+#if defined(__i386__) || defined(__x86_64__)
+  .balign 16, 0x90
+#elif defined(__arm__) || defined(__aarch64__)
+  .balign 4, 0x0
+#endif
+
+CAPTURECONTEXT_SYMBOL:
+CAPTURECONTEXT_SYMBOL2:
+
+#if defined(__i386__)
+
+  .cfi_startproc
+
+  pushl %ebp
+  .cfi_def_cfa_offset 8
+  .cfi_offset %ebp, -8
+  movl %esp, %ebp
+  .cfi_def_cfa_register %ebp
+
+  // Note that 16-byte stack alignment is not maintained because this function
+  // does not call out to any other.
+
+  // pushfl first, because some instructions (but probably none used here)
+  // affect %eflags. %eflags will be in -4(%ebp).
+  pushfl
+
+  // Save the original value of %eax, and use %eax to hold the ucontext_t*
+  // argument. The original value of %eax will be in -8(%ebp).
+  pushl %eax
+  movl 8(%ebp), %eax
+
+  // Save the original value of %ecx, and use %ecx as a scratch register.
+  pushl %ecx
+
+  // The segment registers are 16 bits wide, but mcontext_t declares them
+  // as unsigned 32-bit values, so zero the top half.
+  xorl %ecx, %ecx
+  movw %gs, %cx
+  movl %ecx, 0x14(%eax)  // context->uc_mcontext.xgs
+  movw %fs, %cx
+  movl %ecx, 0x18(%eax)  // context->uc_mcontext.xfs
+  movw %es, %cx
+  movl %ecx, 0x1c(%eax)  // context->uc_mcontext.xes
+  movw %ds, %cx
+  movl %ecx, 0x20(%eax)  // context->uc_mcontext.xds
+
+  // General-purpose registers whose values haven’t changed can be captured
+  // directly.
+  movl %edi, 0x24(%eax)  // context->uc_mcontext.edi
+  movl %esi, 0x28(%eax)  // context->uc_mcontext.esi
+
+  // The original %ebp was saved on the stack in this function’s prologue.
+  movl (%ebp), %ecx
+  movl %ecx, 0x2c(%eax)  // context->uc_mcontext.ebp
+
+  // %esp was saved in %ebp in this function’s prologue, but the caller’s %esp
+  // is 8 more than this value: 4 for the original %ebp saved on the stack in
+  // this function’s prologue, and 4 for the return address saved on the stack
+  // by the call instruction that reached this function.
+  leal 8(%ebp), %ecx
+  movl %ecx, 0x30(%eax)  // context->uc_mcontext.esp
+
+  // More general-purpose registers
+  movl %ebx, 0x34(%eax)  // context->uc_mcontext.ebx
+  movl %edx, 0x38(%eax)  // context->uc_mcontext.edx
+
+  // The original %ecx was saved on the stack above.
+  movl -12(%ebp), %ecx
+  movl %ecx, 0x3c(%eax)  // context->uc_mcontext.ecx
+
+  // The original %eax was saved on the stack above.
+  movl -8(%ebp), %ecx
+  movl %ecx, 0x40(%eax)  // context->uc_mcontext.eax
+
+  // trapno and err are unused so zero them out.
+  xorl %ecx, %ecx
+  movl %ecx, 0x44(%eax)  // context->uc_mcontext.trapno
+  movl %ecx, 0x48(%eax)  // context->uc_mcontext.err
+
+  // %eip can’t be accessed directly, but the return address saved on the stack
+  // by the call instruction that reached this function can be used.
+  movl 4(%ebp), %ecx
+  movl %ecx, 0x4c(%eax)  // context->uc_mcontext.eip
+
+  // More segment registers
+  xorl %ecx, %ecx
+  movw %cs, %cx
+  movl %ecx, 0x50(%eax)  // context->uc_mcontext.xcs
+
+  // The original %eflags was saved on the stack above.
+  movl -4(%ebp), %ecx
+  movl %ecx, 0x54(%eax)  // context->uc_mcontext.eflags
+
+  // uesp is unused so zero it out.
+  xorl %ecx, %ecx
+  movl %ecx, 0x58(%eax)  // context->uc_mcontext.uesp
+
+  // The last segment register.
+  movw %ss, %cx
+  movl %ecx, 0x5c(%eax)  // context->uc_mcontext.xss
+
+  // TODO(jperaza): save floating-point registers.
+
+  // Clean up by restoring clobbered registers, even those considered volatile
+  // by the ABI, so that the captured context represents the state at this
+  // function’s exit.
+  popl %ecx
+  popl %eax
+  popfl
+
+  popl %ebp
+
+  ret
+
+  .cfi_endproc
+
+#elif defined(__x86_64__)
+
+  .cfi_startproc
+
+  pushq %rbp
+  .cfi_def_cfa_offset 16
+  .cfi_offset %rbp, -16
+  movq %rsp, %rbp
+  .cfi_def_cfa_register %rbp
+
+  // Note that 16-byte stack alignment is not maintained because this function
+  // does not call out to any other.
+
+  // pushfq first, because some instructions (but probably none used here)
+  // affect %rflags. %rflags will be in -8(%rbp).
+  pushfq
+
+  // General-purpose registers whose values haven’t changed can be captured
+  // directly.
+  movq %r8, 0x28(%rdi)  // context->uc_mcontext.r8
+  movq %r9, 0x30(%rdi)  // context->uc_mcontext.r9
+  movq %r10, 0x38(%rdi)  // context->uc_mcontext.r10
+  movq %r11, 0x40(%rdi)  // context->uc_mcontext.r11
+  movq %r12, 0x48(%rdi)  // context->uc_mcontext.r12
+  movq %r13, 0x50(%rdi)  // context->uc_mcontext.r13
+  movq %r14, 0x58(%rdi)  // context->uc_mcontext.r14
+  movq %r15, 0x60(%rdi)  // context->uc_mcontext.r15
+
+  // Because of the calling convention, there’s no way to recover the value of
+  // the caller’s %rdi as it existed prior to calling this function. This
+  // function captures a snapshot of the register state at its return, which
+  // involves %rdi containing a pointer to its first argument. Callers that
+  // require the value of %rdi prior to calling this function should obtain it
+  // separately. For example:
+  //   uint64_t rdi;
+  //   asm("movq %%rdi, %0" : "=m"(rdi));
+  movq %rdi, 0x68(%rdi)  // context->uc_mcontext.rdi
+
+  movq %rsi, 0x70(%rdi)  // context->uc_mcontext.rsi
+
+  // Use %r8 as a scratch register now that it has been saved.
+  // The original %rbp was saved on the stack in this function’s prologue.
+  movq (%rbp), %r8
+  movq %r8, 0x78(%rdi)  // context->uc_mcontext.rbp
+
+  // Save the remaining general-purpose registers.
+  movq %rbx, 0x80(%rdi)  // context->uc_mcontext.rbx
+  movq %rdx, 0x88(%rdi)  // context->uc_mcontext.rdx
+  movq %rax, 0x90(%rdi)  // context->uc_mcontext.rax
+  movq %rcx, 0x98(%rdi)  // context->uc_mcontext.rcx
+
+  // %rsp was saved in %rbp in this function’s prologue, but the caller’s %rsp
+  // is 16 more than this value: 8 for the original %rbp saved on the stack in
+  // this function’s prologue, and 8 for the return address saved on the stack
+  // by the call instruction that reached this function.
+  leaq 16(%rbp), %r8
+  movq %r8, 0xa0(%rdi)  // context->uc_mcontext.rsp
+
+  // %rip can’t be accessed directly, but the return address saved on the stack
+  // by the call instruction that reached this function can be used.
+  movq 8(%rbp), %r8
+  movq %r8, 0xa8(%rdi)  // context->uc_mcontext.rip
+
+  // The original %rflags was saved on the stack above.
+  movq -8(%rbp), %r8
+  movq %r8, 0xb0(%rdi)  // context->uc_mcontext.eflags
+
+  // Save the segment registers
+  movw %cs, 0xb8(%rdi)  // context->uc_mcontext.cs
+  movw %gs, 0xba(%rdi)  // context->uc_mcontext.gs
+  movw %fs, 0xbc(%rdi)  // context->uc_mcontext.fs
+
+  xorw %ax, %ax
+  movw %ax, 0xbe(%rdi)  // context->uc_mcontext.padding
+
+  // Zero out the remainder of the unused pseudo-registers
+  xorq %r8, %r8
+  movq %r8, 0xc0(%rdi)  // context->uc_mcontext.err
+  movq %r8, 0xc8(%rdi)  // context->uc_mcontext.trapno
+  movq %r8, 0xd0(%rdi)  // context->uc_mcontext.oldmask
+  movq %r8, 0xd8(%rdi)  // context->uc_mcontext.cr2
+
+  // Clean up by restoring clobbered registers, even those considered volatile
+  // by the ABI, so that the captured context represents the state at this
+  // function’s exit.
+  movq 0x90(%rdi), %rax
+  movq 0x28(%rdi), %r8
+
+  // TODO(jperaza): save floating-point registers.
+
+  popfq
+
+  popq %rbp
+
+  ret
+
+  .cfi_endproc
+
+#elif defined(__arm__)
+
+  // The original r0 can't be recovered.
+  str r0, [r0, #0x20]
+
+  // Now advance r0 to point to the register array.
+  add r0, r0, #0x24
+
+  // Save registers r1-r12 at context->uc_mcontext.regs[i].
+  stm r0, {r1-r12}
+
+  // Restore r0.
+  sub r0, r0, #0x24
+
+  // Save named general purpose registers.
+  str FP, [r0, #0x4c]  // context->uc_mcontext.fp
+  str IP, [r0, #0x50]  // context->uc_mcontext.ip
+  str SP, [r0, #0x54]  // context->uc_mcontext.sp
+
+  // The original LR can't be recovered.
+  str LR, [r0, #0x58]  // context->uc_mcontext.lr
+
+  // The link register holds the return address for this function.
+  str LR, [r0, #0x5c]  // context->uc_mcontext.pc
+
+  // Use r1 as a scratch register.
+
+  // CPSR is a deprecated synonym for APSR.
+  mrs r1, APSR
+  str r1, [r0, #0x60]  // context->uc_mcontext.cpsr
+
+  // Zero out unused fields.
+  mov r1, #0x0
+  str r1, [r0, #0x14]  // context->uc_mcontext.trap_no
+  str r1, [r0, #0x18]  // context->uc_mcontext.error_code
+  str r1, [r0, #0x1c]  // context->uc_mcontext.oldmask
+  str r1, [r0, #0x64]  // context->uc_mcontext.fault_address
+
+  // Restore r1.
+  ldr r1, [r0, #0x24]
+
+  // TODO(jperaza): save floating-point registers.
+
+  mov PC, LR
+
+#elif defined(__aarch64__)
+
+  // Zero out fault_address, which is unused.
+  str x31, [x0, #0xb0]  // context->uc_mcontext.fault_address
+
+  // Save general purpose registers in context->uc_mcontext.regs[i].
+  // The original x0 can't be recovered.
+  stp x0, x1, [x0, #0xb8]
+  stp x2, x3, [x0, #0xc8]
+  stp x4, x5, [x0, #0xd8]
+  stp x6, x7, [x0, #0xe8]
+  stp x8, x9, [x0, #0xf8]
+  stp x10, x11, [x0, #0x108]
+  stp x12, x13, [x0, #0x118]
+  stp x14, x15, [x0, #0x128]
+  stp x16, x17, [x0, #0x138]
+  stp x18, x19, [x0, #0x148]
+  stp x20, x21, [x0, #0x158]
+  stp x22, x23, [x0, #0x168]
+  stp x24, x25, [x0, #0x178]
+  stp x26, x27, [x0, #0x188]
+  stp x28, x29, [x0, #0x198]
+
+  // The original LR can't be recovered.
+  str LR, [x0, #0x1a8]
+
+  // Use x1 as a scratch register.
+  mov x1, SP
+  str x1, [x0, #0x1b0] // context->uc_mcontext.sp
+
+  // The link register holds the return address for this function.
+  str LR, [x0, #0x1b8]  // context->uc_mcontext.pc
+
+  // NZCV, pstate, and CPSR are synonyms.
+  mrs x1, NZCV
+  str x1, [x0, #0x1c0]  // context->uc_mcontext.pstate
+
+  // Restore x1 from the saved context.
+  ldr x1, [x0, #0xc0]
+
+  // TODO(jperaza): save floating-point registers.
+
+  ret
+
+#endif  // __i386__
diff -Naur chromium-67.0.3396.62/third_party/ffmpeg/libavutil/cpu.c chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/cpu.c
--- chromium-67.0.3396.62/third_party/ffmpeg/libavutil/cpu.c	2018-05-30 11:44:29.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/cpu.c	2018-06-06 10:06:12.361134439 +0300
@@ -18,7 +18,13 @@
 
 #include <stddef.h>
 #include <stdint.h>
+// GCC 4.8 didn't have stdatomic, but was advertising it.
+// https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58016
+#if !defined(__clang__) && defined(__GNUC__) && (__GNUC__ == 4 || (__GNUC__ == 4 && (__GNUC_MINOR__ == 8)))
+#include <compat/atomics/gcc/stdatomic.h>
+#else
 #include <stdatomic.h>
+#endif
 
 #include "attributes.h"
 #include "cpu.h"
diff -Naur chromium-67.0.3396.62/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic
--- chromium-67.0.3396.62/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic	2018-05-30 11:44:29.000000000 +0300
@@ -0,0 +1,321 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stddef.h>
+#include <stdint.h>
+#include <stdatomic.h>
+
+#include "attributes.h"
+#include "cpu.h"
+#include "cpu_internal.h"
+#include "config.h"
+#include "opt.h"
+#include "common.h"
+
+#if HAVE_SCHED_GETAFFINITY
+#ifndef _GNU_SOURCE
+# define _GNU_SOURCE
+#endif
+#include <sched.h>
+#endif
+#if HAVE_GETPROCESSAFFINITYMASK || HAVE_WINRT
+#include <windows.h>
+#endif
+#if HAVE_SYSCTL
+#if HAVE_SYS_PARAM_H
+#include <sys/param.h>
+#endif
+#include <sys/types.h>
+#include <sys/sysctl.h>
+#endif
+#if HAVE_UNISTD_H
+#include <unistd.h>
+#endif
+
+static atomic_int cpu_flags = ATOMIC_VAR_INIT(-1);
+
+static int get_cpu_flags(void)
+{
+    if (ARCH_AARCH64)
+        return ff_get_cpu_flags_aarch64();
+    if (ARCH_ARM)
+        return ff_get_cpu_flags_arm();
+    if (ARCH_PPC)
+        return ff_get_cpu_flags_ppc();
+    if (ARCH_X86)
+        return ff_get_cpu_flags_x86();
+    return 0;
+}
+
+void av_force_cpu_flags(int arg){
+    if (ARCH_X86 &&
+           (arg & ( AV_CPU_FLAG_3DNOW    |
+                    AV_CPU_FLAG_3DNOWEXT |
+                    AV_CPU_FLAG_MMXEXT   |
+                    AV_CPU_FLAG_SSE      |
+                    AV_CPU_FLAG_SSE2     |
+                    AV_CPU_FLAG_SSE2SLOW |
+                    AV_CPU_FLAG_SSE3     |
+                    AV_CPU_FLAG_SSE3SLOW |
+                    AV_CPU_FLAG_SSSE3    |
+                    AV_CPU_FLAG_SSE4     |
+                    AV_CPU_FLAG_SSE42    |
+                    AV_CPU_FLAG_AVX      |
+                    AV_CPU_FLAG_AVXSLOW  |
+                    AV_CPU_FLAG_XOP      |
+                    AV_CPU_FLAG_FMA3     |
+                    AV_CPU_FLAG_FMA4     |
+                    AV_CPU_FLAG_AVX2     |
+                    AV_CPU_FLAG_AVX512   ))
+        && !(arg & AV_CPU_FLAG_MMX)) {
+        av_log(NULL, AV_LOG_WARNING, "MMX implied by specified flags\n");
+        arg |= AV_CPU_FLAG_MMX;
+    }
+
+    atomic_store_explicit(&cpu_flags, arg, memory_order_relaxed);
+}
+
+int av_get_cpu_flags(void)
+{
+    int flags = atomic_load_explicit(&cpu_flags, memory_order_relaxed);
+    if (flags == -1) {
+        flags = get_cpu_flags();
+        atomic_store_explicit(&cpu_flags, flags, memory_order_relaxed);
+    }
+    return flags;
+}
+
+void av_set_cpu_flags_mask(int mask)
+{
+    atomic_store_explicit(&cpu_flags, get_cpu_flags() & mask,
+                          memory_order_relaxed);
+}
+
+int av_parse_cpu_flags(const char *s)
+{
+#define CPUFLAG_MMXEXT   (AV_CPU_FLAG_MMX      | AV_CPU_FLAG_MMXEXT | AV_CPU_FLAG_CMOV)
+#define CPUFLAG_3DNOW    (AV_CPU_FLAG_3DNOW    | AV_CPU_FLAG_MMX)
+#define CPUFLAG_3DNOWEXT (AV_CPU_FLAG_3DNOWEXT | CPUFLAG_3DNOW)
+#define CPUFLAG_SSE      (AV_CPU_FLAG_SSE      | CPUFLAG_MMXEXT)
+#define CPUFLAG_SSE2     (AV_CPU_FLAG_SSE2     | CPUFLAG_SSE)
+#define CPUFLAG_SSE2SLOW (AV_CPU_FLAG_SSE2SLOW | CPUFLAG_SSE2)
+#define CPUFLAG_SSE3     (AV_CPU_FLAG_SSE3     | CPUFLAG_SSE2)
+#define CPUFLAG_SSE3SLOW (AV_CPU_FLAG_SSE3SLOW | CPUFLAG_SSE3)
+#define CPUFLAG_SSSE3    (AV_CPU_FLAG_SSSE3    | CPUFLAG_SSE3)
+#define CPUFLAG_SSE4     (AV_CPU_FLAG_SSE4     | CPUFLAG_SSSE3)
+#define CPUFLAG_SSE42    (AV_CPU_FLAG_SSE42    | CPUFLAG_SSE4)
+#define CPUFLAG_AVX      (AV_CPU_FLAG_AVX      | CPUFLAG_SSE42)
+#define CPUFLAG_AVXSLOW  (AV_CPU_FLAG_AVXSLOW  | CPUFLAG_AVX)
+#define CPUFLAG_XOP      (AV_CPU_FLAG_XOP      | CPUFLAG_AVX)
+#define CPUFLAG_FMA3     (AV_CPU_FLAG_FMA3     | CPUFLAG_AVX)
+#define CPUFLAG_FMA4     (AV_CPU_FLAG_FMA4     | CPUFLAG_AVX)
+#define CPUFLAG_AVX2     (AV_CPU_FLAG_AVX2     | CPUFLAG_AVX)
+#define CPUFLAG_BMI2     (AV_CPU_FLAG_BMI2     | AV_CPU_FLAG_BMI1)
+#define CPUFLAG_AESNI    (AV_CPU_FLAG_AESNI    | CPUFLAG_SSE42)
+#define CPUFLAG_AVX512   (AV_CPU_FLAG_AVX512   | CPUFLAG_AVX2)
+    static const AVOption cpuflags_opts[] = {
+        { "flags"   , NULL, 0, AV_OPT_TYPE_FLAGS, { .i64 = 0 }, INT64_MIN, INT64_MAX, .unit = "flags" },
+#if   ARCH_PPC
+        { "altivec" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ALTIVEC  },    .unit = "flags" },
+#elif ARCH_X86
+        { "mmx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX      },    .unit = "flags" },
+        { "mmxext"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_MMXEXT       },    .unit = "flags" },
+        { "sse"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE          },    .unit = "flags" },
+        { "sse2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE2         },    .unit = "flags" },
+        { "sse2slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE2SLOW     },    .unit = "flags" },
+        { "sse3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE3         },    .unit = "flags" },
+        { "sse3slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE3SLOW     },    .unit = "flags" },
+        { "ssse3"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSSE3        },    .unit = "flags" },
+        { "atom"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ATOM     },    .unit = "flags" },
+        { "sse4.1"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE4         },    .unit = "flags" },
+        { "sse4.2"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE42        },    .unit = "flags" },
+        { "avx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX          },    .unit = "flags" },
+        { "avxslow" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVXSLOW      },    .unit = "flags" },
+        { "xop"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_XOP          },    .unit = "flags" },
+        { "fma3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_FMA3         },    .unit = "flags" },
+        { "fma4"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_FMA4         },    .unit = "flags" },
+        { "avx2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX2         },    .unit = "flags" },
+        { "bmi1"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_BMI1     },    .unit = "flags" },
+        { "bmi2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_BMI2         },    .unit = "flags" },
+        { "3dnow"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_3DNOW        },    .unit = "flags" },
+        { "3dnowext", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_3DNOWEXT     },    .unit = "flags" },
+        { "cmov",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_CMOV     },    .unit = "flags" },
+        { "aesni"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AESNI        },    .unit = "flags" },
+        { "avx512"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX512       },    .unit = "flags" },
+#elif ARCH_ARM
+        { "armv5te",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV5TE  },    .unit = "flags" },
+        { "armv6",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6    },    .unit = "flags" },
+        { "armv6t2",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6T2  },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+        { "vfp_vm",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP_VM   },    .unit = "flags" },
+        { "vfpv3",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFPV3    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+#elif ARCH_AARCH64
+        { "armv8",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV8    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+#endif
+        { NULL },
+    };
+    static const AVClass class = {
+        .class_name = "cpuflags",
+        .item_name  = av_default_item_name,
+        .option     = cpuflags_opts,
+        .version    = LIBAVUTIL_VERSION_INT,
+    };
+
+    int flags = 0, ret;
+    const AVClass *pclass = &class;
+
+    if ((ret = av_opt_eval_flags(&pclass, &cpuflags_opts[0], s, &flags)) < 0)
+        return ret;
+
+    return flags & INT_MAX;
+}
+
+int av_parse_cpu_caps(unsigned *flags, const char *s)
+{
+        static const AVOption cpuflags_opts[] = {
+        { "flags"   , NULL, 0, AV_OPT_TYPE_FLAGS, { .i64 = 0 }, INT64_MIN, INT64_MAX, .unit = "flags" },
+#if   ARCH_PPC
+        { "altivec" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ALTIVEC  },    .unit = "flags" },
+#elif ARCH_X86
+        { "mmx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX      },    .unit = "flags" },
+        { "mmx2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX2     },    .unit = "flags" },
+        { "mmxext"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX2     },    .unit = "flags" },
+        { "sse"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE      },    .unit = "flags" },
+        { "sse2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE2     },    .unit = "flags" },
+        { "sse2slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE2SLOW },    .unit = "flags" },
+        { "sse3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE3     },    .unit = "flags" },
+        { "sse3slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE3SLOW },    .unit = "flags" },
+        { "ssse3"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSSE3    },    .unit = "flags" },
+        { "atom"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ATOM     },    .unit = "flags" },
+        { "sse4.1"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE4     },    .unit = "flags" },
+        { "sse4.2"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE42    },    .unit = "flags" },
+        { "avx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVX      },    .unit = "flags" },
+        { "avxslow" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVXSLOW  },    .unit = "flags" },
+        { "xop"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_XOP      },    .unit = "flags" },
+        { "fma3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_FMA3     },    .unit = "flags" },
+        { "fma4"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_FMA4     },    .unit = "flags" },
+        { "avx2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVX2     },    .unit = "flags" },
+        { "bmi1"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_BMI1     },    .unit = "flags" },
+        { "bmi2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_BMI2     },    .unit = "flags" },
+        { "3dnow"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_3DNOW    },    .unit = "flags" },
+        { "3dnowext", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_3DNOWEXT },    .unit = "flags" },
+        { "cmov",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_CMOV     },    .unit = "flags" },
+        { "aesni",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AESNI    },    .unit = "flags" },
+        { "avx512"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVX512   },    .unit = "flags" },
+
+#define CPU_FLAG_P2 AV_CPU_FLAG_CMOV | AV_CPU_FLAG_MMX
+#define CPU_FLAG_P3 CPU_FLAG_P2 | AV_CPU_FLAG_MMX2 | AV_CPU_FLAG_SSE
+#define CPU_FLAG_P4 CPU_FLAG_P3| AV_CPU_FLAG_SSE2
+        { "pentium2", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_P2          },    .unit = "flags" },
+        { "pentium3", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_P3          },    .unit = "flags" },
+        { "pentium4", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_P4          },    .unit = "flags" },
+
+#define CPU_FLAG_K62 AV_CPU_FLAG_MMX | AV_CPU_FLAG_3DNOW
+#define CPU_FLAG_ATHLON   CPU_FLAG_K62 | AV_CPU_FLAG_CMOV | AV_CPU_FLAG_3DNOWEXT | AV_CPU_FLAG_MMX2
+#define CPU_FLAG_ATHLONXP CPU_FLAG_ATHLON | AV_CPU_FLAG_SSE
+#define CPU_FLAG_K8  CPU_FLAG_ATHLONXP | AV_CPU_FLAG_SSE2
+        { "k6",       NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX      },    .unit = "flags" },
+        { "k62",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_K62         },    .unit = "flags" },
+        { "athlon",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_ATHLON      },    .unit = "flags" },
+        { "athlonxp", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_ATHLONXP    },    .unit = "flags" },
+        { "k8",       NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_K8          },    .unit = "flags" },
+#elif ARCH_ARM
+        { "armv5te",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV5TE  },    .unit = "flags" },
+        { "armv6",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6    },    .unit = "flags" },
+        { "armv6t2",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6T2  },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+        { "vfp_vm",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP_VM   },    .unit = "flags" },
+        { "vfpv3",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFPV3    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+        { "setend",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SETEND   },    .unit = "flags" },
+#elif ARCH_AARCH64
+        { "armv8",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV8    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+#endif
+        { NULL },
+    };
+    static const AVClass class = {
+        .class_name = "cpuflags",
+        .item_name  = av_default_item_name,
+        .option     = cpuflags_opts,
+        .version    = LIBAVUTIL_VERSION_INT,
+    };
+    const AVClass *pclass = &class;
+
+    return av_opt_eval_flags(&pclass, &cpuflags_opts[0], s, flags);
+}
+
+int av_cpu_count(void)
+{
+    static volatile int printed;
+
+    int nb_cpus = 1;
+#if HAVE_WINRT
+    SYSTEM_INFO sysinfo;
+#endif
+#if HAVE_SCHED_GETAFFINITY && defined(CPU_COUNT)
+    cpu_set_t cpuset;
+
+    CPU_ZERO(&cpuset);
+
+    if (!sched_getaffinity(0, sizeof(cpuset), &cpuset))
+        nb_cpus = CPU_COUNT(&cpuset);
+#elif HAVE_GETPROCESSAFFINITYMASK
+    DWORD_PTR proc_aff, sys_aff;
+    if (GetProcessAffinityMask(GetCurrentProcess(), &proc_aff, &sys_aff))
+        nb_cpus = av_popcount64(proc_aff);
+#elif HAVE_SYSCTL && defined(HW_NCPU)
+    int mib[2] = { CTL_HW, HW_NCPU };
+    size_t len = sizeof(nb_cpus);
+
+    if (sysctl(mib, 2, &nb_cpus, &len, NULL, 0) == -1)
+        nb_cpus = 0;
+#elif HAVE_SYSCONF && defined(_SC_NPROC_ONLN)
+    nb_cpus = sysconf(_SC_NPROC_ONLN);
+#elif HAVE_SYSCONF && defined(_SC_NPROCESSORS_ONLN)
+    nb_cpus = sysconf(_SC_NPROCESSORS_ONLN);
+#elif HAVE_WINRT
+    GetNativeSystemInfo(&sysinfo);
+    nb_cpus = sysinfo.dwNumberOfProcessors;
+#endif
+
+    if (!printed) {
+        av_log(NULL, AV_LOG_DEBUG, "detected %d logical cores\n", nb_cpus);
+        printed = 1;
+    }
+
+    return nb_cpus;
+}
+
+size_t av_cpu_max_align(void)
+{
+    if (ARCH_AARCH64)
+        return ff_get_cpu_max_align_aarch64();
+    if (ARCH_ARM)
+        return ff_get_cpu_max_align_arm();
+    if (ARCH_PPC)
+        return ff_get_cpu_max_align_ppc();
+    if (ARCH_X86)
+        return ff_get_cpu_max_align_x86();
+
+    return 8;
+}
diff -Naur chromium-67.0.3396.62/third_party/ffmpeg/libavutil/timer.h chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/timer.h
--- chromium-67.0.3396.62/third_party/ffmpeg/libavutil/timer.h	2018-05-30 11:44:29.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/timer.h	2018-06-06 10:06:12.361134439 +0300
@@ -49,13 +49,13 @@
 #include "log.h"
 
 #if   ARCH_AARCH64
-#   include "aarch64/timer.h"
+#   include "libavutil/aarch64/timer.h"
 #elif ARCH_ARM
-#   include "arm/timer.h"
+#   include "libavutil/arm/timer.h"
 #elif ARCH_PPC
-#   include "ppc/timer.h"
+#   include "libavutil/ppc/timer.h"
 #elif ARCH_X86
-#   include "x86/timer.h"
+#   include "libavutil/x86/timer.h"
 #endif
 
 #if !defined(AV_READ_TIME)
diff -Naur chromium-67.0.3396.62/third_party/ffmpeg/libavutil/timer.h.pathfix chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/timer.h.pathfix
--- chromium-67.0.3396.62/third_party/ffmpeg/libavutil/timer.h.pathfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/ffmpeg/libavutil/timer.h.pathfix	2018-05-30 11:44:29.000000000 +0300
@@ -0,0 +1,141 @@
+/*
+ * copyright (c) 2006 Michael Niedermayer <michaelni@gmx.at>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * high precision timer, useful to profile code
+ */
+
+#ifndef AVUTIL_TIMER_H
+#define AVUTIL_TIMER_H
+
+#include "config.h"
+
+#if CONFIG_LINUX_PERF
+# ifndef _GNU_SOURCE
+#  define _GNU_SOURCE
+# endif
+# include <unistd.h> // read(3)
+# include <sys/ioctl.h>
+# include <asm/unistd.h>
+# include <linux/perf_event.h>
+#endif
+
+#include <stdlib.h>
+#include <stdint.h>
+#include <inttypes.h>
+
+#if HAVE_MACH_ABSOLUTE_TIME
+#include <mach/mach_time.h>
+#endif
+
+#include "log.h"
+
+#if   ARCH_AARCH64
+#   include "aarch64/timer.h"
+#elif ARCH_ARM
+#   include "arm/timer.h"
+#elif ARCH_PPC
+#   include "ppc/timer.h"
+#elif ARCH_X86
+#   include "x86/timer.h"
+#endif
+
+#if !defined(AV_READ_TIME)
+#   if HAVE_GETHRTIME
+#       define AV_READ_TIME gethrtime
+#   elif HAVE_MACH_ABSOLUTE_TIME
+#       define AV_READ_TIME mach_absolute_time
+#   endif
+#endif
+
+#ifndef FF_TIMER_UNITS
+#   define FF_TIMER_UNITS "UNITS"
+#endif
+
+#define TIMER_REPORT(id, tdiff)                                           \
+    {                                                                     \
+        static uint64_t tsum   = 0;                                       \
+        static int tcount      = 0;                                       \
+        static int tskip_count = 0;                                       \
+        static int thistogram[32] = {0};                                  \
+        thistogram[av_log2(tdiff)]++;                                     \
+        if (tcount < 2                ||                                  \
+            (tdiff) < 8 * tsum / tcount ||                                \
+            (tdiff) < 2000) {                                             \
+            tsum += (tdiff);                                              \
+            tcount++;                                                     \
+        } else                                                            \
+            tskip_count++;                                                \
+        if (((tcount + tskip_count) & (tcount + tskip_count - 1)) == 0) { \
+            int i;                                                        \
+            av_log(NULL, AV_LOG_ERROR,                                    \
+                   "%7"PRIu64" " FF_TIMER_UNITS " in %s,%8d runs,%7d skips",          \
+                   tsum * 10 / tcount, id, tcount, tskip_count);          \
+            for (i = 0; i < 32; i++)                                      \
+                av_log(NULL, AV_LOG_VERBOSE, " %2d", av_log2(2*thistogram[i]));\
+            av_log(NULL, AV_LOG_ERROR, "\n");                             \
+        }                                                                 \
+    }
+
+#if CONFIG_LINUX_PERF
+
+#define START_TIMER                                                         \
+    static int linux_perf_fd;                                               \
+    uint64_t tperf;                                                         \
+    if (!linux_perf_fd) {                                                   \
+        struct perf_event_attr attr = {                                     \
+            .type           = PERF_TYPE_HARDWARE,                           \
+            .size           = sizeof(struct perf_event_attr),               \
+            .config         = PERF_COUNT_HW_CPU_CYCLES,                     \
+            .disabled       = 1,                                            \
+            .exclude_kernel = 1,                                            \
+            .exclude_hv     = 1,                                            \
+        };                                                                  \
+        linux_perf_fd = syscall(__NR_perf_event_open, &attr,                \
+                                0, -1, -1, 0);                              \
+    }                                                                       \
+    if (linux_perf_fd == -1) {                                              \
+        av_log(NULL, AV_LOG_ERROR, "perf_event_open failed: %s\n",          \
+               av_err2str(AVERROR(errno)));                                 \
+    } else {                                                                \
+        ioctl(linux_perf_fd, PERF_EVENT_IOC_RESET, 0);                      \
+        ioctl(linux_perf_fd, PERF_EVENT_IOC_ENABLE, 0);                     \
+    }
+
+#define STOP_TIMER(id)                                                      \
+    ioctl(linux_perf_fd, PERF_EVENT_IOC_DISABLE, 0);                        \
+    read(linux_perf_fd, &tperf, sizeof(tperf));                             \
+    TIMER_REPORT(id, tperf)
+
+#elif defined(AV_READ_TIME)
+#define START_TIMER                             \
+    uint64_t tend;                              \
+    uint64_t tstart = AV_READ_TIME();           \
+
+#define STOP_TIMER(id)                                                    \
+    tend = AV_READ_TIME();                                                \
+    TIMER_REPORT(id, tend - tstart)
+#else
+#define START_TIMER
+#define STOP_TIMER(id) { }
+#endif
+
+#endif /* AVUTIL_TIMER_H */
diff -Naur chromium-67.0.3396.62/third_party/libjpeg_turbo/jpeglib.h chromium-67.0.3396.62.patched/third_party/libjpeg_turbo/jpeglib.h
--- chromium-67.0.3396.62/third_party/libjpeg_turbo/jpeglib.h	2018-05-30 11:44:29.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/libjpeg_turbo/jpeglib.h	2018-06-06 10:06:12.361134439 +0300
@@ -18,10 +18,6 @@
 #ifndef JPEGLIB_H
 #define JPEGLIB_H
 
-/* Begin chromium edits */
-#include "jpeglibmangler.h"
-/* End chromium edits */
-
 /*
  * First we include the configuration files that record how this
  * installation of the JPEG library is set up.  jconfig.h can be
diff -Naur chromium-67.0.3396.62/third_party/libjpeg_turbo/jpeglib.h.nomangle chromium-67.0.3396.62.patched/third_party/libjpeg_turbo/jpeglib.h.nomangle
--- chromium-67.0.3396.62/third_party/libjpeg_turbo/jpeglib.h.nomangle	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/libjpeg_turbo/jpeglib.h.nomangle	2018-05-30 11:44:29.000000000 +0300
@@ -0,0 +1,1126 @@
+/*
+ * jpeglib.h
+ *
+ * This file was part of the Independent JPEG Group's software:
+ * Copyright (C) 1991-1998, Thomas G. Lane.
+ * Modified 2002-2009 by Guido Vollbeding.
+ * libjpeg-turbo Modifications:
+ * Copyright (C) 2009-2011, 2013-2014, 2016, D. R. Commander.
+ * Copyright (C) 2015, Google, Inc.
+ * For conditions of distribution and use, see the accompanying README.ijg
+ * file.
+ *
+ * This file defines the application interface for the JPEG library.
+ * Most applications using the library need only include this file,
+ * and perhaps jerror.h if they want to know the exact error codes.
+ */
+
+#ifndef JPEGLIB_H
+#define JPEGLIB_H
+
+/* Begin chromium edits */
+#include "jpeglibmangler.h"
+/* End chromium edits */
+
+/*
+ * First we include the configuration files that record how this
+ * installation of the JPEG library is set up.  jconfig.h can be
+ * generated automatically for many systems.  jmorecfg.h contains
+ * manual configuration options that most people need not worry about.
+ */
+
+#ifndef JCONFIG_INCLUDED        /* in case jinclude.h already did */
+#include "jconfig.h"            /* widely used configuration options */
+#endif
+#include "jmorecfg.h"           /* seldom changed options */
+
+
+#ifdef __cplusplus
+#ifndef DONT_USE_EXTERN_C
+extern "C" {
+#endif
+#endif
+
+
+/* Various constants determining the sizes of things.
+ * All of these are specified by the JPEG standard, so don't change them
+ * if you want to be compatible.
+ */
+
+#define DCTSIZE             8   /* The basic DCT block is 8x8 samples */
+#define DCTSIZE2            64  /* DCTSIZE squared; # of elements in a block */
+#define NUM_QUANT_TBLS      4   /* Quantization tables are numbered 0..3 */
+#define NUM_HUFF_TBLS       4   /* Huffman tables are numbered 0..3 */
+#define NUM_ARITH_TBLS      16  /* Arith-coding tables are numbered 0..15 */
+#define MAX_COMPS_IN_SCAN   4   /* JPEG limit on # of components in one scan */
+#define MAX_SAMP_FACTOR     4   /* JPEG limit on sampling factors */
+/* Unfortunately, some bozo at Adobe saw no reason to be bound by the standard;
+ * the PostScript DCT filter can emit files with many more than 10 blocks/MCU.
+ * If you happen to run across such a file, you can up D_MAX_BLOCKS_IN_MCU
+ * to handle it.  We even let you do this from the jconfig.h file.  However,
+ * we strongly discourage changing C_MAX_BLOCKS_IN_MCU; just because Adobe
+ * sometimes emits noncompliant files doesn't mean you should too.
+ */
+#define C_MAX_BLOCKS_IN_MCU   10 /* compressor's limit on blocks per MCU */
+#ifndef D_MAX_BLOCKS_IN_MCU
+#define D_MAX_BLOCKS_IN_MCU   10 /* decompressor's limit on blocks per MCU */
+#endif
+
+
+/* Data structures for images (arrays of samples and of DCT coefficients).
+ */
+
+typedef JSAMPLE *JSAMPROW;      /* ptr to one image row of pixel samples. */
+typedef JSAMPROW *JSAMPARRAY;   /* ptr to some rows (a 2-D sample array) */
+typedef JSAMPARRAY *JSAMPIMAGE; /* a 3-D sample array: top index is color */
+
+typedef JCOEF JBLOCK[DCTSIZE2]; /* one block of coefficients */
+typedef JBLOCK *JBLOCKROW;      /* pointer to one row of coefficient blocks */
+typedef JBLOCKROW *JBLOCKARRAY;         /* a 2-D array of coefficient blocks */
+typedef JBLOCKARRAY *JBLOCKIMAGE;       /* a 3-D array of coefficient blocks */
+
+typedef JCOEF *JCOEFPTR;        /* useful in a couple of places */
+
+
+/* Types for JPEG compression parameters and working tables. */
+
+
+/* DCT coefficient quantization tables. */
+
+typedef struct {
+  /* This array gives the coefficient quantizers in natural array order
+   * (not the zigzag order in which they are stored in a JPEG DQT marker).
+   * CAUTION: IJG versions prior to v6a kept this array in zigzag order.
+   */
+  UINT16 quantval[DCTSIZE2];    /* quantization step for each coefficient */
+  /* This field is used only during compression.  It's initialized FALSE when
+   * the table is created, and set TRUE when it's been output to the file.
+   * You could suppress output of a table by setting this to TRUE.
+   * (See jpeg_suppress_tables for an example.)
+   */
+  boolean sent_table;           /* TRUE when table has been output */
+} JQUANT_TBL;
+
+
+/* Huffman coding tables. */
+
+typedef struct {
+  /* These two fields directly represent the contents of a JPEG DHT marker */
+  UINT8 bits[17];               /* bits[k] = # of symbols with codes of */
+                                /* length k bits; bits[0] is unused */
+  UINT8 huffval[256];           /* The symbols, in order of incr code length */
+  /* This field is used only during compression.  It's initialized FALSE when
+   * the table is created, and set TRUE when it's been output to the file.
+   * You could suppress output of a table by setting this to TRUE.
+   * (See jpeg_suppress_tables for an example.)
+   */
+  boolean sent_table;           /* TRUE when table has been output */
+} JHUFF_TBL;
+
+
+/* Basic info about one component (color channel). */
+
+typedef struct {
+  /* These values are fixed over the whole image. */
+  /* For compression, they must be supplied by parameter setup; */
+  /* for decompression, they are read from the SOF marker. */
+  int component_id;             /* identifier for this component (0..255) */
+  int component_index;          /* its index in SOF or cinfo->comp_info[] */
+  int h_samp_factor;            /* horizontal sampling factor (1..4) */
+  int v_samp_factor;            /* vertical sampling factor (1..4) */
+  int quant_tbl_no;             /* quantization table selector (0..3) */
+  /* These values may vary between scans. */
+  /* For compression, they must be supplied by parameter setup; */
+  /* for decompression, they are read from the SOS marker. */
+  /* The decompressor output side may not use these variables. */
+  int dc_tbl_no;                /* DC entropy table selector (0..3) */
+  int ac_tbl_no;                /* AC entropy table selector (0..3) */
+
+  /* Remaining fields should be treated as private by applications. */
+
+  /* These values are computed during compression or decompression startup: */
+  /* Component's size in DCT blocks.
+   * Any dummy blocks added to complete an MCU are not counted; therefore
+   * these values do not depend on whether a scan is interleaved or not.
+   */
+  JDIMENSION width_in_blocks;
+  JDIMENSION height_in_blocks;
+  /* Size of a DCT block in samples.  Always DCTSIZE for compression.
+   * For decompression this is the size of the output from one DCT block,
+   * reflecting any scaling we choose to apply during the IDCT step.
+   * Values from 1 to 16 are supported.
+   * Note that different components may receive different IDCT scalings.
+   */
+#if JPEG_LIB_VERSION >= 70
+  int DCT_h_scaled_size;
+  int DCT_v_scaled_size;
+#else
+  int DCT_scaled_size;
+#endif
+  /* The downsampled dimensions are the component's actual, unpadded number
+   * of samples at the main buffer (preprocessing/compression interface), thus
+   * downsampled_width = ceil(image_width * Hi/Hmax)
+   * and similarly for height.  For decompression, IDCT scaling is included, so
+   * downsampled_width = ceil(image_width * Hi/Hmax * DCT_[h_]scaled_size/DCTSIZE)
+   */
+  JDIMENSION downsampled_width;  /* actual width in samples */
+  JDIMENSION downsampled_height; /* actual height in samples */
+  /* This flag is used only for decompression.  In cases where some of the
+   * components will be ignored (eg grayscale output from YCbCr image),
+   * we can skip most computations for the unused components.
+   */
+  boolean component_needed;     /* do we need the value of this component? */
+
+  /* These values are computed before starting a scan of the component. */
+  /* The decompressor output side may not use these variables. */
+  int MCU_width;                /* number of blocks per MCU, horizontally */
+  int MCU_height;               /* number of blocks per MCU, vertically */
+  int MCU_blocks;               /* MCU_width * MCU_height */
+  int MCU_sample_width;         /* MCU width in samples, MCU_width*DCT_[h_]scaled_size */
+  int last_col_width;           /* # of non-dummy blocks across in last MCU */
+  int last_row_height;          /* # of non-dummy blocks down in last MCU */
+
+  /* Saved quantization table for component; NULL if none yet saved.
+   * See jdinput.c comments about the need for this information.
+   * This field is currently used only for decompression.
+   */
+  JQUANT_TBL *quant_table;
+
+  /* Private per-component storage for DCT or IDCT subsystem. */
+  void *dct_table;
+} jpeg_component_info;
+
+
+/* The script for encoding a multiple-scan file is an array of these: */
+
+typedef struct {
+  int comps_in_scan;            /* number of components encoded in this scan */
+  int component_index[MAX_COMPS_IN_SCAN]; /* their SOF/comp_info[] indexes */
+  int Ss, Se;                   /* progressive JPEG spectral selection parms */
+  int Ah, Al;                   /* progressive JPEG successive approx. parms */
+} jpeg_scan_info;
+
+/* The decompressor can save APPn and COM markers in a list of these: */
+
+typedef struct jpeg_marker_struct *jpeg_saved_marker_ptr;
+
+struct jpeg_marker_struct {
+  jpeg_saved_marker_ptr next;   /* next in list, or NULL */
+  UINT8 marker;                 /* marker code: JPEG_COM, or JPEG_APP0+n */
+  unsigned int original_length; /* # bytes of data in the file */
+  unsigned int data_length;     /* # bytes of data saved at data[] */
+  JOCTET *data;                 /* the data contained in the marker */
+  /* the marker length word is not counted in data_length or original_length */
+};
+
+/* Known color spaces. */
+
+#define JCS_EXTENSIONS 1
+#define JCS_ALPHA_EXTENSIONS 1
+
+typedef enum {
+  JCS_UNKNOWN,            /* error/unspecified */
+  JCS_GRAYSCALE,          /* monochrome */
+  JCS_RGB,                /* red/green/blue as specified by the RGB_RED,
+                             RGB_GREEN, RGB_BLUE, and RGB_PIXELSIZE macros */
+  JCS_YCbCr,              /* Y/Cb/Cr (also known as YUV) */
+  JCS_CMYK,               /* C/M/Y/K */
+  JCS_YCCK,               /* Y/Cb/Cr/K */
+  JCS_EXT_RGB,            /* red/green/blue */
+  JCS_EXT_RGBX,           /* red/green/blue/x */
+  JCS_EXT_BGR,            /* blue/green/red */
+  JCS_EXT_BGRX,           /* blue/green/red/x */
+  JCS_EXT_XBGR,           /* x/blue/green/red */
+  JCS_EXT_XRGB,           /* x/red/green/blue */
+  /* When out_color_space it set to JCS_EXT_RGBX, JCS_EXT_BGRX, JCS_EXT_XBGR,
+     or JCS_EXT_XRGB during decompression, the X byte is undefined, and in
+     order to ensure the best performance, libjpeg-turbo can set that byte to
+     whatever value it wishes.  Use the following colorspace constants to
+     ensure that the X byte is set to 0xFF, so that it can be interpreted as an
+     opaque alpha channel. */
+  JCS_EXT_RGBA,           /* red/green/blue/alpha */
+  JCS_EXT_BGRA,           /* blue/green/red/alpha */
+  JCS_EXT_ABGR,           /* alpha/blue/green/red */
+  JCS_EXT_ARGB,           /* alpha/red/green/blue */
+  JCS_RGB565              /* 5-bit red/6-bit green/5-bit blue */
+} J_COLOR_SPACE;
+
+/* DCT/IDCT algorithm options. */
+
+typedef enum {
+  JDCT_ISLOW,             /* slow but accurate integer algorithm */
+  JDCT_IFAST,             /* faster, less accurate integer method */
+  JDCT_FLOAT              /* floating-point: accurate, fast on fast HW */
+} J_DCT_METHOD;
+
+#ifndef JDCT_DEFAULT            /* may be overridden in jconfig.h */
+#define JDCT_DEFAULT  JDCT_ISLOW
+#endif
+#ifndef JDCT_FASTEST            /* may be overridden in jconfig.h */
+#define JDCT_FASTEST  JDCT_IFAST
+#endif
+
+/* Dithering options for decompression. */
+
+typedef enum {
+  JDITHER_NONE,           /* no dithering */
+  JDITHER_ORDERED,        /* simple ordered dither */
+  JDITHER_FS              /* Floyd-Steinberg error diffusion dither */
+} J_DITHER_MODE;
+
+
+/* Common fields between JPEG compression and decompression master structs. */
+
+#define jpeg_common_fields \
+  struct jpeg_error_mgr *err;   /* Error handler module */\
+  struct jpeg_memory_mgr *mem;  /* Memory manager module */\
+  struct jpeg_progress_mgr *progress; /* Progress monitor, or NULL if none */\
+  void *client_data;            /* Available for use by application */\
+  boolean is_decompressor;      /* So common code can tell which is which */\
+  int global_state              /* For checking call sequence validity */
+
+/* Routines that are to be used by both halves of the library are declared
+ * to receive a pointer to this structure.  There are no actual instances of
+ * jpeg_common_struct, only of jpeg_compress_struct and jpeg_decompress_struct.
+ */
+struct jpeg_common_struct {
+  jpeg_common_fields;           /* Fields common to both master struct types */
+  /* Additional fields follow in an actual jpeg_compress_struct or
+   * jpeg_decompress_struct.  All three structs must agree on these
+   * initial fields!  (This would be a lot cleaner in C++.)
+   */
+};
+
+typedef struct jpeg_common_struct *j_common_ptr;
+typedef struct jpeg_compress_struct *j_compress_ptr;
+typedef struct jpeg_decompress_struct *j_decompress_ptr;
+
+
+/* Master record for a compression instance */
+
+struct jpeg_compress_struct {
+  jpeg_common_fields;           /* Fields shared with jpeg_decompress_struct */
+
+  /* Destination for compressed data */
+  struct jpeg_destination_mgr *dest;
+
+  /* Description of source image --- these fields must be filled in by
+   * outer application before starting compression.  in_color_space must
+   * be correct before you can even call jpeg_set_defaults().
+   */
+
+  JDIMENSION image_width;       /* input image width */
+  JDIMENSION image_height;      /* input image height */
+  int input_components;         /* # of color components in input image */
+  J_COLOR_SPACE in_color_space; /* colorspace of input image */
+
+  double input_gamma;           /* image gamma of input image */
+
+  /* Compression parameters --- these fields must be set before calling
+   * jpeg_start_compress().  We recommend calling jpeg_set_defaults() to
+   * initialize everything to reasonable defaults, then changing anything
+   * the application specifically wants to change.  That way you won't get
+   * burnt when new parameters are added.  Also note that there are several
+   * helper routines to simplify changing parameters.
+   */
+
+#if JPEG_LIB_VERSION >= 70
+  unsigned int scale_num, scale_denom; /* fraction by which to scale image */
+
+  JDIMENSION jpeg_width;        /* scaled JPEG image width */
+  JDIMENSION jpeg_height;       /* scaled JPEG image height */
+  /* Dimensions of actual JPEG image that will be written to file,
+   * derived from input dimensions by scaling factors above.
+   * These fields are computed by jpeg_start_compress().
+   * You can also use jpeg_calc_jpeg_dimensions() to determine these values
+   * in advance of calling jpeg_start_compress().
+   */
+#endif
+
+  int data_precision;           /* bits of precision in image data */
+
+  int num_components;           /* # of color components in JPEG image */
+  J_COLOR_SPACE jpeg_color_space; /* colorspace of JPEG image */
+
+  jpeg_component_info *comp_info;
+  /* comp_info[i] describes component that appears i'th in SOF */
+
+  JQUANT_TBL *quant_tbl_ptrs[NUM_QUANT_TBLS];
+#if JPEG_LIB_VERSION >= 70
+  int q_scale_factor[NUM_QUANT_TBLS];
+#endif
+  /* ptrs to coefficient quantization tables, or NULL if not defined,
+   * and corresponding scale factors (percentage, initialized 100).
+   */
+
+  JHUFF_TBL *dc_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  JHUFF_TBL *ac_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  /* ptrs to Huffman coding tables, or NULL if not defined */
+
+  UINT8 arith_dc_L[NUM_ARITH_TBLS]; /* L values for DC arith-coding tables */
+  UINT8 arith_dc_U[NUM_ARITH_TBLS]; /* U values for DC arith-coding tables */
+  UINT8 arith_ac_K[NUM_ARITH_TBLS]; /* Kx values for AC arith-coding tables */
+
+  int num_scans;                /* # of entries in scan_info array */
+  const jpeg_scan_info *scan_info; /* script for multi-scan file, or NULL */
+  /* The default value of scan_info is NULL, which causes a single-scan
+   * sequential JPEG file to be emitted.  To create a multi-scan file,
+   * set num_scans and scan_info to point to an array of scan definitions.
+   */
+
+  boolean raw_data_in;          /* TRUE=caller supplies downsampled data */
+  boolean arith_code;           /* TRUE=arithmetic coding, FALSE=Huffman */
+  boolean optimize_coding;      /* TRUE=optimize entropy encoding parms */
+  boolean CCIR601_sampling;     /* TRUE=first samples are cosited */
+#if JPEG_LIB_VERSION >= 70
+  boolean do_fancy_downsampling; /* TRUE=apply fancy downsampling */
+#endif
+  int smoothing_factor;         /* 1..100, or 0 for no input smoothing */
+  J_DCT_METHOD dct_method;      /* DCT algorithm selector */
+
+  /* The restart interval can be specified in absolute MCUs by setting
+   * restart_interval, or in MCU rows by setting restart_in_rows
+   * (in which case the correct restart_interval will be figured
+   * for each scan).
+   */
+  unsigned int restart_interval; /* MCUs per restart, or 0 for no restart */
+  int restart_in_rows;          /* if > 0, MCU rows per restart interval */
+
+  /* Parameters controlling emission of special markers. */
+
+  boolean write_JFIF_header;    /* should a JFIF marker be written? */
+  UINT8 JFIF_major_version;     /* What to write for the JFIF version number */
+  UINT8 JFIF_minor_version;
+  /* These three values are not used by the JPEG code, merely copied */
+  /* into the JFIF APP0 marker.  density_unit can be 0 for unknown, */
+  /* 1 for dots/inch, or 2 for dots/cm.  Note that the pixel aspect */
+  /* ratio is defined by X_density/Y_density even when density_unit=0. */
+  UINT8 density_unit;           /* JFIF code for pixel size units */
+  UINT16 X_density;             /* Horizontal pixel density */
+  UINT16 Y_density;             /* Vertical pixel density */
+  boolean write_Adobe_marker;   /* should an Adobe marker be written? */
+
+  /* State variable: index of next scanline to be written to
+   * jpeg_write_scanlines().  Application may use this to control its
+   * processing loop, e.g., "while (next_scanline < image_height)".
+   */
+
+  JDIMENSION next_scanline;     /* 0 .. image_height-1  */
+
+  /* Remaining fields are known throughout compressor, but generally
+   * should not be touched by a surrounding application.
+   */
+
+  /*
+   * These fields are computed during compression startup
+   */
+  boolean progressive_mode;     /* TRUE if scan script uses progressive mode */
+  int max_h_samp_factor;        /* largest h_samp_factor */
+  int max_v_samp_factor;        /* largest v_samp_factor */
+
+#if JPEG_LIB_VERSION >= 70
+  int min_DCT_h_scaled_size;    /* smallest DCT_h_scaled_size of any component */
+  int min_DCT_v_scaled_size;    /* smallest DCT_v_scaled_size of any component */
+#endif
+
+  JDIMENSION total_iMCU_rows;   /* # of iMCU rows to be input to coef ctlr */
+  /* The coefficient controller receives data in units of MCU rows as defined
+   * for fully interleaved scans (whether the JPEG file is interleaved or not).
+   * There are v_samp_factor * DCTSIZE sample rows of each component in an
+   * "iMCU" (interleaved MCU) row.
+   */
+
+  /*
+   * These fields are valid during any one scan.
+   * They describe the components and MCUs actually appearing in the scan.
+   */
+  int comps_in_scan;            /* # of JPEG components in this scan */
+  jpeg_component_info *cur_comp_info[MAX_COMPS_IN_SCAN];
+  /* *cur_comp_info[i] describes component that appears i'th in SOS */
+
+  JDIMENSION MCUs_per_row;      /* # of MCUs across the image */
+  JDIMENSION MCU_rows_in_scan;  /* # of MCU rows in the image */
+
+  int blocks_in_MCU;            /* # of DCT blocks per MCU */
+  int MCU_membership[C_MAX_BLOCKS_IN_MCU];
+  /* MCU_membership[i] is index in cur_comp_info of component owning */
+  /* i'th block in an MCU */
+
+  int Ss, Se, Ah, Al;           /* progressive JPEG parameters for scan */
+
+#if JPEG_LIB_VERSION >= 80
+  int block_size;               /* the basic DCT block size: 1..16 */
+  const int *natural_order;     /* natural-order position array */
+  int lim_Se;                   /* min( Se, DCTSIZE2-1 ) */
+#endif
+
+  /*
+   * Links to compression subobjects (methods and private variables of modules)
+   */
+  struct jpeg_comp_master *master;
+  struct jpeg_c_main_controller *main;
+  struct jpeg_c_prep_controller *prep;
+  struct jpeg_c_coef_controller *coef;
+  struct jpeg_marker_writer *marker;
+  struct jpeg_color_converter *cconvert;
+  struct jpeg_downsampler *downsample;
+  struct jpeg_forward_dct *fdct;
+  struct jpeg_entropy_encoder *entropy;
+  jpeg_scan_info *script_space; /* workspace for jpeg_simple_progression */
+  int script_space_size;
+};
+
+
+/* Master record for a decompression instance */
+
+struct jpeg_decompress_struct {
+  jpeg_common_fields;           /* Fields shared with jpeg_compress_struct */
+
+  /* Source of compressed data */
+  struct jpeg_source_mgr *src;
+
+  /* Basic description of image --- filled in by jpeg_read_header(). */
+  /* Application may inspect these values to decide how to process image. */
+
+  JDIMENSION image_width;       /* nominal image width (from SOF marker) */
+  JDIMENSION image_height;      /* nominal image height */
+  int num_components;           /* # of color components in JPEG image */
+  J_COLOR_SPACE jpeg_color_space; /* colorspace of JPEG image */
+
+  /* Decompression processing parameters --- these fields must be set before
+   * calling jpeg_start_decompress().  Note that jpeg_read_header() initializes
+   * them to default values.
+   */
+
+  J_COLOR_SPACE out_color_space; /* colorspace for output */
+
+  unsigned int scale_num, scale_denom; /* fraction by which to scale image */
+
+  double output_gamma;          /* image gamma wanted in output */
+
+  boolean buffered_image;       /* TRUE=multiple output passes */
+  boolean raw_data_out;         /* TRUE=downsampled data wanted */
+
+  J_DCT_METHOD dct_method;      /* IDCT algorithm selector */
+  boolean do_fancy_upsampling;  /* TRUE=apply fancy upsampling */
+  boolean do_block_smoothing;   /* TRUE=apply interblock smoothing */
+
+  boolean quantize_colors;      /* TRUE=colormapped output wanted */
+  /* the following are ignored if not quantize_colors: */
+  J_DITHER_MODE dither_mode;    /* type of color dithering to use */
+  boolean two_pass_quantize;    /* TRUE=use two-pass color quantization */
+  int desired_number_of_colors; /* max # colors to use in created colormap */
+  /* these are significant only in buffered-image mode: */
+  boolean enable_1pass_quant;   /* enable future use of 1-pass quantizer */
+  boolean enable_external_quant;/* enable future use of external colormap */
+  boolean enable_2pass_quant;   /* enable future use of 2-pass quantizer */
+
+  /* Description of actual output image that will be returned to application.
+   * These fields are computed by jpeg_start_decompress().
+   * You can also use jpeg_calc_output_dimensions() to determine these values
+   * in advance of calling jpeg_start_decompress().
+   */
+
+  JDIMENSION output_width;      /* scaled image width */
+  JDIMENSION output_height;     /* scaled image height */
+  int out_color_components;     /* # of color components in out_color_space */
+  int output_components;        /* # of color components returned */
+  /* output_components is 1 (a colormap index) when quantizing colors;
+   * otherwise it equals out_color_components.
+   */
+  int rec_outbuf_height;        /* min recommended height of scanline buffer */
+  /* If the buffer passed to jpeg_read_scanlines() is less than this many rows
+   * high, space and time will be wasted due to unnecessary data copying.
+   * Usually rec_outbuf_height will be 1 or 2, at most 4.
+   */
+
+  /* When quantizing colors, the output colormap is described by these fields.
+   * The application can supply a colormap by setting colormap non-NULL before
+   * calling jpeg_start_decompress; otherwise a colormap is created during
+   * jpeg_start_decompress or jpeg_start_output.
+   * The map has out_color_components rows and actual_number_of_colors columns.
+   */
+  int actual_number_of_colors;  /* number of entries in use */
+  JSAMPARRAY colormap;          /* The color map as a 2-D pixel array */
+
+  /* State variables: these variables indicate the progress of decompression.
+   * The application may examine these but must not modify them.
+   */
+
+  /* Row index of next scanline to be read from jpeg_read_scanlines().
+   * Application may use this to control its processing loop, e.g.,
+   * "while (output_scanline < output_height)".
+   */
+  JDIMENSION output_scanline;   /* 0 .. output_height-1  */
+
+  /* Current input scan number and number of iMCU rows completed in scan.
+   * These indicate the progress of the decompressor input side.
+   */
+  int input_scan_number;        /* Number of SOS markers seen so far */
+  JDIMENSION input_iMCU_row;    /* Number of iMCU rows completed */
+
+  /* The "output scan number" is the notional scan being displayed by the
+   * output side.  The decompressor will not allow output scan/row number
+   * to get ahead of input scan/row, but it can fall arbitrarily far behind.
+   */
+  int output_scan_number;       /* Nominal scan number being displayed */
+  JDIMENSION output_iMCU_row;   /* Number of iMCU rows read */
+
+  /* Current progression status.  coef_bits[c][i] indicates the precision
+   * with which component c's DCT coefficient i (in zigzag order) is known.
+   * It is -1 when no data has yet been received, otherwise it is the point
+   * transform (shift) value for the most recent scan of the coefficient
+   * (thus, 0 at completion of the progression).
+   * This pointer is NULL when reading a non-progressive file.
+   */
+  int (*coef_bits)[DCTSIZE2];   /* -1 or current Al value for each coef */
+
+  /* Internal JPEG parameters --- the application usually need not look at
+   * these fields.  Note that the decompressor output side may not use
+   * any parameters that can change between scans.
+   */
+
+  /* Quantization and Huffman tables are carried forward across input
+   * datastreams when processing abbreviated JPEG datastreams.
+   */
+
+  JQUANT_TBL *quant_tbl_ptrs[NUM_QUANT_TBLS];
+  /* ptrs to coefficient quantization tables, or NULL if not defined */
+
+  JHUFF_TBL *dc_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  JHUFF_TBL *ac_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  /* ptrs to Huffman coding tables, or NULL if not defined */
+
+  /* These parameters are never carried across datastreams, since they
+   * are given in SOF/SOS markers or defined to be reset by SOI.
+   */
+
+  int data_precision;           /* bits of precision in image data */
+
+  jpeg_component_info *comp_info;
+  /* comp_info[i] describes component that appears i'th in SOF */
+
+#if JPEG_LIB_VERSION >= 80
+  boolean is_baseline;          /* TRUE if Baseline SOF0 encountered */
+#endif
+  boolean progressive_mode;     /* TRUE if SOFn specifies progressive mode */
+  boolean arith_code;           /* TRUE=arithmetic coding, FALSE=Huffman */
+
+  UINT8 arith_dc_L[NUM_ARITH_TBLS]; /* L values for DC arith-coding tables */
+  UINT8 arith_dc_U[NUM_ARITH_TBLS]; /* U values for DC arith-coding tables */
+  UINT8 arith_ac_K[NUM_ARITH_TBLS]; /* Kx values for AC arith-coding tables */
+
+  unsigned int restart_interval; /* MCUs per restart interval, or 0 for no restart */
+
+  /* These fields record data obtained from optional markers recognized by
+   * the JPEG library.
+   */
+  boolean saw_JFIF_marker;      /* TRUE iff a JFIF APP0 marker was found */
+  /* Data copied from JFIF marker; only valid if saw_JFIF_marker is TRUE: */
+  UINT8 JFIF_major_version;     /* JFIF version number */
+  UINT8 JFIF_minor_version;
+  UINT8 density_unit;           /* JFIF code for pixel size units */
+  UINT16 X_density;             /* Horizontal pixel density */
+  UINT16 Y_density;             /* Vertical pixel density */
+  boolean saw_Adobe_marker;     /* TRUE iff an Adobe APP14 marker was found */
+  UINT8 Adobe_transform;        /* Color transform code from Adobe marker */
+
+  boolean CCIR601_sampling;     /* TRUE=first samples are cosited */
+
+  /* Aside from the specific data retained from APPn markers known to the
+   * library, the uninterpreted contents of any or all APPn and COM markers
+   * can be saved in a list for examination by the application.
+   */
+  jpeg_saved_marker_ptr marker_list; /* Head of list of saved markers */
+
+  /* Remaining fields are known throughout decompressor, but generally
+   * should not be touched by a surrounding application.
+   */
+
+  /*
+   * These fields are computed during decompression startup
+   */
+  int max_h_samp_factor;        /* largest h_samp_factor */
+  int max_v_samp_factor;        /* largest v_samp_factor */
+
+#if JPEG_LIB_VERSION >= 70
+  int min_DCT_h_scaled_size;    /* smallest DCT_h_scaled_size of any component */
+  int min_DCT_v_scaled_size;    /* smallest DCT_v_scaled_size of any component */
+#else
+  int min_DCT_scaled_size;      /* smallest DCT_scaled_size of any component */
+#endif
+
+  JDIMENSION total_iMCU_rows;   /* # of iMCU rows in image */
+  /* The coefficient controller's input and output progress is measured in
+   * units of "iMCU" (interleaved MCU) rows.  These are the same as MCU rows
+   * in fully interleaved JPEG scans, but are used whether the scan is
+   * interleaved or not.  We define an iMCU row as v_samp_factor DCT block
+   * rows of each component.  Therefore, the IDCT output contains
+   * v_samp_factor*DCT_[v_]scaled_size sample rows of a component per iMCU row.
+   */
+
+  JSAMPLE *sample_range_limit;  /* table for fast range-limiting */
+
+  /*
+   * These fields are valid during any one scan.
+   * They describe the components and MCUs actually appearing in the scan.
+   * Note that the decompressor output side must not use these fields.
+   */
+  int comps_in_scan;            /* # of JPEG components in this scan */
+  jpeg_component_info *cur_comp_info[MAX_COMPS_IN_SCAN];
+  /* *cur_comp_info[i] describes component that appears i'th in SOS */
+
+  JDIMENSION MCUs_per_row;      /* # of MCUs across the image */
+  JDIMENSION MCU_rows_in_scan;  /* # of MCU rows in the image */
+
+  int blocks_in_MCU;            /* # of DCT blocks per MCU */
+  int MCU_membership[D_MAX_BLOCKS_IN_MCU];
+  /* MCU_membership[i] is index in cur_comp_info of component owning */
+  /* i'th block in an MCU */
+
+  int Ss, Se, Ah, Al;           /* progressive JPEG parameters for scan */
+
+#if JPEG_LIB_VERSION >= 80
+  /* These fields are derived from Se of first SOS marker.
+   */
+  int block_size;               /* the basic DCT block size: 1..16 */
+  const int *natural_order; /* natural-order position array for entropy decode */
+  int lim_Se;                   /* min( Se, DCTSIZE2-1 ) for entropy decode */
+#endif
+
+  /* This field is shared between entropy decoder and marker parser.
+   * It is either zero or the code of a JPEG marker that has been
+   * read from the data source, but has not yet been processed.
+   */
+  int unread_marker;
+
+  /*
+   * Links to decompression subobjects (methods, private variables of modules)
+   */
+  struct jpeg_decomp_master *master;
+  struct jpeg_d_main_controller *main;
+  struct jpeg_d_coef_controller *coef;
+  struct jpeg_d_post_controller *post;
+  struct jpeg_input_controller *inputctl;
+  struct jpeg_marker_reader *marker;
+  struct jpeg_entropy_decoder *entropy;
+  struct jpeg_inverse_dct *idct;
+  struct jpeg_upsampler *upsample;
+  struct jpeg_color_deconverter *cconvert;
+  struct jpeg_color_quantizer *cquantize;
+};
+
+
+/* "Object" declarations for JPEG modules that may be supplied or called
+ * directly by the surrounding application.
+ * As with all objects in the JPEG library, these structs only define the
+ * publicly visible methods and state variables of a module.  Additional
+ * private fields may exist after the public ones.
+ */
+
+
+/* Error handler object */
+
+struct jpeg_error_mgr {
+  /* Error exit handler: does not return to caller */
+  void (*error_exit) (j_common_ptr cinfo);
+  /* Conditionally emit a trace or warning message */
+  void (*emit_message) (j_common_ptr cinfo, int msg_level);
+  /* Routine that actually outputs a trace or error message */
+  void (*output_message) (j_common_ptr cinfo);
+  /* Format a message string for the most recent JPEG error or message */
+  void (*format_message) (j_common_ptr cinfo, char *buffer);
+#define JMSG_LENGTH_MAX  200    /* recommended size of format_message buffer */
+  /* Reset error state variables at start of a new image */
+  void (*reset_error_mgr) (j_common_ptr cinfo);
+
+  /* The message ID code and any parameters are saved here.
+   * A message can have one string parameter or up to 8 int parameters.
+   */
+  int msg_code;
+#define JMSG_STR_PARM_MAX  80
+  union {
+    int i[8];
+    char s[JMSG_STR_PARM_MAX];
+  } msg_parm;
+
+  /* Standard state variables for error facility */
+
+  int trace_level;              /* max msg_level that will be displayed */
+
+  /* For recoverable corrupt-data errors, we emit a warning message,
+   * but keep going unless emit_message chooses to abort.  emit_message
+   * should count warnings in num_warnings.  The surrounding application
+   * can check for bad data by seeing if num_warnings is nonzero at the
+   * end of processing.
+   */
+  long num_warnings;            /* number of corrupt-data warnings */
+
+  /* These fields point to the table(s) of error message strings.
+   * An application can change the table pointer to switch to a different
+   * message list (typically, to change the language in which errors are
+   * reported).  Some applications may wish to add additional error codes
+   * that will be handled by the JPEG library error mechanism; the second
+   * table pointer is used for this purpose.
+   *
+   * First table includes all errors generated by JPEG library itself.
+   * Error code 0 is reserved for a "no such error string" message.
+   */
+  const char * const *jpeg_message_table; /* Library errors */
+  int last_jpeg_message;    /* Table contains strings 0..last_jpeg_message */
+  /* Second table can be added by application (see cjpeg/djpeg for example).
+   * It contains strings numbered first_addon_message..last_addon_message.
+   */
+  const char * const *addon_message_table; /* Non-library errors */
+  int first_addon_message;      /* code for first string in addon table */
+  int last_addon_message;       /* code for last string in addon table */
+};
+
+
+/* Progress monitor object */
+
+struct jpeg_progress_mgr {
+  void (*progress_monitor) (j_common_ptr cinfo);
+
+  long pass_counter;            /* work units completed in this pass */
+  long pass_limit;              /* total number of work units in this pass */
+  int completed_passes;         /* passes completed so far */
+  int total_passes;             /* total number of passes expected */
+};
+
+
+/* Data destination object for compression */
+
+struct jpeg_destination_mgr {
+  JOCTET *next_output_byte;     /* => next byte to write in buffer */
+  size_t free_in_buffer;        /* # of byte spaces remaining in buffer */
+
+  void (*init_destination) (j_compress_ptr cinfo);
+  boolean (*empty_output_buffer) (j_compress_ptr cinfo);
+  void (*term_destination) (j_compress_ptr cinfo);
+};
+
+
+/* Data source object for decompression */
+
+struct jpeg_source_mgr {
+  const JOCTET *next_input_byte; /* => next byte to read from buffer */
+  size_t bytes_in_buffer;       /* # of bytes remaining in buffer */
+
+  void (*init_source) (j_decompress_ptr cinfo);
+  boolean (*fill_input_buffer) (j_decompress_ptr cinfo);
+  void (*skip_input_data) (j_decompress_ptr cinfo, long num_bytes);
+  boolean (*resync_to_restart) (j_decompress_ptr cinfo, int desired);
+  void (*term_source) (j_decompress_ptr cinfo);
+};
+
+
+/* Memory manager object.
+ * Allocates "small" objects (a few K total), "large" objects (tens of K),
+ * and "really big" objects (virtual arrays with backing store if needed).
+ * The memory manager does not allow individual objects to be freed; rather,
+ * each created object is assigned to a pool, and whole pools can be freed
+ * at once.  This is faster and more convenient than remembering exactly what
+ * to free, especially where malloc()/free() are not too speedy.
+ * NB: alloc routines never return NULL.  They exit to error_exit if not
+ * successful.
+ */
+
+#define JPOOL_PERMANENT 0       /* lasts until master record is destroyed */
+#define JPOOL_IMAGE     1       /* lasts until done with image/datastream */
+#define JPOOL_NUMPOOLS  2
+
+typedef struct jvirt_sarray_control *jvirt_sarray_ptr;
+typedef struct jvirt_barray_control *jvirt_barray_ptr;
+
+
+struct jpeg_memory_mgr {
+  /* Method pointers */
+  void *(*alloc_small) (j_common_ptr cinfo, int pool_id, size_t sizeofobject);
+  void *(*alloc_large) (j_common_ptr cinfo, int pool_id,
+                        size_t sizeofobject);
+  JSAMPARRAY (*alloc_sarray) (j_common_ptr cinfo, int pool_id,
+                              JDIMENSION samplesperrow, JDIMENSION numrows);
+  JBLOCKARRAY (*alloc_barray) (j_common_ptr cinfo, int pool_id,
+                               JDIMENSION blocksperrow, JDIMENSION numrows);
+  jvirt_sarray_ptr (*request_virt_sarray) (j_common_ptr cinfo, int pool_id,
+                                           boolean pre_zero,
+                                           JDIMENSION samplesperrow,
+                                           JDIMENSION numrows,
+                                           JDIMENSION maxaccess);
+  jvirt_barray_ptr (*request_virt_barray) (j_common_ptr cinfo, int pool_id,
+                                           boolean pre_zero,
+                                           JDIMENSION blocksperrow,
+                                           JDIMENSION numrows,
+                                           JDIMENSION maxaccess);
+  void (*realize_virt_arrays) (j_common_ptr cinfo);
+  JSAMPARRAY (*access_virt_sarray) (j_common_ptr cinfo, jvirt_sarray_ptr ptr,
+                                    JDIMENSION start_row, JDIMENSION num_rows,
+                                    boolean writable);
+  JBLOCKARRAY (*access_virt_barray) (j_common_ptr cinfo, jvirt_barray_ptr ptr,
+                                     JDIMENSION start_row, JDIMENSION num_rows,
+                                     boolean writable);
+  void (*free_pool) (j_common_ptr cinfo, int pool_id);
+  void (*self_destruct) (j_common_ptr cinfo);
+
+  /* Limit on memory allocation for this JPEG object.  (Note that this is
+   * merely advisory, not a guaranteed maximum; it only affects the space
+   * used for virtual-array buffers.)  May be changed by outer application
+   * after creating the JPEG object.
+   */
+  long max_memory_to_use;
+
+  /* Maximum allocation request accepted by alloc_large. */
+  long max_alloc_chunk;
+};
+
+
+/* Routine signature for application-supplied marker processing methods.
+ * Need not pass marker code since it is stored in cinfo->unread_marker.
+ */
+typedef boolean (*jpeg_marker_parser_method) (j_decompress_ptr cinfo);
+
+
+/* Originally, this macro was used as a way of defining function prototypes
+ * for both modern compilers as well as older compilers that did not support
+ * prototype parameters.  libjpeg-turbo has never supported these older,
+ * non-ANSI compilers, but the macro is still included because there is some
+ * software out there that uses it.
+ */
+
+#define JPP(arglist)    arglist
+
+
+/* Default error-management setup */
+EXTERN(struct jpeg_error_mgr *) jpeg_std_error (struct jpeg_error_mgr *err);
+
+/* Initialization of JPEG compression objects.
+ * jpeg_create_compress() and jpeg_create_decompress() are the exported
+ * names that applications should call.  These expand to calls on
+ * jpeg_CreateCompress and jpeg_CreateDecompress with additional information
+ * passed for version mismatch checking.
+ * NB: you must set up the error-manager BEFORE calling jpeg_create_xxx.
+ */
+#define jpeg_create_compress(cinfo) \
+    jpeg_CreateCompress((cinfo), JPEG_LIB_VERSION, \
+                        (size_t) sizeof(struct jpeg_compress_struct))
+#define jpeg_create_decompress(cinfo) \
+    jpeg_CreateDecompress((cinfo), JPEG_LIB_VERSION, \
+                          (size_t) sizeof(struct jpeg_decompress_struct))
+EXTERN(void) jpeg_CreateCompress (j_compress_ptr cinfo, int version,
+                                  size_t structsize);
+EXTERN(void) jpeg_CreateDecompress (j_decompress_ptr cinfo, int version,
+                                    size_t structsize);
+/* Destruction of JPEG compression objects */
+EXTERN(void) jpeg_destroy_compress (j_compress_ptr cinfo);
+EXTERN(void) jpeg_destroy_decompress (j_decompress_ptr cinfo);
+
+/* Standard data source and destination managers: stdio streams. */
+/* Caller is responsible for opening the file before and closing after. */
+EXTERN(void) jpeg_stdio_dest (j_compress_ptr cinfo, FILE *outfile);
+EXTERN(void) jpeg_stdio_src (j_decompress_ptr cinfo, FILE *infile);
+
+#if JPEG_LIB_VERSION >= 80 || defined(MEM_SRCDST_SUPPORTED)
+/* Data source and destination managers: memory buffers. */
+EXTERN(void) jpeg_mem_dest (j_compress_ptr cinfo, unsigned char **outbuffer,
+                            unsigned long *outsize);
+EXTERN(void) jpeg_mem_src (j_decompress_ptr cinfo,
+                           const unsigned char *inbuffer,
+                           unsigned long insize);
+#endif
+
+/* Default parameter setup for compression */
+EXTERN(void) jpeg_set_defaults (j_compress_ptr cinfo);
+/* Compression parameter setup aids */
+EXTERN(void) jpeg_set_colorspace (j_compress_ptr cinfo,
+                                  J_COLOR_SPACE colorspace);
+EXTERN(void) jpeg_default_colorspace (j_compress_ptr cinfo);
+EXTERN(void) jpeg_set_quality (j_compress_ptr cinfo, int quality,
+                               boolean force_baseline);
+EXTERN(void) jpeg_set_linear_quality (j_compress_ptr cinfo, int scale_factor,
+                                      boolean force_baseline);
+#if JPEG_LIB_VERSION >= 70
+EXTERN(void) jpeg_default_qtables (j_compress_ptr cinfo,
+                                   boolean force_baseline);
+#endif
+EXTERN(void) jpeg_add_quant_table (j_compress_ptr cinfo, int which_tbl,
+                                   const unsigned int *basic_table,
+                                   int scale_factor, boolean force_baseline);
+EXTERN(int) jpeg_quality_scaling (int quality);
+EXTERN(void) jpeg_simple_progression (j_compress_ptr cinfo);
+EXTERN(void) jpeg_suppress_tables (j_compress_ptr cinfo, boolean suppress);
+EXTERN(JQUANT_TBL *) jpeg_alloc_quant_table (j_common_ptr cinfo);
+EXTERN(JHUFF_TBL *) jpeg_alloc_huff_table (j_common_ptr cinfo);
+
+/* Main entry points for compression */
+EXTERN(void) jpeg_start_compress (j_compress_ptr cinfo,
+                                  boolean write_all_tables);
+EXTERN(JDIMENSION) jpeg_write_scanlines (j_compress_ptr cinfo,
+                                         JSAMPARRAY scanlines,
+                                         JDIMENSION num_lines);
+EXTERN(void) jpeg_finish_compress (j_compress_ptr cinfo);
+
+#if JPEG_LIB_VERSION >= 70
+/* Precalculate JPEG dimensions for current compression parameters. */
+EXTERN(void) jpeg_calc_jpeg_dimensions (j_compress_ptr cinfo);
+#endif
+
+/* Replaces jpeg_write_scanlines when writing raw downsampled data. */
+EXTERN(JDIMENSION) jpeg_write_raw_data (j_compress_ptr cinfo, JSAMPIMAGE data,
+                                        JDIMENSION num_lines);
+
+/* Write a special marker.  See libjpeg.txt concerning safe usage. */
+EXTERN(void) jpeg_write_marker (j_compress_ptr cinfo, int marker,
+                                const JOCTET *dataptr, unsigned int datalen);
+/* Same, but piecemeal. */
+EXTERN(void) jpeg_write_m_header (j_compress_ptr cinfo, int marker,
+                                  unsigned int datalen);
+EXTERN(void) jpeg_write_m_byte (j_compress_ptr cinfo, int val);
+
+/* Alternate compression function: just write an abbreviated table file */
+EXTERN(void) jpeg_write_tables (j_compress_ptr cinfo);
+
+/* Decompression startup: read start of JPEG datastream to see what's there */
+EXTERN(int) jpeg_read_header (j_decompress_ptr cinfo, boolean require_image);
+/* Return value is one of: */
+#define JPEG_SUSPENDED          0 /* Suspended due to lack of input data */
+#define JPEG_HEADER_OK          1 /* Found valid image datastream */
+#define JPEG_HEADER_TABLES_ONLY 2 /* Found valid table-specs-only datastream */
+/* If you pass require_image = TRUE (normal case), you need not check for
+ * a TABLES_ONLY return code; an abbreviated file will cause an error exit.
+ * JPEG_SUSPENDED is only possible if you use a data source module that can
+ * give a suspension return (the stdio source module doesn't).
+ */
+
+/* Main entry points for decompression */
+EXTERN(boolean) jpeg_start_decompress (j_decompress_ptr cinfo);
+EXTERN(JDIMENSION) jpeg_read_scanlines (j_decompress_ptr cinfo,
+                                        JSAMPARRAY scanlines,
+                                        JDIMENSION max_lines);
+EXTERN(JDIMENSION) jpeg_skip_scanlines (j_decompress_ptr cinfo,
+                                        JDIMENSION num_lines);
+EXTERN(void) jpeg_crop_scanline (j_decompress_ptr cinfo, JDIMENSION *xoffset,
+                                 JDIMENSION *width);
+EXTERN(boolean) jpeg_finish_decompress (j_decompress_ptr cinfo);
+
+/* Replaces jpeg_read_scanlines when reading raw downsampled data. */
+EXTERN(JDIMENSION) jpeg_read_raw_data (j_decompress_ptr cinfo, JSAMPIMAGE data,
+                                       JDIMENSION max_lines);
+
+/* Additional entry points for buffered-image mode. */
+EXTERN(boolean) jpeg_has_multiple_scans (j_decompress_ptr cinfo);
+EXTERN(boolean) jpeg_start_output (j_decompress_ptr cinfo, int scan_number);
+EXTERN(boolean) jpeg_finish_output (j_decompress_ptr cinfo);
+EXTERN(boolean) jpeg_input_complete (j_decompress_ptr cinfo);
+EXTERN(void) jpeg_new_colormap (j_decompress_ptr cinfo);
+EXTERN(int) jpeg_consume_input (j_decompress_ptr cinfo);
+/* Return value is one of: */
+/* #define JPEG_SUSPENDED       0    Suspended due to lack of input data */
+#define JPEG_REACHED_SOS        1 /* Reached start of new scan */
+#define JPEG_REACHED_EOI        2 /* Reached end of image */
+#define JPEG_ROW_COMPLETED      3 /* Completed one iMCU row */
+#define JPEG_SCAN_COMPLETED     4 /* Completed last iMCU row of a scan */
+
+/* Precalculate output dimensions for current decompression parameters. */
+#if JPEG_LIB_VERSION >= 80
+EXTERN(void) jpeg_core_output_dimensions (j_decompress_ptr cinfo);
+#endif
+EXTERN(void) jpeg_calc_output_dimensions (j_decompress_ptr cinfo);
+
+/* Control saving of COM and APPn markers into marker_list. */
+EXTERN(void) jpeg_save_markers (j_decompress_ptr cinfo, int marker_code,
+                                unsigned int length_limit);
+
+/* Install a special processing method for COM or APPn markers. */
+EXTERN(void) jpeg_set_marker_processor (j_decompress_ptr cinfo,
+                                        int marker_code,
+                                        jpeg_marker_parser_method routine);
+
+/* Read or write raw DCT coefficients --- useful for lossless transcoding. */
+EXTERN(jvirt_barray_ptr *) jpeg_read_coefficients (j_decompress_ptr cinfo);
+EXTERN(void) jpeg_write_coefficients (j_compress_ptr cinfo,
+                                      jvirt_barray_ptr *coef_arrays);
+EXTERN(void) jpeg_copy_critical_parameters (j_decompress_ptr srcinfo,
+                                            j_compress_ptr dstinfo);
+
+/* If you choose to abort compression or decompression before completing
+ * jpeg_finish_(de)compress, then you need to clean up to release memory,
+ * temporary files, etc.  You can just call jpeg_destroy_(de)compress
+ * if you're done with the JPEG object, but if you want to clean it up and
+ * reuse it, call this:
+ */
+EXTERN(void) jpeg_abort_compress (j_compress_ptr cinfo);
+EXTERN(void) jpeg_abort_decompress (j_decompress_ptr cinfo);
+
+/* Generic versions of jpeg_abort and jpeg_destroy that work on either
+ * flavor of JPEG object.  These may be more convenient in some places.
+ */
+EXTERN(void) jpeg_abort (j_common_ptr cinfo);
+EXTERN(void) jpeg_destroy (j_common_ptr cinfo);
+
+/* Default restart-marker-resync procedure for use by data source modules */
+EXTERN(boolean) jpeg_resync_to_restart (j_decompress_ptr cinfo, int desired);
+
+
+/* These marker codes are exported since applications and data source modules
+ * are likely to want to use them.
+ */
+
+#define JPEG_RST0       0xD0    /* RST0 marker code */
+#define JPEG_EOI        0xD9    /* EOI marker code */
+#define JPEG_APP0       0xE0    /* APP0 marker code */
+#define JPEG_COM        0xFE    /* COM marker code */
+
+
+/* If we have a brain-damaged compiler that emits warnings (or worse, errors)
+ * for structure definitions that are never filled in, keep it quiet by
+ * supplying dummy definitions for the various substructures.
+ */
+
+#ifdef INCOMPLETE_TYPES_BROKEN
+#ifndef JPEG_INTERNALS          /* will be defined in jpegint.h */
+struct jvirt_sarray_control { long dummy; };
+struct jvirt_barray_control { long dummy; };
+struct jpeg_comp_master { long dummy; };
+struct jpeg_c_main_controller { long dummy; };
+struct jpeg_c_prep_controller { long dummy; };
+struct jpeg_c_coef_controller { long dummy; };
+struct jpeg_marker_writer { long dummy; };
+struct jpeg_color_converter { long dummy; };
+struct jpeg_downsampler { long dummy; };
+struct jpeg_forward_dct { long dummy; };
+struct jpeg_entropy_encoder { long dummy; };
+struct jpeg_decomp_master { long dummy; };
+struct jpeg_d_main_controller { long dummy; };
+struct jpeg_d_coef_controller { long dummy; };
+struct jpeg_d_post_controller { long dummy; };
+struct jpeg_input_controller { long dummy; };
+struct jpeg_marker_reader { long dummy; };
+struct jpeg_entropy_decoder { long dummy; };
+struct jpeg_inverse_dct { long dummy; };
+struct jpeg_upsampler { long dummy; };
+struct jpeg_color_deconverter { long dummy; };
+struct jpeg_color_quantizer { long dummy; };
+#endif /* JPEG_INTERNALS */
+#endif /* INCOMPLETE_TYPES_BROKEN */
+
+
+/*
+ * The JPEG library modules define JPEG_INTERNALS before including this file.
+ * The internal structure declarations are read only when that is true.
+ * Applications using the library should not include jpegint.h, but may wish
+ * to include jerror.h.
+ */
+
+#ifdef JPEG_INTERNALS
+#include "jpegint.h"            /* fetch private declarations */
+#include "jerror.h"             /* fetch error codes too */
+#endif
+
+#ifdef __cplusplus
+#ifndef DONT_USE_EXTERN_C
+}
+#endif
+#endif
+
+#endif /* JPEGLIB_H */
diff -Naur chromium-67.0.3396.62/third_party/libpng/pnglibconf.h chromium-67.0.3396.62.patched/third_party/libpng/pnglibconf.h
--- chromium-67.0.3396.62/third_party/libpng/pnglibconf.h	2018-05-30 11:43:42.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/libpng/pnglibconf.h	2018-06-06 10:06:12.361134439 +0300
@@ -225,13 +225,4 @@
 #define PNG_USER_CHUNK_MALLOC_MAX 4000000L
 /* end of chromium settings */
 
-/* chromium prefixing */
-/*
- * This is necessary to build multiple copies of libpng.  We need this while pdfium builds
- * its own copy of libpng.
- */
-#define PNG_PREFIX
-#include "pngprefix.h"
-/* end of chromium prefixing */
-
 #endif /* PNGLCONF_H */
diff -Naur chromium-67.0.3396.62/third_party/libpng/pnglibconf.h.noprefix chromium-67.0.3396.62.patched/third_party/libpng/pnglibconf.h.noprefix
--- chromium-67.0.3396.62/third_party/libpng/pnglibconf.h.noprefix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/libpng/pnglibconf.h.noprefix	2018-05-30 11:43:42.000000000 +0300
@@ -0,0 +1,237 @@
+/* libpng 1.6.22 CUSTOM API DEFINITION */
+
+/* pnglibconf.h - library build configuration */
+
+/* Libpng version 1.6.22 - May 29, 2016 */
+
+/* Copyright (c) 1998-2015 Glenn Randers-Pehrson */
+
+/* This code is released under the libpng license. */
+/* For conditions of distribution and use, see the disclaimer */
+/* and license in png.h */
+
+/* pnglibconf.h */
+/* Derived from: scripts/pnglibconf.dfa */
+#ifndef PNGLCONF_H
+#define PNGLCONF_H
+
+/* default options */
+/* These are PNG options that match the default in scripts/pnglibconf.dfa */
+#define PNG_16BIT_SUPPORTED
+#define PNG_ALIGNED_MEMORY_SUPPORTED
+/*#undef PNG_ARM_NEON_API_SUPPORTED*/
+/*#undef PNG_ARM_NEON_CHECK_SUPPORTED*/
+#define PNG_BENIGN_ERRORS_SUPPORTED
+#define PNG_BENIGN_READ_ERRORS_SUPPORTED
+/*#undef PNG_BENIGN_WRITE_ERRORS_SUPPORTED*/
+#define PNG_COLORSPACE_SUPPORTED
+#define PNG_EASY_ACCESS_SUPPORTED
+/*#undef PNG_ERROR_NUMBERS_SUPPORTED*/
+#define PNG_ERROR_TEXT_SUPPORTED
+#define PNG_FIXED_POINT_SUPPORTED
+#define PNG_FLOATING_ARITHMETIC_SUPPORTED
+#define PNG_FLOATING_POINT_SUPPORTED
+#define PNG_FORMAT_AFIRST_SUPPORTED
+#define PNG_FORMAT_BGR_SUPPORTED
+#define PNG_GAMMA_SUPPORTED
+#define PNG_HANDLE_AS_UNKNOWN_SUPPORTED
+#define PNG_INFO_IMAGE_SUPPORTED
+#define PNG_POINTER_INDEXING_SUPPORTED
+#define PNG_PROGRESSIVE_READ_SUPPORTED
+#define PNG_READ_16BIT_SUPPORTED
+#define PNG_READ_ALPHA_MODE_SUPPORTED
+#define PNG_READ_ANCILLARY_CHUNKS_SUPPORTED
+#define PNG_READ_BACKGROUND_SUPPORTED
+#define PNG_READ_BGR_SUPPORTED
+#define PNG_READ_COMPOSITE_NODIV_SUPPORTED
+#define PNG_READ_COMPRESSED_TEXT_SUPPORTED
+#define PNG_READ_EXPAND_16_SUPPORTED
+#define PNG_READ_EXPAND_SUPPORTED
+#define PNG_READ_FILLER_SUPPORTED
+#define PNG_READ_GAMMA_SUPPORTED
+#define PNG_READ_GRAY_TO_RGB_SUPPORTED
+#define PNG_READ_INTERLACING_SUPPORTED
+#define PNG_READ_INT_FUNCTIONS_SUPPORTED
+#define PNG_READ_PACKSWAP_SUPPORTED
+#define PNG_READ_PACK_SUPPORTED
+#define PNG_READ_RGB_TO_GRAY_SUPPORTED
+#define PNG_READ_SCALE_16_TO_8_SUPPORTED
+#define PNG_READ_SHIFT_SUPPORTED
+#define PNG_READ_STRIP_16_TO_8_SUPPORTED
+#define PNG_READ_STRIP_ALPHA_SUPPORTED
+#define PNG_READ_SUPPORTED
+#define PNG_READ_SWAP_ALPHA_SUPPORTED
+#define PNG_READ_SWAP_SUPPORTED
+#define PNG_READ_TEXT_SUPPORTED
+#define PNG_READ_TRANSFORMS_SUPPORTED
+#define PNG_READ_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_READ_USER_CHUNKS_SUPPORTED
+#define PNG_READ_USER_TRANSFORM_SUPPORTED
+#define PNG_READ_cHRM_SUPPORTED
+#define PNG_READ_gAMA_SUPPORTED
+#define PNG_READ_iCCP_SUPPORTED
+#define PNG_READ_sRGB_SUPPORTED
+#define PNG_READ_tEXt_SUPPORTED
+#define PNG_READ_tRNS_SUPPORTED
+#define PNG_READ_zTXt_SUPPORTED
+#define PNG_SAVE_INT_32_SUPPORTED
+#define PNG_SAVE_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_SEQUENTIAL_READ_SUPPORTED
+#define PNG_SETJMP_SUPPORTED
+#define PNG_SET_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_SET_USER_LIMITS_SUPPORTED
+#define PNG_SIMPLIFIED_READ_AFIRST_SUPPORTED
+#define PNG_SIMPLIFIED_READ_BGR_SUPPORTED
+#define PNG_SIMPLIFIED_READ_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_AFIRST_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_BGR_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_STDIO_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_SUPPORTED
+#define PNG_STDIO_SUPPORTED
+#define PNG_STORE_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_TEXT_SUPPORTED
+#define PNG_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_USER_CHUNKS_SUPPORTED
+#define PNG_USER_LIMITS_SUPPORTED
+#define PNG_USER_MEM_SUPPORTED
+#define PNG_USER_TRANSFORM_INFO_SUPPORTED
+#define PNG_USER_TRANSFORM_PTR_SUPPORTED
+#define PNG_WARNINGS_SUPPORTED
+#define PNG_WRITE_16BIT_SUPPORTED
+#define PNG_WRITE_ANCILLARY_CHUNKS_SUPPORTED
+#define PNG_WRITE_BGR_SUPPORTED
+#define PNG_WRITE_COMPRESSED_TEXT_SUPPORTED
+#define PNG_WRITE_CUSTOMIZE_COMPRESSION_SUPPORTED
+#define PNG_WRITE_CUSTOMIZE_ZTXT_COMPRESSION_SUPPORTED
+#define PNG_WRITE_FILLER_SUPPORTED
+#define PNG_WRITE_FILTER_SUPPORTED
+#define PNG_WRITE_FLUSH_SUPPORTED
+#define PNG_WRITE_INTERLACING_SUPPORTED
+#define PNG_WRITE_INT_FUNCTIONS_SUPPORTED
+#define PNG_WRITE_PACKSWAP_SUPPORTED
+#define PNG_WRITE_PACK_SUPPORTED
+#define PNG_WRITE_SHIFT_SUPPORTED
+#define PNG_WRITE_SUPPORTED
+#define PNG_WRITE_SWAP_ALPHA_SUPPORTED
+#define PNG_WRITE_SWAP_SUPPORTED
+#define PNG_WRITE_TEXT_SUPPORTED
+#define PNG_WRITE_TRANSFORMS_SUPPORTED
+#define PNG_WRITE_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_WRITE_USER_TRANSFORM_SUPPORTED
+#define PNG_WRITE_WEIGHTED_FILTER_SUPPORTED
+#define PNG_WRITE_cHRM_SUPPORTED
+#define PNG_WRITE_gAMA_SUPPORTED
+#define PNG_WRITE_iCCP_SUPPORTED
+#define PNG_WRITE_sRGB_SUPPORTED
+#define PNG_WRITE_tEXt_SUPPORTED
+#define PNG_WRITE_tRNS_SUPPORTED
+#define PNG_WRITE_zTXt_SUPPORTED
+#define PNG_cHRM_SUPPORTED
+#define PNG_gAMA_SUPPORTED
+#define PNG_iCCP_SUPPORTED
+#define PNG_sBIT_SUPPORTED
+#define PNG_sRGB_SUPPORTED
+#define PNG_tEXt_SUPPORTED
+#define PNG_tRNS_SUPPORTED
+#define PNG_zTXt_SUPPORTED
+/* end of options */
+
+/* chromium options */
+/* These are PNG options that chromium chooses to explicitly disable */
+/*#undef PNG_BUILD_GRAYSCALE_PALETTE_SUPPORTED*/
+/*#undef PNG_CHECK_FOR_INVALID_INDEX_SUPPORTED*/
+/*#undef PNG_CONSOLE_IO_SUPPORTED*/
+/*#undef PNG_CONVERT_tIME_SUPPORTED*/
+/*#undef PNG_GET_PALETTE_MAX_SUPPORTED*/
+/*#undef PNG_INCH_CONVERSIONS_SUPPORTED*/
+/*#undef PNG_IO_STATE_SUPPORTED*/
+/*#undef PNG_MNG_FEATURES_SUPPORTED*/
+/*#undef PNG_READ_CHECK_FOR_INVALID_INDEX_SUPPORTED*/
+/*#undef PNG_READ_GET_PALETTE_MAX_SUPPORTED*/
+/*#undef PNG_READ_INVERT_ALPHA_SUPPORTED*/
+/*#undef PNG_READ_INVERT_SUPPORTED*/
+/*#undef PNG_READ_OPT_PLTE_SUPPORTED*/
+/*#undef PNG_READ_QUANTIZE_SUPPORTED*/
+/*#undef PNG_READ_bKGD_SUPPORTED*/
+/*#undef PNG_READ_hIST_SUPPORTED*/
+/*#undef PNG_READ_iTXt_SUPPORTED*/
+/*#undef PNG_READ_oFFs_SUPPORTED*/
+/*#undef PNG_READ_pCAL_SUPPORTED*/
+/*#undef PNG_READ_pHYs_SUPPORTED*/
+/*#undef PNG_READ_sBIT_SUPPORTED*/
+/*#undef PNG_READ_sCAL_SUPPORTED*/
+/*#undef PNG_READ_sPLT_SUPPORTED*/
+/*#undef PNG_READ_tIME_SUPPORTED*/
+/*#undef PNG_SET_OPTION_SUPPORTED*/
+/*#undef PNG_TIME_RFC1123_SUPPORTED*/
+/*#undef PNG_WRITE_CHECK_FOR_INVALID_INDEX_SUPPORTED*/
+/*#undef PNG_WRITE_GET_PALETTE_MAX_SUPPORTED*/
+/*#undef PNG_WRITE_INVERT_ALPHA_SUPPORTED*/
+/*#undef PNG_WRITE_INVERT_SUPPORTED*/
+/*#undef PNG_WRITE_OPTIMIZE_CMF_SUPPORTED*/
+/*#undef PNG_WRITE_bKGD_SUPPORTED*/
+/*#undef PNG_WRITE_hIST_SUPPORTED*/
+/*#undef PNG_WRITE_iTXt_SUPPORTED*/
+/*#undef PNG_WRITE_oFFs_SUPPORTED*/
+/*#undef PNG_WRITE_pCAL_SUPPORTED*/
+/*#undef PNG_WRITE_pHYs_SUPPORTED*/
+/*#undef PNG_WRITE_sBIT_SUPPORTED*/
+/*#undef PNG_WRITE_sCAL_SUPPORTED*/
+/*#undef PNG_WRITE_sPLT_SUPPORTED*/
+/*#undef PNG_WRITE_tIME_SUPPORTED*/
+/*#undef PNG_bKGD_SUPPORTED*/
+/*#undef PNG_hIST_SUPPORTED*/
+/*#undef PNG_iTXt_SUPPORTED*/
+/*#undef PNG_oFFs_SUPPORTED*/
+/*#undef PNG_pCAL_SUPPORTED*/
+/*#undef PNG_pHYs_SUPPORTED*/
+/*#undef PNG_sCAL_SUPPORTED*/
+/*#undef PNG_sPLT_SUPPORTED*/
+/*#undef PNG_tIME_SUPPORTED*/
+/* end of chromium options */
+
+/* default settings */
+/* These are PNG settings that match the default in scripts/pnglibconf.dfa */
+#define PNG_API_RULE 0
+#define PNG_DEFAULT_READ_MACROS 1
+#define PNG_GAMMA_THRESHOLD_FIXED 5000
+#define PNG_IDAT_READ_SIZE PNG_ZBUF_SIZE
+#define PNG_INFLATE_BUF_SIZE 1024
+#define PNG_LINKAGE_API extern
+#define PNG_LINKAGE_CALLBACK extern
+#define PNG_LINKAGE_DATA extern
+#define PNG_LINKAGE_FUNCTION extern
+#define PNG_MAX_GAMMA_8 11
+#define PNG_QUANTIZE_BLUE_BITS 5
+#define PNG_QUANTIZE_GREEN_BITS 5
+#define PNG_QUANTIZE_RED_BITS 5
+#define PNG_TEXT_Z_DEFAULT_COMPRESSION (-1)
+#define PNG_TEXT_Z_DEFAULT_STRATEGY 0
+#define PNG_USER_HEIGHT_MAX 1000000
+#define PNG_USER_WIDTH_MAX 1000000
+#define PNG_ZBUF_SIZE 8192
+#define PNG_ZLIB_VERNUM 0 /* unknown */
+#define PNG_Z_DEFAULT_COMPRESSION (-1)
+#define PNG_Z_DEFAULT_NOFILTER_STRATEGY 0
+#define PNG_Z_DEFAULT_STRATEGY 1
+#define PNG_sCAL_PRECISION 5
+#define PNG_sRGB_PROFILE_CHECKS 2
+/* end of default settings */
+
+/* chromium settings */
+/* These are PNG setting that chromium has modified */
+/* crbug.com/117369 */
+#define PNG_USER_CHUNK_CACHE_MAX 128
+#define PNG_USER_CHUNK_MALLOC_MAX 4000000L
+/* end of chromium settings */
+
+/* chromium prefixing */
+/*
+ * This is necessary to build multiple copies of libpng.  We need this while pdfium builds
+ * its own copy of libpng.
+ */
+#define PNG_PREFIX
+#include "pngprefix.h"
+/* end of chromium prefixing */
+
+#endif /* PNGLCONF_H */
diff -Naur chromium-67.0.3396.62/third_party/skia/src/opts/SkRasterPipeline_opts.h chromium-67.0.3396.62.patched/third_party/skia/src/opts/SkRasterPipeline_opts.h
--- chromium-67.0.3396.62/third_party/skia/src/opts/SkRasterPipeline_opts.h	2018-05-30 11:44:31.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/skia/src/opts/SkRasterPipeline_opts.h	2018-06-06 10:06:12.365134376 +0300
@@ -653,7 +653,7 @@
 }
 
 SI F from_half(U16 h) {
-#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+#if defined(JUMPER_IS_NEON) && defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
     return vcvt_f32_f16(h);
 
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
@@ -673,7 +673,7 @@
 }
 
 SI U16 to_half(F f) {
-#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+#if defined(JUMPER_IS_NEON) && defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
     return vcvt_f16_f32(f);
 
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
diff -Naur chromium-67.0.3396.62/third_party/skia/src/opts/SkRasterPipeline_opts.h.aarch64fix chromium-67.0.3396.62.patched/third_party/skia/src/opts/SkRasterPipeline_opts.h.aarch64fix
--- chromium-67.0.3396.62/third_party/skia/src/opts/SkRasterPipeline_opts.h.aarch64fix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/skia/src/opts/SkRasterPipeline_opts.h.aarch64fix	2018-05-30 11:44:31.000000000 +0300
@@ -0,0 +1,3371 @@
+/*
+ * Copyright 2018 Google Inc.
+ *
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef SkRasterPipeline_opts_DEFINED
+#define SkRasterPipeline_opts_DEFINED
+
+#include "../jumper/SkJumper.h"
+#include "../jumper/SkJumper_misc.h"
+
+#if !defined(__clang__)
+    #define JUMPER_IS_SCALAR
+#elif defined(__ARM_NEON)
+    #define JUMPER_IS_NEON
+#elif defined(__AVX512F__)
+    #define JUMPER_IS_AVX512
+#elif defined(__AVX2__) && defined(__F16C__) && defined(__FMA__)
+    #define JUMPER_IS_HSW
+#elif defined(__AVX__)
+    #define JUMPER_IS_AVX
+#elif defined(__SSE4_1__)
+    #define JUMPER_IS_SSE41
+#elif defined(__SSE2__)
+    #define JUMPER_IS_SSE2
+#else
+    #define JUMPER_IS_SCALAR
+#endif
+
+// Older Clangs seem to crash when generating non-optimized NEON code for ARMv7.
+#if defined(__clang__) && !defined(__OPTIMIZE__) && defined(__arm__)
+    // Apple Clang 9 and vanilla Clang 5 are fine, and may even be conservative.
+    #if defined(__apple_build_version__) && __clang_major__ < 9
+        #define JUMPER_IS_SCALAR
+    #elif __clang_major__ < 5
+        #define JUMPER_IS_SCALAR
+    #endif
+#endif
+
+#if defined(JUMPER_IS_SCALAR)
+    #include <math.h>
+#elif defined(JUMPER_IS_NEON)
+    #include <arm_neon.h>
+#else
+    #include <immintrin.h>
+#endif
+
+namespace SK_OPTS_NS {
+
+#if defined(JUMPER_IS_SCALAR)
+    // This path should lead to portable scalar code.
+    using F   = float   ;
+    using I32 =  int32_t;
+    using U64 = uint64_t;
+    using U32 = uint32_t;
+    using U16 = uint16_t;
+    using U8  = uint8_t ;
+
+    SI F   mad(F f, F m, F a)   { return f*m+a; }
+    SI F   min(F a, F b)        { return fminf(a,b); }
+    SI F   max(F a, F b)        { return fmaxf(a,b); }
+    SI F   abs_  (F v)          { return fabsf(v); }
+    SI F   floor_(F v)          { return floorf(v); }
+    SI F   rcp   (F v)          { return 1.0f / v; }
+    SI F   rsqrt (F v)          { return 1.0f / sqrtf(v); }
+    SI F    sqrt_(F v)          { return sqrtf(v); }
+    SI U32 round (F v, F scale) { return (uint32_t)(v*scale + 0.5f); }
+    SI U16 pack(U32 v)          { return (U16)v; }
+    SI U8  pack(U16 v)          { return  (U8)v; }
+
+    SI F if_then_else(I32 c, F t, F e) { return c ? t : e; }
+
+    template <typename T>
+    SI T gather(const T* p, U32 ix) { return p[ix]; }
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        *r = ptr[0];
+        *g = ptr[1];
+        *b = ptr[2];
+    }
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        *r = ptr[0];
+        *g = ptr[1];
+        *b = ptr[2];
+        *a = ptr[3];
+    }
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        ptr[0] = r;
+        ptr[1] = g;
+        ptr[2] = b;
+        ptr[3] = a;
+    }
+
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        *r = ptr[0];
+        *g = ptr[1];
+        *b = ptr[2];
+        *a = ptr[3];
+    }
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        ptr[0] = r;
+        ptr[1] = g;
+        ptr[2] = b;
+        ptr[3] = a;
+    }
+
+#elif defined(JUMPER_IS_NEON)
+    // Since we know we're using Clang, we can use its vector extensions.
+    template <typename T> using V = T __attribute__((ext_vector_type(4)));
+    using F   = V<float   >;
+    using I32 = V< int32_t>;
+    using U64 = V<uint64_t>;
+    using U32 = V<uint32_t>;
+    using U16 = V<uint16_t>;
+    using U8  = V<uint8_t >;
+
+    // We polyfill a few routines that Clang doesn't build into ext_vector_types.
+    SI F   min(F a, F b)                         { return vminq_f32(a,b);          }
+    SI F   max(F a, F b)                         { return vmaxq_f32(a,b);          }
+    SI F   abs_  (F v)                           { return vabsq_f32(v);            }
+    SI F   rcp   (F v) { auto e = vrecpeq_f32 (v); return vrecpsq_f32 (v,e  ) * e; }
+    SI F   rsqrt (F v) { auto e = vrsqrteq_f32(v); return vrsqrtsq_f32(v,e*e) * e; }
+    SI U16 pack(U32 v)                           { return __builtin_convertvector(v, U16); }
+    SI U8  pack(U16 v)                           { return __builtin_convertvector(v,  U8); }
+
+    SI F if_then_else(I32 c, F t, F e) { return vbslq_f32((U32)c,t,e); }
+
+    #if defined(__aarch64__)
+        SI F     mad(F f, F m, F a) { return vfmaq_f32(a,f,m); }
+        SI F  floor_(F v) { return vrndmq_f32(v); }
+        SI F   sqrt_(F v) { return vsqrtq_f32(v); }
+        SI U32 round(F v, F scale) { return vcvtnq_u32_f32(v*scale); }
+    #else
+        SI F mad(F f, F m, F a) { return vmlaq_f32(a,f,m); }
+        SI F floor_(F v) {
+            F roundtrip = vcvtq_f32_s32(vcvtq_s32_f32(v));
+            return roundtrip - if_then_else(roundtrip > v, 1, 0);
+        }
+
+        SI F sqrt_(F v) {
+            auto e = vrsqrteq_f32(v);  // Estimate and two refinement steps for e = rsqrt(v).
+            e *= vrsqrtsq_f32(v,e*e);
+            e *= vrsqrtsq_f32(v,e*e);
+            return v*e;                // sqrt(v) == v*rsqrt(v).
+        }
+
+        SI U32 round(F v, F scale) {
+            return vcvtq_u32_f32(mad(v,scale,0.5f));
+        }
+    #endif
+
+
+    template <typename T>
+    SI V<T> gather(const T* p, U32 ix) {
+        return {p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]]};
+    }
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        uint16x4x3_t rgb;
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { rgb = vld3_lane_u16(ptr + 0, rgb, 0); }
+            if (tail > 1) { rgb = vld3_lane_u16(ptr + 3, rgb, 1); }
+            if (tail > 2) { rgb = vld3_lane_u16(ptr + 6, rgb, 2); }
+        } else {
+            rgb = vld3_u16(ptr);
+        }
+        *r = rgb.val[0];
+        *g = rgb.val[1];
+        *b = rgb.val[2];
+    }
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        uint16x4x4_t rgba;
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { rgba = vld4_lane_u16(ptr + 0, rgba, 0); }
+            if (tail > 1) { rgba = vld4_lane_u16(ptr + 4, rgba, 1); }
+            if (tail > 2) { rgba = vld4_lane_u16(ptr + 8, rgba, 2); }
+        } else {
+            rgba = vld4_u16(ptr);
+        }
+        *r = rgba.val[0];
+        *g = rgba.val[1];
+        *b = rgba.val[2];
+        *a = rgba.val[3];
+    }
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { vst4_lane_u16(ptr + 0, (uint16x4x4_t{{r,g,b,a}}), 0); }
+            if (tail > 1) { vst4_lane_u16(ptr + 4, (uint16x4x4_t{{r,g,b,a}}), 1); }
+            if (tail > 2) { vst4_lane_u16(ptr + 8, (uint16x4x4_t{{r,g,b,a}}), 2); }
+        } else {
+            vst4_u16(ptr, (uint16x4x4_t{{r,g,b,a}}));
+        }
+    }
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        float32x4x4_t rgba;
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { rgba = vld4q_lane_f32(ptr + 0, rgba, 0); }
+            if (tail > 1) { rgba = vld4q_lane_f32(ptr + 4, rgba, 1); }
+            if (tail > 2) { rgba = vld4q_lane_f32(ptr + 8, rgba, 2); }
+        } else {
+            rgba = vld4q_f32(ptr);
+        }
+        *r = rgba.val[0];
+        *g = rgba.val[1];
+        *b = rgba.val[2];
+        *a = rgba.val[3];
+    }
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { vst4q_lane_f32(ptr + 0, (float32x4x4_t{{r,g,b,a}}), 0); }
+            if (tail > 1) { vst4q_lane_f32(ptr + 4, (float32x4x4_t{{r,g,b,a}}), 1); }
+            if (tail > 2) { vst4q_lane_f32(ptr + 8, (float32x4x4_t{{r,g,b,a}}), 2); }
+        } else {
+            vst4q_f32(ptr, (float32x4x4_t{{r,g,b,a}}));
+        }
+    }
+
+#elif defined(JUMPER_IS_AVX) || defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    // These are __m256 and __m256i, but friendlier and strongly-typed.
+    template <typename T> using V = T __attribute__((ext_vector_type(8)));
+    using F   = V<float   >;
+    using I32 = V< int32_t>;
+    using U64 = V<uint64_t>;
+    using U32 = V<uint32_t>;
+    using U16 = V<uint16_t>;
+    using U8  = V<uint8_t >;
+
+    SI F mad(F f, F m, F a)  {
+    #if defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+        return _mm256_fmadd_ps(f,m,a);
+    #else
+        return f*m+a;
+    #endif
+    }
+
+    SI F   min(F a, F b)        { return _mm256_min_ps(a,b);    }
+    SI F   max(F a, F b)        { return _mm256_max_ps(a,b);    }
+    SI F   abs_  (F v)          { return _mm256_and_ps(v, 0-v); }
+    SI F   floor_(F v)          { return _mm256_floor_ps(v);    }
+    SI F   rcp   (F v)          { return _mm256_rcp_ps  (v);    }
+    SI F   rsqrt (F v)          { return _mm256_rsqrt_ps(v);    }
+    SI F    sqrt_(F v)          { return _mm256_sqrt_ps (v);    }
+    SI U32 round (F v, F scale) { return _mm256_cvtps_epi32(v*scale); }
+
+    SI U16 pack(U32 v) {
+        return _mm_packus_epi32(_mm256_extractf128_si256(v, 0),
+                                _mm256_extractf128_si256(v, 1));
+    }
+    SI U8 pack(U16 v) {
+        auto r = _mm_packus_epi16(v,v);
+        return unaligned_load<U8>(&r);
+    }
+
+    SI F if_then_else(I32 c, F t, F e) { return _mm256_blendv_ps(e,t,c); }
+
+    template <typename T>
+    SI V<T> gather(const T* p, U32 ix) {
+        return { p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]],
+                 p[ix[4]], p[ix[5]], p[ix[6]], p[ix[7]], };
+    }
+    #if defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+        SI F   gather(const float*    p, U32 ix) { return _mm256_i32gather_ps   (p, ix, 4); }
+        SI U32 gather(const uint32_t* p, U32 ix) { return _mm256_i32gather_epi32(p, ix, 4); }
+        SI U64 gather(const uint64_t* p, U32 ix) {
+            __m256i parts[] = {
+                _mm256_i32gather_epi64(p, _mm256_extracti128_si256(ix,0), 8),
+                _mm256_i32gather_epi64(p, _mm256_extracti128_si256(ix,1), 8),
+            };
+            return bit_cast<U64>(parts);
+        }
+    #endif
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        __m128i _0,_1,_2,_3,_4,_5,_6,_7;
+        if (__builtin_expect(tail,0)) {
+            auto load_rgb = [](const uint16_t* src) {
+                auto v = _mm_cvtsi32_si128(*(const uint32_t*)src);
+                return _mm_insert_epi16(v, src[2], 2);
+            };
+            _1 = _2 = _3 = _4 = _5 = _6 = _7 = _mm_setzero_si128();
+            if (  true  ) { _0 = load_rgb(ptr +  0); }
+            if (tail > 1) { _1 = load_rgb(ptr +  3); }
+            if (tail > 2) { _2 = load_rgb(ptr +  6); }
+            if (tail > 3) { _3 = load_rgb(ptr +  9); }
+            if (tail > 4) { _4 = load_rgb(ptr + 12); }
+            if (tail > 5) { _5 = load_rgb(ptr + 15); }
+            if (tail > 6) { _6 = load_rgb(ptr + 18); }
+        } else {
+            // Load 0+1, 2+3, 4+5 normally, and 6+7 backed up 4 bytes so we don't run over.
+            auto _01 =                _mm_loadu_si128((const __m128i*)(ptr +  0))    ;
+            auto _23 =                _mm_loadu_si128((const __m128i*)(ptr +  6))    ;
+            auto _45 =                _mm_loadu_si128((const __m128i*)(ptr + 12))    ;
+            auto _67 = _mm_srli_si128(_mm_loadu_si128((const __m128i*)(ptr + 16)), 4);
+            _0 = _01; _1 = _mm_srli_si128(_01, 6);
+            _2 = _23; _3 = _mm_srli_si128(_23, 6);
+            _4 = _45; _5 = _mm_srli_si128(_45, 6);
+            _6 = _67; _7 = _mm_srli_si128(_67, 6);
+        }
+
+        auto _02 = _mm_unpacklo_epi16(_0, _2),  // r0 r2 g0 g2 b0 b2 xx xx
+             _13 = _mm_unpacklo_epi16(_1, _3),
+             _46 = _mm_unpacklo_epi16(_4, _6),
+             _57 = _mm_unpacklo_epi16(_5, _7);
+
+        auto rg0123 = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             bx0123 = _mm_unpackhi_epi16(_02, _13),  // b0 b1 b2 b3 xx xx xx xx
+             rg4567 = _mm_unpacklo_epi16(_46, _57),
+             bx4567 = _mm_unpackhi_epi16(_46, _57);
+
+        *r = _mm_unpacklo_epi64(rg0123, rg4567);
+        *g = _mm_unpackhi_epi64(rg0123, rg4567);
+        *b = _mm_unpacklo_epi64(bx0123, bx4567);
+    }
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        __m128i _01, _23, _45, _67;
+        if (__builtin_expect(tail,0)) {
+            auto src = (const double*)ptr;
+            _01 = _23 = _45 = _67 = _mm_setzero_si128();
+            if (tail > 0) { _01 = _mm_loadl_pd(_01, src+0); }
+            if (tail > 1) { _01 = _mm_loadh_pd(_01, src+1); }
+            if (tail > 2) { _23 = _mm_loadl_pd(_23, src+2); }
+            if (tail > 3) { _23 = _mm_loadh_pd(_23, src+3); }
+            if (tail > 4) { _45 = _mm_loadl_pd(_45, src+4); }
+            if (tail > 5) { _45 = _mm_loadh_pd(_45, src+5); }
+            if (tail > 6) { _67 = _mm_loadl_pd(_67, src+6); }
+        } else {
+            _01 = _mm_loadu_si128(((__m128i*)ptr) + 0);
+            _23 = _mm_loadu_si128(((__m128i*)ptr) + 1);
+            _45 = _mm_loadu_si128(((__m128i*)ptr) + 2);
+            _67 = _mm_loadu_si128(((__m128i*)ptr) + 3);
+        }
+
+        auto _02 = _mm_unpacklo_epi16(_01, _23),  // r0 r2 g0 g2 b0 b2 a0 a2
+             _13 = _mm_unpackhi_epi16(_01, _23),  // r1 r3 g1 g3 b1 b3 a1 a3
+             _46 = _mm_unpacklo_epi16(_45, _67),
+             _57 = _mm_unpackhi_epi16(_45, _67);
+
+        auto rg0123 = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             ba0123 = _mm_unpackhi_epi16(_02, _13),  // b0 b1 b2 b3 a0 a1 a2 a3
+             rg4567 = _mm_unpacklo_epi16(_46, _57),
+             ba4567 = _mm_unpackhi_epi16(_46, _57);
+
+        *r = _mm_unpacklo_epi64(rg0123, rg4567);
+        *g = _mm_unpackhi_epi64(rg0123, rg4567);
+        *b = _mm_unpacklo_epi64(ba0123, ba4567);
+        *a = _mm_unpackhi_epi64(ba0123, ba4567);
+    }
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        auto rg0123 = _mm_unpacklo_epi16(r, g),  // r0 g0 r1 g1 r2 g2 r3 g3
+             rg4567 = _mm_unpackhi_epi16(r, g),  // r4 g4 r5 g5 r6 g6 r7 g7
+             ba0123 = _mm_unpacklo_epi16(b, a),
+             ba4567 = _mm_unpackhi_epi16(b, a);
+
+        auto _01 = _mm_unpacklo_epi32(rg0123, ba0123),
+             _23 = _mm_unpackhi_epi32(rg0123, ba0123),
+             _45 = _mm_unpacklo_epi32(rg4567, ba4567),
+             _67 = _mm_unpackhi_epi32(rg4567, ba4567);
+
+        if (__builtin_expect(tail,0)) {
+            auto dst = (double*)ptr;
+            if (tail > 0) { _mm_storel_pd(dst+0, _01); }
+            if (tail > 1) { _mm_storeh_pd(dst+1, _01); }
+            if (tail > 2) { _mm_storel_pd(dst+2, _23); }
+            if (tail > 3) { _mm_storeh_pd(dst+3, _23); }
+            if (tail > 4) { _mm_storel_pd(dst+4, _45); }
+            if (tail > 5) { _mm_storeh_pd(dst+5, _45); }
+            if (tail > 6) { _mm_storel_pd(dst+6, _67); }
+        } else {
+            _mm_storeu_si128((__m128i*)ptr + 0, _01);
+            _mm_storeu_si128((__m128i*)ptr + 1, _23);
+            _mm_storeu_si128((__m128i*)ptr + 2, _45);
+            _mm_storeu_si128((__m128i*)ptr + 3, _67);
+        }
+    }
+
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        F _04, _15, _26, _37;
+        _04 = _15 = _26 = _37 = 0;
+        switch (tail) {
+            case 0: _37 = _mm256_insertf128_ps(_37, _mm_loadu_ps(ptr+28), 1);
+            case 7: _26 = _mm256_insertf128_ps(_26, _mm_loadu_ps(ptr+24), 1);
+            case 6: _15 = _mm256_insertf128_ps(_15, _mm_loadu_ps(ptr+20), 1);
+            case 5: _04 = _mm256_insertf128_ps(_04, _mm_loadu_ps(ptr+16), 1);
+            case 4: _37 = _mm256_insertf128_ps(_37, _mm_loadu_ps(ptr+12), 0);
+            case 3: _26 = _mm256_insertf128_ps(_26, _mm_loadu_ps(ptr+ 8), 0);
+            case 2: _15 = _mm256_insertf128_ps(_15, _mm_loadu_ps(ptr+ 4), 0);
+            case 1: _04 = _mm256_insertf128_ps(_04, _mm_loadu_ps(ptr+ 0), 0);
+        }
+
+        F rg0145 = _mm256_unpacklo_ps(_04,_15),  // r0 r1 g0 g1 | r4 r5 g4 g5
+          ba0145 = _mm256_unpackhi_ps(_04,_15),
+          rg2367 = _mm256_unpacklo_ps(_26,_37),
+          ba2367 = _mm256_unpackhi_ps(_26,_37);
+
+        *r = _mm256_unpacklo_pd(rg0145, rg2367);
+        *g = _mm256_unpackhi_pd(rg0145, rg2367);
+        *b = _mm256_unpacklo_pd(ba0145, ba2367);
+        *a = _mm256_unpackhi_pd(ba0145, ba2367);
+    }
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        F rg0145 = _mm256_unpacklo_ps(r, g),  // r0 g0 r1 g1 | r4 g4 r5 g5
+          rg2367 = _mm256_unpackhi_ps(r, g),  // r2 ...      | r6 ...
+          ba0145 = _mm256_unpacklo_ps(b, a),  // b0 a0 b1 a1 | b4 a4 b5 a5
+          ba2367 = _mm256_unpackhi_ps(b, a);  // b2 ...      | b6 ...
+
+        F _04 = _mm256_unpacklo_pd(rg0145, ba0145),  // r0 g0 b0 a0 | r4 g4 b4 a4
+          _15 = _mm256_unpackhi_pd(rg0145, ba0145),  // r1 ...      | r5 ...
+          _26 = _mm256_unpacklo_pd(rg2367, ba2367),  // r2 ...      | r6 ...
+          _37 = _mm256_unpackhi_pd(rg2367, ba2367);  // r3 ...      | r7 ...
+
+        if (__builtin_expect(tail, 0)) {
+            if (tail > 0) { _mm_storeu_ps(ptr+ 0, _mm256_extractf128_ps(_04, 0)); }
+            if (tail > 1) { _mm_storeu_ps(ptr+ 4, _mm256_extractf128_ps(_15, 0)); }
+            if (tail > 2) { _mm_storeu_ps(ptr+ 8, _mm256_extractf128_ps(_26, 0)); }
+            if (tail > 3) { _mm_storeu_ps(ptr+12, _mm256_extractf128_ps(_37, 0)); }
+            if (tail > 4) { _mm_storeu_ps(ptr+16, _mm256_extractf128_ps(_04, 1)); }
+            if (tail > 5) { _mm_storeu_ps(ptr+20, _mm256_extractf128_ps(_15, 1)); }
+            if (tail > 6) { _mm_storeu_ps(ptr+24, _mm256_extractf128_ps(_26, 1)); }
+        } else {
+            F _01 = _mm256_permute2f128_ps(_04, _15, 32),  // 32 == 0010 0000 == lo, lo
+              _23 = _mm256_permute2f128_ps(_26, _37, 32),
+              _45 = _mm256_permute2f128_ps(_04, _15, 49),  // 49 == 0011 0001 == hi, hi
+              _67 = _mm256_permute2f128_ps(_26, _37, 49);
+            _mm256_storeu_ps(ptr+ 0, _01);
+            _mm256_storeu_ps(ptr+ 8, _23);
+            _mm256_storeu_ps(ptr+16, _45);
+            _mm256_storeu_ps(ptr+24, _67);
+        }
+    }
+
+#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41)
+    template <typename T> using V = T __attribute__((ext_vector_type(4)));
+    using F   = V<float   >;
+    using I32 = V< int32_t>;
+    using U64 = V<uint64_t>;
+    using U32 = V<uint32_t>;
+    using U16 = V<uint16_t>;
+    using U8  = V<uint8_t >;
+
+    SI F   mad(F f, F m, F a)  { return f*m+a;              }
+    SI F   min(F a, F b)       { return _mm_min_ps(a,b);    }
+    SI F   max(F a, F b)       { return _mm_max_ps(a,b);    }
+    SI F   abs_(F v)           { return _mm_and_ps(v, 0-v); }
+    SI F   rcp   (F v)         { return _mm_rcp_ps  (v);    }
+    SI F   rsqrt (F v)         { return _mm_rsqrt_ps(v);    }
+    SI F    sqrt_(F v)         { return _mm_sqrt_ps (v);    }
+    SI U32 round(F v, F scale) { return _mm_cvtps_epi32(v*scale); }
+
+    SI U16 pack(U32 v) {
+    #if defined(JUMPER_IS_SSE41)
+        auto p = _mm_packus_epi32(v,v);
+    #else
+        // Sign extend so that _mm_packs_epi32() does the pack we want.
+        auto p = _mm_srai_epi32(_mm_slli_epi32(v, 16), 16);
+        p = _mm_packs_epi32(p,p);
+    #endif
+        return unaligned_load<U16>(&p);  // We have two copies.  Return (the lower) one.
+    }
+    SI U8 pack(U16 v) {
+        auto r = widen_cast<__m128i>(v);
+        r = _mm_packus_epi16(r,r);
+        return unaligned_load<U8>(&r);
+    }
+
+    SI F if_then_else(I32 c, F t, F e) {
+        return _mm_or_ps(_mm_and_ps(c, t), _mm_andnot_ps(c, e));
+    }
+
+    SI F floor_(F v) {
+    #if defined(JUMPER_IS_SSE41)
+        return _mm_floor_ps(v);
+    #else
+        F roundtrip = _mm_cvtepi32_ps(_mm_cvttps_epi32(v));
+        return roundtrip - if_then_else(roundtrip > v, 1, 0);
+    #endif
+    }
+
+    template <typename T>
+    SI V<T> gather(const T* p, U32 ix) {
+        return {p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]]};
+    }
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        __m128i _0, _1, _2, _3;
+        if (__builtin_expect(tail,0)) {
+            _1 = _2 = _3 = _mm_setzero_si128();
+            auto load_rgb = [](const uint16_t* src) {
+                auto v = _mm_cvtsi32_si128(*(const uint32_t*)src);
+                return _mm_insert_epi16(v, src[2], 2);
+            };
+            if (  true  ) { _0 = load_rgb(ptr + 0); }
+            if (tail > 1) { _1 = load_rgb(ptr + 3); }
+            if (tail > 2) { _2 = load_rgb(ptr + 6); }
+        } else {
+            // Load slightly weirdly to make sure we don't load past the end of 4x48 bits.
+            auto _01 =                _mm_loadu_si128((const __m128i*)(ptr + 0))    ,
+                 _23 = _mm_srli_si128(_mm_loadu_si128((const __m128i*)(ptr + 4)), 4);
+
+            // Each _N holds R,G,B for pixel N in its lower 3 lanes (upper 5 are ignored).
+            _0 = _01;
+            _1 = _mm_srli_si128(_01, 6);
+            _2 = _23;
+            _3 = _mm_srli_si128(_23, 6);
+        }
+
+        // De-interlace to R,G,B.
+        auto _02 = _mm_unpacklo_epi16(_0, _2),  // r0 r2 g0 g2 b0 b2 xx xx
+             _13 = _mm_unpacklo_epi16(_1, _3);  // r1 r3 g1 g3 b1 b3 xx xx
+
+        auto R = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             G = _mm_srli_si128(R, 8),
+             B = _mm_unpackhi_epi16(_02, _13);  // b0 b1 b2 b3 xx xx xx xx
+
+        *r = unaligned_load<U16>(&R);
+        *g = unaligned_load<U16>(&G);
+        *b = unaligned_load<U16>(&B);
+    }
+
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        __m128i _01, _23;
+        if (__builtin_expect(tail,0)) {
+            _01 = _23 = _mm_setzero_si128();
+            auto src = (const double*)ptr;
+            if (  true  ) { _01 = _mm_loadl_pd(_01, src + 0); } // r0 g0 b0 a0 00 00 00 00
+            if (tail > 1) { _01 = _mm_loadh_pd(_01, src + 1); } // r0 g0 b0 a0 r1 g1 b1 a1
+            if (tail > 2) { _23 = _mm_loadl_pd(_23, src + 2); } // r2 g2 b2 a2 00 00 00 00
+        } else {
+            _01 = _mm_loadu_si128(((__m128i*)ptr) + 0); // r0 g0 b0 a0 r1 g1 b1 a1
+            _23 = _mm_loadu_si128(((__m128i*)ptr) + 1); // r2 g2 b2 a2 r3 g3 b3 a3
+        }
+
+        auto _02 = _mm_unpacklo_epi16(_01, _23),  // r0 r2 g0 g2 b0 b2 a0 a2
+             _13 = _mm_unpackhi_epi16(_01, _23);  // r1 r3 g1 g3 b1 b3 a1 a3
+
+        auto rg = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             ba = _mm_unpackhi_epi16(_02, _13);  // b0 b1 b2 b3 a0 a1 a2 a3
+
+        *r = unaligned_load<U16>((uint16_t*)&rg + 0);
+        *g = unaligned_load<U16>((uint16_t*)&rg + 4);
+        *b = unaligned_load<U16>((uint16_t*)&ba + 0);
+        *a = unaligned_load<U16>((uint16_t*)&ba + 4);
+    }
+
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        auto rg = _mm_unpacklo_epi16(widen_cast<__m128i>(r), widen_cast<__m128i>(g)),
+             ba = _mm_unpacklo_epi16(widen_cast<__m128i>(b), widen_cast<__m128i>(a));
+
+        if (__builtin_expect(tail, 0)) {
+            auto dst = (double*)ptr;
+            if (  true  ) { _mm_storel_pd(dst + 0, _mm_unpacklo_epi32(rg, ba)); }
+            if (tail > 1) { _mm_storeh_pd(dst + 1, _mm_unpacklo_epi32(rg, ba)); }
+            if (tail > 2) { _mm_storel_pd(dst + 2, _mm_unpackhi_epi32(rg, ba)); }
+        } else {
+            _mm_storeu_si128((__m128i*)ptr + 0, _mm_unpacklo_epi32(rg, ba));
+            _mm_storeu_si128((__m128i*)ptr + 1, _mm_unpackhi_epi32(rg, ba));
+        }
+    }
+
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        F _0, _1, _2, _3;
+        if (__builtin_expect(tail, 0)) {
+            _1 = _2 = _3 = _mm_setzero_si128();
+            if (  true  ) { _0 = _mm_loadu_ps(ptr + 0); }
+            if (tail > 1) { _1 = _mm_loadu_ps(ptr + 4); }
+            if (tail > 2) { _2 = _mm_loadu_ps(ptr + 8); }
+        } else {
+            _0 = _mm_loadu_ps(ptr + 0);
+            _1 = _mm_loadu_ps(ptr + 4);
+            _2 = _mm_loadu_ps(ptr + 8);
+            _3 = _mm_loadu_ps(ptr +12);
+        }
+        _MM_TRANSPOSE4_PS(_0,_1,_2,_3);
+        *r = _0;
+        *g = _1;
+        *b = _2;
+        *a = _3;
+    }
+
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        _MM_TRANSPOSE4_PS(r,g,b,a);
+        if (__builtin_expect(tail, 0)) {
+            if (  true  ) { _mm_storeu_ps(ptr + 0, r); }
+            if (tail > 1) { _mm_storeu_ps(ptr + 4, g); }
+            if (tail > 2) { _mm_storeu_ps(ptr + 8, b); }
+        } else {
+            _mm_storeu_ps(ptr + 0, r);
+            _mm_storeu_ps(ptr + 4, g);
+            _mm_storeu_ps(ptr + 8, b);
+            _mm_storeu_ps(ptr +12, a);
+        }
+    }
+#endif
+
+// We need to be a careful with casts.
+// (F)x means cast x to float in the portable path, but bit_cast x to float in the others.
+// These named casts and bit_cast() are always what they seem to be.
+#if defined(JUMPER_IS_SCALAR)
+    SI F   cast  (U32 v) { return   (F)v; }
+    SI U32 trunc_(F   v) { return (U32)v; }
+    SI U32 expand(U16 v) { return (U32)v; }
+    SI U32 expand(U8  v) { return (U32)v; }
+#else
+    SI F   cast  (U32 v) { return      __builtin_convertvector((I32)v,   F); }
+    SI U32 trunc_(F   v) { return (U32)__builtin_convertvector(     v, I32); }
+    SI U32 expand(U16 v) { return      __builtin_convertvector(     v, U32); }
+    SI U32 expand(U8  v) { return      __builtin_convertvector(     v, U32); }
+#endif
+
+template <typename V>
+SI V if_then_else(I32 c, V t, V e) {
+    return bit_cast<V>(if_then_else(c, bit_cast<F>(t), bit_cast<F>(e)));
+}
+
+SI U16 bswap(U16 x) {
+#if defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41)
+    // Somewhat inexplicably Clang decides to do (x<<8) | (x>>8) in 32-bit lanes
+    // when generating code for SSE2 and SSE4.1.  We'll do it manually...
+    auto v = widen_cast<__m128i>(x);
+    v = _mm_slli_epi16(v,8) | _mm_srli_epi16(v,8);
+    return unaligned_load<U16>(&v);
+#else
+    return (x<<8) | (x>>8);
+#endif
+}
+
+SI F fract(F v) { return v - floor_(v); }
+
+// See http://www.machinedlearnings.com/2011/06/fast-approximate-logarithm-exponential.html.
+SI F approx_log2(F x) {
+    // e - 127 is a fair approximation of log2(x) in its own right...
+    F e = cast(bit_cast<U32>(x)) * (1.0f / (1<<23));
+
+    // ... but using the mantissa to refine its error is _much_ better.
+    F m = bit_cast<F>((bit_cast<U32>(x) & 0x007fffff) | 0x3f000000);
+    return e
+         - 124.225514990f
+         -   1.498030302f * m
+         -   1.725879990f / (0.3520887068f + m);
+}
+SI F approx_pow2(F x) {
+    F f = fract(x);
+    return bit_cast<F>(round(1.0f * (1<<23),
+                             x + 121.274057500f
+                               -   1.490129070f * f
+                               +  27.728023300f / (4.84252568f - f)));
+}
+
+SI F approx_powf(F x, F y) {
+    return if_then_else(x == 0, 0
+                              , approx_pow2(approx_log2(x) * y));
+}
+
+SI F from_half(U16 h) {
+#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+    return vcvt_f32_f16(h);
+
+#elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    return _mm256_cvtph_ps(h);
+
+#else
+    // Remember, a half is 1-5-10 (sign-exponent-mantissa) with 15 exponent bias.
+    U32 sem = expand(h),
+        s   = sem & 0x8000,
+         em = sem ^ s;
+
+    // Convert to 1-8-23 float with 127 bias, flushing denorm halfs (including zero) to zero.
+    auto denorm = (I32)em < 0x0400;      // I32 comparison is often quicker, and always safe here.
+    return if_then_else(denorm, F(0)
+                              , bit_cast<F>( (s<<16) + (em<<13) + ((127-15)<<23) ));
+#endif
+}
+
+SI U16 to_half(F f) {
+#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+    return vcvt_f16_f32(f);
+
+#elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    return _mm256_cvtps_ph(f, _MM_FROUND_CUR_DIRECTION);
+
+#else
+    // Remember, a float is 1-8-23 (sign-exponent-mantissa) with 127 exponent bias.
+    U32 sem = bit_cast<U32>(f),
+        s   = sem & 0x80000000,
+         em = sem ^ s;
+
+    // Convert to 1-5-10 half with 15 bias, flushing denorm halfs (including zero) to zero.
+    auto denorm = (I32)em < 0x38800000;  // I32 comparison is often quicker, and always safe here.
+    return pack(if_then_else(denorm, U32(0)
+                                   , (s>>16) + (em>>13) - ((127-15)<<10)));
+#endif
+}
+
+// Our fundamental vector depth is our pixel stride.
+static const size_t N = sizeof(F) / sizeof(float);
+
+// We're finally going to get to what a Stage function looks like!
+//    tail == 0 ~~> work on a full N pixels
+//    tail != 0 ~~> work on only the first tail pixels
+// tail is always < N.
+
+// Any custom ABI to use for all (non-externally-facing) stage functions?
+// Also decide here whether to use narrow (compromise) or wide (ideal) stages.
+#if defined(__arm__) && defined(__ARM_NEON)
+    // This lets us pass vectors more efficiently on 32-bit ARM.
+    // We can still only pass 16 floats, so best as 4x {r,g,b,a}.
+    #define ABI __attribute__((pcs("aapcs-vfp")))
+    #define JUMPER_NARROW_STAGES 1
+#elif 0 && defined(_MSC_VER) && defined(__clang__) && defined(__x86_64__)
+    // SysV ABI makes it very sensible to use wide stages with clang-cl.
+    // TODO: crashes during compilation  :(
+    #define ABI __attribute__((sysv_abi))
+    #define JUMPER_NARROW_STAGES 0
+#elif defined(_MSC_VER)
+    // Even if not vectorized, this lets us pass {r,g,b,a} as registers,
+    // instead of {b,a} on the stack.  Narrow stages work best for __vectorcall.
+    #define ABI __vectorcall
+    #define JUMPER_NARROW_STAGES 1
+#elif defined(__x86_64__) || defined(__aarch64__)
+    // These platforms are ideal for wider stages, and their default ABI is ideal.
+    #define ABI
+    #define JUMPER_NARROW_STAGES 0
+#else
+    // 32-bit or unknown... shunt them down the narrow path.
+    // Odds are these have few registers and are better off there.
+    #define ABI
+    #define JUMPER_NARROW_STAGES 1
+#endif
+
+#if JUMPER_NARROW_STAGES
+    struct Params {
+        size_t dx, dy, tail;
+        F dr,dg,db,da;
+    };
+    using Stage = void(ABI*)(Params*, void** program, F r, F g, F b, F a);
+#else
+    // We keep program the second argument, so that it's passed in rsi for load_and_inc().
+    using Stage = void(ABI*)(size_t tail, void** program, size_t dx, size_t dy, F,F,F,F, F,F,F,F);
+#endif
+
+
+static void start_pipeline(size_t dx, size_t dy, size_t xlimit, size_t ylimit, void** program) {
+    auto start = (Stage)load_and_inc(program);
+    const size_t x0 = dx;
+    for (; dy < ylimit; dy++) {
+    #if JUMPER_NARROW_STAGES
+        Params params = { x0,dy,0, 0,0,0,0 };
+        while (params.dx + N <= xlimit) {
+            start(&params,program, 0,0,0,0);
+            params.dx += N;
+        }
+        if (size_t tail = xlimit - params.dx) {
+            params.tail = tail;
+            start(&params,program, 0,0,0,0);
+        }
+    #else
+        dx = x0;
+        while (dx + N <= xlimit) {
+            start(0,program,dx,dy,    0,0,0,0, 0,0,0,0);
+            dx += N;
+        }
+        if (size_t tail = xlimit - dx) {
+            start(tail,program,dx,dy, 0,0,0,0, 0,0,0,0);
+        }
+    #endif
+    }
+}
+
+#if JUMPER_NARROW_STAGES
+    #define STAGE(name, ...)                                                    \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,        \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da);   \
+        static void ABI name(Params* params, void** program,                    \
+                             F r, F g, F b, F a) {                              \
+            name##_k(Ctx{program},params->dx,params->dy,params->tail, r,g,b,a,  \
+                     params->dr, params->dg, params->db, params->da);           \
+            auto next = (Stage)load_and_inc(program);                           \
+            next(params,program, r,g,b,a);                                      \
+        }                                                                       \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,        \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da)
+#else
+    #define STAGE(name, ...)                                                         \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,             \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da);        \
+        static void ABI name(size_t tail, void** program, size_t dx, size_t dy,      \
+                             F r, F g, F b, F a, F dr, F dg, F db, F da) {           \
+            name##_k(Ctx{program},dx,dy,tail, r,g,b,a, dr,dg,db,da);                 \
+            auto next = (Stage)load_and_inc(program);                                \
+            next(tail,program,dx,dy, r,g,b,a, dr,dg,db,da);                          \
+        }                                                                            \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,             \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da)
+#endif
+
+
+// just_return() is a simple no-op stage that only exists to end the chain,
+// returning back up to start_pipeline(), and from there to the caller.
+#if JUMPER_NARROW_STAGES
+    static void ABI just_return(Params*, void**, F,F,F,F) {}
+#else
+    static void ABI just_return(size_t, void**, size_t,size_t, F,F,F,F, F,F,F,F) {}
+#endif
+
+
+// We could start defining normal Stages now.  But first, some helper functions.
+
+// These load() and store() methods are tail-aware,
+// but focus mainly on keeping the at-stride tail==0 case fast.
+
+template <typename V, typename T>
+SI V load(const T* src, size_t tail) {
+#if !defined(JUMPER_IS_SCALAR)
+    __builtin_assume(tail < N);
+    if (__builtin_expect(tail, 0)) {
+        V v{};  // Any inactive lanes are zeroed.
+        switch (tail) {
+            case 7: v[6] = src[6];
+            case 6: v[5] = src[5];
+            case 5: v[4] = src[4];
+            case 4: memcpy(&v, src, 4*sizeof(T)); break;
+            case 3: v[2] = src[2];
+            case 2: memcpy(&v, src, 2*sizeof(T)); break;
+            case 1: memcpy(&v, src, 1*sizeof(T)); break;
+        }
+        return v;
+    }
+#endif
+    return unaligned_load<V>(src);
+}
+
+template <typename V, typename T>
+SI void store(T* dst, V v, size_t tail) {
+#if !defined(JUMPER_IS_SCALAR)
+    __builtin_assume(tail < N);
+    if (__builtin_expect(tail, 0)) {
+        switch (tail) {
+            case 7: dst[6] = v[6];
+            case 6: dst[5] = v[5];
+            case 5: dst[4] = v[4];
+            case 4: memcpy(dst, &v, 4*sizeof(T)); break;
+            case 3: dst[2] = v[2];
+            case 2: memcpy(dst, &v, 2*sizeof(T)); break;
+            case 1: memcpy(dst, &v, 1*sizeof(T)); break;
+        }
+        return;
+    }
+#endif
+    unaligned_store(dst, v);
+}
+
+SI F from_byte(U8 b) {
+    return cast(expand(b)) * (1/255.0f);
+}
+SI void from_565(U16 _565, F* r, F* g, F* b) {
+    U32 wide = expand(_565);
+    *r = cast(wide & (31<<11)) * (1.0f / (31<<11));
+    *g = cast(wide & (63<< 5)) * (1.0f / (63<< 5));
+    *b = cast(wide & (31<< 0)) * (1.0f / (31<< 0));
+}
+SI void from_4444(U16 _4444, F* r, F* g, F* b, F* a) {
+    U32 wide = expand(_4444);
+    *r = cast(wide & (15<<12)) * (1.0f / (15<<12));
+    *g = cast(wide & (15<< 8)) * (1.0f / (15<< 8));
+    *b = cast(wide & (15<< 4)) * (1.0f / (15<< 4));
+    *a = cast(wide & (15<< 0)) * (1.0f / (15<< 0));
+}
+SI void from_8888(U32 _8888, F* r, F* g, F* b, F* a) {
+    *r = cast((_8888      ) & 0xff) * (1/255.0f);
+    *g = cast((_8888 >>  8) & 0xff) * (1/255.0f);
+    *b = cast((_8888 >> 16) & 0xff) * (1/255.0f);
+    *a = cast((_8888 >> 24)       ) * (1/255.0f);
+}
+SI void from_1010102(U32 rgba, F* r, F* g, F* b, F* a) {
+    *r = cast((rgba      ) & 0x3ff) * (1/1023.0f);
+    *g = cast((rgba >> 10) & 0x3ff) * (1/1023.0f);
+    *b = cast((rgba >> 20) & 0x3ff) * (1/1023.0f);
+    *a = cast((rgba >> 30)        ) * (1/   3.0f);
+}
+
+// Used by load_ and store_ stages to get to the right (dx,dy) starting point of contiguous memory.
+template <typename T>
+SI T* ptr_at_xy(const SkJumper_MemoryCtx* ctx, size_t dx, size_t dy) {
+    return (T*)ctx->pixels + dy*ctx->stride + dx;
+}
+
+// clamp v to [0,limit).
+SI F clamp(F v, F limit) {
+    F inclusive = bit_cast<F>( bit_cast<U32>(limit) - 1 );  // Exclusive -> inclusive.
+    return min(max(0, v), inclusive);
+}
+
+// Used by gather_ stages to calculate the base pointer and a vector of indices to load.
+template <typename T>
+SI U32 ix_and_ptr(T** ptr, const SkJumper_GatherCtx* ctx, F x, F y) {
+    x = clamp(x, ctx->width);
+    y = clamp(y, ctx->height);
+
+    *ptr = (const T*)ctx->pixels;
+    return trunc_(y)*ctx->stride + trunc_(x);
+}
+
+// We often have a nominally [0,1] float value we need to scale and convert to an integer,
+// whether for a table lookup or to pack back down into bytes for storage.
+//
+// In practice, especially when dealing with interesting color spaces, that notionally
+// [0,1] float may be out of [0,1] range.  Unorms cannot represent that, so we must clamp.
+//
+// You can adjust the expected input to [0,bias] by tweaking that parameter.
+SI U32 to_unorm(F v, F scale, F bias = 1.0f) {
+    // TODO: platform-specific implementations to to_unorm(), removing round() entirely?
+    // Any time we use round() we probably want to use to_unorm().
+    return round(min(max(0, v), bias), scale);
+}
+
+SI I32 cond_to_mask(I32 cond) { return if_then_else(cond, I32(~0), I32(0)); }
+
+// Now finally, normal Stages!
+
+STAGE(seed_shader, Ctx::None) {
+    static const float iota[] = {
+        0.5f, 1.5f, 2.5f, 3.5f, 4.5f, 5.5f, 6.5f, 7.5f,
+        8.5f, 9.5f,10.5f,11.5f,12.5f,13.5f,14.5f,15.5f,
+    };
+    // It's important for speed to explicitly cast(dx) and cast(dy),
+    // which has the effect of splatting them to vectors before converting to floats.
+    // On Intel this breaks a data dependency on previous loop iterations' registers.
+    r = cast(dx) + unaligned_load<F>(iota);
+    g = cast(dy) + 0.5f;
+    b = 1.0f;
+    a = 0;
+    dr = dg = db = da = 0;
+}
+
+STAGE(dither, const float* rate) {
+    // Get [(dx,dy), (dx+1,dy), (dx+2,dy), ...] loaded up in integer vectors.
+    uint32_t iota[] = {0,1,2,3,4,5,6,7};
+    U32 X = dx + unaligned_load<U32>(iota),
+        Y = dy;
+
+    // We're doing 8x8 ordered dithering, see https://en.wikipedia.org/wiki/Ordered_dithering.
+    // In this case n=8 and we're using the matrix that looks like 1/64 x [ 0 48 12 60 ... ].
+
+    // We only need X and X^Y from here on, so it's easier to just think of that as "Y".
+    Y ^= X;
+
+    // We'll mix the bottom 3 bits of each of X and Y to make 6 bits,
+    // for 2^6 == 64 == 8x8 matrix values.  If X=abc and Y=def, we make fcebda.
+    U32 M = (Y & 1) << 5 | (X & 1) << 4
+          | (Y & 2) << 2 | (X & 2) << 1
+          | (Y & 4) >> 1 | (X & 4) >> 2;
+
+    // Scale that dither to [0,1), then (-0.5,+0.5), here using 63/128 = 0.4921875 as 0.5-epsilon.
+    // We want to make sure our dither is less than 0.5 in either direction to keep exact values
+    // like 0 and 1 unchanged after rounding.
+    F dither = cast(M) * (2/128.0f) - (63/128.0f);
+
+    r += *rate*dither;
+    g += *rate*dither;
+    b += *rate*dither;
+
+    r = max(0, min(r, a));
+    g = max(0, min(g, a));
+    b = max(0, min(b, a));
+}
+
+// load 4 floats from memory, and splat them into r,g,b,a
+STAGE(uniform_color, const SkJumper_UniformColorCtx* c) {
+    r = c->r;
+    g = c->g;
+    b = c->b;
+    a = c->a;
+}
+
+// splats opaque-black into r,g,b,a
+STAGE(black_color, Ctx::None) {
+    r = g = b = 0.0f;
+    a = 1.0f;
+}
+
+STAGE(white_color, Ctx::None) {
+    r = g = b = a = 1.0f;
+}
+
+// load registers r,g,b,a from context (mirrors store_rgba)
+STAGE(load_rgba, const float* ptr) {
+    r = unaligned_load<F>(ptr + 0*N);
+    g = unaligned_load<F>(ptr + 1*N);
+    b = unaligned_load<F>(ptr + 2*N);
+    a = unaligned_load<F>(ptr + 3*N);
+}
+
+// store registers r,g,b,a into context (mirrors load_rgba)
+STAGE(store_rgba, float* ptr) {
+    unaligned_store(ptr + 0*N, r);
+    unaligned_store(ptr + 1*N, g);
+    unaligned_store(ptr + 2*N, b);
+    unaligned_store(ptr + 3*N, a);
+}
+
+// Most blend modes apply the same logic to each channel.
+#define BLEND_MODE(name)                       \
+    SI F name##_channel(F s, F d, F sa, F da); \
+    STAGE(name, Ctx::None) {                   \
+        r = name##_channel(r,dr,a,da);         \
+        g = name##_channel(g,dg,a,da);         \
+        b = name##_channel(b,db,a,da);         \
+        a = name##_channel(a,da,a,da);         \
+    }                                          \
+    SI F name##_channel(F s, F d, F sa, F da)
+
+SI F inv(F x) { return 1.0f - x; }
+SI F two(F x) { return x + x; }
+
+
+BLEND_MODE(clear)    { return 0; }
+BLEND_MODE(srcatop)  { return s*da + d*inv(sa); }
+BLEND_MODE(dstatop)  { return d*sa + s*inv(da); }
+BLEND_MODE(srcin)    { return s * da; }
+BLEND_MODE(dstin)    { return d * sa; }
+BLEND_MODE(srcout)   { return s * inv(da); }
+BLEND_MODE(dstout)   { return d * inv(sa); }
+BLEND_MODE(srcover)  { return mad(d, inv(sa), s); }
+BLEND_MODE(dstover)  { return mad(s, inv(da), d); }
+
+BLEND_MODE(modulate) { return s*d; }
+BLEND_MODE(multiply) { return s*inv(da) + d*inv(sa) + s*d; }
+BLEND_MODE(plus_)    { return min(s + d, 1.0f); }  // We can clamp to either 1 or sa.
+BLEND_MODE(screen)   { return s + d - s*d; }
+BLEND_MODE(xor_)     { return s*inv(da) + d*inv(sa); }
+#undef BLEND_MODE
+
+// Most other blend modes apply the same logic to colors, and srcover to alpha.
+#define BLEND_MODE(name)                       \
+    SI F name##_channel(F s, F d, F sa, F da); \
+    STAGE(name, Ctx::None) {                   \
+        r = name##_channel(r,dr,a,da);         \
+        g = name##_channel(g,dg,a,da);         \
+        b = name##_channel(b,db,a,da);         \
+        a = mad(da, inv(a), a);                \
+    }                                          \
+    SI F name##_channel(F s, F d, F sa, F da)
+
+BLEND_MODE(darken)     { return s + d -     max(s*da, d*sa) ; }
+BLEND_MODE(lighten)    { return s + d -     min(s*da, d*sa) ; }
+BLEND_MODE(difference) { return s + d - two(min(s*da, d*sa)); }
+BLEND_MODE(exclusion)  { return s + d - two(s*d); }
+
+BLEND_MODE(colorburn) {
+    return if_then_else(d == da,    d +    s*inv(da),
+           if_then_else(s ==  0, /* s + */ d*inv(sa),
+                                 sa*(da - min(da, (da-d)*sa*rcp(s))) + s*inv(da) + d*inv(sa)));
+}
+BLEND_MODE(colordodge) {
+    return if_then_else(d ==  0, /* d + */ s*inv(da),
+           if_then_else(s == sa,    s +    d*inv(sa),
+                                 sa*min(da, (d*sa)*rcp(sa - s)) + s*inv(da) + d*inv(sa)));
+}
+BLEND_MODE(hardlight) {
+    return s*inv(da) + d*inv(sa)
+         + if_then_else(two(s) <= sa, two(s*d), sa*da - two((da-d)*(sa-s)));
+}
+BLEND_MODE(overlay) {
+    return s*inv(da) + d*inv(sa)
+         + if_then_else(two(d) <= da, two(s*d), sa*da - two((da-d)*(sa-s)));
+}
+
+BLEND_MODE(softlight) {
+    F m  = if_then_else(da > 0, d / da, 0),
+      s2 = two(s),
+      m4 = two(two(m));
+
+    // The logic forks three ways:
+    //    1. dark src?
+    //    2. light src, dark dst?
+    //    3. light src, light dst?
+    F darkSrc = d*(sa + (s2 - sa)*(1.0f - m)),     // Used in case 1.
+      darkDst = (m4*m4 + m4)*(m - 1.0f) + 7.0f*m,  // Used in case 2.
+      liteDst = rcp(rsqrt(m)) - m,                 // Used in case 3.
+      liteSrc = d*sa + da*(s2 - sa) * if_then_else(two(two(d)) <= da, darkDst, liteDst); // 2 or 3?
+    return s*inv(da) + d*inv(sa) + if_then_else(s2 <= sa, darkSrc, liteSrc);      // 1 or (2 or 3)?
+}
+#undef BLEND_MODE
+
+// We're basing our implemenation of non-separable blend modes on
+//   https://www.w3.org/TR/compositing-1/#blendingnonseparable.
+// and
+//   https://www.khronos.org/registry/OpenGL/specs/es/3.2/es_spec_3.2.pdf
+// They're equivalent, but ES' math has been better simplified.
+//
+// Anything extra we add beyond that is to make the math work with premul inputs.
+
+SI F max(F r, F g, F b) { return max(r, max(g, b)); }
+SI F min(F r, F g, F b) { return min(r, min(g, b)); }
+
+SI F sat(F r, F g, F b) { return max(r,g,b) - min(r,g,b); }
+SI F lum(F r, F g, F b) { return r*0.30f + g*0.59f + b*0.11f; }
+
+SI void set_sat(F* r, F* g, F* b, F s) {
+    F mn  = min(*r,*g,*b),
+      mx  = max(*r,*g,*b),
+      sat = mx - mn;
+
+    // Map min channel to 0, max channel to s, and scale the middle proportionally.
+    auto scale = [=](F c) {
+        return if_then_else(sat == 0, 0, (c - mn) * s / sat);
+    };
+    *r = scale(*r);
+    *g = scale(*g);
+    *b = scale(*b);
+}
+SI void set_lum(F* r, F* g, F* b, F l) {
+    F diff = l - lum(*r, *g, *b);
+    *r += diff;
+    *g += diff;
+    *b += diff;
+}
+SI void clip_color(F* r, F* g, F* b, F a) {
+    F mn = min(*r, *g, *b),
+      mx = max(*r, *g, *b),
+      l  = lum(*r, *g, *b);
+
+    auto clip = [=](F c) {
+        c = if_then_else(mn >= 0, c, l + (c - l) * (    l) / (l - mn)   );
+        c = if_then_else(mx >  a,    l + (c - l) * (a - l) / (mx - l), c);
+        c = max(c, 0);  // Sometimes without this we may dip just a little negative.
+        return c;
+    };
+    *r = clip(*r);
+    *g = clip(*g);
+    *b = clip(*b);
+}
+
+STAGE(hue, Ctx::None) {
+    F R = r*a,
+      G = g*a,
+      B = b*a;
+
+    set_sat(&R, &G, &B, sat(dr,dg,db)*a);
+    set_lum(&R, &G, &B, lum(dr,dg,db)*a);
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+STAGE(saturation, Ctx::None) {
+    F R = dr*a,
+      G = dg*a,
+      B = db*a;
+
+    set_sat(&R, &G, &B, sat( r, g, b)*da);
+    set_lum(&R, &G, &B, lum(dr,dg,db)* a);  // (This is not redundant.)
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+STAGE(color, Ctx::None) {
+    F R = r*da,
+      G = g*da,
+      B = b*da;
+
+    set_lum(&R, &G, &B, lum(dr,dg,db)*a);
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+STAGE(luminosity, Ctx::None) {
+    F R = dr*a,
+      G = dg*a,
+      B = db*a;
+
+    set_lum(&R, &G, &B, lum(r,g,b)*da);
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+
+STAGE(srcover_rgba_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 dst = load<U32>(ptr, tail);
+    dr = cast((dst      ) & 0xff);
+    dg = cast((dst >>  8) & 0xff);
+    db = cast((dst >> 16) & 0xff);
+    da = cast((dst >> 24)       );
+    // {dr,dg,db,da} are in [0,255]
+    // { r, g, b, a} are in [0,  1] (but may be out of gamut)
+
+    r = mad(dr, inv(a), r*255.0f);
+    g = mad(dg, inv(a), g*255.0f);
+    b = mad(db, inv(a), b*255.0f);
+    a = mad(da, inv(a), a*255.0f);
+    // { r, g, b, a} are now in [0,255]  (but may be out of gamut)
+
+    // to_unorm() clamps back to gamut.  Scaling by 1 since we're already 255-biased.
+    dst = to_unorm(r, 1, 255)
+        | to_unorm(g, 1, 255) <<  8
+        | to_unorm(b, 1, 255) << 16
+        | to_unorm(a, 1, 255) << 24;
+    store(ptr, dst, tail);
+}
+
+STAGE(srcover_bgra_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 dst = load<U32>(ptr, tail);
+    db = cast((dst      ) & 0xff);
+    dg = cast((dst >>  8) & 0xff);
+    dr = cast((dst >> 16) & 0xff);
+    da = cast((dst >> 24)       );
+    // {dr,dg,db,da} are in [0,255]
+    // { r, g, b, a} are in [0,  1] (but may be out of gamut)
+
+    r = mad(dr, inv(a), r*255.0f);
+    g = mad(dg, inv(a), g*255.0f);
+    b = mad(db, inv(a), b*255.0f);
+    a = mad(da, inv(a), a*255.0f);
+    // { r, g, b, a} are now in [0,255]  (but may be out of gamut)
+
+    // to_unorm() clamps back to gamut.  Scaling by 1 since we're already 255-biased.
+    dst = to_unorm(b, 1, 255)
+        | to_unorm(g, 1, 255) <<  8
+        | to_unorm(r, 1, 255) << 16
+        | to_unorm(a, 1, 255) << 24;
+    store(ptr, dst, tail);
+}
+
+STAGE(clamp_0, Ctx::None) {
+    r = max(r, 0);
+    g = max(g, 0);
+    b = max(b, 0);
+    a = max(a, 0);
+}
+
+STAGE(clamp_1, Ctx::None) {
+    r = min(r, 1.0f);
+    g = min(g, 1.0f);
+    b = min(b, 1.0f);
+    a = min(a, 1.0f);
+}
+
+STAGE(clamp_a, Ctx::None) {
+    a = min(a, 1.0f);
+    r = min(r, a);
+    g = min(g, a);
+    b = min(b, a);
+}
+
+STAGE(clamp_a_dst, Ctx::None) {
+    da = min(da, 1.0f);
+    dr = min(dr, da);
+    dg = min(dg, da);
+    db = min(db, da);
+}
+
+STAGE(set_rgb, const float* rgb) {
+    r = rgb[0];
+    g = rgb[1];
+    b = rgb[2];
+}
+STAGE(swap_rb, Ctx::None) {
+    auto tmp = r;
+    r = b;
+    b = tmp;
+}
+STAGE(invert, Ctx::None) {
+    r = inv(r);
+    g = inv(g);
+    b = inv(b);
+    a = inv(a);
+}
+
+STAGE(move_src_dst, Ctx::None) {
+    dr = r;
+    dg = g;
+    db = b;
+    da = a;
+}
+STAGE(move_dst_src, Ctx::None) {
+    r = dr;
+    g = dg;
+    b = db;
+    a = da;
+}
+
+STAGE(premul, Ctx::None) {
+    r = r * a;
+    g = g * a;
+    b = b * a;
+}
+STAGE(premul_dst, Ctx::None) {
+    dr = dr * da;
+    dg = dg * da;
+    db = db * da;
+}
+STAGE(unpremul, Ctx::None) {
+    float inf = bit_cast<float>(0x7f800000);
+    auto scale = if_then_else(1.0f/a < inf, 1.0f/a, 0);
+    r *= scale;
+    g *= scale;
+    b *= scale;
+}
+
+STAGE(force_opaque    , Ctx::None) {  a = 1; }
+STAGE(force_opaque_dst, Ctx::None) { da = 1; }
+
+SI F from_srgb_(F s) {
+    auto lo = s * (1/12.92f);
+    auto hi = mad(s*s, mad(s, 0.3000f, 0.6975f), 0.0025f);
+    return if_then_else(s < 0.055f, lo, hi);
+}
+
+STAGE(from_srgb, Ctx::None) {
+    r = from_srgb_(r);
+    g = from_srgb_(g);
+    b = from_srgb_(b);
+}
+STAGE(from_srgb_dst, Ctx::None) {
+    dr = from_srgb_(dr);
+    dg = from_srgb_(dg);
+    db = from_srgb_(db);
+}
+STAGE(to_srgb, Ctx::None) {
+    auto fn = [&](F l) {
+        // We tweak c and d for each instruction set to make sure fn(1) is exactly 1.
+    #if defined(JUMPER_IS_AVX512)
+        const float c = 1.130026340485f,
+                    d = 0.141387879848f;
+    #elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41) || \
+          defined(JUMPER_IS_AVX ) || defined(JUMPER_IS_HSW )
+        const float c = 1.130048394203f,
+                    d = 0.141357362270f;
+    #elif defined(JUMPER_IS_NEON)
+        const float c = 1.129999995232f,
+                    d = 0.141381442547f;
+    #else
+        const float c = 1.129999995232f,
+                    d = 0.141377761960f;
+    #endif
+        F t = rsqrt(l);
+        auto lo = l * 12.92f;
+        auto hi = mad(t, mad(t, -0.0024542345f, 0.013832027f), c)
+                * rcp(d + t);
+        return if_then_else(l < 0.00465985f, lo, hi);
+    };
+    r = fn(r);
+    g = fn(g);
+    b = fn(b);
+}
+
+STAGE(rgb_to_hsl, Ctx::None) {
+    F mx = max(r,g,b),
+      mn = min(r,g,b),
+      d = mx - mn,
+      d_rcp = 1.0f / d;
+
+    F h = (1/6.0f) *
+          if_then_else(mx == mn, 0,
+          if_then_else(mx ==  r, (g-b)*d_rcp + if_then_else(g < b, 6.0f, 0),
+          if_then_else(mx ==  g, (b-r)*d_rcp + 2.0f,
+                                 (r-g)*d_rcp + 4.0f)));
+
+    F l = (mx + mn) * 0.5f;
+    F s = if_then_else(mx == mn, 0,
+                       d / if_then_else(l > 0.5f, 2.0f-mx-mn, mx+mn));
+
+    r = h;
+    g = s;
+    b = l;
+}
+STAGE(hsl_to_rgb, Ctx::None) {
+    F h = r,
+      s = g,
+      l = b;
+
+    F q = l + if_then_else(l >= 0.5f, s - l*s, l*s),
+      p = 2.0f*l - q;
+
+    auto hue_to_rgb = [&](F t) {
+        t = fract(t);
+
+        F r = p;
+        r = if_then_else(t >= 4/6.0f, r, p + (q-p)*(4.0f - 6.0f*t));
+        r = if_then_else(t >= 3/6.0f, r, q);
+        r = if_then_else(t >= 1/6.0f, r, p + (q-p)*(       6.0f*t));
+        return r;
+    };
+
+    r = if_then_else(s == 0, l, hue_to_rgb(h + (1/3.0f)));
+    g = if_then_else(s == 0, l, hue_to_rgb(h           ));
+    b = if_then_else(s == 0, l, hue_to_rgb(h - (1/3.0f)));
+}
+
+// Derive alpha's coverage from rgb coverage and the values of src and dst alpha.
+SI F alpha_coverage_from_rgb_coverage(F a, F da, F cr, F cg, F cb) {
+    return if_then_else(a < da, min(cr,cg,cb)
+                              , max(cr,cg,cb));
+}
+
+STAGE(scale_1_float, const float* c) {
+    r = r * *c;
+    g = g * *c;
+    b = b * *c;
+    a = a * *c;
+}
+STAGE(scale_u8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    auto scales = load<U8>(ptr, tail);
+    auto c = from_byte(scales);
+
+    r = r * c;
+    g = g * c;
+    b = b * c;
+    a = a * c;
+}
+STAGE(scale_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    F cr,cg,cb;
+    from_565(load<U16>(ptr, tail), &cr, &cg, &cb);
+
+    F ca = alpha_coverage_from_rgb_coverage(a,da, cr,cg,cb);
+
+    r = r * cr;
+    g = g * cg;
+    b = b * cb;
+    a = a * ca;
+}
+
+SI F lerp(F from, F to, F t) {
+    return mad(to-from, t, from);
+}
+
+STAGE(lerp_1_float, const float* c) {
+    r = lerp(dr, r, *c);
+    g = lerp(dg, g, *c);
+    b = lerp(db, b, *c);
+    a = lerp(da, a, *c);
+}
+STAGE(lerp_u8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    auto scales = load<U8>(ptr, tail);
+    auto c = from_byte(scales);
+
+    r = lerp(dr, r, c);
+    g = lerp(dg, g, c);
+    b = lerp(db, b, c);
+    a = lerp(da, a, c);
+}
+STAGE(lerp_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    F cr,cg,cb;
+    from_565(load<U16>(ptr, tail), &cr, &cg, &cb);
+
+    F ca = alpha_coverage_from_rgb_coverage(a,da, cr,cg,cb);
+
+    r = lerp(dr, r, cr);
+    g = lerp(dg, g, cg);
+    b = lerp(db, b, cb);
+    a = lerp(da, a, ca);
+}
+
+STAGE(load_tables, const SkJumper_LoadTablesCtx* c) {
+    auto px = load<U32>((const uint32_t*)c->src + dx, tail);
+    r = gather(c->r, (px      ) & 0xff);
+    g = gather(c->g, (px >>  8) & 0xff);
+    b = gather(c->b, (px >> 16) & 0xff);
+    a = cast(        (px >> 24)) * (1/255.0f);
+}
+STAGE(load_tables_u16_be, const SkJumper_LoadTablesCtx* c) {
+    auto ptr = (const uint16_t*)c->src + 4*dx;
+
+    U16 R,G,B,A;
+    load4(ptr, tail, &R,&G,&B,&A);
+
+    // c->src is big-endian, so & 0xff grabs the 8 most signficant bits.
+    r = gather(c->r, expand(R) & 0xff);
+    g = gather(c->g, expand(G) & 0xff);
+    b = gather(c->b, expand(B) & 0xff);
+    a = (1/65535.0f) * cast(expand(bswap(A)));
+}
+STAGE(load_tables_rgb_u16_be, const SkJumper_LoadTablesCtx* c) {
+    auto ptr = (const uint16_t*)c->src + 3*dx;
+
+    U16 R,G,B;
+    load3(ptr, tail, &R,&G,&B);
+
+    // c->src is big-endian, so & 0xff grabs the 8 most signficant bits.
+    r = gather(c->r, expand(R) & 0xff);
+    g = gather(c->g, expand(G) & 0xff);
+    b = gather(c->b, expand(B) & 0xff);
+    a = 1.0f;
+}
+
+STAGE(byte_tables, const void* ctx) {  // TODO: rename Tables SkJumper_ByteTablesCtx
+    struct Tables { const uint8_t *r, *g, *b, *a; };
+    auto tables = (const Tables*)ctx;
+
+    r = from_byte(gather(tables->r, to_unorm(r, 255)));
+    g = from_byte(gather(tables->g, to_unorm(g, 255)));
+    b = from_byte(gather(tables->b, to_unorm(b, 255)));
+    a = from_byte(gather(tables->a, to_unorm(a, 255)));
+}
+
+STAGE(byte_tables_rgb, const SkJumper_ByteTablesRGBCtx* ctx) {
+    int scale = ctx->n - 1;
+    r = from_byte(gather(ctx->r, to_unorm(r, scale)));
+    g = from_byte(gather(ctx->g, to_unorm(g, scale)));
+    b = from_byte(gather(ctx->b, to_unorm(b, scale)));
+}
+
+SI F table(F v, const SkJumper_TableCtx* ctx) {
+    return gather(ctx->table, to_unorm(v, ctx->size - 1));
+}
+STAGE(table_r, const SkJumper_TableCtx* ctx) { r = table(r, ctx); }
+STAGE(table_g, const SkJumper_TableCtx* ctx) { g = table(g, ctx); }
+STAGE(table_b, const SkJumper_TableCtx* ctx) { b = table(b, ctx); }
+STAGE(table_a, const SkJumper_TableCtx* ctx) { a = table(a, ctx); }
+
+SI F parametric(F v, const SkJumper_ParametricTransferFunction* ctx) {
+    F r = if_then_else(v <= ctx->D, mad(ctx->C, v, ctx->F)
+                                  , approx_powf(mad(ctx->A, v, ctx->B), ctx->G) + ctx->E);
+    return min(max(r, 0), 1.0f);  // Clamp to [0,1], with argument order mattering to handle NaN.
+}
+STAGE(parametric_r, const SkJumper_ParametricTransferFunction* ctx) { r = parametric(r, ctx); }
+STAGE(parametric_g, const SkJumper_ParametricTransferFunction* ctx) { g = parametric(g, ctx); }
+STAGE(parametric_b, const SkJumper_ParametricTransferFunction* ctx) { b = parametric(b, ctx); }
+STAGE(parametric_a, const SkJumper_ParametricTransferFunction* ctx) { a = parametric(a, ctx); }
+
+STAGE(gamma, const float* G) {
+    r = approx_powf(r, *G);
+    g = approx_powf(g, *G);
+    b = approx_powf(b, *G);
+}
+STAGE(gamma_dst, const float* G) {
+    dr = approx_powf(dr, *G);
+    dg = approx_powf(dg, *G);
+    db = approx_powf(db, *G);
+}
+
+STAGE(lab_to_xyz, Ctx::None) {
+    F L = r * 100.0f,
+      A = g * 255.0f - 128.0f,
+      B = b * 255.0f - 128.0f;
+
+    F Y = (L + 16.0f) * (1/116.0f),
+      X = Y + A*(1/500.0f),
+      Z = Y - B*(1/200.0f);
+
+    X = if_then_else(X*X*X > 0.008856f, X*X*X, (X - (16/116.0f)) * (1/7.787f));
+    Y = if_then_else(Y*Y*Y > 0.008856f, Y*Y*Y, (Y - (16/116.0f)) * (1/7.787f));
+    Z = if_then_else(Z*Z*Z > 0.008856f, Z*Z*Z, (Z - (16/116.0f)) * (1/7.787f));
+
+    // Adjust to D50 illuminant.
+    r = X * 0.96422f;
+    g = Y           ;
+    b = Z * 0.82521f;
+}
+
+STAGE(load_a8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    r = g = b = 0.0f;
+    a = from_byte(load<U8>(ptr, tail));
+}
+STAGE(load_a8_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    dr = dg = db = 0.0f;
+    da = from_byte(load<U8>(ptr, tail));
+}
+STAGE(gather_a8, const SkJumper_GatherCtx* ctx) {
+    const uint8_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    r = g = b = 0.0f;
+    a = from_byte(gather(ptr, ix));
+}
+STAGE(store_a8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint8_t>(ctx, dx,dy);
+
+    U8 packed = pack(pack(to_unorm(a, 255)));
+    store(ptr, packed, tail);
+}
+
+STAGE(load_g8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    r = g = b = from_byte(load<U8>(ptr, tail));
+    a = 1.0f;
+}
+STAGE(load_g8_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    dr = dg = db = from_byte(load<U8>(ptr, tail));
+    da = 1.0f;
+}
+STAGE(gather_g8, const SkJumper_GatherCtx* ctx) {
+    const uint8_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    r = g = b = from_byte(gather(ptr, ix));
+    a = 1.0f;
+}
+
+STAGE(load_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    from_565(load<U16>(ptr, tail), &r,&g,&b);
+    a = 1.0f;
+}
+STAGE(load_565_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    from_565(load<U16>(ptr, tail), &dr,&dg,&db);
+    da = 1.0f;
+}
+STAGE(gather_565, const SkJumper_GatherCtx* ctx) {
+    const uint16_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_565(gather(ptr, ix), &r,&g,&b);
+    a = 1.0f;
+}
+STAGE(store_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint16_t>(ctx, dx,dy);
+
+    U16 px = pack( to_unorm(r, 31) << 11
+                 | to_unorm(g, 63) <<  5
+                 | to_unorm(b, 31)      );
+    store(ptr, px, tail);
+}
+
+STAGE(load_4444, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+    from_4444(load<U16>(ptr, tail), &r,&g,&b,&a);
+}
+STAGE(load_4444_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+    from_4444(load<U16>(ptr, tail), &dr,&dg,&db,&da);
+}
+STAGE(gather_4444, const SkJumper_GatherCtx* ctx) {
+    const uint16_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_4444(gather(ptr, ix), &r,&g,&b,&a);
+}
+STAGE(store_4444, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint16_t>(ctx, dx,dy);
+    U16 px = pack( to_unorm(r, 15) << 12
+                 | to_unorm(g, 15) <<  8
+                 | to_unorm(b, 15) <<  4
+                 | to_unorm(a, 15)      );
+    store(ptr, px, tail);
+}
+
+STAGE(load_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &r,&g,&b,&a);
+}
+STAGE(load_8888_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &dr,&dg,&db,&da);
+}
+STAGE(gather_8888, const SkJumper_GatherCtx* ctx) {
+    const uint32_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_8888(gather(ptr, ix), &r,&g,&b,&a);
+}
+STAGE(store_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 px = to_unorm(r, 255)
+           | to_unorm(g, 255) <<  8
+           | to_unorm(b, 255) << 16
+           | to_unorm(a, 255) << 24;
+    store(ptr, px, tail);
+}
+
+STAGE(load_bgra, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &b,&g,&r,&a);
+}
+STAGE(load_bgra_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &db,&dg,&dr,&da);
+}
+STAGE(gather_bgra, const SkJumper_GatherCtx* ctx) {
+    const uint32_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_8888(gather(ptr, ix), &b,&g,&r,&a);
+}
+STAGE(store_bgra, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 px = to_unorm(b, 255)
+           | to_unorm(g, 255) <<  8
+           | to_unorm(r, 255) << 16
+           | to_unorm(a, 255) << 24;
+    store(ptr, px, tail);
+}
+
+STAGE(load_1010102, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_1010102(load<U32>(ptr, tail), &r,&g,&b,&a);
+}
+STAGE(load_1010102_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_1010102(load<U32>(ptr, tail), &dr,&dg,&db,&da);
+}
+STAGE(gather_1010102, const SkJumper_GatherCtx* ctx) {
+    const uint32_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_1010102(gather(ptr, ix), &r,&g,&b,&a);
+}
+STAGE(store_1010102, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 px = to_unorm(r, 1023)
+           | to_unorm(g, 1023) << 10
+           | to_unorm(b, 1023) << 20
+           | to_unorm(a,    3) << 30;
+    store(ptr, px, tail);
+}
+
+STAGE(load_f16, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint64_t>(ctx, dx,dy);
+
+    U16 R,G,B,A;
+    load4((const uint16_t*)ptr,tail, &R,&G,&B,&A);
+    r = from_half(R);
+    g = from_half(G);
+    b = from_half(B);
+    a = from_half(A);
+}
+STAGE(load_f16_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint64_t>(ctx, dx,dy);
+
+    U16 R,G,B,A;
+    load4((const uint16_t*)ptr,tail, &R,&G,&B,&A);
+    dr = from_half(R);
+    dg = from_half(G);
+    db = from_half(B);
+    da = from_half(A);
+}
+STAGE(gather_f16, const SkJumper_GatherCtx* ctx) {
+    const uint64_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    auto px = gather(ptr, ix);
+
+    U16 R,G,B,A;
+    load4((const uint16_t*)&px,0, &R,&G,&B,&A);
+    r = from_half(R);
+    g = from_half(G);
+    b = from_half(B);
+    a = from_half(A);
+}
+STAGE(store_f16, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint64_t>(ctx, dx,dy);
+    store4((uint16_t*)ptr,tail, to_half(r)
+                              , to_half(g)
+                              , to_half(b)
+                              , to_half(a));
+}
+
+STAGE(load_u16_be, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, 4*dx,dy);
+
+    U16 R,G,B,A;
+    load4(ptr,tail, &R,&G,&B,&A);
+
+    r = (1/65535.0f) * cast(expand(bswap(R)));
+    g = (1/65535.0f) * cast(expand(bswap(G)));
+    b = (1/65535.0f) * cast(expand(bswap(B)));
+    a = (1/65535.0f) * cast(expand(bswap(A)));
+}
+STAGE(load_rgb_u16_be, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, 3*dx,dy);
+
+    U16 R,G,B;
+    load3(ptr,tail, &R,&G,&B);
+
+    r = (1/65535.0f) * cast(expand(bswap(R)));
+    g = (1/65535.0f) * cast(expand(bswap(G)));
+    b = (1/65535.0f) * cast(expand(bswap(B)));
+    a = 1.0f;
+}
+STAGE(store_u16_be, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint16_t>(ctx, 4*dx,dy);
+
+    U16 R = bswap(pack(to_unorm(r, 65535))),
+        G = bswap(pack(to_unorm(g, 65535))),
+        B = bswap(pack(to_unorm(b, 65535))),
+        A = bswap(pack(to_unorm(a, 65535)));
+
+    store4(ptr,tail, R,G,B,A);
+}
+
+STAGE(load_f32, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const float>(ctx, 4*dx,dy);
+    load4(ptr,tail, &r,&g,&b,&a);
+}
+STAGE(load_f32_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const float>(ctx, 4*dx,dy);
+    load4(ptr,tail, &dr,&dg,&db,&da);
+}
+STAGE(store_f32, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<float>(ctx, 4*dx,dy);
+    store4(ptr,tail, r,g,b,a);
+}
+
+SI F exclusive_repeat(F v, const SkJumper_TileCtx* ctx) {
+    return v - floor_(v*ctx->invScale)*ctx->scale;
+}
+SI F exclusive_mirror(F v, const SkJumper_TileCtx* ctx) {
+    auto limit = ctx->scale;
+    auto invLimit = ctx->invScale;
+    return abs_( (v-limit) - (limit+limit)*floor_((v-limit)*(invLimit*0.5f)) - limit );
+}
+// Tile x or y to [0,limit) == [0,limit - 1 ulp] (think, sampling from images).
+// The gather stages will hard clamp the output of these stages to [0,limit)...
+// we just need to do the basic repeat or mirroring.
+STAGE(repeat_x, const SkJumper_TileCtx* ctx) { r = exclusive_repeat(r, ctx); }
+STAGE(repeat_y, const SkJumper_TileCtx* ctx) { g = exclusive_repeat(g, ctx); }
+STAGE(mirror_x, const SkJumper_TileCtx* ctx) { r = exclusive_mirror(r, ctx); }
+STAGE(mirror_y, const SkJumper_TileCtx* ctx) { g = exclusive_mirror(g, ctx); }
+
+// Clamp x to [0,1], both sides inclusive (think, gradients).
+// Even repeat and mirror funnel through a clamp to handle bad inputs like +Inf, NaN.
+SI F clamp_01(F v) { return min(max(0, v), 1); }
+
+STAGE( clamp_x_1, Ctx::None) { r = clamp_01(r); }
+STAGE(repeat_x_1, Ctx::None) { r = clamp_01(r - floor_(r)); }
+STAGE(mirror_x_1, Ctx::None) { r = clamp_01(abs_( (r-1.0f) - two(floor_((r-1.0f)*0.5f)) - 1.0f )); }
+
+// Decal stores a 32bit mask after checking the coordinate (x and/or y) against its domain:
+//      mask == 0x00000000 if the coordinate(s) are out of bounds
+//      mask == 0xFFFFFFFF if the coordinate(s) are in bounds
+// After the gather stage, the r,g,b,a values are AND'd with this mask, setting them to 0
+// if either of the coordinates were out of bounds.
+
+STAGE(decal_x, SkJumper_DecalTileCtx* ctx) {
+    auto w = ctx->limit_x;
+    unaligned_store(ctx->mask, cond_to_mask((0 <= r) & (r < w)));
+}
+STAGE(decal_y, SkJumper_DecalTileCtx* ctx) {
+    auto h = ctx->limit_y;
+    unaligned_store(ctx->mask, cond_to_mask((0 <= g) & (g < h)));
+}
+STAGE(decal_x_and_y, SkJumper_DecalTileCtx* ctx) {
+    auto w = ctx->limit_x;
+    auto h = ctx->limit_y;
+    unaligned_store(ctx->mask,
+                    cond_to_mask((0 <= r) & (r < w) & (0 <= g) & (g < h)));
+}
+STAGE(check_decal_mask, SkJumper_DecalTileCtx* ctx) {
+    auto mask = unaligned_load<U32>(ctx->mask);
+    r = bit_cast<F>( bit_cast<U32>(r) & mask );
+    g = bit_cast<F>( bit_cast<U32>(g) & mask );
+    b = bit_cast<F>( bit_cast<U32>(b) & mask );
+    a = bit_cast<F>( bit_cast<U32>(a) & mask );
+}
+
+STAGE(luminance_to_alpha, Ctx::None) {
+    a = r*0.2126f + g*0.7152f + b*0.0722f;
+    r = g = b = 0;
+}
+
+STAGE(matrix_translate, const float* m) {
+    r += m[0];
+    g += m[1];
+}
+STAGE(matrix_scale_translate, const float* m) {
+    r = mad(r,m[0], m[2]);
+    g = mad(g,m[1], m[3]);
+}
+STAGE(matrix_2x3, const float* m) {
+    auto R = mad(r,m[0], mad(g,m[2], m[4])),
+         G = mad(r,m[1], mad(g,m[3], m[5]));
+    r = R;
+    g = G;
+}
+STAGE(matrix_3x4, const float* m) {
+    auto R = mad(r,m[0], mad(g,m[3], mad(b,m[6], m[ 9]))),
+         G = mad(r,m[1], mad(g,m[4], mad(b,m[7], m[10]))),
+         B = mad(r,m[2], mad(g,m[5], mad(b,m[8], m[11])));
+    r = R;
+    g = G;
+    b = B;
+}
+STAGE(matrix_4x5, const float* m) {
+    auto R = mad(r,m[0], mad(g,m[4], mad(b,m[ 8], mad(a,m[12], m[16])))),
+         G = mad(r,m[1], mad(g,m[5], mad(b,m[ 9], mad(a,m[13], m[17])))),
+         B = mad(r,m[2], mad(g,m[6], mad(b,m[10], mad(a,m[14], m[18])))),
+         A = mad(r,m[3], mad(g,m[7], mad(b,m[11], mad(a,m[15], m[19]))));
+    r = R;
+    g = G;
+    b = B;
+    a = A;
+}
+STAGE(matrix_4x3, const float* m) {
+    auto X = r,
+         Y = g;
+
+    r = mad(X, m[0], mad(Y, m[4], m[ 8]));
+    g = mad(X, m[1], mad(Y, m[5], m[ 9]));
+    b = mad(X, m[2], mad(Y, m[6], m[10]));
+    a = mad(X, m[3], mad(Y, m[7], m[11]));
+}
+STAGE(matrix_perspective, const float* m) {
+    // N.B. Unlike the other matrix_ stages, this matrix is row-major.
+    auto R = mad(r,m[0], mad(g,m[1], m[2])),
+         G = mad(r,m[3], mad(g,m[4], m[5])),
+         Z = mad(r,m[6], mad(g,m[7], m[8]));
+    r = R * rcp(Z);
+    g = G * rcp(Z);
+}
+
+SI void gradient_lookup(const SkJumper_GradientCtx* c, U32 idx, F t,
+                        F* r, F* g, F* b, F* a) {
+    F fr, br, fg, bg, fb, bb, fa, ba;
+#if defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    if (c->stopCount <=8) {
+        fr = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[0]), idx);
+        br = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[0]), idx);
+        fg = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[1]), idx);
+        bg = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[1]), idx);
+        fb = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[2]), idx);
+        bb = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[2]), idx);
+        fa = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[3]), idx);
+        ba = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[3]), idx);
+    } else
+#endif
+    {
+        fr = gather(c->fs[0], idx);
+        br = gather(c->bs[0], idx);
+        fg = gather(c->fs[1], idx);
+        bg = gather(c->bs[1], idx);
+        fb = gather(c->fs[2], idx);
+        bb = gather(c->bs[2], idx);
+        fa = gather(c->fs[3], idx);
+        ba = gather(c->bs[3], idx);
+    }
+
+    *r = mad(t, fr, br);
+    *g = mad(t, fg, bg);
+    *b = mad(t, fb, bb);
+    *a = mad(t, fa, ba);
+}
+
+STAGE(evenly_spaced_gradient, const SkJumper_GradientCtx* c) {
+    auto t = r;
+    auto idx = trunc_(t * (c->stopCount-1));
+    gradient_lookup(c, idx, t, &r, &g, &b, &a);
+}
+
+STAGE(gradient, const SkJumper_GradientCtx* c) {
+    auto t = r;
+    U32 idx = 0;
+
+    // N.B. The loop starts at 1 because idx 0 is the color to use before the first stop.
+    for (size_t i = 1; i < c->stopCount; i++) {
+        idx += if_then_else(t >= c->ts[i], U32(1), U32(0));
+    }
+
+    gradient_lookup(c, idx, t, &r, &g, &b, &a);
+}
+
+STAGE(evenly_spaced_2_stop_gradient, const void* ctx) {
+    // TODO: Rename Ctx SkJumper_EvenlySpaced2StopGradientCtx.
+    struct Ctx { float f[4], b[4]; };
+    auto c = (const Ctx*)ctx;
+
+    auto t = r;
+    r = mad(t, c->f[0], c->b[0]);
+    g = mad(t, c->f[1], c->b[1]);
+    b = mad(t, c->f[2], c->b[2]);
+    a = mad(t, c->f[3], c->b[3]);
+}
+
+STAGE(xy_to_unit_angle, Ctx::None) {
+    F X = r,
+      Y = g;
+    F xabs = abs_(X),
+      yabs = abs_(Y);
+
+    F slope = min(xabs, yabs)/max(xabs, yabs);
+    F s = slope * slope;
+
+    // Use a 7th degree polynomial to approximate atan.
+    // This was generated using sollya.gforge.inria.fr.
+    // A float optimized polynomial was generated using the following command.
+    // P1 = fpminimax((1/(2*Pi))*atan(x),[|1,3,5,7|],[|24...|],[2^(-40),1],relative);
+    F phi = slope
+             * (0.15912117063999176025390625f     + s
+             * (-5.185396969318389892578125e-2f   + s
+             * (2.476101927459239959716796875e-2f + s
+             * (-7.0547382347285747528076171875e-3f))));
+
+    phi = if_then_else(xabs < yabs, 1.0f/4.0f - phi, phi);
+    phi = if_then_else(X < 0.0f   , 1.0f/2.0f - phi, phi);
+    phi = if_then_else(Y < 0.0f   , 1.0f - phi     , phi);
+    phi = if_then_else(phi != phi , 0              , phi);  // Check for NaN.
+    r = phi;
+}
+
+STAGE(xy_to_radius, Ctx::None) {
+    F X2 = r * r,
+      Y2 = g * g;
+    r = sqrt_(X2 + Y2);
+}
+
+// Please see https://skia.org/dev/design/conical for how our 2pt conical shader works.
+
+STAGE(negate_x, Ctx::None) { r = -r; }
+
+STAGE(xy_to_2pt_conical_strip, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = x + sqrt_(ctx->fP0 - y*y); // ctx->fP0 = r0 * r0
+}
+
+STAGE(xy_to_2pt_conical_focal_on_circle, Ctx::None) {
+    F x = r, y = g, &t = r;
+    t = x + y*y / x; // (x^2 + y^2) / x
+}
+
+STAGE(xy_to_2pt_conical_well_behaved, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = sqrt_(x*x + y*y) - x * ctx->fP0; // ctx->fP0 = 1/r1
+}
+
+STAGE(xy_to_2pt_conical_greater, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = sqrt_(x*x - y*y) - x * ctx->fP0; // ctx->fP0 = 1/r1
+}
+
+STAGE(xy_to_2pt_conical_smaller, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = -sqrt_(x*x - y*y) - x * ctx->fP0; // ctx->fP0 = 1/r1
+}
+
+STAGE(alter_2pt_conical_compensate_focal, const SkJumper_2PtConicalCtx* ctx) {
+    F& t = r;
+    t = t + ctx->fP1; // ctx->fP1 = f
+}
+
+STAGE(alter_2pt_conical_unswap, Ctx::None) {
+    F& t = r;
+    t = 1 - t;
+}
+
+STAGE(mask_2pt_conical_nan, SkJumper_2PtConicalCtx* c) {
+    F& t = r;
+    auto is_degenerate = (t != t); // NaN
+    t = if_then_else(is_degenerate, F(0), t);
+    unaligned_store(&c->fMask, cond_to_mask(!is_degenerate));
+}
+
+STAGE(mask_2pt_conical_degenerates, SkJumper_2PtConicalCtx* c) {
+    F& t = r;
+    auto is_degenerate = (t <= 0) | (t != t);
+    t = if_then_else(is_degenerate, F(0), t);
+    unaligned_store(&c->fMask, cond_to_mask(!is_degenerate));
+}
+
+STAGE(apply_vector_mask, const uint32_t* ctx) {
+    const U32 mask = unaligned_load<U32>(ctx);
+    r = bit_cast<F>(bit_cast<U32>(r) & mask);
+    g = bit_cast<F>(bit_cast<U32>(g) & mask);
+    b = bit_cast<F>(bit_cast<U32>(b) & mask);
+    a = bit_cast<F>(bit_cast<U32>(a) & mask);
+}
+
+STAGE(save_xy, SkJumper_SamplerCtx* c) {
+    // Whether bilinear or bicubic, all sample points are at the same fractional offset (fx,fy).
+    // They're either the 4 corners of a logical 1x1 pixel or the 16 corners of a 3x3 grid
+    // surrounding (x,y) at (0.5,0.5) off-center.
+    F fx = fract(r + 0.5f),
+      fy = fract(g + 0.5f);
+
+    // Samplers will need to load x and fx, or y and fy.
+    unaligned_store(c->x,  r);
+    unaligned_store(c->y,  g);
+    unaligned_store(c->fx, fx);
+    unaligned_store(c->fy, fy);
+}
+
+STAGE(accumulate, const SkJumper_SamplerCtx* c) {
+    // Bilinear and bicubic filters are both separable, so we produce independent contributions
+    // from x and y, multiplying them together here to get each pixel's total scale factor.
+    auto scale = unaligned_load<F>(c->scalex)
+               * unaligned_load<F>(c->scaley);
+    dr = mad(scale, r, dr);
+    dg = mad(scale, g, dg);
+    db = mad(scale, b, db);
+    da = mad(scale, a, da);
+}
+
+// In bilinear interpolation, the 4 pixels at +/- 0.5 offsets from the sample pixel center
+// are combined in direct proportion to their area overlapping that logical query pixel.
+// At positive offsets, the x-axis contribution to that rectangle is fx, or (1-fx) at negative x.
+// The y-axis is symmetric.
+
+template <int kScale>
+SI void bilinear_x(SkJumper_SamplerCtx* ctx, F* x) {
+    *x = unaligned_load<F>(ctx->x) + (kScale * 0.5f);
+    F fx = unaligned_load<F>(ctx->fx);
+
+    F scalex;
+    if (kScale == -1) { scalex = 1.0f - fx; }
+    if (kScale == +1) { scalex =        fx; }
+    unaligned_store(ctx->scalex, scalex);
+}
+template <int kScale>
+SI void bilinear_y(SkJumper_SamplerCtx* ctx, F* y) {
+    *y = unaligned_load<F>(ctx->y) + (kScale * 0.5f);
+    F fy = unaligned_load<F>(ctx->fy);
+
+    F scaley;
+    if (kScale == -1) { scaley = 1.0f - fy; }
+    if (kScale == +1) { scaley =        fy; }
+    unaligned_store(ctx->scaley, scaley);
+}
+
+STAGE(bilinear_nx, SkJumper_SamplerCtx* ctx) { bilinear_x<-1>(ctx, &r); }
+STAGE(bilinear_px, SkJumper_SamplerCtx* ctx) { bilinear_x<+1>(ctx, &r); }
+STAGE(bilinear_ny, SkJumper_SamplerCtx* ctx) { bilinear_y<-1>(ctx, &g); }
+STAGE(bilinear_py, SkJumper_SamplerCtx* ctx) { bilinear_y<+1>(ctx, &g); }
+
+
+// In bicubic interpolation, the 16 pixels and +/- 0.5 and +/- 1.5 offsets from the sample
+// pixel center are combined with a non-uniform cubic filter, with higher values near the center.
+//
+// We break this function into two parts, one for near 0.5 offsets and one for far 1.5 offsets.
+// See GrCubicEffect for details of this particular filter.
+
+SI F bicubic_near(F t) {
+    // 1/18 + 9/18t + 27/18t^2 - 21/18t^3 == t ( t ( -21/18t + 27/18) + 9/18) + 1/18
+    return mad(t, mad(t, mad((-21/18.0f), t, (27/18.0f)), (9/18.0f)), (1/18.0f));
+}
+SI F bicubic_far(F t) {
+    // 0/18 + 0/18*t - 6/18t^2 + 7/18t^3 == t^2 (7/18t - 6/18)
+    return (t*t)*mad((7/18.0f), t, (-6/18.0f));
+}
+
+template <int kScale>
+SI void bicubic_x(SkJumper_SamplerCtx* ctx, F* x) {
+    *x = unaligned_load<F>(ctx->x) + (kScale * 0.5f);
+    F fx = unaligned_load<F>(ctx->fx);
+
+    F scalex;
+    if (kScale == -3) { scalex = bicubic_far (1.0f - fx); }
+    if (kScale == -1) { scalex = bicubic_near(1.0f - fx); }
+    if (kScale == +1) { scalex = bicubic_near(       fx); }
+    if (kScale == +3) { scalex = bicubic_far (       fx); }
+    unaligned_store(ctx->scalex, scalex);
+}
+template <int kScale>
+SI void bicubic_y(SkJumper_SamplerCtx* ctx, F* y) {
+    *y = unaligned_load<F>(ctx->y) + (kScale * 0.5f);
+    F fy = unaligned_load<F>(ctx->fy);
+
+    F scaley;
+    if (kScale == -3) { scaley = bicubic_far (1.0f - fy); }
+    if (kScale == -1) { scaley = bicubic_near(1.0f - fy); }
+    if (kScale == +1) { scaley = bicubic_near(       fy); }
+    if (kScale == +3) { scaley = bicubic_far (       fy); }
+    unaligned_store(ctx->scaley, scaley);
+}
+
+STAGE(bicubic_n3x, SkJumper_SamplerCtx* ctx) { bicubic_x<-3>(ctx, &r); }
+STAGE(bicubic_n1x, SkJumper_SamplerCtx* ctx) { bicubic_x<-1>(ctx, &r); }
+STAGE(bicubic_p1x, SkJumper_SamplerCtx* ctx) { bicubic_x<+1>(ctx, &r); }
+STAGE(bicubic_p3x, SkJumper_SamplerCtx* ctx) { bicubic_x<+3>(ctx, &r); }
+
+STAGE(bicubic_n3y, SkJumper_SamplerCtx* ctx) { bicubic_y<-3>(ctx, &g); }
+STAGE(bicubic_n1y, SkJumper_SamplerCtx* ctx) { bicubic_y<-1>(ctx, &g); }
+STAGE(bicubic_p1y, SkJumper_SamplerCtx* ctx) { bicubic_y<+1>(ctx, &g); }
+STAGE(bicubic_p3y, SkJumper_SamplerCtx* ctx) { bicubic_y<+3>(ctx, &g); }
+
+STAGE(callback, SkJumper_CallbackCtx* c) {
+    store4(c->rgba,0, r,g,b,a);
+    c->fn(c, tail ? tail : N);
+    load4(c->read_from,0, &r,&g,&b,&a);
+}
+
+// Our general strategy is to recursively interpolate each dimension,
+// accumulating the index to sample at, and our current pixel stride to help accumulate the index.
+template <int dim>
+SI void color_lookup_table(const SkJumper_ColorLookupTableCtx* ctx,
+                           F& r, F& g, F& b, F a, U32 index, U32 stride) {
+    // We'd logically like to sample this dimension at x.
+    int limit = ctx->limits[dim-1];
+    F src;
+    switch(dim) {
+        case 1: src = r; break;
+        case 2: src = g; break;
+        case 3: src = b; break;
+        case 4: src = a; break;
+    }
+    F x = src * (limit - 1);
+
+    // We can't index an array by a float (darn) so we have to snap to nearby integers lo and hi.
+    U32 lo = trunc_(x          ),
+        hi = trunc_(x + 0.9999f);
+
+    // Recursively sample at lo and hi.
+    F lr = r, lg = g, lb = b,
+      hr = r, hg = g, hb = b;
+    color_lookup_table<dim-1>(ctx, lr,lg,lb,a, stride*lo + index, stride*limit);
+    color_lookup_table<dim-1>(ctx, hr,hg,hb,a, stride*hi + index, stride*limit);
+
+    // Linearly interpolate those colors based on their distance to x.
+    F t = x - cast(lo);
+    r = lerp(lr, hr, t);
+    g = lerp(lg, hg, t);
+    b = lerp(lb, hb, t);
+}
+
+// Bottom out our recursion at 0 dimensions, i.e. just return the colors at index.
+template<>
+inline void color_lookup_table<0>(const SkJumper_ColorLookupTableCtx* ctx,
+                                  F& r, F& g, F& b, F a, U32 index, U32 stride) {
+    r = gather(ctx->table, 3*index+0);
+    g = gather(ctx->table, 3*index+1);
+    b = gather(ctx->table, 3*index+2);
+}
+
+STAGE(clut_3D, const SkJumper_ColorLookupTableCtx* ctx) {
+    color_lookup_table<3>(ctx, r,g,b,a, 0,1);
+    // This 3D color lookup table leaves alpha alone.
+}
+STAGE(clut_4D, const SkJumper_ColorLookupTableCtx* ctx) {
+    color_lookup_table<4>(ctx, r,g,b,a, 0,1);
+    // "a" was really CMYK's K, so we just set alpha opaque.
+    a = 1.0f;
+}
+
+STAGE(gauss_a_to_rgba, Ctx::None) {
+    // x = 1 - x;
+    // exp(-x * x * 4) - 0.018f;
+    // ... now approximate with quartic
+    //
+    const float c4 = -2.26661229133605957031f;
+    const float c3 = 2.89795351028442382812f;
+    const float c2 = 0.21345567703247070312f;
+    const float c1 = 0.15489584207534790039f;
+    const float c0 = 0.00030726194381713867f;
+    a = mad(a, mad(a, mad(a, mad(a, c4, c3), c2), c1), c0);
+    r = a;
+    g = a;
+    b = a;
+}
+
+// A specialized fused image shader for clamp-x, clamp-y, non-sRGB sampling.
+STAGE(bilerp_clamp_8888, SkJumper_GatherCtx* ctx) {
+    // (cx,cy) are the center of our sample.
+    F cx = r,
+      cy = g;
+
+    // All sample points are at the same fractional offset (fx,fy).
+    // They're the 4 corners of a logical 1x1 pixel surrounding (x,y) at (0.5,0.5) offsets.
+    F fx = fract(cx + 0.5f),
+      fy = fract(cy + 0.5f);
+
+    // We'll accumulate the color of all four samples into {r,g,b,a} directly.
+    r = g = b = a = 0;
+
+    for (float dy = -0.5f; dy <= +0.5f; dy += 1.0f)
+    for (float dx = -0.5f; dx <= +0.5f; dx += 1.0f) {
+        // (x,y) are the coordinates of this sample point.
+        F x = cx + dx,
+          y = cy + dy;
+
+        // ix_and_ptr() will clamp to the image's bounds for us.
+        const uint32_t* ptr;
+        U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+
+        F sr,sg,sb,sa;
+        from_8888(gather(ptr, ix), &sr,&sg,&sb,&sa);
+
+        // In bilinear interpolation, the 4 pixels at +/- 0.5 offsets from the sample pixel center
+        // are combined in direct proportion to their area overlapping that logical query pixel.
+        // At positive offsets, the x-axis contribution to that rectangle is fx,
+        // or (1-fx) at negative x.  Same deal for y.
+        F sx = (dx > 0) ? fx : 1.0f - fx,
+          sy = (dy > 0) ? fy : 1.0f - fy,
+          area = sx * sy;
+
+        r += sr * area;
+        g += sg * area;
+        b += sb * area;
+        a += sa * area;
+    }
+}
+
+namespace lowp {
+#if defined(JUMPER_IS_SCALAR)
+    // If we're not compiled by Clang, or otherwise switched into scalar mode (old Clang, manually),
+    // we don't generate lowp stages.  All these nullptrs will tell SkJumper.cpp to always use the
+    // highp float pipeline.
+    #define M(st) static void (*st)(void) = nullptr;
+        SK_RASTER_PIPELINE_STAGES(M)
+    #undef M
+    static void (*just_return)(void) = nullptr;
+
+    static void start_pipeline(size_t,size_t,size_t,size_t, void**) {}
+
+#else  // We are compiling vector code with Clang... let's make some lowp stages!
+
+#if defined(__AVX2__)
+    using U8  = uint8_t  __attribute__((ext_vector_type(16)));
+    using U16 = uint16_t __attribute__((ext_vector_type(16)));
+    using I16 =  int16_t __attribute__((ext_vector_type(16)));
+    using I32 =  int32_t __attribute__((ext_vector_type(16)));
+    using U32 = uint32_t __attribute__((ext_vector_type(16)));
+    using F   = float    __attribute__((ext_vector_type(16)));
+#else
+    using U8  = uint8_t  __attribute__((ext_vector_type(8)));
+    using U16 = uint16_t __attribute__((ext_vector_type(8)));
+    using I16 =  int16_t __attribute__((ext_vector_type(8)));
+    using I32 =  int32_t __attribute__((ext_vector_type(8)));
+    using U32 = uint32_t __attribute__((ext_vector_type(8)));
+    using F   = float    __attribute__((ext_vector_type(8)));
+#endif
+
+static const size_t N = sizeof(U16) / sizeof(uint16_t);
+
+// Once again, some platforms benefit from a restricted Stage calling convention,
+// but others can pass tons and tons of registers and we're happy to exploit that.
+// It's exactly the same decision and implementation strategy as the F stages above.
+#if JUMPER_NARROW_STAGES
+    struct Params {
+        size_t dx, dy, tail;
+        U16 dr,dg,db,da;
+    };
+    using Stage = void(ABI*)(Params*, void** program, U16 r, U16 g, U16 b, U16 a);
+#else
+    // We pass program as the second argument so that load_and_inc() will find it in %rsi on x86-64.
+    using Stage = void (ABI*)(size_t tail, void** program, size_t dx, size_t dy,
+                              U16  r, U16  g, U16  b, U16  a,
+                              U16 dr, U16 dg, U16 db, U16 da);
+#endif
+
+static void start_pipeline(const size_t x0,     const size_t y0,
+                           const size_t xlimit, const size_t ylimit, void** program) {
+    auto start = (Stage)load_and_inc(program);
+    for (size_t dy = y0; dy < ylimit; dy++) {
+    #if JUMPER_NARROW_STAGES
+        Params params = { x0,dy,0, 0,0,0,0 };
+        for (; params.dx + N <= xlimit; params.dx += N) {
+            start(&params,program, 0,0,0,0);
+        }
+        if (size_t tail = xlimit - params.dx) {
+            params.tail = tail;
+            start(&params,program, 0,0,0,0);
+        }
+    #else
+        size_t dx = x0;
+        for (; dx + N <= xlimit; dx += N) {
+            start(   0,program,dx,dy, 0,0,0,0, 0,0,0,0);
+        }
+        if (size_t tail = xlimit - dx) {
+            start(tail,program,dx,dy, 0,0,0,0, 0,0,0,0);
+        }
+    #endif
+    }
+}
+
+#if JUMPER_NARROW_STAGES
+    static void ABI just_return(Params*, void**, U16,U16,U16,U16) {}
+#else
+    static void ABI just_return(size_t,void**,size_t,size_t, U16,U16,U16,U16, U16,U16,U16,U16) {}
+#endif
+
+// All stages use the same function call ABI to chain into each other, but there are three types:
+//   GG: geometry in, geometry out  -- think, a matrix
+//   GP: geometry in, pixels out.   -- think, a memory gather
+//   PP: pixels in, pixels out.     -- think, a blend mode
+//
+// (Some stages ignore their inputs or produce no logical output.  That's perfectly fine.)
+//
+// These three STAGE_ macros let you define each type of stage,
+// and will have (x,y) geometry and/or (r,g,b,a, dr,dg,db,da) pixel arguments as appropriate.
+
+#if JUMPER_NARROW_STAGES
+    #define STAGE_GG(name, ...)                                                            \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F& x, F& y);      \
+        static void ABI name(Params* params, void** program, U16 r, U16 g, U16 b, U16 a) { \
+            auto x = join<F>(r,g),                                                         \
+                 y = join<F>(b,a);                                                         \
+            name##_k(Ctx{program}, params->dx,params->dy,params->tail, x,y);               \
+            split(x, &r,&g);                                                               \
+            split(y, &b,&a);                                                               \
+            auto next = (Stage)load_and_inc(program);                                      \
+            next(params,program, r,g,b,a);                                                 \
+        }                                                                                  \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F& x, F& y)
+
+    #define STAGE_GP(name, ...)                                                            \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F x, F y,         \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da);                              \
+        static void ABI name(Params* params, void** program, U16 r, U16 g, U16 b, U16 a) { \
+            auto x = join<F>(r,g),                                                         \
+                 y = join<F>(b,a);                                                         \
+            name##_k(Ctx{program}, params->dx,params->dy,params->tail, x,y, r,g,b,a,       \
+                     params->dr,params->dg,params->db,params->da);                         \
+            auto next = (Stage)load_and_inc(program);                                      \
+            next(params,program, r,g,b,a);                                                 \
+        }                                                                                  \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F x, F y,         \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da)
+
+    #define STAGE_PP(name, ...)                                                            \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,                   \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da);                              \
+        static void ABI name(Params* params, void** program, U16 r, U16 g, U16 b, U16 a) { \
+            name##_k(Ctx{program}, params->dx,params->dy,params->tail, r,g,b,a,            \
+                     params->dr,params->dg,params->db,params->da);                         \
+            auto next = (Stage)load_and_inc(program);                                      \
+            next(params,program, r,g,b,a);                                                 \
+        }                                                                                  \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,                   \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da)
+#else
+    #define STAGE_GG(name, ...)                                                            \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F& x, F& y);      \
+        static void ABI name(size_t tail, void** program, size_t dx, size_t dy,            \
+                             U16  r, U16  g, U16  b, U16  a,                               \
+                             U16 dr, U16 dg, U16 db, U16 da) {                             \
+            auto x = join<F>(r,g),                                                         \
+                 y = join<F>(b,a);                                                         \
+            name##_k(Ctx{program}, dx,dy,tail, x,y);                                       \
+            split(x, &r,&g);                                                               \
+            split(y, &b,&a);                                                               \
+            auto next = (Stage)load_and_inc(program);                                      \
+            next(tail,program,dx,dy, r,g,b,a, dr,dg,db,da);                                \
+        }                                                                                  \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F& x, F& y)
+
+    #define STAGE_GP(name, ...)                                                            \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F x, F y,         \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da);                              \
+        static void ABI name(size_t tail, void** program, size_t dx, size_t dy,            \
+                             U16  r, U16  g, U16  b, U16  a,                               \
+                             U16 dr, U16 dg, U16 db, U16 da) {                             \
+            auto x = join<F>(r,g),                                                         \
+                 y = join<F>(b,a);                                                         \
+            name##_k(Ctx{program}, dx,dy,tail, x,y, r,g,b,a, dr,dg,db,da);                 \
+            auto next = (Stage)load_and_inc(program);                                      \
+            next(tail,program,dx,dy, r,g,b,a, dr,dg,db,da);                                \
+        }                                                                                  \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail, F x, F y,         \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da)
+
+    #define STAGE_PP(name, ...)                                                            \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,                   \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da);                              \
+        static void ABI name(size_t tail, void** program, size_t dx, size_t dy,            \
+                             U16  r, U16  g, U16  b, U16  a,                               \
+                             U16 dr, U16 dg, U16 db, U16 da) {                             \
+            name##_k(Ctx{program}, dx,dy,tail, r,g,b,a, dr,dg,db,da);                      \
+            auto next = (Stage)load_and_inc(program);                                      \
+            next(tail,program,dx,dy, r,g,b,a, dr,dg,db,da);                                \
+        }                                                                                  \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,                   \
+                         U16&  r, U16&  g, U16&  b, U16&  a,                               \
+                         U16& dr, U16& dg, U16& db, U16& da)
+#endif
+
+// ~~~~~~ Commonly used helper functions ~~~~~~ //
+
+SI U16 div255(U16 v) {
+#if 0
+    return (v+127)/255;  // The ideal rounding divide by 255.
+#elif 1 && defined(__ARM_NEON)
+    // With NEON we can compute (v+127)/255 as (v + ((v+128)>>8) + 128)>>8
+    // just as fast as we can do the approximation below, so might as well be correct!
+    // First we compute v + ((v+128)>>8), then one more round of (...+128)>>8 to finish up.
+    return vrshrq_n_u16(vrsraq_n_u16(v, v, 8), 8);
+#else
+    return (v+255)/256;  // A good approximation of (v+127)/255.
+#endif
+}
+
+SI U16 inv(U16 v) { return 255-v; }
+
+SI U16 if_then_else(I16 c, U16 t, U16 e) { return (t & c) | (e & ~c); }
+SI U32 if_then_else(I32 c, U32 t, U32 e) { return (t & c) | (e & ~c); }
+
+SI U16 max(U16 x, U16 y) { return if_then_else(x < y, y, x); }
+SI U16 min(U16 x, U16 y) { return if_then_else(x < y, x, y); }
+SI U16 max(U16 x, U16 y, U16 z) { return max(x, max(y, z)); }
+SI U16 min(U16 x, U16 y, U16 z) { return min(x, min(y, z)); }
+
+SI U16 from_float(float f) { return f * 255.0f + 0.5f; }
+
+SI U16 lerp(U16 from, U16 to, U16 t) { return div255( from*inv(t) + to*t ); }
+
+template <typename D, typename S>
+SI D cast(S src) {
+    return __builtin_convertvector(src, D);
+}
+
+template <typename D, typename S>
+SI void split(S v, D* lo, D* hi) {
+    static_assert(2*sizeof(D) == sizeof(S), "");
+    memcpy(lo, (const char*)&v + 0*sizeof(D), sizeof(D));
+    memcpy(hi, (const char*)&v + 1*sizeof(D), sizeof(D));
+}
+template <typename D, typename S>
+SI D join(S lo, S hi) {
+    static_assert(sizeof(D) == 2*sizeof(S), "");
+    D v;
+    memcpy((char*)&v + 0*sizeof(S), &lo, sizeof(S));
+    memcpy((char*)&v + 1*sizeof(S), &hi, sizeof(S));
+    return v;
+}
+template <typename V, typename H>
+SI V map(V v, H (*fn)(H)) {
+    H lo,hi;
+    split(v, &lo,&hi);
+    lo = fn(lo);
+    hi = fn(hi);
+    return join<V>(lo,hi);
+}
+
+SI F if_then_else(I32 c, F t, F e) {
+    return bit_cast<F>( (bit_cast<I32>(t) & c) | (bit_cast<I32>(e) & ~c) );
+}
+SI F max(F x, F y) { return if_then_else(x < y, y, x); }
+SI F min(F x, F y) { return if_then_else(x < y, x, y); }
+
+SI F mad(F f, F m, F a) { return f*m+a; }
+SI U32 trunc_(F x) { return (U32)cast<I32>(x); }
+
+SI F rcp(F x) {
+#if defined(__AVX2__)
+    return map(x, _mm256_rcp_ps);
+#elif defined(__SSE__)
+    return map(x, _mm_rcp_ps);
+#elif defined(__ARM_NEON)
+    return map(x, +[](float32x4_t v) {
+        auto est = vrecpeq_f32(v);
+        return vrecpsq_f32(v,est)*est;
+    });
+#else
+    return 1.0f / x;
+#endif
+}
+SI F sqrt_(F x) {
+#if defined(__AVX2__)
+    return map(x, _mm256_sqrt_ps);
+#elif defined(__SSE__)
+    return map(x, _mm_sqrt_ps);
+#elif defined(__aarch64__)
+    return map(x, vsqrtq_f32);
+#elif defined(__ARM_NEON)
+    return map(x, +[](float32x4_t v) {
+        auto est = vrsqrteq_f32(v);  // Estimate and two refinement steps for est = rsqrt(v).
+        est *= vrsqrtsq_f32(v,est*est);
+        est *= vrsqrtsq_f32(v,est*est);
+        return v*est;                // sqrt(v) == v*rsqrt(v).
+    });
+#else
+    return F{
+        sqrtf(x[0]), sqrtf(x[1]), sqrtf(x[2]), sqrtf(x[3]),
+        sqrtf(x[4]), sqrtf(x[5]), sqrtf(x[6]), sqrtf(x[7]),
+    };
+#endif
+}
+
+SI F floor_(F x) {
+#if defined(__aarch64__)
+    return map(x, vrndmq_f32);
+#elif defined(__AVX2__)
+    return map(x, +[](__m256 v){ return _mm256_floor_ps(v); });  // _mm256_floor_ps is a macro...
+#elif defined(__SSE4_1__)
+    return map(x, +[](__m128 v){ return    _mm_floor_ps(v); });  // _mm_floor_ps() is a macro too.
+#else
+    F roundtrip = cast<F>(cast<I32>(x));
+    return roundtrip - if_then_else(roundtrip > x, F(1), F(0));
+#endif
+}
+SI F abs_(F x) { return bit_cast<F>( bit_cast<I32>(x) & 0x7fffffff ); }
+
+// ~~~~~~ Basic / misc. stages ~~~~~~ //
+
+STAGE_GG(seed_shader, Ctx::None) {
+    static const float iota[] = {
+        0.5f, 1.5f, 2.5f, 3.5f, 4.5f, 5.5f, 6.5f, 7.5f,
+        8.5f, 9.5f,10.5f,11.5f,12.5f,13.5f,14.5f,15.5f,
+    };
+    x = cast<F>(I32(dx)) + unaligned_load<F>(iota);
+    y = cast<F>(I32(dy)) + 0.5f;
+}
+
+STAGE_GG(matrix_translate, const float* m) {
+    x += m[0];
+    y += m[1];
+}
+STAGE_GG(matrix_scale_translate, const float* m) {
+    x = mad(x,m[0], m[2]);
+    y = mad(y,m[1], m[3]);
+}
+STAGE_GG(matrix_2x3, const float* m) {
+    auto X = mad(x,m[0], mad(y,m[2], m[4])),
+         Y = mad(x,m[1], mad(y,m[3], m[5]));
+    x = X;
+    y = Y;
+}
+STAGE_GG(matrix_perspective, const float* m) {
+    // N.B. Unlike the other matrix_ stages, this matrix is row-major.
+    auto X = mad(x,m[0], mad(y,m[1], m[2])),
+         Y = mad(x,m[3], mad(y,m[4], m[5])),
+         Z = mad(x,m[6], mad(y,m[7], m[8]));
+    x = X * rcp(Z);
+    y = Y * rcp(Z);
+}
+
+STAGE_PP(uniform_color, const SkJumper_UniformColorCtx* c) {
+    r = c->rgba[0];
+    g = c->rgba[1];
+    b = c->rgba[2];
+    a = c->rgba[3];
+}
+STAGE_PP(black_color, Ctx::None) { r = g = b =   0; a = 255; }
+STAGE_PP(white_color, Ctx::None) { r = g = b = 255; a = 255; }
+
+STAGE_PP(set_rgb, const float rgb[3]) {
+    r = from_float(rgb[0]);
+    g = from_float(rgb[1]);
+    b = from_float(rgb[2]);
+}
+
+STAGE_PP(clamp_a, Ctx::None) {
+    r = min(r, a);
+    g = min(g, a);
+    b = min(b, a);
+}
+STAGE_PP(clamp_a_dst, Ctx::None) {
+    dr = min(dr, da);
+    dg = min(dg, da);
+    db = min(db, da);
+}
+
+STAGE_PP(premul, Ctx::None) {
+    r = div255(r * a);
+    g = div255(g * a);
+    b = div255(b * a);
+}
+STAGE_PP(premul_dst, Ctx::None) {
+    dr = div255(dr * da);
+    dg = div255(dg * da);
+    db = div255(db * da);
+}
+
+STAGE_PP(force_opaque    , Ctx::None) {  a = 255; }
+STAGE_PP(force_opaque_dst, Ctx::None) { da = 255; }
+
+STAGE_PP(swap_rb, Ctx::None) {
+    auto tmp = r;
+    r = b;
+    b = tmp;
+}
+
+STAGE_PP(move_src_dst, Ctx::None) {
+    dr = r;
+    dg = g;
+    db = b;
+    da = a;
+}
+
+STAGE_PP(move_dst_src, Ctx::None) {
+    r = dr;
+    g = dg;
+    b = db;
+    a = da;
+}
+
+STAGE_PP(invert, Ctx::None) {
+    r = inv(r);
+    g = inv(g);
+    b = inv(b);
+    a = inv(a);
+}
+
+// ~~~~~~ Blend modes ~~~~~~ //
+
+// The same logic applied to all 4 channels.
+#define BLEND_MODE(name)                                 \
+    SI U16 name##_channel(U16 s, U16 d, U16 sa, U16 da); \
+    STAGE_PP(name, Ctx::None) {                          \
+        r = name##_channel(r,dr,a,da);                   \
+        g = name##_channel(g,dg,a,da);                   \
+        b = name##_channel(b,db,a,da);                   \
+        a = name##_channel(a,da,a,da);                   \
+    }                                                    \
+    SI U16 name##_channel(U16 s, U16 d, U16 sa, U16 da)
+
+    BLEND_MODE(clear)    { return 0; }
+    BLEND_MODE(srcatop)  { return div255( s*da + d*inv(sa) ); }
+    BLEND_MODE(dstatop)  { return div255( d*sa + s*inv(da) ); }
+    BLEND_MODE(srcin)    { return div255( s*da ); }
+    BLEND_MODE(dstin)    { return div255( d*sa ); }
+    BLEND_MODE(srcout)   { return div255( s*inv(da) ); }
+    BLEND_MODE(dstout)   { return div255( d*inv(sa) ); }
+    BLEND_MODE(srcover)  { return s + div255( d*inv(sa) ); }
+    BLEND_MODE(dstover)  { return d + div255( s*inv(da) ); }
+    BLEND_MODE(modulate) { return div255( s*d ); }
+    BLEND_MODE(multiply) { return div255( s*inv(da) + d*inv(sa) + s*d ); }
+    BLEND_MODE(plus_)    { return min(s+d, 255); }
+    BLEND_MODE(screen)   { return s + d - div255( s*d ); }
+    BLEND_MODE(xor_)     { return div255( s*inv(da) + d*inv(sa) ); }
+#undef BLEND_MODE
+
+// The same logic applied to color, and srcover for alpha.
+#define BLEND_MODE(name)                                 \
+    SI U16 name##_channel(U16 s, U16 d, U16 sa, U16 da); \
+    STAGE_PP(name, Ctx::None) {                          \
+        r = name##_channel(r,dr,a,da);                   \
+        g = name##_channel(g,dg,a,da);                   \
+        b = name##_channel(b,db,a,da);                   \
+        a = a + div255( da*inv(a) );                     \
+    }                                                    \
+    SI U16 name##_channel(U16 s, U16 d, U16 sa, U16 da)
+
+    BLEND_MODE(darken)     { return s + d -   div255( max(s*da, d*sa) ); }
+    BLEND_MODE(lighten)    { return s + d -   div255( min(s*da, d*sa) ); }
+    BLEND_MODE(difference) { return s + d - 2*div255( min(s*da, d*sa) ); }
+    BLEND_MODE(exclusion)  { return s + d - 2*div255( s*d ); }
+
+    BLEND_MODE(hardlight) {
+        return div255( s*inv(da) + d*inv(sa) +
+                       if_then_else(2*s <= sa, 2*s*d, sa*da - 2*(sa-s)*(da-d)) );
+    }
+    BLEND_MODE(overlay) {
+        return div255( s*inv(da) + d*inv(sa) +
+                       if_then_else(2*d <= da, 2*s*d, sa*da - 2*(sa-s)*(da-d)) );
+    }
+#undef BLEND_MODE
+
+// ~~~~~~ Helpers for interacting with memory ~~~~~~ //
+
+template <typename T>
+SI T* ptr_at_xy(const SkJumper_MemoryCtx* ctx, size_t dx, size_t dy) {
+    return (T*)ctx->pixels + dy*ctx->stride + dx;
+}
+
+template <typename T>
+SI U32 ix_and_ptr(T** ptr, const SkJumper_GatherCtx* ctx, F x, F y) {
+    auto clamp = [](F v, F limit) {
+        limit = bit_cast<F>( bit_cast<U32>(limit) - 1 );  // Exclusive -> inclusive.
+        return min(max(0, v), limit);
+    };
+    x = clamp(x, ctx->width);
+    y = clamp(y, ctx->height);
+
+    *ptr = (const T*)ctx->pixels;
+    return trunc_(y)*ctx->stride + trunc_(x);
+}
+
+template <typename V, typename T>
+SI V load(const T* ptr, size_t tail) {
+    V v = 0;
+    switch (tail & (N-1)) {
+        case  0: memcpy(&v, ptr, sizeof(v)); break;
+    #if defined(__AVX2__)
+        case 15: v[14] = ptr[14];
+        case 14: v[13] = ptr[13];
+        case 13: v[12] = ptr[12];
+        case 12: memcpy(&v, ptr, 12*sizeof(T)); break;
+        case 11: v[10] = ptr[10];
+        case 10: v[ 9] = ptr[ 9];
+        case  9: v[ 8] = ptr[ 8];
+        case  8: memcpy(&v, ptr,  8*sizeof(T)); break;
+    #endif
+        case  7: v[ 6] = ptr[ 6];
+        case  6: v[ 5] = ptr[ 5];
+        case  5: v[ 4] = ptr[ 4];
+        case  4: memcpy(&v, ptr,  4*sizeof(T)); break;
+        case  3: v[ 2] = ptr[ 2];
+        case  2: memcpy(&v, ptr,  2*sizeof(T)); break;
+        case  1: v[ 0] = ptr[ 0];
+    }
+    return v;
+}
+template <typename V, typename T>
+SI void store(T* ptr, size_t tail, V v) {
+    switch (tail & (N-1)) {
+        case  0: memcpy(ptr, &v, sizeof(v)); break;
+    #if defined(__AVX2__)
+        case 15: ptr[14] = v[14];
+        case 14: ptr[13] = v[13];
+        case 13: ptr[12] = v[12];
+        case 12: memcpy(ptr, &v, 12*sizeof(T)); break;
+        case 11: ptr[10] = v[10];
+        case 10: ptr[ 9] = v[ 9];
+        case  9: ptr[ 8] = v[ 8];
+        case  8: memcpy(ptr, &v,  8*sizeof(T)); break;
+    #endif
+        case  7: ptr[ 6] = v[ 6];
+        case  6: ptr[ 5] = v[ 5];
+        case  5: ptr[ 4] = v[ 4];
+        case  4: memcpy(ptr, &v,  4*sizeof(T)); break;
+        case  3: ptr[ 2] = v[ 2];
+        case  2: memcpy(ptr, &v,  2*sizeof(T)); break;
+        case  1: ptr[ 0] = v[ 0];
+    }
+}
+
+#if defined(__AVX2__)
+    template <typename V, typename T>
+    SI V gather(const T* ptr, U32 ix) {
+        return V{ ptr[ix[ 0]], ptr[ix[ 1]], ptr[ix[ 2]], ptr[ix[ 3]],
+                  ptr[ix[ 4]], ptr[ix[ 5]], ptr[ix[ 6]], ptr[ix[ 7]],
+                  ptr[ix[ 8]], ptr[ix[ 9]], ptr[ix[10]], ptr[ix[11]],
+                  ptr[ix[12]], ptr[ix[13]], ptr[ix[14]], ptr[ix[15]], };
+    }
+
+    template<>
+    F gather(const float* ptr, U32 ix) {
+        __m256i lo, hi;
+        split(ix, &lo, &hi);
+
+        return join<F>(_mm256_i32gather_ps(ptr, lo, 4),
+                       _mm256_i32gather_ps(ptr, hi, 4));
+    }
+
+    template<>
+    U32 gather(const uint32_t* ptr, U32 ix) {
+        __m256i lo, hi;
+        split(ix, &lo, &hi);
+
+        return join<U32>(_mm256_i32gather_epi32(ptr, lo, 4),
+                         _mm256_i32gather_epi32(ptr, hi, 4));
+    }
+#else
+    template <typename V, typename T>
+    SI V gather(const T* ptr, U32 ix) {
+        return V{ ptr[ix[ 0]], ptr[ix[ 1]], ptr[ix[ 2]], ptr[ix[ 3]],
+                  ptr[ix[ 4]], ptr[ix[ 5]], ptr[ix[ 6]], ptr[ix[ 7]], };
+    }
+#endif
+
+
+// ~~~~~~ 32-bit memory loads and stores ~~~~~~ //
+
+SI void from_8888(U32 rgba, U16* r, U16* g, U16* b, U16* a) {
+#if 1 && defined(__AVX2__)
+    // Swap the middle 128-bit lanes to make _mm256_packus_epi32() in cast_U16() work out nicely.
+    __m256i _01,_23;
+    split(rgba, &_01, &_23);
+    __m256i _02 = _mm256_permute2x128_si256(_01,_23, 0x20),
+            _13 = _mm256_permute2x128_si256(_01,_23, 0x31);
+    rgba = join<U32>(_02, _13);
+
+    auto cast_U16 = [](U32 v) -> U16 {
+        __m256i _02,_13;
+        split(v, &_02,&_13);
+        return _mm256_packus_epi32(_02,_13);
+    };
+#else
+    auto cast_U16 = [](U32 v) -> U16 {
+        return cast<U16>(v);
+    };
+#endif
+    *r = cast_U16(rgba & 65535) & 255;
+    *g = cast_U16(rgba & 65535) >>  8;
+    *b = cast_U16(rgba >>   16) & 255;
+    *a = cast_U16(rgba >>   16) >>  8;
+}
+
+SI void load_8888_(const uint32_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+#if 1 && defined(__ARM_NEON)
+    uint8x8x4_t rgba;
+    switch (tail & (N-1)) {
+        case 0: rgba = vld4_u8     ((const uint8_t*)(ptr+0)         ); break;
+        case 7: rgba = vld4_lane_u8((const uint8_t*)(ptr+6), rgba, 6);
+        case 6: rgba = vld4_lane_u8((const uint8_t*)(ptr+5), rgba, 5);
+        case 5: rgba = vld4_lane_u8((const uint8_t*)(ptr+4), rgba, 4);
+        case 4: rgba = vld4_lane_u8((const uint8_t*)(ptr+3), rgba, 3);
+        case 3: rgba = vld4_lane_u8((const uint8_t*)(ptr+2), rgba, 2);
+        case 2: rgba = vld4_lane_u8((const uint8_t*)(ptr+1), rgba, 1);
+        case 1: rgba = vld4_lane_u8((const uint8_t*)(ptr+0), rgba, 0);
+    }
+    *r = cast<U16>(rgba.val[0]);
+    *g = cast<U16>(rgba.val[1]);
+    *b = cast<U16>(rgba.val[2]);
+    *a = cast<U16>(rgba.val[3]);
+#else
+    from_8888(load<U32>(ptr, tail), r,g,b,a);
+#endif
+}
+SI void store_8888_(uint32_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+#if 1 && defined(__ARM_NEON)
+    uint8x8x4_t rgba = {{
+        cast<U8>(r),
+        cast<U8>(g),
+        cast<U8>(b),
+        cast<U8>(a),
+    }};
+    switch (tail & (N-1)) {
+        case 0: vst4_u8     ((uint8_t*)(ptr+0), rgba   ); break;
+        case 7: vst4_lane_u8((uint8_t*)(ptr+6), rgba, 6);
+        case 6: vst4_lane_u8((uint8_t*)(ptr+5), rgba, 5);
+        case 5: vst4_lane_u8((uint8_t*)(ptr+4), rgba, 4);
+        case 4: vst4_lane_u8((uint8_t*)(ptr+3), rgba, 3);
+        case 3: vst4_lane_u8((uint8_t*)(ptr+2), rgba, 2);
+        case 2: vst4_lane_u8((uint8_t*)(ptr+1), rgba, 1);
+        case 1: vst4_lane_u8((uint8_t*)(ptr+0), rgba, 0);
+    }
+#else
+    store(ptr, tail, cast<U32>(r | (g<<8)) <<  0
+                   | cast<U32>(b | (a<<8)) << 16);
+#endif
+}
+
+STAGE_PP(load_8888, const SkJumper_MemoryCtx* ctx) {
+    load_8888_(ptr_at_xy<const uint32_t>(ctx, dx,dy), tail, &r,&g,&b,&a);
+}
+STAGE_PP(load_8888_dst, const SkJumper_MemoryCtx* ctx) {
+    load_8888_(ptr_at_xy<const uint32_t>(ctx, dx,dy), tail, &dr,&dg,&db,&da);
+}
+STAGE_PP(store_8888, const SkJumper_MemoryCtx* ctx) {
+    store_8888_(ptr_at_xy<uint32_t>(ctx, dx,dy), tail, r,g,b,a);
+}
+
+STAGE_PP(load_bgra, const SkJumper_MemoryCtx* ctx) {
+    load_8888_(ptr_at_xy<const uint32_t>(ctx, dx,dy), tail, &b,&g,&r,&a);
+}
+STAGE_PP(load_bgra_dst, const SkJumper_MemoryCtx* ctx) {
+    load_8888_(ptr_at_xy<const uint32_t>(ctx, dx,dy), tail, &db,&dg,&dr,&da);
+}
+STAGE_PP(store_bgra, const SkJumper_MemoryCtx* ctx) {
+    store_8888_(ptr_at_xy<uint32_t>(ctx, dx,dy), tail, b,g,r,a);
+}
+
+STAGE_GP(gather_8888, const SkJumper_GatherCtx* ctx) {
+    const uint32_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+    from_8888(gather<U32>(ptr, ix), &r, &g, &b, &a);
+}
+STAGE_GP(gather_bgra, const SkJumper_GatherCtx* ctx) {
+    const uint32_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+    from_8888(gather<U32>(ptr, ix), &b, &g, &r, &a);
+}
+
+// ~~~~~~ 16-bit memory loads and stores ~~~~~~ //
+
+SI void from_565(U16 rgb, U16* r, U16* g, U16* b) {
+    // Format for 565 buffers: 15|rrrrr gggggg bbbbb|0
+    U16 R = (rgb >> 11) & 31,
+        G = (rgb >>  5) & 63,
+        B = (rgb >>  0) & 31;
+
+    // These bit replications are the same as multiplying by 255/31 or 255/63 to scale to 8-bit.
+    *r = (R << 3) | (R >> 2);
+    *g = (G << 2) | (G >> 4);
+    *b = (B << 3) | (B >> 2);
+}
+SI void load_565_(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+    from_565(load<U16>(ptr, tail), r,g,b);
+}
+SI void store_565_(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b) {
+    // Select the top 5,6,5 bits.
+    U16 R = r >> 3,
+        G = g >> 2,
+        B = b >> 3;
+    // Pack them back into 15|rrrrr gggggg bbbbb|0.
+    store(ptr, tail, R << 11
+                   | G <<  5
+                   | B <<  0);
+}
+
+STAGE_PP(load_565, const SkJumper_MemoryCtx* ctx) {
+    load_565_(ptr_at_xy<const uint16_t>(ctx, dx,dy), tail, &r,&g,&b);
+    a = 255;
+}
+STAGE_PP(load_565_dst, const SkJumper_MemoryCtx* ctx) {
+    load_565_(ptr_at_xy<const uint16_t>(ctx, dx,dy), tail, &dr,&dg,&db);
+    da = 255;
+}
+STAGE_PP(store_565, const SkJumper_MemoryCtx* ctx) {
+    store_565_(ptr_at_xy<uint16_t>(ctx, dx,dy), tail, r,g,b);
+}
+STAGE_GP(gather_565, const SkJumper_GatherCtx* ctx) {
+    const uint16_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+    from_565(gather<U16>(ptr, ix), &r, &g, &b);
+    a = 255;
+}
+
+SI void from_4444(U16 rgba, U16* r, U16* g, U16* b, U16* a) {
+    // Format for 4444 buffers: 15|rrrr gggg bbbb aaaa|0.
+    U16 R = (rgba >> 12) & 15,
+        G = (rgba >>  8) & 15,
+        B = (rgba >>  4) & 15,
+        A = (rgba >>  0) & 15;
+
+    // Scale [0,15] to [0,255].
+    *r = (R << 4) | R;
+    *g = (G << 4) | G;
+    *b = (B << 4) | B;
+    *a = (A << 4) | A;
+}
+SI void load_4444_(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+    from_4444(load<U16>(ptr, tail), r,g,b,a);
+}
+SI void store_4444_(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+    // Select the top 4 bits of each.
+    U16 R = r >> 4,
+        G = g >> 4,
+        B = b >> 4,
+        A = a >> 4;
+    // Pack them back into 15|rrrr gggg bbbb aaaa|0.
+    store(ptr, tail, R << 12
+                   | G <<  8
+                   | B <<  4
+                   | A <<  0);
+}
+
+STAGE_PP(load_4444, const SkJumper_MemoryCtx* ctx) {
+    load_4444_(ptr_at_xy<const uint16_t>(ctx, dx,dy), tail, &r,&g,&b,&a);
+}
+STAGE_PP(load_4444_dst, const SkJumper_MemoryCtx* ctx) {
+    load_4444_(ptr_at_xy<const uint16_t>(ctx, dx,dy), tail, &dr,&dg,&db,&da);
+}
+STAGE_PP(store_4444, const SkJumper_MemoryCtx* ctx) {
+    store_4444_(ptr_at_xy<uint16_t>(ctx, dx,dy), tail, r,g,b,a);
+}
+STAGE_GP(gather_4444, const SkJumper_GatherCtx* ctx) {
+    const uint16_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+    from_4444(gather<U16>(ptr, ix), &r,&g,&b,&a);
+}
+
+// ~~~~~~ 8-bit memory loads and stores ~~~~~~ //
+
+SI U16 load_8(const uint8_t* ptr, size_t tail) {
+    return cast<U16>(load<U8>(ptr, tail));
+}
+SI void store_8(uint8_t* ptr, size_t tail, U16 v) {
+    store(ptr, tail, cast<U8>(v));
+}
+
+STAGE_PP(load_a8, const SkJumper_MemoryCtx* ctx) {
+    r = g = b = 0;
+    a = load_8(ptr_at_xy<const uint8_t>(ctx, dx,dy), tail);
+}
+STAGE_PP(load_a8_dst, const SkJumper_MemoryCtx* ctx) {
+    dr = dg = db = 0;
+    da = load_8(ptr_at_xy<const uint8_t>(ctx, dx,dy), tail);
+}
+STAGE_PP(store_a8, const SkJumper_MemoryCtx* ctx) {
+    store_8(ptr_at_xy<uint8_t>(ctx, dx,dy), tail, a);
+}
+STAGE_GP(gather_a8, const SkJumper_GatherCtx* ctx) {
+    const uint8_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+    r = g = b = 0;
+    a = cast<U16>(gather<U8>(ptr, ix));
+}
+
+STAGE_PP(load_g8, const SkJumper_MemoryCtx* ctx) {
+    r = g = b = load_8(ptr_at_xy<const uint8_t>(ctx, dx,dy), tail);
+    a = 255;
+}
+STAGE_PP(load_g8_dst, const SkJumper_MemoryCtx* ctx) {
+    dr = dg = db = load_8(ptr_at_xy<const uint8_t>(ctx, dx,dy), tail);
+    da = 255;
+}
+STAGE_PP(luminance_to_alpha, Ctx::None) {
+    a = (r*54 + g*183 + b*19)/256;  // 0.2126, 0.7152, 0.0722 with 256 denominator.
+    r = g = b = 0;
+}
+STAGE_GP(gather_g8, const SkJumper_GatherCtx* ctx) {
+    const uint8_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+    r = g = b = cast<U16>(gather<U8>(ptr, ix));
+    a = 255;
+}
+
+// ~~~~~~ Coverage scales / lerps ~~~~~~ //
+
+STAGE_PP(scale_1_float, const float* f) {
+    U16 c = from_float(*f);
+    r = div255( r * c );
+    g = div255( g * c );
+    b = div255( b * c );
+    a = div255( a * c );
+}
+STAGE_PP(lerp_1_float, const float* f) {
+    U16 c = from_float(*f);
+    r = lerp(dr, r, c);
+    g = lerp(dg, g, c);
+    b = lerp(db, b, c);
+    a = lerp(da, a, c);
+}
+
+STAGE_PP(scale_u8, const SkJumper_MemoryCtx* ctx) {
+    U16 c = load_8(ptr_at_xy<const uint8_t>(ctx, dx,dy), tail);
+    r = div255( r * c );
+    g = div255( g * c );
+    b = div255( b * c );
+    a = div255( a * c );
+}
+STAGE_PP(lerp_u8, const SkJumper_MemoryCtx* ctx) {
+    U16 c = load_8(ptr_at_xy<const uint8_t>(ctx, dx,dy), tail);
+    r = lerp(dr, r, c);
+    g = lerp(dg, g, c);
+    b = lerp(db, b, c);
+    a = lerp(da, a, c);
+}
+
+// Derive alpha's coverage from rgb coverage and the values of src and dst alpha.
+SI U16 alpha_coverage_from_rgb_coverage(U16 a, U16 da, U16 cr, U16 cg, U16 cb) {
+    return if_then_else(a < da, min(cr,cg,cb)
+                              , max(cr,cg,cb));
+}
+STAGE_PP(scale_565, const SkJumper_MemoryCtx* ctx) {
+    U16 cr,cg,cb;
+    load_565_(ptr_at_xy<const uint16_t>(ctx, dx,dy), tail, &cr,&cg,&cb);
+    U16 ca = alpha_coverage_from_rgb_coverage(a,da, cr,cg,cb);
+
+    r = div255( r * cr );
+    g = div255( g * cg );
+    b = div255( b * cb );
+    a = div255( a * ca );
+}
+STAGE_PP(lerp_565, const SkJumper_MemoryCtx* ctx) {
+    U16 cr,cg,cb;
+    load_565_(ptr_at_xy<const uint16_t>(ctx, dx,dy), tail, &cr,&cg,&cb);
+    U16 ca = alpha_coverage_from_rgb_coverage(a,da, cr,cg,cb);
+
+    r = lerp(dr, r, cr);
+    g = lerp(dg, g, cg);
+    b = lerp(db, b, cb);
+    a = lerp(da, a, ca);
+}
+
+// ~~~~~~ Gradient stages ~~~~~~ //
+
+// Clamp x to [0,1], both sides inclusive (think, gradients).
+// Even repeat and mirror funnel through a clamp to handle bad inputs like +Inf, NaN.
+SI F clamp_01(F v) { return min(max(0, v), 1); }
+
+STAGE_GG(clamp_x_1 , Ctx::None) { x = clamp_01(x); }
+STAGE_GG(repeat_x_1, Ctx::None) { x = clamp_01(x - floor_(x)); }
+STAGE_GG(mirror_x_1, Ctx::None) {
+    auto two = [](F x){ return x+x; };
+    x = clamp_01(abs_( (x-1.0f) - two(floor_((x-1.0f)*0.5f)) - 1.0f ));
+}
+
+SI I16 cond_to_mask_16(I32 cond) { return cast<I16>(cond); }
+
+STAGE_GG(decal_x, SkJumper_DecalTileCtx* ctx) {
+    auto w = ctx->limit_x;
+    unaligned_store(ctx->mask, cond_to_mask_16((0 <= x) & (x < w)));
+}
+STAGE_GG(decal_y, SkJumper_DecalTileCtx* ctx) {
+    auto h = ctx->limit_y;
+    unaligned_store(ctx->mask, cond_to_mask_16((0 <= y) & (y < h)));
+}
+STAGE_GG(decal_x_and_y, SkJumper_DecalTileCtx* ctx) {
+    auto w = ctx->limit_x;
+    auto h = ctx->limit_y;
+    unaligned_store(ctx->mask, cond_to_mask_16((0 <= x) & (x < w) & (0 <= y) & (y < h)));
+}
+STAGE_PP(check_decal_mask, SkJumper_DecalTileCtx* ctx) {
+    auto mask = unaligned_load<U16>(ctx->mask);
+    r = r & mask;
+    g = g & mask;
+    b = b & mask;
+    a = a & mask;
+}
+
+
+SI U16 round_F_to_U16(F x) { return cast<U16>(x * 255.0f + 0.5f); }
+
+SI void gradient_lookup(const SkJumper_GradientCtx* c, U32 idx, F t,
+                        U16* r, U16* g, U16* b, U16* a) {
+
+    F fr, fg, fb, fa, br, bg, bb, ba;
+#if defined(__AVX2__)
+    if (c->stopCount <=8) {
+        __m256i lo, hi;
+        split(idx, &lo, &hi);
+
+        fr = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[0]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[0]), hi));
+        br = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[0]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[0]), hi));
+        fg = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[1]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[1]), hi));
+        bg = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[1]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[1]), hi));
+        fb = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[2]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[2]), hi));
+        bb = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[2]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[2]), hi));
+        fa = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[3]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[3]), hi));
+        ba = join<F>(_mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[3]), lo),
+                     _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[3]), hi));
+    } else
+#endif
+    {
+        fr = gather<F>(c->fs[0], idx);
+        fg = gather<F>(c->fs[1], idx);
+        fb = gather<F>(c->fs[2], idx);
+        fa = gather<F>(c->fs[3], idx);
+        br = gather<F>(c->bs[0], idx);
+        bg = gather<F>(c->bs[1], idx);
+        bb = gather<F>(c->bs[2], idx);
+        ba = gather<F>(c->bs[3], idx);
+    }
+    *r = round_F_to_U16(mad(t, fr, br));
+    *g = round_F_to_U16(mad(t, fg, bg));
+    *b = round_F_to_U16(mad(t, fb, bb));
+    *a = round_F_to_U16(mad(t, fa, ba));
+}
+
+STAGE_GP(gradient, const SkJumper_GradientCtx* c) {
+    auto t = x;
+    U32 idx = 0;
+
+    // N.B. The loop starts at 1 because idx 0 is the color to use before the first stop.
+    for (size_t i = 1; i < c->stopCount; i++) {
+        idx += if_then_else(t >= c->ts[i], U32(1), U32(0));
+    }
+
+    gradient_lookup(c, idx, t, &r, &g, &b, &a);
+}
+
+STAGE_GP(evenly_spaced_gradient, const SkJumper_GradientCtx* c) {
+    auto t = x;
+    auto idx = trunc_(t * (c->stopCount-1));
+    gradient_lookup(c, idx, t, &r, &g, &b, &a);
+}
+
+STAGE_GP(evenly_spaced_2_stop_gradient, const void* ctx) {
+    // TODO: Rename Ctx SkJumper_EvenlySpaced2StopGradientCtx.
+    struct Ctx { float f[4], b[4]; };
+    auto c = (const Ctx*)ctx;
+
+    auto t = x;
+    r = round_F_to_U16(mad(t, c->f[0], c->b[0]));
+    g = round_F_to_U16(mad(t, c->f[1], c->b[1]));
+    b = round_F_to_U16(mad(t, c->f[2], c->b[2]));
+    a = round_F_to_U16(mad(t, c->f[3], c->b[3]));
+}
+
+STAGE_GG(xy_to_unit_angle, Ctx::None) {
+    F xabs = abs_(x),
+      yabs = abs_(y);
+
+    F slope = min(xabs, yabs)/max(xabs, yabs);
+    F s = slope * slope;
+
+    // Use a 7th degree polynomial to approximate atan.
+    // This was generated using sollya.gforge.inria.fr.
+    // A float optimized polynomial was generated using the following command.
+    // P1 = fpminimax((1/(2*Pi))*atan(x),[|1,3,5,7|],[|24...|],[2^(-40),1],relative);
+    F phi = slope
+             * (0.15912117063999176025390625f     + s
+             * (-5.185396969318389892578125e-2f   + s
+             * (2.476101927459239959716796875e-2f + s
+             * (-7.0547382347285747528076171875e-3f))));
+
+    phi = if_then_else(xabs < yabs, 1.0f/4.0f - phi, phi);
+    phi = if_then_else(x < 0.0f   , 1.0f/2.0f - phi, phi);
+    phi = if_then_else(y < 0.0f   , 1.0f - phi     , phi);
+    phi = if_then_else(phi != phi , 0              , phi);  // Check for NaN.
+    x = phi;
+}
+STAGE_GG(xy_to_radius, Ctx::None) {
+    x = sqrt_(x*x + y*y);
+}
+
+// ~~~~~~ Compound stages ~~~~~~ //
+
+STAGE_PP(srcover_rgba_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    load_8888_(ptr, tail, &dr,&dg,&db,&da);
+    r = r + div255( dr*inv(a) );
+    g = g + div255( dg*inv(a) );
+    b = b + div255( db*inv(a) );
+    a = a + div255( da*inv(a) );
+    store_8888_(ptr, tail, r,g,b,a);
+}
+STAGE_PP(srcover_bgra_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    load_8888_(ptr, tail, &db,&dg,&dr,&da);
+    r = r + div255( dr*inv(a) );
+    g = g + div255( dg*inv(a) );
+    b = b + div255( db*inv(a) );
+    a = a + div255( da*inv(a) );
+    store_8888_(ptr, tail, b,g,r,a);
+}
+
+// Now we'll add null stand-ins for stages we haven't implemented in lowp.
+// If a pipeline uses these stages, it'll boot it out of lowp into highp.
+
+using NotImplemented = void(*)(void);
+
+static NotImplemented
+        callback, load_rgba, store_rgba,
+        clamp_0, clamp_1,
+        unpremul, dither,
+        from_srgb, from_srgb_dst, to_srgb,
+        load_f16    , load_f16_dst    , store_f16    , gather_f16,
+        load_f32    , load_f32_dst    , store_f32    , gather_f32,
+        load_1010102, load_1010102_dst, store_1010102, gather_1010102,
+        load_u16_be, load_rgb_u16_be, store_u16_be,
+        load_tables_u16_be, load_tables_rgb_u16_be,
+        load_tables, byte_tables, byte_tables_rgb,
+        colorburn, colordodge, softlight, hue, saturation, color, luminosity,
+        matrix_3x4, matrix_4x5, matrix_4x3,
+        parametric_r, parametric_g, parametric_b, parametric_a,
+        table_r, table_g, table_b, table_a,
+        gamma, gamma_dst,
+        lab_to_xyz, rgb_to_hsl, hsl_to_rgb, clut_3D, clut_4D,
+        gauss_a_to_rgba,
+        mirror_x, repeat_x,
+        mirror_y, repeat_y,
+        negate_x,
+        bilinear_nx, bilinear_ny, bilinear_px, bilinear_py,
+        bicubic_n3x, bicubic_n1x, bicubic_p1x, bicubic_p3x,
+        bicubic_n3y, bicubic_n1y, bicubic_p1y, bicubic_p3y,
+        save_xy, accumulate,
+        xy_to_2pt_conical_well_behaved,
+        xy_to_2pt_conical_strip,
+        xy_to_2pt_conical_focal_on_circle,
+        xy_to_2pt_conical_smaller,
+        xy_to_2pt_conical_greater,
+        xy_to_2pt_conical_compensate_focal,
+        alter_2pt_conical_compensate_focal,
+        alter_2pt_conical_unswap,
+        mask_2pt_conical_nan,
+        mask_2pt_conical_degenerates,
+        apply_vector_mask,
+        bilerp_clamp_8888;
+
+#endif//defined(JUMPER_IS_SCALAR) controlling whether we build lowp stages
+}  // namespace lowp
+
+}  // namespace SK_OPTS_NS
+
+#endif//SkRasterPipeline_opts_DEFINED
diff -Naur chromium-67.0.3396.62/third_party/webgl/src/specs/latest/2.0/webgl2.idl chromium-67.0.3396.62.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl
--- chromium-67.0.3396.62/third_party/webgl/src/specs/latest/2.0/webgl2.idl	2018-05-30 11:44:33.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl	2018-06-06 10:06:12.313135206 +0300
@@ -262,7 +262,7 @@
   const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES          = 0x8A43;
   const GLenum UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER     = 0x8A44;
   const GLenum UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER   = 0x8A46;
-  const GLenum INVALID_INDEX                                 = 0xFFFFFFFF;
+  const GLenum INVALID_INDEX                                 = 256;
   const GLenum MAX_VERTEX_OUTPUT_COMPONENTS                  = 0x9122;
   const GLenum MAX_FRAGMENT_INPUT_COMPONENTS                 = 0x9125;
   const GLenum MAX_SERVER_WAIT_TIMEOUT                       = 0x9111;
diff -Naur chromium-67.0.3396.62/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5 chromium-67.0.3396.62.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5
--- chromium-67.0.3396.62/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5	2018-05-30 11:44:33.000000000 +0300
@@ -0,0 +1,580 @@
+// AUTOGENERATED FILE -- DO NOT EDIT -- SEE Makefile
+//
+// WebGL IDL definitions scraped from the Khronos specification:
+// https://www.khronos.org/registry/webgl/specs/latest/
+//
+// This IDL depends on the typed array specification defined at:
+// https://www.khronos.org/registry/typedarray/specs/latest/typedarrays.idl
+
+typedef long long GLint64;
+typedef unsigned long long GLuint64;
+
+
+interface WebGLQuery : WebGLObject {
+};
+
+interface WebGLSampler : WebGLObject {
+};
+
+interface WebGLSync : WebGLObject {
+};
+
+interface WebGLTransformFeedback : WebGLObject {
+};
+
+interface WebGLVertexArrayObject : WebGLObject {
+};
+
+typedef ([AllowShared] Uint32Array or sequence<GLuint>) Uint32List;
+
+interface mixin WebGL2RenderingContextBase
+{
+  const GLenum READ_BUFFER                                   = 0x0C02;
+  const GLenum UNPACK_ROW_LENGTH                             = 0x0CF2;
+  const GLenum UNPACK_SKIP_ROWS                              = 0x0CF3;
+  const GLenum UNPACK_SKIP_PIXELS                            = 0x0CF4;
+  const GLenum PACK_ROW_LENGTH                               = 0x0D02;
+  const GLenum PACK_SKIP_ROWS                                = 0x0D03;
+  const GLenum PACK_SKIP_PIXELS                              = 0x0D04;
+  const GLenum COLOR                                         = 0x1800;
+  const GLenum DEPTH                                         = 0x1801;
+  const GLenum STENCIL                                       = 0x1802;
+  const GLenum RED                                           = 0x1903;
+  const GLenum RGB8                                          = 0x8051;
+  const GLenum RGBA8                                         = 0x8058;
+  const GLenum RGB10_A2                                      = 0x8059;
+  const GLenum TEXTURE_BINDING_3D                            = 0x806A;
+  const GLenum UNPACK_SKIP_IMAGES                            = 0x806D;
+  const GLenum UNPACK_IMAGE_HEIGHT                           = 0x806E;
+  const GLenum TEXTURE_3D                                    = 0x806F;
+  const GLenum TEXTURE_WRAP_R                                = 0x8072;
+  const GLenum MAX_3D_TEXTURE_SIZE                           = 0x8073;
+  const GLenum UNSIGNED_INT_2_10_10_10_REV                   = 0x8368;
+  const GLenum MAX_ELEMENTS_VERTICES                         = 0x80E8;
+  const GLenum MAX_ELEMENTS_INDICES                          = 0x80E9;
+  const GLenum TEXTURE_MIN_LOD                               = 0x813A;
+  const GLenum TEXTURE_MAX_LOD                               = 0x813B;
+  const GLenum TEXTURE_BASE_LEVEL                            = 0x813C;
+  const GLenum TEXTURE_MAX_LEVEL                             = 0x813D;
+  const GLenum MIN                                           = 0x8007;
+  const GLenum MAX                                           = 0x8008;
+  const GLenum DEPTH_COMPONENT24                             = 0x81A6;
+  const GLenum MAX_TEXTURE_LOD_BIAS                          = 0x84FD;
+  const GLenum TEXTURE_COMPARE_MODE                          = 0x884C;
+  const GLenum TEXTURE_COMPARE_FUNC                          = 0x884D;
+  const GLenum CURRENT_QUERY                                 = 0x8865;
+  const GLenum QUERY_RESULT                                  = 0x8866;
+  const GLenum QUERY_RESULT_AVAILABLE                        = 0x8867;
+  const GLenum STREAM_READ                                   = 0x88E1;
+  const GLenum STREAM_COPY                                   = 0x88E2;
+  const GLenum STATIC_READ                                   = 0x88E5;
+  const GLenum STATIC_COPY                                   = 0x88E6;
+  const GLenum DYNAMIC_READ                                  = 0x88E9;
+  const GLenum DYNAMIC_COPY                                  = 0x88EA;
+  const GLenum MAX_DRAW_BUFFERS                              = 0x8824;
+  const GLenum DRAW_BUFFER0                                  = 0x8825;
+  const GLenum DRAW_BUFFER1                                  = 0x8826;
+  const GLenum DRAW_BUFFER2                                  = 0x8827;
+  const GLenum DRAW_BUFFER3                                  = 0x8828;
+  const GLenum DRAW_BUFFER4                                  = 0x8829;
+  const GLenum DRAW_BUFFER5                                  = 0x882A;
+  const GLenum DRAW_BUFFER6                                  = 0x882B;
+  const GLenum DRAW_BUFFER7                                  = 0x882C;
+  const GLenum DRAW_BUFFER8                                  = 0x882D;
+  const GLenum DRAW_BUFFER9                                  = 0x882E;
+  const GLenum DRAW_BUFFER10                                 = 0x882F;
+  const GLenum DRAW_BUFFER11                                 = 0x8830;
+  const GLenum DRAW_BUFFER12                                 = 0x8831;
+  const GLenum DRAW_BUFFER13                                 = 0x8832;
+  const GLenum DRAW_BUFFER14                                 = 0x8833;
+  const GLenum DRAW_BUFFER15                                 = 0x8834;
+  const GLenum MAX_FRAGMENT_UNIFORM_COMPONENTS               = 0x8B49;
+  const GLenum MAX_VERTEX_UNIFORM_COMPONENTS                 = 0x8B4A;
+  const GLenum SAMPLER_3D                                    = 0x8B5F;
+  const GLenum SAMPLER_2D_SHADOW                             = 0x8B62;
+  const GLenum FRAGMENT_SHADER_DERIVATIVE_HINT               = 0x8B8B;
+  const GLenum PIXEL_PACK_BUFFER                             = 0x88EB;
+  const GLenum PIXEL_UNPACK_BUFFER                           = 0x88EC;
+  const GLenum PIXEL_PACK_BUFFER_BINDING                     = 0x88ED;
+  const GLenum PIXEL_UNPACK_BUFFER_BINDING                   = 0x88EF;
+  const GLenum FLOAT_MAT2x3                                  = 0x8B65;
+  const GLenum FLOAT_MAT2x4                                  = 0x8B66;
+  const GLenum FLOAT_MAT3x2                                  = 0x8B67;
+  const GLenum FLOAT_MAT3x4                                  = 0x8B68;
+  const GLenum FLOAT_MAT4x2                                  = 0x8B69;
+  const GLenum FLOAT_MAT4x3                                  = 0x8B6A;
+  const GLenum SRGB                                          = 0x8C40;
+  const GLenum SRGB8                                         = 0x8C41;
+  const GLenum SRGB8_ALPHA8                                  = 0x8C43;
+  const GLenum COMPARE_REF_TO_TEXTURE                        = 0x884E;
+  const GLenum RGBA32F                                       = 0x8814;
+  const GLenum RGB32F                                        = 0x8815;
+  const GLenum RGBA16F                                       = 0x881A;
+  const GLenum RGB16F                                        = 0x881B;
+  const GLenum VERTEX_ATTRIB_ARRAY_INTEGER                   = 0x88FD;
+  const GLenum MAX_ARRAY_TEXTURE_LAYERS                      = 0x88FF;
+  const GLenum MIN_PROGRAM_TEXEL_OFFSET                      = 0x8904;
+  const GLenum MAX_PROGRAM_TEXEL_OFFSET                      = 0x8905;
+  const GLenum MAX_VARYING_COMPONENTS                        = 0x8B4B;
+  const GLenum TEXTURE_2D_ARRAY                              = 0x8C1A;
+  const GLenum TEXTURE_BINDING_2D_ARRAY                      = 0x8C1D;
+  const GLenum R11F_G11F_B10F                                = 0x8C3A;
+  const GLenum UNSIGNED_INT_10F_11F_11F_REV                  = 0x8C3B;
+  const GLenum RGB9_E5                                       = 0x8C3D;
+  const GLenum UNSIGNED_INT_5_9_9_9_REV                      = 0x8C3E;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_MODE                = 0x8C7F;
+  const GLenum MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS    = 0x8C80;
+  const GLenum TRANSFORM_FEEDBACK_VARYINGS                   = 0x8C83;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_START               = 0x8C84;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_SIZE                = 0x8C85;
+  const GLenum TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN         = 0x8C88;
+  const GLenum RASTERIZER_DISCARD                            = 0x8C89;
+  const GLenum MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS = 0x8C8A;
+  const GLenum MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS       = 0x8C8B;
+  const GLenum INTERLEAVED_ATTRIBS                           = 0x8C8C;
+  const GLenum SEPARATE_ATTRIBS                              = 0x8C8D;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER                     = 0x8C8E;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_BINDING             = 0x8C8F;
+  const GLenum RGBA32UI                                      = 0x8D70;
+  const GLenum RGB32UI                                       = 0x8D71;
+  const GLenum RGBA16UI                                      = 0x8D76;
+  const GLenum RGB16UI                                       = 0x8D77;
+  const GLenum RGBA8UI                                       = 0x8D7C;
+  const GLenum RGB8UI                                        = 0x8D7D;
+  const GLenum RGBA32I                                       = 0x8D82;
+  const GLenum RGB32I                                        = 0x8D83;
+  const GLenum RGBA16I                                       = 0x8D88;
+  const GLenum RGB16I                                        = 0x8D89;
+  const GLenum RGBA8I                                        = 0x8D8E;
+  const GLenum RGB8I                                         = 0x8D8F;
+  const GLenum RED_INTEGER                                   = 0x8D94;
+  const GLenum RGB_INTEGER                                   = 0x8D98;
+  const GLenum RGBA_INTEGER                                  = 0x8D99;
+  const GLenum SAMPLER_2D_ARRAY                              = 0x8DC1;
+  const GLenum SAMPLER_2D_ARRAY_SHADOW                       = 0x8DC4;
+  const GLenum SAMPLER_CUBE_SHADOW                           = 0x8DC5;
+  const GLenum UNSIGNED_INT_VEC2                             = 0x8DC6;
+  const GLenum UNSIGNED_INT_VEC3                             = 0x8DC7;
+  const GLenum UNSIGNED_INT_VEC4                             = 0x8DC8;
+  const GLenum INT_SAMPLER_2D                                = 0x8DCA;
+  const GLenum INT_SAMPLER_3D                                = 0x8DCB;
+  const GLenum INT_SAMPLER_CUBE                              = 0x8DCC;
+  const GLenum INT_SAMPLER_2D_ARRAY                          = 0x8DCF;
+  const GLenum UNSIGNED_INT_SAMPLER_2D                       = 0x8DD2;
+  const GLenum UNSIGNED_INT_SAMPLER_3D                       = 0x8DD3;
+  const GLenum UNSIGNED_INT_SAMPLER_CUBE                     = 0x8DD4;
+  const GLenum UNSIGNED_INT_SAMPLER_2D_ARRAY                 = 0x8DD7;
+  const GLenum DEPTH_COMPONENT32F                            = 0x8CAC;
+  const GLenum DEPTH32F_STENCIL8                             = 0x8CAD;
+  const GLenum FLOAT_32_UNSIGNED_INT_24_8_REV                = 0x8DAD;
+  const GLenum FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING         = 0x8210;
+  const GLenum FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE         = 0x8211;
+  const GLenum FRAMEBUFFER_ATTACHMENT_RED_SIZE               = 0x8212;
+  const GLenum FRAMEBUFFER_ATTACHMENT_GREEN_SIZE             = 0x8213;
+  const GLenum FRAMEBUFFER_ATTACHMENT_BLUE_SIZE              = 0x8214;
+  const GLenum FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE             = 0x8215;
+  const GLenum FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE             = 0x8216;
+  const GLenum FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE           = 0x8217;
+  const GLenum FRAMEBUFFER_DEFAULT                           = 0x8218;
+  const GLenum DEPTH_STENCIL_ATTACHMENT                      = 0x821A;
+  const GLenum DEPTH_STENCIL                                 = 0x84F9;
+  const GLenum UNSIGNED_INT_24_8                             = 0x84FA;
+  const GLenum DEPTH24_STENCIL8                              = 0x88F0;
+  const GLenum UNSIGNED_NORMALIZED                           = 0x8C17;
+  const GLenum DRAW_FRAMEBUFFER_BINDING                      = 0x8CA6; /* Same as FRAMEBUFFER_BINDING */
+  const GLenum READ_FRAMEBUFFER                              = 0x8CA8;
+  const GLenum DRAW_FRAMEBUFFER                              = 0x8CA9;
+  const GLenum READ_FRAMEBUFFER_BINDING                      = 0x8CAA;
+  const GLenum RENDERBUFFER_SAMPLES                          = 0x8CAB;
+  const GLenum FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER          = 0x8CD4;
+  const GLenum MAX_COLOR_ATTACHMENTS                         = 0x8CDF;
+  const GLenum COLOR_ATTACHMENT1                             = 0x8CE1;
+  const GLenum COLOR_ATTACHMENT2                             = 0x8CE2;
+  const GLenum COLOR_ATTACHMENT3                             = 0x8CE3;
+  const GLenum COLOR_ATTACHMENT4                             = 0x8CE4;
+  const GLenum COLOR_ATTACHMENT5                             = 0x8CE5;
+  const GLenum COLOR_ATTACHMENT6                             = 0x8CE6;
+  const GLenum COLOR_ATTACHMENT7                             = 0x8CE7;
+  const GLenum COLOR_ATTACHMENT8                             = 0x8CE8;
+  const GLenum COLOR_ATTACHMENT9                             = 0x8CE9;
+  const GLenum COLOR_ATTACHMENT10                            = 0x8CEA;
+  const GLenum COLOR_ATTACHMENT11                            = 0x8CEB;
+  const GLenum COLOR_ATTACHMENT12                            = 0x8CEC;
+  const GLenum COLOR_ATTACHMENT13                            = 0x8CED;
+  const GLenum COLOR_ATTACHMENT14                            = 0x8CEE;
+  const GLenum COLOR_ATTACHMENT15                            = 0x8CEF;
+  const GLenum FRAMEBUFFER_INCOMPLETE_MULTISAMPLE            = 0x8D56;
+  const GLenum MAX_SAMPLES                                   = 0x8D57;
+  const GLenum HALF_FLOAT                                    = 0x140B;
+  const GLenum RG                                            = 0x8227;
+  const GLenum RG_INTEGER                                    = 0x8228;
+  const GLenum R8                                            = 0x8229;
+  const GLenum RG8                                           = 0x822B;
+  const GLenum R16F                                          = 0x822D;
+  const GLenum R32F                                          = 0x822E;
+  const GLenum RG16F                                         = 0x822F;
+  const GLenum RG32F                                         = 0x8230;
+  const GLenum R8I                                           = 0x8231;
+  const GLenum R8UI                                          = 0x8232;
+  const GLenum R16I                                          = 0x8233;
+  const GLenum R16UI                                         = 0x8234;
+  const GLenum R32I                                          = 0x8235;
+  const GLenum R32UI                                         = 0x8236;
+  const GLenum RG8I                                          = 0x8237;
+  const GLenum RG8UI                                         = 0x8238;
+  const GLenum RG16I                                         = 0x8239;
+  const GLenum RG16UI                                        = 0x823A;
+  const GLenum RG32I                                         = 0x823B;
+  const GLenum RG32UI                                        = 0x823C;
+  const GLenum VERTEX_ARRAY_BINDING                          = 0x85B5;
+  const GLenum R8_SNORM                                      = 0x8F94;
+  const GLenum RG8_SNORM                                     = 0x8F95;
+  const GLenum RGB8_SNORM                                    = 0x8F96;
+  const GLenum RGBA8_SNORM                                   = 0x8F97;
+  const GLenum SIGNED_NORMALIZED                             = 0x8F9C;
+  const GLenum COPY_READ_BUFFER                              = 0x8F36;
+  const GLenum COPY_WRITE_BUFFER                             = 0x8F37;
+  const GLenum COPY_READ_BUFFER_BINDING                      = 0x8F36; /* Same as COPY_READ_BUFFER */
+  const GLenum COPY_WRITE_BUFFER_BINDING                     = 0x8F37; /* Same as COPY_WRITE_BUFFER */
+  const GLenum UNIFORM_BUFFER                                = 0x8A11;
+  const GLenum UNIFORM_BUFFER_BINDING                        = 0x8A28;
+  const GLenum UNIFORM_BUFFER_START                          = 0x8A29;
+  const GLenum UNIFORM_BUFFER_SIZE                           = 0x8A2A;
+  const GLenum MAX_VERTEX_UNIFORM_BLOCKS                     = 0x8A2B;
+  const GLenum MAX_FRAGMENT_UNIFORM_BLOCKS                   = 0x8A2D;
+  const GLenum MAX_COMBINED_UNIFORM_BLOCKS                   = 0x8A2E;
+  const GLenum MAX_UNIFORM_BUFFER_BINDINGS                   = 0x8A2F;
+  const GLenum MAX_UNIFORM_BLOCK_SIZE                        = 0x8A30;
+  const GLenum MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS        = 0x8A31;
+  const GLenum MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS      = 0x8A33;
+  const GLenum UNIFORM_BUFFER_OFFSET_ALIGNMENT               = 0x8A34;
+  const GLenum ACTIVE_UNIFORM_BLOCKS                         = 0x8A36;
+  const GLenum UNIFORM_TYPE                                  = 0x8A37;
+  const GLenum UNIFORM_SIZE                                  = 0x8A38;
+  const GLenum UNIFORM_BLOCK_INDEX                           = 0x8A3A;
+  const GLenum UNIFORM_OFFSET                                = 0x8A3B;
+  const GLenum UNIFORM_ARRAY_STRIDE                          = 0x8A3C;
+  const GLenum UNIFORM_MATRIX_STRIDE                         = 0x8A3D;
+  const GLenum UNIFORM_IS_ROW_MAJOR                          = 0x8A3E;
+  const GLenum UNIFORM_BLOCK_BINDING                         = 0x8A3F;
+  const GLenum UNIFORM_BLOCK_DATA_SIZE                       = 0x8A40;
+  const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORMS                 = 0x8A42;
+  const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES          = 0x8A43;
+  const GLenum UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER     = 0x8A44;
+  const GLenum UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER   = 0x8A46;
+  const GLenum INVALID_INDEX                                 = 0xFFFFFFFF;
+  const GLenum MAX_VERTEX_OUTPUT_COMPONENTS                  = 0x9122;
+  const GLenum MAX_FRAGMENT_INPUT_COMPONENTS                 = 0x9125;
+  const GLenum MAX_SERVER_WAIT_TIMEOUT                       = 0x9111;
+  const GLenum OBJECT_TYPE                                   = 0x9112;
+  const GLenum SYNC_CONDITION                                = 0x9113;
+  const GLenum SYNC_STATUS                                   = 0x9114;
+  const GLenum SYNC_FLAGS                                    = 0x9115;
+  const GLenum SYNC_FENCE                                    = 0x9116;
+  const GLenum SYNC_GPU_COMMANDS_COMPLETE                    = 0x9117;
+  const GLenum UNSIGNALED                                    = 0x9118;
+  const GLenum SIGNALED                                      = 0x9119;
+  const GLenum ALREADY_SIGNALED                              = 0x911A;
+  const GLenum TIMEOUT_EXPIRED                               = 0x911B;
+  const GLenum CONDITION_SATISFIED                           = 0x911C;
+  const GLenum WAIT_FAILED                                   = 0x911D;
+  const GLenum SYNC_FLUSH_COMMANDS_BIT                       = 0x00000001;
+  const GLenum VERTEX_ATTRIB_ARRAY_DIVISOR                   = 0x88FE;
+  const GLenum ANY_SAMPLES_PASSED                            = 0x8C2F;
+  const GLenum ANY_SAMPLES_PASSED_CONSERVATIVE               = 0x8D6A;
+  const GLenum SAMPLER_BINDING                               = 0x8919;
+  const GLenum RGB10_A2UI                                    = 0x906F;
+  const GLenum INT_2_10_10_10_REV                            = 0x8D9F;
+  const GLenum TRANSFORM_FEEDBACK                            = 0x8E22;
+  const GLenum TRANSFORM_FEEDBACK_PAUSED                     = 0x8E23;
+  const GLenum TRANSFORM_FEEDBACK_ACTIVE                     = 0x8E24;
+  const GLenum TRANSFORM_FEEDBACK_BINDING                    = 0x8E25;
+  const GLenum TEXTURE_IMMUTABLE_FORMAT                      = 0x912F;
+  const GLenum MAX_ELEMENT_INDEX                             = 0x8D6B;
+  const GLenum TEXTURE_IMMUTABLE_LEVELS                      = 0x82DF;
+
+  const GLint64 TIMEOUT_IGNORED                              = -1;
+
+  /* WebGL-specific enums */
+  const GLenum MAX_CLIENT_WAIT_TIMEOUT_WEBGL                 = 0x9247;
+
+  /* Buffer objects */
+  // WebGL1:
+  void bufferData(GLenum target, GLsizeiptr size, GLenum usage);
+  void bufferData(GLenum target, [AllowShared] BufferSource? srcData, GLenum usage);
+  void bufferSubData(GLenum target, GLintptr dstByteOffset, [AllowShared] BufferSource srcData);
+  // WebGL2:
+  void bufferData(GLenum target, [AllowShared] ArrayBufferView srcData, GLenum usage, GLuint srcOffset,
+                  optional GLuint length = 0);
+  void bufferSubData(GLenum target, GLintptr dstByteOffset, [AllowShared] ArrayBufferView srcData,
+                     GLuint srcOffset, optional GLuint length = 0);
+
+  void copyBufferSubData(GLenum readTarget, GLenum writeTarget, GLintptr readOffset,
+                         GLintptr writeOffset, GLsizeiptr size);
+  // MapBufferRange, in particular its read-only and write-only modes,
+  // can not be exposed safely to JavaScript. GetBufferSubData
+  // replaces it for the purpose of fetching data back from the GPU.
+  void getBufferSubData(GLenum target, GLintptr srcByteOffset, [AllowShared] ArrayBufferView dstBuffer,
+                        optional GLuint dstOffset = 0, optional GLuint length = 0);
+
+  /* Framebuffer objects */
+  void blitFramebuffer(GLint srcX0, GLint srcY0, GLint srcX1, GLint srcY1, GLint dstX0, GLint dstY0,
+                       GLint dstX1, GLint dstY1, GLbitfield mask, GLenum filter);
+  void framebufferTextureLayer(GLenum target, GLenum attachment, WebGLTexture? texture, GLint level,
+                               GLint layer);
+  void invalidateFramebuffer(GLenum target, sequence<GLenum> attachments);
+  void invalidateSubFramebuffer(GLenum target, sequence<GLenum> attachments,
+                                GLint x, GLint y, GLsizei width, GLsizei height);
+  void readBuffer(GLenum src);
+
+  /* Renderbuffer objects */
+  any getInternalformatParameter(GLenum target, GLenum internalformat, GLenum pname);
+  void renderbufferStorageMultisample(GLenum target, GLsizei samples, GLenum internalformat,
+                                      GLsizei width, GLsizei height);
+
+  /* Texture objects */
+  void texStorage2D(GLenum target, GLsizei levels, GLenum internalformat, GLsizei width,
+                    GLsizei height);
+  void texStorage3D(GLenum target, GLsizei levels, GLenum internalformat, GLsizei width,
+                    GLsizei height, GLsizei depth);
+
+  // WebGL1 legacy entrypoints:
+  void texImage2D(GLenum target, GLint level, GLint internalformat,
+                  GLsizei width, GLsizei height, GLint border, GLenum format,
+                  GLenum type, [AllowShared] ArrayBufferView? pixels);
+  void texImage2D(GLenum target, GLint level, GLint internalformat,
+                  GLenum format, GLenum type, TexImageSource source); // May throw DOMException
+
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                     GLsizei width, GLsizei height,
+                     GLenum format, GLenum type, [AllowShared] ArrayBufferView? pixels);
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                     GLenum format, GLenum type, TexImageSource source); // May throw DOMException
+
+  // WebGL2 entrypoints:
+  void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLint border, GLenum format, GLenum type, GLintptr pboOffset);
+  void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLint border, GLenum format, GLenum type,
+                  TexImageSource source); // May throw DOMException
+  void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData,
+                  GLuint srcOffset);
+
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type, GLintptr pboOffset);
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type,
+                  TexImageSource source); // May throw DOMException
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView? srcData);
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData,
+                  GLuint srcOffset);
+
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width,
+                     GLsizei height, GLenum format, GLenum type, GLintptr pboOffset);
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width,
+                     GLsizei height, GLenum format, GLenum type,
+                     TexImageSource source); // May throw DOMException
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width,
+                     GLsizei height, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData,
+                     GLuint srcOffset);
+
+  void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                     GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type,
+                     GLintptr pboOffset);
+  void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                     GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type,
+                     TexImageSource source); // May throw DOMException
+  void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                     GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type,
+                     [AllowShared] ArrayBufferView? srcData, optional GLuint srcOffset = 0);
+
+  void copyTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                         GLint x, GLint y, GLsizei width, GLsizei height);
+
+  void compressedTexImage2D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLint border, GLsizei imageSize, GLintptr offset);
+  void compressedTexImage2D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLint border, [AllowShared] ArrayBufferView srcData,
+                            optional GLuint srcOffset = 0, optional GLuint srcLengthOverride = 0);
+
+  void compressedTexImage3D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLsizei depth, GLint border, GLsizei imageSize, GLintptr offset);
+  void compressedTexImage3D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLsizei depth, GLint border, [AllowShared] ArrayBufferView srcData,
+                            optional GLuint srcOffset = 0, optional GLuint srcLengthOverride = 0);
+
+  void compressedTexSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLsizei width, GLsizei height, GLenum format, GLsizei imageSize, GLintptr offset);
+  void compressedTexSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLsizei width, GLsizei height, GLenum format,
+                               [AllowShared] ArrayBufferView srcData,
+                               optional GLuint srcOffset = 0,
+                               optional GLuint srcLengthOverride = 0);
+
+  void compressedTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLint zoffset, GLsizei width, GLsizei height, GLsizei depth,
+                               GLenum format, GLsizei imageSize, GLintptr offset);
+  void compressedTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLint zoffset, GLsizei width, GLsizei height, GLsizei depth,
+                               GLenum format, [AllowShared] ArrayBufferView srcData,
+                               optional GLuint srcOffset = 0,
+                               optional GLuint srcLengthOverride = 0);
+
+  /* Programs and shaders */
+  [WebGLHandlesContextLoss] GLint getFragDataLocation(WebGLProgram program, DOMString name);
+
+  /* Uniforms */
+  void uniform1ui(WebGLUniformLocation? location, GLuint v0);
+  void uniform2ui(WebGLUniformLocation? location, GLuint v0, GLuint v1);
+  void uniform3ui(WebGLUniformLocation? location, GLuint v0, GLuint v1, GLuint v2);
+  void uniform4ui(WebGLUniformLocation? location, GLuint v0, GLuint v1, GLuint v2, GLuint v3);
+
+  void uniform1fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform2fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform3fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform4fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+
+  void uniform1iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform2iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform3iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform4iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+
+  void uniform1uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform2uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform3uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform4uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+
+  void uniformMatrix2fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                        optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix3x2fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix4x2fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+
+  void uniformMatrix2x3fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix3fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                        optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix4x3fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+
+  void uniformMatrix2x4fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix3x4fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix4fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                        optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+
+  /* Vertex attribs */
+  void vertexAttribI4i(GLuint index, GLint x, GLint y, GLint z, GLint w);
+  void vertexAttribI4iv(GLuint index, Int32List values);
+  void vertexAttribI4ui(GLuint index, GLuint x, GLuint y, GLuint z, GLuint w);
+  void vertexAttribI4uiv(GLuint index, Uint32List values);
+  void vertexAttribIPointer(GLuint index, GLint size, GLenum type, GLsizei stride, GLintptr offset);
+
+  /* Writing to the drawing buffer */
+  void vertexAttribDivisor(GLuint index, GLuint divisor);
+  void drawArraysInstanced(GLenum mode, GLint first, GLsizei count, GLsizei instanceCount);
+  void drawElementsInstanced(GLenum mode, GLsizei count, GLenum type, GLintptr offset, GLsizei instanceCount);
+  void drawRangeElements(GLenum mode, GLuint start, GLuint end, GLsizei count, GLenum type, GLintptr offset);
+
+  /* Reading back pixels */
+  // WebGL1:
+  void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type,
+                  [AllowShared] ArrayBufferView? dstData);
+  // WebGL2:
+  void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type,
+                  GLintptr offset);
+  void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type,
+                  [AllowShared] ArrayBufferView dstData, GLuint dstOffset);
+
+  /* Multiple Render Targets */
+  void drawBuffers(sequence<GLenum> buffers);
+
+  void clearBufferfv(GLenum buffer, GLint drawbuffer, Float32List values,
+                     optional GLuint srcOffset = 0);
+  void clearBufferiv(GLenum buffer, GLint drawbuffer, Int32List values,
+                     optional GLuint srcOffset = 0);
+  void clearBufferuiv(GLenum buffer, GLint drawbuffer, Uint32List values,
+                      optional GLuint srcOffset = 0);
+
+  void clearBufferfi(GLenum buffer, GLint drawbuffer, GLfloat depth, GLint stencil);
+
+  /* Query Objects */
+  WebGLQuery? createQuery();
+  void deleteQuery(WebGLQuery? query);
+  [WebGLHandlesContextLoss] GLboolean isQuery(WebGLQuery? query);
+  void beginQuery(GLenum target, WebGLQuery query);
+  void endQuery(GLenum target);
+  WebGLQuery? getQuery(GLenum target, GLenum pname);
+  any getQueryParameter(WebGLQuery query, GLenum pname);
+
+  /* Sampler Objects */
+  WebGLSampler? createSampler();
+  void deleteSampler(WebGLSampler? sampler);
+  [WebGLHandlesContextLoss] GLboolean isSampler(WebGLSampler? sampler);
+  void bindSampler(GLuint unit, WebGLSampler? sampler);
+  void samplerParameteri(WebGLSampler sampler, GLenum pname, GLint param);
+  void samplerParameterf(WebGLSampler sampler, GLenum pname, GLfloat param);
+  any getSamplerParameter(WebGLSampler sampler, GLenum pname);
+
+  /* Sync objects */
+  WebGLSync? fenceSync(GLenum condition, GLbitfield flags);
+  [WebGLHandlesContextLoss] GLboolean isSync(WebGLSync? sync);
+  void deleteSync(WebGLSync? sync);
+  GLenum clientWaitSync(WebGLSync sync, GLbitfield flags, GLuint64 timeout);
+  void waitSync(WebGLSync sync, GLbitfield flags, GLint64 timeout);
+  any getSyncParameter(WebGLSync sync, GLenum pname);
+
+  /* Transform Feedback */
+  WebGLTransformFeedback? createTransformFeedback();
+  void deleteTransformFeedback(WebGLTransformFeedback? tf);
+  [WebGLHandlesContextLoss] GLboolean isTransformFeedback(WebGLTransformFeedback? tf);
+  void bindTransformFeedback (GLenum target, WebGLTransformFeedback? tf);
+  void beginTransformFeedback(GLenum primitiveMode);
+  void endTransformFeedback();
+  void transformFeedbackVaryings(WebGLProgram program, sequence<DOMString> varyings, GLenum bufferMode);
+  WebGLActiveInfo? getTransformFeedbackVarying(WebGLProgram program, GLuint index);
+  void pauseTransformFeedback();
+  void resumeTransformFeedback();
+
+  /* Uniform Buffer Objects and Transform Feedback Buffers */
+  void bindBufferBase(GLenum target, GLuint index, WebGLBuffer? buffer);
+  void bindBufferRange(GLenum target, GLuint index, WebGLBuffer? buffer, GLintptr offset, GLsizeiptr size);
+  any getIndexedParameter(GLenum target, GLuint index);
+  sequence<GLuint>? getUniformIndices(WebGLProgram program, sequence<DOMString> uniformNames);
+  any getActiveUniforms(WebGLProgram program, sequence<GLuint> uniformIndices, GLenum pname);
+  GLuint getUniformBlockIndex(WebGLProgram program, DOMString uniformBlockName);
+  any getActiveUniformBlockParameter(WebGLProgram program, GLuint uniformBlockIndex, GLenum pname);
+  DOMString? getActiveUniformBlockName(WebGLProgram program, GLuint uniformBlockIndex);
+  void uniformBlockBinding(WebGLProgram program, GLuint uniformBlockIndex, GLuint uniformBlockBinding);
+
+  /* Vertex Array Objects */
+  WebGLVertexArrayObject? createVertexArray();
+  void deleteVertexArray(WebGLVertexArrayObject? vertexArray);
+  [WebGLHandlesContextLoss] GLboolean isVertexArray(WebGLVertexArrayObject? vertexArray);
+  void bindVertexArray(WebGLVertexArrayObject? array);
+};
+
+interface WebGL2RenderingContext
+{
+};
+WebGL2RenderingContext includes WebGLRenderingContextBase;
+WebGL2RenderingContext includes WebGL2RenderingContextBase;
+
+
diff -Naur chromium-67.0.3396.62/third_party/webrtc/p2p/base/port.cc chromium-67.0.3396.62.patched/third_party/webrtc/p2p/base/port.cc
--- chromium-67.0.3396.62/third_party/webrtc/p2p/base/port.cc	2018-05-30 11:44:32.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/webrtc/p2p/base/port.cc	2018-06-06 10:06:12.365134376 +0300
@@ -10,7 +10,7 @@
 
 #include "p2p/base/port.h"
 
-#include <math.h>
+#include <cmath>
 
 #include <algorithm>
 #include <utility>
diff -Naur chromium-67.0.3396.62/third_party/webrtc/p2p/base/port.cc.gcc-round-fix chromium-67.0.3396.62.patched/third_party/webrtc/p2p/base/port.cc.gcc-round-fix
--- chromium-67.0.3396.62/third_party/webrtc/p2p/base/port.cc.gcc-round-fix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/webrtc/p2p/base/port.cc.gcc-round-fix	2018-05-30 11:44:32.000000000 +0300
@@ -0,0 +1,1856 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "p2p/base/port.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <utility>
+#include <vector>
+
+#include "p2p/base/portallocator.h"
+#include "rtc_base/base64.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/crc32.h"
+#include "rtc_base/helpers.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/messagedigest.h"
+#include "rtc_base/network.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "rtc_base/ptr_util.h"
+#include "rtc_base/stringencode.h"
+#include "rtc_base/stringutils.h"
+
+namespace {
+
+// Determines whether we have seen at least the given maximum number of
+// pings fail to have a response.
+inline bool TooManyFailures(
+    const std::vector<cricket::Connection::SentPing>& pings_since_last_response,
+    uint32_t maximum_failures,
+    int rtt_estimate,
+    int64_t now) {
+  // If we haven't sent that many pings, then we can't have failed that many.
+  if (pings_since_last_response.size() < maximum_failures)
+    return false;
+
+  // Check if the window in which we would expect a response to the ping has
+  // already elapsed.
+  int64_t expected_response_time =
+      pings_since_last_response[maximum_failures - 1].sent_time + rtt_estimate;
+  return now > expected_response_time;
+}
+
+// Determines whether we have gone too long without seeing any response.
+inline bool TooLongWithoutResponse(
+    const std::vector<cricket::Connection::SentPing>& pings_since_last_response,
+    int64_t maximum_time,
+    int64_t now) {
+  if (pings_since_last_response.size() == 0)
+    return false;
+
+  auto first = pings_since_last_response[0];
+  return now > (first.sent_time + maximum_time);
+}
+
+// Helper methods for converting string values of log description fields to
+// enum.
+webrtc::IceCandidateType GetCandidateTypeByString(const std::string& type) {
+  if (type == cricket::LOCAL_PORT_TYPE) {
+    return webrtc::IceCandidateType::kLocal;
+  } else if (type == cricket::STUN_PORT_TYPE) {
+    return webrtc::IceCandidateType::kStun;
+  } else if (type == cricket::PRFLX_PORT_TYPE) {
+    return webrtc::IceCandidateType::kPrflx;
+  } else if (type == cricket::RELAY_PORT_TYPE) {
+    return webrtc::IceCandidateType::kRelay;
+  }
+  return webrtc::IceCandidateType::kUnknown;
+}
+
+webrtc::IceCandidatePairProtocol GetProtocolByString(
+    const std::string& protocol) {
+  if (protocol == cricket::UDP_PROTOCOL_NAME) {
+    return webrtc::IceCandidatePairProtocol::kUdp;
+  } else if (protocol == cricket::TCP_PROTOCOL_NAME) {
+    return webrtc::IceCandidatePairProtocol::kTcp;
+  } else if (protocol == cricket::SSLTCP_PROTOCOL_NAME) {
+    return webrtc::IceCandidatePairProtocol::kSsltcp;
+  } else if (protocol == cricket::TLS_PROTOCOL_NAME) {
+    return webrtc::IceCandidatePairProtocol::kTls;
+  }
+  return webrtc::IceCandidatePairProtocol::kUnknown;
+}
+
+webrtc::IceCandidatePairAddressFamily GetAddressFamilyByInt(
+    int address_family) {
+  if (address_family == AF_INET) {
+    return webrtc::IceCandidatePairAddressFamily::kIpv4;
+  } else if (address_family == AF_INET6) {
+    return webrtc::IceCandidatePairAddressFamily::kIpv6;
+  }
+  return webrtc::IceCandidatePairAddressFamily::kUnknown;
+}
+
+webrtc::IceCandidateNetworkType ConvertNetworkType(rtc::AdapterType type) {
+  if (type == rtc::ADAPTER_TYPE_ETHERNET) {
+    return webrtc::IceCandidateNetworkType::kEthernet;
+  } else if (type == rtc::ADAPTER_TYPE_LOOPBACK) {
+    return webrtc::IceCandidateNetworkType::kLoopback;
+  } else if (type == rtc::ADAPTER_TYPE_WIFI) {
+    return webrtc::IceCandidateNetworkType::kWifi;
+  } else if (type == rtc::ADAPTER_TYPE_VPN) {
+    return webrtc::IceCandidateNetworkType::kVpn;
+  } else if (type == rtc::ADAPTER_TYPE_CELLULAR) {
+    return webrtc::IceCandidateNetworkType::kCellular;
+  }
+  return webrtc::IceCandidateNetworkType::kUnknown;
+}
+
+// We will restrict RTT estimates (when used for determining state) to be
+// within a reasonable range.
+const int MINIMUM_RTT = 100;   // 0.1 seconds
+const int MAXIMUM_RTT = 60000;  // 60 seconds
+
+// When we don't have any RTT data, we have to pick something reasonable.  We
+// use a large value just in case the connection is really slow.
+const int DEFAULT_RTT = 3000;  // 3 seconds
+
+// Computes our estimate of the RTT given the current estimate.
+inline int ConservativeRTTEstimate(int rtt) {
+  return rtc::SafeClamp(2 * rtt, MINIMUM_RTT, MAXIMUM_RTT);
+}
+
+// Weighting of the old rtt value to new data.
+const int RTT_RATIO = 3;  // 3 : 1
+
+// The delay before we begin checking if this port is useless. We set
+// it to a little higher than a total STUN timeout.
+const int kPortTimeoutDelay = cricket::STUN_TOTAL_TIMEOUT + 5000;
+
+// For packet loss estimation.
+const int64_t kConsiderPacketLostAfter = 3000;  // 3 seconds
+
+// For packet loss estimation.
+const int64_t kForgetPacketAfter = 30000;  // 30 seconds
+
+}  // namespace
+
+namespace cricket {
+
+using webrtc::RTCErrorType;
+using webrtc::RTCError;
+
+// TODO(ronghuawu): Use "local", "srflx", "prflx" and "relay". But this requires
+// the signaling part be updated correspondingly as well.
+const char LOCAL_PORT_TYPE[] = "local";
+const char STUN_PORT_TYPE[] = "stun";
+const char PRFLX_PORT_TYPE[] = "prflx";
+const char RELAY_PORT_TYPE[] = "relay";
+
+static const char* const PROTO_NAMES[] = {UDP_PROTOCOL_NAME, TCP_PROTOCOL_NAME,
+                                          SSLTCP_PROTOCOL_NAME,
+                                          TLS_PROTOCOL_NAME};
+
+const char* ProtoToString(ProtocolType proto) {
+  return PROTO_NAMES[proto];
+}
+
+bool StringToProto(const char* value, ProtocolType* proto) {
+  for (size_t i = 0; i <= PROTO_LAST; ++i) {
+    if (_stricmp(PROTO_NAMES[i], value) == 0) {
+      *proto = static_cast<ProtocolType>(i);
+      return true;
+    }
+  }
+  return false;
+}
+
+// RFC 6544, TCP candidate encoding rules.
+const int DISCARD_PORT = 9;
+const char TCPTYPE_ACTIVE_STR[] = "active";
+const char TCPTYPE_PASSIVE_STR[] = "passive";
+const char TCPTYPE_SIMOPEN_STR[] = "so";
+
+// Foundation:  An arbitrary string that is the same for two candidates
+//   that have the same type, base IP address, protocol (UDP, TCP,
+//   etc.), and STUN or TURN server.  If any of these are different,
+//   then the foundation will be different.  Two candidate pairs with
+//   the same foundation pairs are likely to have similar network
+//   characteristics.  Foundations are used in the frozen algorithm.
+static std::string ComputeFoundation(const std::string& type,
+                                     const std::string& protocol,
+                                     const std::string& relay_protocol,
+                                     const rtc::SocketAddress& base_address) {
+  std::ostringstream ost;
+  ost << type << base_address.ipaddr().ToString() << protocol << relay_protocol;
+  return rtc::ToString<uint32_t>(rtc::ComputeCrc32(ost.str()));
+}
+
+CandidateStats::CandidateStats() = default;
+
+CandidateStats::CandidateStats(const CandidateStats&) = default;
+
+CandidateStats::CandidateStats(Candidate candidate) {
+  this->candidate = candidate;
+}
+
+CandidateStats::~CandidateStats() = default;
+
+ConnectionInfo::ConnectionInfo()
+    : best_connection(false),
+      writable(false),
+      receiving(false),
+      timeout(false),
+      new_connection(false),
+      rtt(0),
+      sent_total_bytes(0),
+      sent_bytes_second(0),
+      sent_discarded_packets(0),
+      sent_total_packets(0),
+      sent_ping_requests_total(0),
+      sent_ping_requests_before_first_response(0),
+      sent_ping_responses(0),
+      recv_total_bytes(0),
+      recv_bytes_second(0),
+      recv_ping_requests(0),
+      recv_ping_responses(0),
+      key(nullptr),
+      state(IceCandidatePairState::WAITING),
+      priority(0),
+      nominated(false),
+      total_round_trip_time_ms(0) {}
+
+ConnectionInfo::ConnectionInfo(const ConnectionInfo&) = default;
+
+ConnectionInfo::~ConnectionInfo() = default;
+
+Port::Port(rtc::Thread* thread,
+           const std::string& type,
+           rtc::PacketSocketFactory* factory,
+           rtc::Network* network,
+           const std::string& username_fragment,
+           const std::string& password)
+    : thread_(thread),
+      factory_(factory),
+      type_(type),
+      send_retransmit_count_attribute_(false),
+      network_(network),
+      min_port_(0),
+      max_port_(0),
+      component_(ICE_CANDIDATE_COMPONENT_DEFAULT),
+      generation_(0),
+      ice_username_fragment_(username_fragment),
+      password_(password),
+      timeout_delay_(kPortTimeoutDelay),
+      enable_port_packets_(false),
+      ice_role_(ICEROLE_UNKNOWN),
+      tiebreaker_(0),
+      shared_socket_(true) {
+  Construct();
+}
+
+Port::Port(rtc::Thread* thread,
+           const std::string& type,
+           rtc::PacketSocketFactory* factory,
+           rtc::Network* network,
+           const rtc::IPAddress& ip,
+           const std::string& username_fragment,
+           const std::string& password)
+    : Port(thread, type, factory, network, username_fragment, password) {}
+
+Port::Port(rtc::Thread* thread,
+           const std::string& type,
+           rtc::PacketSocketFactory* factory,
+           rtc::Network* network,
+           uint16_t min_port,
+           uint16_t max_port,
+           const std::string& username_fragment,
+           const std::string& password)
+    : thread_(thread),
+      factory_(factory),
+      type_(type),
+      send_retransmit_count_attribute_(false),
+      network_(network),
+      min_port_(min_port),
+      max_port_(max_port),
+      component_(ICE_CANDIDATE_COMPONENT_DEFAULT),
+      generation_(0),
+      ice_username_fragment_(username_fragment),
+      password_(password),
+      timeout_delay_(kPortTimeoutDelay),
+      enable_port_packets_(false),
+      ice_role_(ICEROLE_UNKNOWN),
+      tiebreaker_(0),
+      shared_socket_(false) {
+  RTC_DCHECK(factory_ != NULL);
+  Construct();
+}
+
+void Port::Construct() {
+  // TODO(pthatcher): Remove this old behavior once we're sure no one
+  // relies on it.  If the username_fragment and password are empty,
+  // we should just create one.
+  if (ice_username_fragment_.empty()) {
+    RTC_DCHECK(password_.empty());
+    ice_username_fragment_ = rtc::CreateRandomString(ICE_UFRAG_LENGTH);
+    password_ = rtc::CreateRandomString(ICE_PWD_LENGTH);
+  }
+  network_->SignalTypeChanged.connect(this, &Port::OnNetworkTypeChanged);
+  network_cost_ = network_->GetCost();
+
+  thread_->PostDelayed(RTC_FROM_HERE, timeout_delay_, this,
+                       MSG_DESTROY_IF_DEAD);
+  RTC_LOG(LS_INFO) << ToString()
+                   << ": Port created with network cost " << network_cost_;
+}
+
+Port::~Port() {
+  // Delete all of the remaining connections.  We copy the list up front
+  // because each deletion will cause it to be modified.
+
+  std::vector<Connection*> list;
+
+  AddressMap::iterator iter = connections_.begin();
+  while (iter != connections_.end()) {
+    list.push_back(iter->second);
+    ++iter;
+  }
+
+  for (uint32_t i = 0; i < list.size(); i++)
+    delete list[i];
+}
+
+const std::string& Port::Type() const {
+  return type_;
+}
+rtc::Network* Port::Network() const {
+  return network_;
+}
+
+IceRole Port::GetIceRole() const {
+  return ice_role_;
+}
+
+void Port::SetIceRole(IceRole role) {
+  ice_role_ = role;
+}
+
+void Port::SetIceTiebreaker(uint64_t tiebreaker) {
+  tiebreaker_ = tiebreaker;
+}
+uint64_t Port::IceTiebreaker() const {
+  return tiebreaker_;
+}
+
+bool Port::SharedSocket() const {
+  return shared_socket_;
+}
+
+void Port::SetIceParameters(int component,
+                            const std::string& username_fragment,
+                            const std::string& password) {
+  component_ = component;
+  ice_username_fragment_ = username_fragment;
+  password_ = password;
+  for (Candidate& c : candidates_) {
+    c.set_component(component);
+    c.set_username(username_fragment);
+    c.set_password(password);
+  }
+}
+
+const std::vector<Candidate>& Port::Candidates() const {
+  return candidates_;
+}
+
+Connection* Port::GetConnection(const rtc::SocketAddress& remote_addr) {
+  AddressMap::const_iterator iter = connections_.find(remote_addr);
+  if (iter != connections_.end())
+    return iter->second;
+  else
+    return NULL;
+}
+
+void Port::AddAddress(const rtc::SocketAddress& address,
+                      const rtc::SocketAddress& base_address,
+                      const rtc::SocketAddress& related_address,
+                      const std::string& protocol,
+                      const std::string& relay_protocol,
+                      const std::string& tcptype,
+                      const std::string& type,
+                      uint32_t type_preference,
+                      uint32_t relay_preference,
+                      bool final) {
+  AddAddress(address, base_address, related_address, protocol, relay_protocol,
+             tcptype, type, type_preference, relay_preference, "", final);
+}
+
+void Port::AddAddress(const rtc::SocketAddress& address,
+                      const rtc::SocketAddress& base_address,
+                      const rtc::SocketAddress& related_address,
+                      const std::string& protocol,
+                      const std::string& relay_protocol,
+                      const std::string& tcptype,
+                      const std::string& type,
+                      uint32_t type_preference,
+                      uint32_t relay_preference,
+                      const std::string& url,
+                      bool final) {
+  if (protocol == TCP_PROTOCOL_NAME && type == LOCAL_PORT_TYPE) {
+    RTC_DCHECK(!tcptype.empty());
+  }
+
+  std::string foundation =
+      ComputeFoundation(type, protocol, relay_protocol, base_address);
+  Candidate c(component_, protocol, address, 0U, username_fragment(), password_,
+              type, generation_, foundation, network_->id(), network_cost_);
+  c.set_priority(
+      c.GetPriority(type_preference, network_->preference(), relay_preference));
+  c.set_relay_protocol(relay_protocol);
+  c.set_tcptype(tcptype);
+  c.set_network_name(network_->name());
+  c.set_network_type(network_->type());
+  c.set_related_address(related_address);
+  c.set_url(url);
+  candidates_.push_back(c);
+  SignalCandidateReady(this, c);
+
+  if (final) {
+    SignalPortComplete(this);
+  }
+}
+
+void Port::AddOrReplaceConnection(Connection* conn) {
+  auto ret = connections_.insert(
+      std::make_pair(conn->remote_candidate().address(), conn));
+  // If there is a different connection on the same remote address, replace
+  // it with the new one and destroy the old one.
+  if (ret.second == false && ret.first->second != conn) {
+    RTC_LOG(LS_WARNING)
+        << ToString()
+        << ": A new connection was created on an existing remote address. "
+           "New remote candidate: "
+        << conn->remote_candidate().ToString();
+    ret.first->second->SignalDestroyed.disconnect(this);
+    ret.first->second->Destroy();
+    ret.first->second = conn;
+  }
+  conn->SignalDestroyed.connect(this, &Port::OnConnectionDestroyed);
+  SignalConnectionCreated(this, conn);
+}
+
+void Port::OnReadPacket(
+    const char* data, size_t size, const rtc::SocketAddress& addr,
+    ProtocolType proto) {
+  // If the user has enabled port packets, just hand this over.
+  if (enable_port_packets_) {
+    SignalReadPacket(this, data, size, addr);
+    return;
+  }
+
+  // If this is an authenticated STUN request, then signal unknown address and
+  // send back a proper binding response.
+  std::unique_ptr<IceMessage> msg;
+  std::string remote_username;
+  if (!GetStunMessage(data, size, addr, &msg, &remote_username)) {
+    RTC_LOG(LS_ERROR) << ToString()
+                      << ": Received non-STUN packet from unknown address: "
+                      << addr.ToSensitiveString();
+  } else if (!msg) {
+    // STUN message handled already
+  } else if (msg->type() == STUN_BINDING_REQUEST) {
+    RTC_LOG(LS_INFO) << "Received STUN ping id="
+                     << rtc::hex_encode(msg->transaction_id())
+                     << " from unknown address " << addr.ToSensitiveString();
+    // We need to signal an unknown address before we handle any role conflict
+    // below. Otherwise there would be no candidate pair and TURN entry created
+    // to send the error response in case of a role conflict.
+    SignalUnknownAddress(this, addr, proto, msg.get(), remote_username, false);
+    // Check for role conflicts.
+    if (!MaybeIceRoleConflict(addr, msg.get(), remote_username)) {
+      RTC_LOG(LS_INFO) << "Received conflicting role from the peer.";
+      return;
+    }
+  } else {
+    // NOTE(tschmelcher): STUN_BINDING_RESPONSE is benign. It occurs if we
+    // pruned a connection for this port while it had STUN requests in flight,
+    // because we then get back responses for them, which this code correctly
+    // does not handle.
+    if (msg->type() != STUN_BINDING_RESPONSE) {
+      RTC_LOG(LS_ERROR) << ToString()
+                        << ": Received unexpected STUN message type: "
+                        << msg->type() << " from unknown address: "
+                        << addr.ToSensitiveString();
+    }
+  }
+}
+
+void Port::OnReadyToSend() {
+  AddressMap::iterator iter = connections_.begin();
+  for (; iter != connections_.end(); ++iter) {
+    iter->second->OnReadyToSend();
+  }
+}
+
+size_t Port::AddPrflxCandidate(const Candidate& local) {
+  candidates_.push_back(local);
+  return (candidates_.size() - 1);
+}
+
+bool Port::GetStunMessage(const char* data,
+                          size_t size,
+                          const rtc::SocketAddress& addr,
+                          std::unique_ptr<IceMessage>* out_msg,
+                          std::string* out_username) {
+  // NOTE: This could clearly be optimized to avoid allocating any memory.
+  //       However, at the data rates we'll be looking at on the client side,
+  //       this probably isn't worth worrying about.
+  RTC_DCHECK(out_msg != NULL);
+  RTC_DCHECK(out_username != NULL);
+  out_username->clear();
+
+  // Don't bother parsing the packet if we can tell it's not STUN.
+  // In ICE mode, all STUN packets will have a valid fingerprint.
+  if (!StunMessage::ValidateFingerprint(data, size)) {
+    return false;
+  }
+
+  // Parse the request message.  If the packet is not a complete and correct
+  // STUN message, then ignore it.
+  std::unique_ptr<IceMessage> stun_msg(new IceMessage());
+  rtc::ByteBufferReader buf(data, size);
+  if (!stun_msg->Read(&buf) || (buf.Length() > 0)) {
+    return false;
+  }
+
+  if (stun_msg->type() == STUN_BINDING_REQUEST) {
+    // Check for the presence of USERNAME and MESSAGE-INTEGRITY (if ICE) first.
+    // If not present, fail with a 400 Bad Request.
+    if (!stun_msg->GetByteString(STUN_ATTR_USERNAME) ||
+        !stun_msg->GetByteString(STUN_ATTR_MESSAGE_INTEGRITY)) {
+      RTC_LOG(LS_ERROR) << ToString()
+                        << ": Received STUN request without username/M-I from: "
+                        << addr.ToSensitiveString();
+      SendBindingErrorResponse(stun_msg.get(), addr, STUN_ERROR_BAD_REQUEST,
+                               STUN_ERROR_REASON_BAD_REQUEST);
+      return true;
+    }
+
+    // If the username is bad or unknown, fail with a 401 Unauthorized.
+    std::string local_ufrag;
+    std::string remote_ufrag;
+    if (!ParseStunUsername(stun_msg.get(), &local_ufrag, &remote_ufrag) ||
+        local_ufrag != username_fragment()) {
+      RTC_LOG(LS_ERROR) << ToString()
+                        << ": Received STUN request with bad local username "
+                        << local_ufrag << " from " << addr.ToSensitiveString();
+      SendBindingErrorResponse(stun_msg.get(), addr, STUN_ERROR_UNAUTHORIZED,
+                               STUN_ERROR_REASON_UNAUTHORIZED);
+      return true;
+    }
+
+    // If ICE, and the MESSAGE-INTEGRITY is bad, fail with a 401 Unauthorized
+    if (!stun_msg->ValidateMessageIntegrity(data, size, password_)) {
+      RTC_LOG(LS_ERROR) << ToString()
+                        << ": Received STUN request with bad M-I from "
+                        << addr.ToSensitiveString()
+                        << ", password_=" << password_;
+      SendBindingErrorResponse(stun_msg.get(), addr, STUN_ERROR_UNAUTHORIZED,
+                               STUN_ERROR_REASON_UNAUTHORIZED);
+      return true;
+    }
+    out_username->assign(remote_ufrag);
+  } else if ((stun_msg->type() == STUN_BINDING_RESPONSE) ||
+             (stun_msg->type() == STUN_BINDING_ERROR_RESPONSE)) {
+    if (stun_msg->type() == STUN_BINDING_ERROR_RESPONSE) {
+      if (const StunErrorCodeAttribute* error_code = stun_msg->GetErrorCode()) {
+        RTC_LOG(LS_ERROR) << ToString()
+                          << ": Received STUN binding error: class="
+                          << error_code->eclass()
+                          << " number=" << error_code->number() << " reason='"
+                          << error_code->reason() << "' from "
+                          << addr.ToSensitiveString();
+        // Return message to allow error-specific processing
+      } else {
+        RTC_LOG(LS_ERROR)
+            << ToString()
+            << ": Received STUN binding error without a error code from "
+            << addr.ToSensitiveString();
+        return true;
+      }
+    }
+    // NOTE: Username should not be used in verifying response messages.
+    out_username->clear();
+  } else if (stun_msg->type() == STUN_BINDING_INDICATION) {
+    RTC_LOG(LS_VERBOSE) << ToString()
+                        << ": Received STUN binding indication: from "
+                        << addr.ToSensitiveString();
+    out_username->clear();
+    // No stun attributes will be verified, if it's stun indication message.
+    // Returning from end of the this method.
+  } else {
+    RTC_LOG(LS_ERROR) << ToString()
+                      << ": Received STUN packet with invalid type ("
+                      << stun_msg->type() << ") from "
+                      << addr.ToSensitiveString();
+    return true;
+  }
+
+  // Return the STUN message found.
+  *out_msg = std::move(stun_msg);
+  return true;
+}
+
+bool Port::IsCompatibleAddress(const rtc::SocketAddress& addr) {
+  // Get a representative IP for the Network this port is configured to use.
+  rtc::IPAddress ip = network_->GetBestIP();
+  // We use single-stack sockets, so families must match.
+  if (addr.family() != ip.family()) {
+    return false;
+  }
+  // Link-local IPv6 ports can only connect to other link-local IPv6 ports.
+  if (ip.family() == AF_INET6 &&
+      (IPIsLinkLocal(ip) != IPIsLinkLocal(addr.ipaddr()))) {
+    return false;
+  }
+  return true;
+}
+
+bool Port::ParseStunUsername(const StunMessage* stun_msg,
+                             std::string* local_ufrag,
+                             std::string* remote_ufrag) const {
+  // The packet must include a username that either begins or ends with our
+  // fragment.  It should begin with our fragment if it is a request and it
+  // should end with our fragment if it is a response.
+  local_ufrag->clear();
+  remote_ufrag->clear();
+  const StunByteStringAttribute* username_attr =
+        stun_msg->GetByteString(STUN_ATTR_USERNAME);
+  if (username_attr == NULL)
+    return false;
+
+  // RFRAG:LFRAG
+  const std::string username = username_attr->GetString();
+  size_t colon_pos = username.find(":");
+  if (colon_pos == std::string::npos) {
+    return false;
+  }
+
+  *local_ufrag = username.substr(0, colon_pos);
+  *remote_ufrag = username.substr(colon_pos + 1, username.size());
+  return true;
+}
+
+bool Port::MaybeIceRoleConflict(
+    const rtc::SocketAddress& addr, IceMessage* stun_msg,
+    const std::string& remote_ufrag) {
+  // Validate ICE_CONTROLLING or ICE_CONTROLLED attributes.
+  bool ret = true;
+  IceRole remote_ice_role = ICEROLE_UNKNOWN;
+  uint64_t remote_tiebreaker = 0;
+  const StunUInt64Attribute* stun_attr =
+      stun_msg->GetUInt64(STUN_ATTR_ICE_CONTROLLING);
+  if (stun_attr) {
+    remote_ice_role = ICEROLE_CONTROLLING;
+    remote_tiebreaker = stun_attr->value();
+  }
+
+  // If |remote_ufrag| is same as port local username fragment and
+  // tie breaker value received in the ping message matches port
+  // tiebreaker value this must be a loopback call.
+  // We will treat this as valid scenario.
+  if (remote_ice_role == ICEROLE_CONTROLLING &&
+      username_fragment() == remote_ufrag &&
+      remote_tiebreaker == IceTiebreaker()) {
+    return true;
+  }
+
+  stun_attr = stun_msg->GetUInt64(STUN_ATTR_ICE_CONTROLLED);
+  if (stun_attr) {
+    remote_ice_role = ICEROLE_CONTROLLED;
+    remote_tiebreaker = stun_attr->value();
+  }
+
+  switch (ice_role_) {
+    case ICEROLE_CONTROLLING:
+      if (ICEROLE_CONTROLLING == remote_ice_role) {
+        if (remote_tiebreaker >= tiebreaker_) {
+          SignalRoleConflict(this);
+        } else {
+          // Send Role Conflict (487) error response.
+          SendBindingErrorResponse(stun_msg, addr,
+              STUN_ERROR_ROLE_CONFLICT, STUN_ERROR_REASON_ROLE_CONFLICT);
+          ret = false;
+        }
+      }
+      break;
+    case ICEROLE_CONTROLLED:
+      if (ICEROLE_CONTROLLED == remote_ice_role) {
+        if (remote_tiebreaker < tiebreaker_) {
+          SignalRoleConflict(this);
+        } else {
+          // Send Role Conflict (487) error response.
+          SendBindingErrorResponse(stun_msg, addr,
+              STUN_ERROR_ROLE_CONFLICT, STUN_ERROR_REASON_ROLE_CONFLICT);
+          ret = false;
+        }
+      }
+      break;
+    default:
+      RTC_NOTREACHED();
+  }
+  return ret;
+}
+
+void Port::CreateStunUsername(const std::string& remote_username,
+                              std::string* stun_username_attr_str) const {
+  stun_username_attr_str->clear();
+  *stun_username_attr_str = remote_username;
+  stun_username_attr_str->append(":");
+  stun_username_attr_str->append(username_fragment());
+}
+
+bool Port::HandleIncomingPacket(rtc::AsyncPacketSocket* socket,
+                                const char* data,
+                                size_t size,
+                                const rtc::SocketAddress& remote_addr,
+                                const rtc::PacketTime& packet_time) {
+  RTC_NOTREACHED();
+  return false;
+}
+
+bool Port::CanHandleIncomingPacketsFrom(const rtc::SocketAddress&) const {
+  return false;
+}
+
+void Port::SendBindingResponse(StunMessage* request,
+                               const rtc::SocketAddress& addr) {
+  RTC_DCHECK(request->type() == STUN_BINDING_REQUEST);
+
+  // Retrieve the username from the request.
+  const StunByteStringAttribute* username_attr =
+      request->GetByteString(STUN_ATTR_USERNAME);
+  RTC_DCHECK(username_attr != NULL);
+  if (username_attr == NULL) {
+    // No valid username, skip the response.
+    return;
+  }
+
+  // Fill in the response message.
+  StunMessage response;
+  response.SetType(STUN_BINDING_RESPONSE);
+  response.SetTransactionID(request->transaction_id());
+  const StunUInt32Attribute* retransmit_attr =
+      request->GetUInt32(STUN_ATTR_RETRANSMIT_COUNT);
+  if (retransmit_attr) {
+    // Inherit the incoming retransmit value in the response so the other side
+    // can see our view of lost pings.
+    response.AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+        STUN_ATTR_RETRANSMIT_COUNT, retransmit_attr->value()));
+
+    if (retransmit_attr->value() > CONNECTION_WRITE_CONNECT_FAILURES) {
+      RTC_LOG(LS_INFO)
+          << ToString()
+          << ": Received a remote ping with high retransmit count: "
+          << retransmit_attr->value();
+    }
+  }
+
+  response.AddAttribute(rtc::MakeUnique<StunXorAddressAttribute>(
+      STUN_ATTR_XOR_MAPPED_ADDRESS, addr));
+  response.AddMessageIntegrity(password_);
+  response.AddFingerprint();
+
+  // Send the response message.
+  rtc::ByteBufferWriter buf;
+  response.Write(&buf);
+  rtc::PacketOptions options(DefaultDscpValue());
+  auto err = SendTo(buf.Data(), buf.Length(), addr, options, false);
+  if (err < 0) {
+    RTC_LOG(LS_ERROR) << ToString()
+                      << ": Failed to send STUN ping response, to="
+                      << addr.ToSensitiveString() << ", err=" << err
+                      << ", id=" << rtc::hex_encode(response.transaction_id());
+  } else {
+    // Log at LS_INFO if we send a stun ping response on an unwritable
+    // connection.
+    Connection* conn = GetConnection(addr);
+    rtc::LoggingSeverity sev = (conn && !conn->writable()) ?
+        rtc::LS_INFO : rtc::LS_VERBOSE;
+    RTC_LOG_V(sev) << ToString()
+                   << ": Sent STUN ping response, to="
+                   << addr.ToSensitiveString()
+                   << ", id=" << rtc::hex_encode(response.transaction_id());
+
+    conn->stats_.sent_ping_responses++;
+    conn->LogCandidatePairEvent(
+        webrtc::IceCandidatePairEventType::kCheckResponseSent);
+  }
+}
+
+void Port::SendBindingErrorResponse(StunMessage* request,
+                                    const rtc::SocketAddress& addr,
+                                    int error_code, const std::string& reason) {
+  RTC_DCHECK(request->type() == STUN_BINDING_REQUEST);
+
+  // Fill in the response message.
+  StunMessage response;
+  response.SetType(STUN_BINDING_ERROR_RESPONSE);
+  response.SetTransactionID(request->transaction_id());
+
+  // When doing GICE, we need to write out the error code incorrectly to
+  // maintain backwards compatiblility.
+  auto error_attr = StunAttribute::CreateErrorCode();
+  error_attr->SetCode(error_code);
+  error_attr->SetReason(reason);
+  response.AddAttribute(std::move(error_attr));
+
+  // Per Section 10.1.2, certain error cases don't get a MESSAGE-INTEGRITY,
+  // because we don't have enough information to determine the shared secret.
+  if (error_code != STUN_ERROR_BAD_REQUEST &&
+      error_code != STUN_ERROR_UNAUTHORIZED)
+    response.AddMessageIntegrity(password_);
+  response.AddFingerprint();
+
+  // Send the response message.
+  rtc::ByteBufferWriter buf;
+  response.Write(&buf);
+  rtc::PacketOptions options(DefaultDscpValue());
+  SendTo(buf.Data(), buf.Length(), addr, options, false);
+  RTC_LOG(LS_INFO) << ToString()
+                   << ": Sending STUN binding error: reason=" << reason
+                   << " to " << addr.ToSensitiveString();
+}
+
+void Port::KeepAliveUntilPruned() {
+  // If it is pruned, we won't bring it up again.
+  if (state_ == State::INIT) {
+    state_ = State::KEEP_ALIVE_UNTIL_PRUNED;
+  }
+}
+
+void Port::Prune() {
+  state_ = State::PRUNED;
+  thread_->Post(RTC_FROM_HERE, this, MSG_DESTROY_IF_DEAD);
+}
+
+void Port::OnMessage(rtc::Message *pmsg) {
+  RTC_DCHECK(pmsg->message_id == MSG_DESTROY_IF_DEAD);
+  bool dead =
+      (state_ == State::INIT || state_ == State::PRUNED) &&
+      connections_.empty() &&
+      rtc::TimeMillis() - last_time_all_connections_removed_ >= timeout_delay_;
+  if (dead) {
+    Destroy();
+  }
+}
+
+void Port::OnNetworkTypeChanged(const rtc::Network* network) {
+  RTC_DCHECK(network == network_);
+
+  UpdateNetworkCost();
+}
+
+std::string Port::ToString() const {
+  std::stringstream ss;
+  ss << "Port[" << std::hex << this << std::dec << ":" << content_name_ << ":"
+     << component_ << ":" << generation_ << ":" << type_ << ":"
+     << network_->ToString() << "]";
+  return ss.str();
+}
+
+// TODO(honghaiz): Make the network cost configurable from user setting.
+void Port::UpdateNetworkCost() {
+  uint16_t new_cost = network_->GetCost();
+  if (network_cost_ == new_cost) {
+    return;
+  }
+  RTC_LOG(LS_INFO) << "Network cost changed from " << network_cost_ << " to "
+                   << new_cost
+                   << ". Number of candidates created: " << candidates_.size()
+                   << ". Number of connections created: "
+                   << connections_.size();
+  network_cost_ = new_cost;
+  for (cricket::Candidate& candidate : candidates_) {
+    candidate.set_network_cost(network_cost_);
+  }
+  // Network cost change will affect the connection selection criteria.
+  // Signal the connection state change on each connection to force a
+  // re-sort in P2PTransportChannel.
+  for (auto kv : connections_) {
+    Connection* conn = kv.second;
+    conn->SignalStateChange(conn);
+  }
+}
+
+void Port::EnablePortPackets() {
+  enable_port_packets_ = true;
+}
+
+void Port::OnConnectionDestroyed(Connection* conn) {
+  AddressMap::iterator iter =
+      connections_.find(conn->remote_candidate().address());
+  RTC_DCHECK(iter != connections_.end());
+  connections_.erase(iter);
+  HandleConnectionDestroyed(conn);
+
+  // Ports time out after all connections fail if it is not marked as
+  // "keep alive until pruned."
+  // Note: If a new connection is added after this message is posted, but it
+  // fails and is removed before kPortTimeoutDelay, then this message will
+  // not cause the Port to be destroyed.
+  if (connections_.empty()) {
+    last_time_all_connections_removed_ = rtc::TimeMillis();
+    thread_->PostDelayed(RTC_FROM_HERE, timeout_delay_, this,
+                         MSG_DESTROY_IF_DEAD);
+  }
+}
+
+void Port::Destroy() {
+  RTC_DCHECK(connections_.empty());
+  RTC_LOG(LS_INFO) << ToString() << ": Port deleted";
+  SignalDestroyed(this);
+  delete this;
+}
+
+const std::string Port::username_fragment() const {
+  return ice_username_fragment_;
+}
+
+// A ConnectionRequest is a simple STUN ping used to determine writability.
+class ConnectionRequest : public StunRequest {
+ public:
+  explicit ConnectionRequest(Connection* connection)
+      : StunRequest(new IceMessage()),
+        connection_(connection) {
+  }
+
+  void Prepare(StunMessage* request) override {
+    request->SetType(STUN_BINDING_REQUEST);
+    std::string username;
+    connection_->port()->CreateStunUsername(
+        connection_->remote_candidate().username(), &username);
+    request->AddAttribute(
+        rtc::MakeUnique<StunByteStringAttribute>(STUN_ATTR_USERNAME, username));
+
+    // connection_ already holds this ping, so subtract one from count.
+    if (connection_->port()->send_retransmit_count_attribute()) {
+      request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+          STUN_ATTR_RETRANSMIT_COUNT,
+          static_cast<uint32_t>(connection_->pings_since_last_response_.size() -
+                                1)));
+    }
+    uint32_t network_info = connection_->port()->Network()->id();
+    network_info = (network_info << 16) | connection_->port()->network_cost();
+    request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+        STUN_ATTR_NETWORK_INFO, network_info));
+
+    // Adding ICE_CONTROLLED or ICE_CONTROLLING attribute based on the role.
+    if (connection_->port()->GetIceRole() == ICEROLE_CONTROLLING) {
+      request->AddAttribute(rtc::MakeUnique<StunUInt64Attribute>(
+          STUN_ATTR_ICE_CONTROLLING, connection_->port()->IceTiebreaker()));
+      // We should have either USE_CANDIDATE attribute or ICE_NOMINATION
+      // attribute but not both. That was enforced in p2ptransportchannel.
+      if (connection_->use_candidate_attr()) {
+        request->AddAttribute(
+            rtc::MakeUnique<StunByteStringAttribute>(STUN_ATTR_USE_CANDIDATE));
+      }
+      if (connection_->nomination() &&
+          connection_->nomination() != connection_->acked_nomination()) {
+        request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+            STUN_ATTR_NOMINATION, connection_->nomination()));
+      }
+    } else if (connection_->port()->GetIceRole() == ICEROLE_CONTROLLED) {
+      request->AddAttribute(rtc::MakeUnique<StunUInt64Attribute>(
+          STUN_ATTR_ICE_CONTROLLED, connection_->port()->IceTiebreaker()));
+    } else {
+      RTC_NOTREACHED();
+    }
+
+    // Adding PRIORITY Attribute.
+    // Changing the type preference to Peer Reflexive and local preference
+    // and component id information is unchanged from the original priority.
+    // priority = (2^24)*(type preference) +
+    //           (2^8)*(local preference) +
+    //           (2^0)*(256 - component ID)
+    uint32_t type_preference =
+        (connection_->local_candidate().protocol() == TCP_PROTOCOL_NAME)
+            ? ICE_TYPE_PREFERENCE_PRFLX_TCP
+            : ICE_TYPE_PREFERENCE_PRFLX;
+    uint32_t prflx_priority =
+        type_preference << 24 |
+        (connection_->local_candidate().priority() & 0x00FFFFFF);
+    request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+        STUN_ATTR_PRIORITY, prflx_priority));
+
+    // Adding Message Integrity attribute.
+    request->AddMessageIntegrity(connection_->remote_candidate().password());
+    // Adding Fingerprint.
+    request->AddFingerprint();
+  }
+
+  void OnResponse(StunMessage* response) override {
+    connection_->OnConnectionRequestResponse(this, response);
+  }
+
+  void OnErrorResponse(StunMessage* response) override {
+    connection_->OnConnectionRequestErrorResponse(this, response);
+  }
+
+  void OnTimeout() override {
+    connection_->OnConnectionRequestTimeout(this);
+  }
+
+  void OnSent() override {
+    connection_->OnConnectionRequestSent(this);
+    // Each request is sent only once.  After a single delay , the request will
+    // time out.
+    timeout_ = true;
+  }
+
+  int resend_delay() override {
+    return CONNECTION_RESPONSE_TIMEOUT;
+  }
+
+ private:
+  Connection* connection_;
+};
+
+//
+// Connection
+//
+
+Connection::Connection(Port* port,
+                       size_t index,
+                       const Candidate& remote_candidate)
+    : port_(port),
+      local_candidate_index_(index),
+      remote_candidate_(remote_candidate),
+      recv_rate_tracker_(100, 10u),
+      send_rate_tracker_(100, 10u),
+      write_state_(STATE_WRITE_INIT),
+      receiving_(false),
+      connected_(true),
+      pruned_(false),
+      use_candidate_attr_(false),
+      remote_ice_mode_(ICEMODE_FULL),
+      requests_(port->thread()),
+      rtt_(DEFAULT_RTT),
+      last_ping_sent_(0),
+      last_ping_received_(0),
+      last_data_received_(0),
+      last_ping_response_received_(0),
+      packet_loss_estimator_(kConsiderPacketLostAfter, kForgetPacketAfter),
+      reported_(false),
+      state_(IceCandidatePairState::WAITING),
+      time_created_ms_(rtc::TimeMillis()) {
+  // All of our connections start in WAITING state.
+  // TODO(mallinath) - Start connections from STATE_FROZEN.
+  // Wire up to send stun packets
+  requests_.SignalSendPacket.connect(this, &Connection::OnSendStunPacket);
+  hash_ = static_cast<uint32_t>(std::hash<std::string>{}(ToString()));
+  RTC_LOG(LS_INFO) << ToString() << ": Connection created";
+}
+
+Connection::~Connection() {
+}
+
+const Candidate& Connection::local_candidate() const {
+  RTC_DCHECK(local_candidate_index_ < port_->Candidates().size());
+  return port_->Candidates()[local_candidate_index_];
+}
+
+const Candidate& Connection::remote_candidate() const {
+  return remote_candidate_;
+}
+
+uint64_t Connection::priority() const {
+  uint64_t priority = 0;
+  // RFC 5245 - 5.7.2.  Computing Pair Priority and Ordering Pairs
+  // Let G be the priority for the candidate provided by the controlling
+  // agent.  Let D be the priority for the candidate provided by the
+  // controlled agent.
+  // pair priority = 2^32*MIN(G,D) + 2*MAX(G,D) + (G>D?1:0)
+  IceRole role = port_->GetIceRole();
+  if (role != ICEROLE_UNKNOWN) {
+    uint32_t g = 0;
+    uint32_t d = 0;
+    if (role == ICEROLE_CONTROLLING) {
+      g = local_candidate().priority();
+      d = remote_candidate_.priority();
+    } else {
+      g = remote_candidate_.priority();
+      d = local_candidate().priority();
+    }
+    priority = std::min(g, d);
+    priority = priority << 32;
+    priority += 2 * std::max(g, d) + (g > d ? 1 : 0);
+  }
+  return priority;
+}
+
+void Connection::set_write_state(WriteState value) {
+  WriteState old_value = write_state_;
+  write_state_ = value;
+  if (value != old_value) {
+    RTC_LOG(LS_VERBOSE) << ToString()
+                        << ": set_write_state from: " << old_value << " to "
+                        << value;
+    SignalStateChange(this);
+  }
+}
+
+void Connection::UpdateReceiving(int64_t now) {
+  bool receiving =
+      last_received() > 0 && now <= last_received() + receiving_timeout();
+  if (receiving_ == receiving) {
+    return;
+  }
+  RTC_LOG(LS_VERBOSE) << ToString() << ": set_receiving to "
+                      << receiving;
+  receiving_ = receiving;
+  receiving_unchanged_since_ = now;
+  SignalStateChange(this);
+}
+
+void Connection::set_state(IceCandidatePairState state) {
+  IceCandidatePairState old_state = state_;
+  state_ = state;
+  if (state != old_state) {
+    RTC_LOG(LS_VERBOSE) << ToString() << ": set_state";
+  }
+}
+
+void Connection::set_connected(bool value) {
+  bool old_value = connected_;
+  connected_ = value;
+  if (value != old_value) {
+    RTC_LOG(LS_VERBOSE) << ToString()
+                        << ": Change connected_ to " << value;
+    SignalStateChange(this);
+  }
+}
+
+void Connection::set_use_candidate_attr(bool enable) {
+  use_candidate_attr_ = enable;
+}
+
+int Connection::unwritable_timeout() const {
+  return unwritable_timeout_.value_or(CONNECTION_WRITE_CONNECT_TIMEOUT);
+}
+
+int Connection::unwritable_min_checks() const {
+  return unwritable_min_checks_.value_or(CONNECTION_WRITE_CONNECT_FAILURES);
+}
+
+int Connection::receiving_timeout() const {
+  return receiving_timeout_.value_or(WEAK_CONNECTION_RECEIVE_TIMEOUT);
+}
+
+void Connection::OnSendStunPacket(const void* data, size_t size,
+                                  StunRequest* req) {
+  rtc::PacketOptions options(port_->DefaultDscpValue());
+  auto err = port_->SendTo(
+      data, size, remote_candidate_.address(), options, false);
+  if (err < 0) {
+    RTC_LOG(LS_WARNING) << ToString()
+                        << ": Failed to send STUN ping "
+                           " err="
+                        << err << " id=" << rtc::hex_encode(req->id());
+  }
+}
+
+void Connection::OnReadPacket(
+  const char* data, size_t size, const rtc::PacketTime& packet_time) {
+  std::unique_ptr<IceMessage> msg;
+  std::string remote_ufrag;
+  const rtc::SocketAddress& addr(remote_candidate_.address());
+  if (!port_->GetStunMessage(data, size, addr, &msg, &remote_ufrag)) {
+    // The packet did not parse as a valid STUN message
+    // This is a data packet, pass it along.
+    last_data_received_ = rtc::TimeMillis();
+    UpdateReceiving(last_data_received_);
+    recv_rate_tracker_.AddSamples(size);
+    SignalReadPacket(this, data, size, packet_time);
+
+    // If timed out sending writability checks, start up again
+    if (!pruned_ && (write_state_ == STATE_WRITE_TIMEOUT)) {
+      RTC_LOG(LS_WARNING)
+          << "Received a data packet on a timed-out Connection. "
+             "Resetting state to STATE_WRITE_INIT.";
+      set_write_state(STATE_WRITE_INIT);
+    }
+  } else if (!msg) {
+    // The packet was STUN, but failed a check and was handled internally.
+  } else {
+    // The packet is STUN and passed the Port checks.
+    // Perform our own checks to ensure this packet is valid.
+    // If this is a STUN request, then update the receiving bit and respond.
+    // If this is a STUN response, then update the writable bit.
+    // Log at LS_INFO if we receive a ping on an unwritable connection.
+    rtc::LoggingSeverity sev = (!writable() ? rtc::LS_INFO : rtc::LS_VERBOSE);
+    switch (msg->type()) {
+      case STUN_BINDING_REQUEST:
+        RTC_LOG_V(sev) << ToString()
+                       << ": Received STUN ping, id="
+                       << rtc::hex_encode(msg->transaction_id());
+
+        if (remote_ufrag == remote_candidate_.username()) {
+          HandleBindingRequest(msg.get());
+        } else {
+          // The packet had the right local username, but the remote username
+          // was not the right one for the remote address.
+          RTC_LOG(LS_ERROR)
+              << ToString()
+              << ": Received STUN request with bad remote username "
+              << remote_ufrag;
+          port_->SendBindingErrorResponse(msg.get(), addr,
+                                          STUN_ERROR_UNAUTHORIZED,
+                                          STUN_ERROR_REASON_UNAUTHORIZED);
+        }
+        break;
+
+      // Response from remote peer. Does it match request sent?
+      // This doesn't just check, it makes callbacks if transaction
+      // id's match.
+      case STUN_BINDING_RESPONSE:
+      case STUN_BINDING_ERROR_RESPONSE:
+        if (msg->ValidateMessageIntegrity(
+                data, size, remote_candidate().password())) {
+          requests_.CheckResponse(msg.get());
+        }
+        // Otherwise silently discard the response message.
+        break;
+
+      // Remote end point sent an STUN indication instead of regular binding
+      // request. In this case |last_ping_received_| will be updated but no
+      // response will be sent.
+      case STUN_BINDING_INDICATION:
+        ReceivedPing();
+        break;
+
+      default:
+        RTC_NOTREACHED();
+        break;
+    }
+  }
+}
+
+void Connection::HandleBindingRequest(IceMessage* msg) {
+  // This connection should now be receiving.
+  ReceivedPing();
+
+  const rtc::SocketAddress& remote_addr = remote_candidate_.address();
+  const std::string& remote_ufrag = remote_candidate_.username();
+  // Check for role conflicts.
+  if (!port_->MaybeIceRoleConflict(remote_addr, msg, remote_ufrag)) {
+    // Received conflicting role from the peer.
+    RTC_LOG(LS_INFO) << "Received conflicting role from the peer.";
+    return;
+  }
+
+  stats_.recv_ping_requests++;
+  LogCandidatePairEvent(webrtc::IceCandidatePairEventType::kCheckReceived);
+
+  // This is a validated stun request from remote peer.
+  port_->SendBindingResponse(msg, remote_addr);
+
+  // If it timed out on writing check, start up again
+  if (!pruned_ && write_state_ == STATE_WRITE_TIMEOUT) {
+    set_write_state(STATE_WRITE_INIT);
+  }
+
+  if (port_->GetIceRole() == ICEROLE_CONTROLLED) {
+    const StunUInt32Attribute* nomination_attr =
+        msg->GetUInt32(STUN_ATTR_NOMINATION);
+    uint32_t nomination = 0;
+    if (nomination_attr) {
+      nomination = nomination_attr->value();
+      if (nomination == 0) {
+        RTC_LOG(LS_ERROR) << "Invalid nomination: " << nomination;
+      }
+    } else {
+      const StunByteStringAttribute* use_candidate_attr =
+          msg->GetByteString(STUN_ATTR_USE_CANDIDATE);
+      if (use_candidate_attr) {
+        nomination = 1;
+      }
+    }
+    // We don't un-nominate a connection, so we only keep a larger nomination.
+    if (nomination > remote_nomination_) {
+      set_remote_nomination(nomination);
+      SignalNominated(this);
+    }
+  }
+  // Set the remote cost if the network_info attribute is available.
+  // Note: If packets are re-ordered, we may get incorrect network cost
+  // temporarily, but it should get the correct value shortly after that.
+  const StunUInt32Attribute* network_attr =
+      msg->GetUInt32(STUN_ATTR_NETWORK_INFO);
+  if (network_attr) {
+    uint32_t network_info = network_attr->value();
+    uint16_t network_cost = static_cast<uint16_t>(network_info);
+    if (network_cost != remote_candidate_.network_cost()) {
+      remote_candidate_.set_network_cost(network_cost);
+      // Network cost change will affect the connection ranking, so signal
+      // state change to force a re-sort in P2PTransportChannel.
+      SignalStateChange(this);
+    }
+  }
+}
+
+void Connection::OnReadyToSend() {
+  SignalReadyToSend(this);
+}
+
+void Connection::Prune() {
+  if (!pruned_ || active()) {
+    RTC_LOG(LS_INFO) << ToString() << ": Connection pruned";
+    pruned_ = true;
+    requests_.Clear();
+    set_write_state(STATE_WRITE_TIMEOUT);
+  }
+}
+
+void Connection::Destroy() {
+  // TODO(deadbeef, nisse): This may leak if an application closes a
+  // PeerConnection and then quickly destroys the PeerConnectionFactory (along
+  // with the networking thread on which this message is posted). Also affects
+  // tests, with a workaround in
+  // AutoSocketServerThread::~AutoSocketServerThread.
+  RTC_LOG(LS_VERBOSE) << ToString()
+                      << ": Connection destroyed";
+  port_->thread()->Post(RTC_FROM_HERE, this, MSG_DELETE);
+  LogCandidatePairEvent(webrtc::IceCandidatePairEventType::kDestroyed);
+}
+
+void Connection::FailAndDestroy() {
+  set_state(IceCandidatePairState::FAILED);
+  Destroy();
+}
+
+void Connection::FailAndPrune() {
+  set_state(IceCandidatePairState::FAILED);
+  Prune();
+}
+
+void Connection::PrintPingsSinceLastResponse(std::string* s, size_t max) {
+  std::ostringstream oss;
+  oss << std::boolalpha;
+  if (pings_since_last_response_.size() > max) {
+    for (size_t i = 0; i < max; i++) {
+      const SentPing& ping = pings_since_last_response_[i];
+      oss << rtc::hex_encode(ping.id) << " ";
+    }
+    oss << "... " << (pings_since_last_response_.size() - max) << " more";
+  } else {
+    for (const SentPing& ping : pings_since_last_response_) {
+      oss << rtc::hex_encode(ping.id) << " ";
+    }
+  }
+  *s = oss.str();
+}
+
+void Connection::UpdateState(int64_t now) {
+  int rtt = ConservativeRTTEstimate(rtt_);
+
+  if (RTC_LOG_CHECK_LEVEL(LS_VERBOSE)) {
+    std::string pings;
+    PrintPingsSinceLastResponse(&pings, 5);
+    RTC_LOG(LS_VERBOSE) << ToString()
+                        << ": UpdateState()"
+                           ", ms since last received response="
+                        << now - last_ping_response_received_
+                        << ", ms since last received data="
+                        << now - last_data_received_ << ", rtt=" << rtt
+                        << ", pings_since_last_response=" << pings;
+  }
+
+  // Check the writable state.  (The order of these checks is important.)
+  //
+  // Before becoming unwritable, we allow for a fixed number of pings to fail
+  // (i.e., receive no response).  We also have to give the response time to
+  // get back, so we include a conservative estimate of this.
+  //
+  // Before timing out writability, we give a fixed amount of time.  This is to
+  // allow for changes in network conditions.
+
+  if ((write_state_ == STATE_WRITABLE) &&
+      TooManyFailures(pings_since_last_response_, unwritable_min_checks(), rtt,
+                      now) &&
+      TooLongWithoutResponse(pings_since_last_response_, unwritable_timeout(),
+                             now)) {
+    uint32_t max_pings = unwritable_min_checks();
+    RTC_LOG(LS_INFO) << ToString() << ": Unwritable after "
+                     << max_pings << " ping failures and "
+                     << now - pings_since_last_response_[0].sent_time
+                     << " ms without a response,"
+                        " ms since last received ping="
+                     << now - last_ping_received_
+                     << " ms since last received data="
+                     << now - last_data_received_ << " rtt=" << rtt;
+    set_write_state(STATE_WRITE_UNRELIABLE);
+  }
+  if ((write_state_ == STATE_WRITE_UNRELIABLE ||
+       write_state_ == STATE_WRITE_INIT) &&
+      TooLongWithoutResponse(pings_since_last_response_,
+                             CONNECTION_WRITE_TIMEOUT,
+                             now)) {
+    RTC_LOG(LS_INFO) << ToString() << ": Timed out after "
+                     << now - pings_since_last_response_[0].sent_time
+                     << " ms without a response, rtt=" << rtt;
+    set_write_state(STATE_WRITE_TIMEOUT);
+  }
+
+  // Update the receiving state.
+  UpdateReceiving(now);
+  if (dead(now)) {
+    Destroy();
+  }
+}
+
+void Connection::Ping(int64_t now) {
+  last_ping_sent_ = now;
+  ConnectionRequest *req = new ConnectionRequest(this);
+  // If not using renomination, we use "1" to mean "nominated" and "0" to mean
+  // "not nominated". If using renomination, values greater than 1 are used for
+  // re-nominated pairs.
+  int nomination = use_candidate_attr_ ? 1 : 0;
+  if (nomination_ > 0) {
+    nomination = nomination_;
+  }
+  pings_since_last_response_.push_back(SentPing(req->id(), now, nomination));
+  packet_loss_estimator_.ExpectResponse(req->id(), now);
+  RTC_LOG(LS_VERBOSE) << ToString()
+                      << ": Sending STUN ping, id="
+                      << rtc::hex_encode(req->id())
+                      << ", nomination=" << nomination_;
+  requests_.Send(req);
+  state_ = IceCandidatePairState::IN_PROGRESS;
+  num_pings_sent_++;
+}
+
+void Connection::ReceivedPing() {
+  last_ping_received_ = rtc::TimeMillis();
+  UpdateReceiving(last_ping_received_);
+}
+
+void Connection::ReceivedPingResponse(int rtt, const std::string& request_id) {
+  RTC_DCHECK_GE(rtt, 0);
+  // We've already validated that this is a STUN binding response with
+  // the correct local and remote username for this connection.
+  // So if we're not already, become writable. We may be bringing a pruned
+  // connection back to life, but if we don't really want it, we can always
+  // prune it again.
+  auto iter = std::find_if(
+      pings_since_last_response_.begin(), pings_since_last_response_.end(),
+      [request_id](const SentPing& ping) { return ping.id == request_id; });
+  if (iter != pings_since_last_response_.end() &&
+      iter->nomination > acked_nomination_) {
+    acked_nomination_ = iter->nomination;
+  }
+
+  total_round_trip_time_ms_ += rtt;
+  current_round_trip_time_ms_ = static_cast<uint32_t>(rtt);
+
+  pings_since_last_response_.clear();
+  last_ping_response_received_ = rtc::TimeMillis();
+  UpdateReceiving(last_ping_response_received_);
+  set_write_state(STATE_WRITABLE);
+  set_state(IceCandidatePairState::SUCCEEDED);
+  if (rtt_samples_ > 0) {
+    rtt_ = rtc::GetNextMovingAverage(rtt_, rtt, RTT_RATIO);
+  } else {
+    rtt_ = rtt;
+  }
+  rtt_samples_++;
+}
+
+bool Connection::dead(int64_t now) const {
+  if (last_received() > 0) {
+    // If it has ever received anything, we keep it alive until it hasn't
+    // received anything for DEAD_CONNECTION_RECEIVE_TIMEOUT. This covers the
+    // normal case of a successfully used connection that stops working. This
+    // also allows a remote peer to continue pinging over a locally inactive
+    // (pruned) connection.
+    return (now > (last_received() + DEAD_CONNECTION_RECEIVE_TIMEOUT));
+  }
+
+  if (active()) {
+    // If it has never received anything, keep it alive as long as it is
+    // actively pinging and not pruned. Otherwise, the connection might be
+    // deleted before it has a chance to ping. This is the normal case for a
+    // new connection that is pinging but hasn't received anything yet.
+    return false;
+  }
+
+  // If it has never received anything and is not actively pinging (pruned), we
+  // keep it around for at least MIN_CONNECTION_LIFETIME to prevent connections
+  // from being pruned too quickly during a network change event when two
+  // networks would be up simultaneously but only for a brief period.
+  return now > (time_created_ms_ + MIN_CONNECTION_LIFETIME);
+}
+
+bool Connection::stable(int64_t now) const {
+  // A connection is stable if it's RTT has converged and it isn't missing any
+  // responses.  We should send pings at a higher rate until the RTT converges
+  // and whenever a ping response is missing (so that we can detect
+  // unwritability faster)
+  return rtt_converged() && !missing_responses(now);
+}
+
+std::string Connection::ToDebugId() const {
+  std::stringstream ss;
+  ss << std::hex << this;
+  return ss.str();
+}
+
+uint32_t Connection::ComputeNetworkCost() const {
+  // TODO(honghaiz): Will add rtt as part of the network cost.
+  return port()->network_cost() + remote_candidate_.network_cost();
+}
+
+std::string Connection::ToString() const {
+  const char CONNECT_STATE_ABBREV[2] = {
+    '-',  // not connected (false)
+    'C',  // connected (true)
+  };
+  const char RECEIVE_STATE_ABBREV[2] = {
+    '-',  // not receiving (false)
+    'R',  // receiving (true)
+  };
+  const char WRITE_STATE_ABBREV[4] = {
+    'W',  // STATE_WRITABLE
+    'w',  // STATE_WRITE_UNRELIABLE
+    '-',  // STATE_WRITE_INIT
+    'x',  // STATE_WRITE_TIMEOUT
+  };
+  const std::string ICESTATE[4] = {
+    "W",  // STATE_WAITING
+    "I",  // STATE_INPROGRESS
+    "S",  // STATE_SUCCEEDED
+    "F"   // STATE_FAILED
+  };
+  const Candidate& local = local_candidate();
+  const Candidate& remote = remote_candidate();
+  std::stringstream ss;
+  ss << "Conn[" << ToDebugId() << ":" << port_->content_name() << ":"
+     << local.id() << ":" << local.component() << ":" << local.generation()
+     << ":" << local.type() << ":" << local.protocol() << ":"
+     << local.address().ToSensitiveString() << "->" << remote.id() << ":"
+     << remote.component() << ":" << remote.priority() << ":" << remote.type()
+     << ":" << remote.protocol() << ":" << remote.address().ToSensitiveString()
+     << "|" << CONNECT_STATE_ABBREV[connected()]
+     << RECEIVE_STATE_ABBREV[receiving()] << WRITE_STATE_ABBREV[write_state()]
+     << ICESTATE[static_cast<int>(state())] << "|" << remote_nomination() << "|"
+     << nomination() << "|" << priority() << "|";
+  if (rtt_ < DEFAULT_RTT) {
+    ss << rtt_ << "]";
+  } else {
+    ss << "-]";
+  }
+  return ss.str();
+}
+
+std::string Connection::ToSensitiveString() const {
+  return ToString();
+}
+
+const webrtc::IceCandidatePairDescription& Connection::ToLogDescription() {
+  if (log_description_.has_value()) {
+    return log_description_.value();
+  }
+  const Candidate& local = local_candidate();
+  const Candidate& remote = remote_candidate();
+  const rtc::Network* network = port()->Network();
+  log_description_ = webrtc::IceCandidatePairDescription();
+  log_description_->local_candidate_type =
+      GetCandidateTypeByString(local.type());
+  log_description_->local_relay_protocol =
+      GetProtocolByString(local.relay_protocol());
+  log_description_->local_network_type = ConvertNetworkType(network->type());
+  log_description_->local_address_family =
+      GetAddressFamilyByInt(local.address().family());
+  log_description_->remote_candidate_type =
+      GetCandidateTypeByString(remote.type());
+  log_description_->remote_address_family =
+      GetAddressFamilyByInt(remote.address().family());
+  log_description_->candidate_pair_protocol =
+      GetProtocolByString(local.protocol());
+  return log_description_.value();
+}
+
+void Connection::LogCandidatePairEvent(webrtc::IceCandidatePairEventType type) {
+  if (ice_event_log_ == nullptr) {
+    return;
+  }
+  ice_event_log_->LogCandidatePairEvent(type, hash(), ToLogDescription());
+}
+
+void Connection::OnConnectionRequestResponse(ConnectionRequest* request,
+                                             StunMessage* response) {
+  // Log at LS_INFO if we receive a ping response on an unwritable
+  // connection.
+  rtc::LoggingSeverity sev = !writable() ? rtc::LS_INFO : rtc::LS_VERBOSE;
+
+  int rtt = request->Elapsed();
+
+  if (RTC_LOG_CHECK_LEVEL_V(sev)) {
+    std::string pings;
+    PrintPingsSinceLastResponse(&pings, 5);
+    RTC_LOG_V(sev) << ToString()
+                   << ": Received STUN ping response, id="
+                   << rtc::hex_encode(request->id())
+                   << ", code=0"  // Makes logging easier to parse.
+                      ", rtt="
+                   << rtt << ", pings_since_last_response=" << pings;
+  }
+  ReceivedPingResponse(rtt, request->id());
+
+  int64_t time_received = rtc::TimeMillis();
+  packet_loss_estimator_.ReceivedResponse(request->id(), time_received);
+
+  stats_.recv_ping_responses++;
+  LogCandidatePairEvent(
+      webrtc::IceCandidatePairEventType::kCheckResponseReceived);
+
+  MaybeUpdateLocalCandidate(request, response);
+}
+
+void Connection::OnConnectionRequestErrorResponse(ConnectionRequest* request,
+                                                  StunMessage* response) {
+  int error_code = response->GetErrorCodeValue();
+  RTC_LOG(LS_WARNING) << ToString()
+                      << ": Received STUN error response id="
+                      << rtc::hex_encode(request->id())
+                      << " code=" << error_code
+                      << " rtt=" << request->Elapsed();
+
+  if (error_code == STUN_ERROR_UNKNOWN_ATTRIBUTE ||
+      error_code == STUN_ERROR_SERVER_ERROR ||
+      error_code == STUN_ERROR_UNAUTHORIZED) {
+    // Recoverable error, retry
+  } else if (error_code == STUN_ERROR_STALE_CREDENTIALS) {
+    // Race failure, retry
+  } else if (error_code == STUN_ERROR_ROLE_CONFLICT) {
+    HandleRoleConflictFromPeer();
+  } else {
+    // This is not a valid connection.
+    RTC_LOG(LS_ERROR) << ToString()
+                      << ": Received STUN error response, code=" << error_code
+                      << "; killing connection";
+    FailAndDestroy();
+  }
+}
+
+void Connection::OnConnectionRequestTimeout(ConnectionRequest* request) {
+  // Log at LS_INFO if we miss a ping on a writable connection.
+  rtc::LoggingSeverity sev = writable() ? rtc::LS_INFO : rtc::LS_VERBOSE;
+  RTC_LOG_V(sev) << ToString() << ": Timing-out STUN ping "
+                 << rtc::hex_encode(request->id()) << " after "
+                 << request->Elapsed() << " ms";
+}
+
+void Connection::OnConnectionRequestSent(ConnectionRequest* request) {
+  // Log at LS_INFO if we send a ping on an unwritable connection.
+  rtc::LoggingSeverity sev = !writable() ? rtc::LS_INFO : rtc::LS_VERBOSE;
+  RTC_LOG_V(sev) << ToString()
+                 << ": Sent STUN ping, id=" << rtc::hex_encode(request->id())
+                 << ", use_candidate=" << use_candidate_attr()
+                 << ", nomination=" << nomination();
+  stats_.sent_ping_requests_total++;
+  LogCandidatePairEvent(webrtc::IceCandidatePairEventType::kCheckSent);
+  if (stats_.recv_ping_responses == 0) {
+    stats_.sent_ping_requests_before_first_response++;
+  }
+}
+
+void Connection::HandleRoleConflictFromPeer() {
+  port_->SignalRoleConflict(port_);
+}
+
+void Connection::MaybeSetRemoteIceParametersAndGeneration(
+    const IceParameters& ice_params,
+    int generation) {
+  if (remote_candidate_.username() == ice_params.ufrag &&
+      remote_candidate_.password().empty()) {
+    remote_candidate_.set_password(ice_params.pwd);
+  }
+  // TODO(deadbeef): A value of '0' for the generation is used for both
+  // generation 0 and "generation unknown". It should be changed to an
+  // rtc::Optional to fix this.
+  if (remote_candidate_.username() == ice_params.ufrag &&
+      remote_candidate_.password() == ice_params.pwd &&
+      remote_candidate_.generation() == 0) {
+    remote_candidate_.set_generation(generation);
+  }
+}
+
+void Connection::MaybeUpdatePeerReflexiveCandidate(
+    const Candidate& new_candidate) {
+  if (remote_candidate_.type() == PRFLX_PORT_TYPE &&
+      new_candidate.type() != PRFLX_PORT_TYPE &&
+      remote_candidate_.protocol() == new_candidate.protocol() &&
+      remote_candidate_.address() == new_candidate.address() &&
+      remote_candidate_.username() == new_candidate.username() &&
+      remote_candidate_.password() == new_candidate.password() &&
+      remote_candidate_.generation() == new_candidate.generation()) {
+    remote_candidate_ = new_candidate;
+  }
+}
+
+void Connection::OnMessage(rtc::Message *pmsg) {
+  RTC_DCHECK(pmsg->message_id == MSG_DELETE);
+  RTC_LOG(LS_INFO) << "Connection deleted with number of pings sent: "
+                   << num_pings_sent_;
+  SignalDestroyed(this);
+  delete this;
+}
+
+int64_t Connection::last_received() const {
+  return std::max(last_data_received_,
+             std::max(last_ping_received_, last_ping_response_received_));
+}
+
+ConnectionInfo Connection::stats() {
+  stats_.recv_bytes_second = round(recv_rate_tracker_.ComputeRate());
+  stats_.recv_total_bytes = recv_rate_tracker_.TotalSampleCount();
+  stats_.sent_bytes_second = round(send_rate_tracker_.ComputeRate());
+  stats_.sent_total_bytes = send_rate_tracker_.TotalSampleCount();
+  stats_.receiving = receiving_;
+  stats_.writable = write_state_ == STATE_WRITABLE;
+  stats_.timeout = write_state_ == STATE_WRITE_TIMEOUT;
+  stats_.new_connection = !reported_;
+  stats_.rtt = rtt_;
+  stats_.local_candidate = local_candidate();
+  stats_.remote_candidate = remote_candidate();
+  stats_.key = this;
+  stats_.state = state_;
+  stats_.priority = priority();
+  stats_.nominated = nominated();
+  stats_.total_round_trip_time_ms = total_round_trip_time_ms_;
+  stats_.current_round_trip_time_ms = current_round_trip_time_ms_;
+  return stats_;
+}
+
+void Connection::MaybeUpdateLocalCandidate(ConnectionRequest* request,
+                                           StunMessage* response) {
+  // RFC 5245
+  // The agent checks the mapped address from the STUN response.  If the
+  // transport address does not match any of the local candidates that the
+  // agent knows about, the mapped address represents a new candidate -- a
+  // peer reflexive candidate.
+  const StunAddressAttribute* addr =
+      response->GetAddress(STUN_ATTR_XOR_MAPPED_ADDRESS);
+  if (!addr) {
+    RTC_LOG(LS_WARNING)
+        << "Connection::OnConnectionRequestResponse - "
+           "No MAPPED-ADDRESS or XOR-MAPPED-ADDRESS found in the "
+           "stun response message";
+    return;
+  }
+
+  for (size_t i = 0; i < port_->Candidates().size(); ++i) {
+    if (port_->Candidates()[i].address() == addr->GetAddress()) {
+      if (local_candidate_index_ != i) {
+        RTC_LOG(LS_INFO) << ToString()
+                         << ": Updating local candidate type to srflx.";
+        local_candidate_index_ = i;
+        // SignalStateChange to force a re-sort in P2PTransportChannel as this
+        // Connection's local candidate has changed.
+        SignalStateChange(this);
+      }
+      return;
+    }
+  }
+
+  // RFC 5245
+  // Its priority is set equal to the value of the PRIORITY attribute
+  // in the Binding request.
+  const StunUInt32Attribute* priority_attr =
+      request->msg()->GetUInt32(STUN_ATTR_PRIORITY);
+  if (!priority_attr) {
+    RTC_LOG(LS_WARNING) << "Connection::OnConnectionRequestResponse - "
+                           "No STUN_ATTR_PRIORITY found in the "
+                           "stun response message";
+    return;
+  }
+  const uint32_t priority = priority_attr->value();
+  std::string id = rtc::CreateRandomString(8);
+
+  Candidate new_local_candidate;
+  new_local_candidate.set_id(id);
+  new_local_candidate.set_component(local_candidate().component());
+  new_local_candidate.set_type(PRFLX_PORT_TYPE);
+  new_local_candidate.set_protocol(local_candidate().protocol());
+  new_local_candidate.set_address(addr->GetAddress());
+  new_local_candidate.set_priority(priority);
+  new_local_candidate.set_username(local_candidate().username());
+  new_local_candidate.set_password(local_candidate().password());
+  new_local_candidate.set_network_name(local_candidate().network_name());
+  new_local_candidate.set_network_type(local_candidate().network_type());
+  new_local_candidate.set_related_address(local_candidate().address());
+  new_local_candidate.set_generation(local_candidate().generation());
+  new_local_candidate.set_foundation(ComputeFoundation(
+      PRFLX_PORT_TYPE, local_candidate().protocol(),
+      local_candidate().relay_protocol(), local_candidate().address()));
+  new_local_candidate.set_network_id(local_candidate().network_id());
+  new_local_candidate.set_network_cost(local_candidate().network_cost());
+
+  // Change the local candidate of this Connection to the new prflx candidate.
+  RTC_LOG(LS_INFO) << ToString()
+                   << ": Updating local candidate type to prflx.";
+  local_candidate_index_ = port_->AddPrflxCandidate(new_local_candidate);
+
+  // SignalStateChange to force a re-sort in P2PTransportChannel as this
+  // Connection's local candidate has changed.
+  SignalStateChange(this);
+}
+
+bool Connection::rtt_converged() const {
+  return rtt_samples_ > (RTT_RATIO + 1);
+}
+
+bool Connection::missing_responses(int64_t now) const {
+  if (pings_since_last_response_.empty()) {
+    return false;
+  }
+
+  int64_t waiting = now - pings_since_last_response_[0].sent_time;
+  return waiting > 2 * rtt();
+}
+
+ProxyConnection::ProxyConnection(Port* port,
+                                 size_t index,
+                                 const Candidate& remote_candidate)
+    : Connection(port, index, remote_candidate) {}
+
+int ProxyConnection::Send(const void* data, size_t size,
+                          const rtc::PacketOptions& options) {
+  stats_.sent_total_packets++;
+  int sent = port_->SendTo(data, size, remote_candidate_.address(),
+                           options, true);
+  if (sent <= 0) {
+    RTC_DCHECK(sent < 0);
+    error_ = port_->GetError();
+    stats_.sent_discarded_packets++;
+  } else {
+    send_rate_tracker_.AddSamples(sent);
+  }
+  return sent;
+}
+
+int ProxyConnection::GetError() {
+  return error_;
+}
+
+}  // namespace cricket
diff -Naur chromium-67.0.3396.62/third_party/zlib/zconf.h chromium-67.0.3396.62.patched/third_party/zlib/zconf.h
--- chromium-67.0.3396.62/third_party/zlib/zconf.h	2018-05-30 11:43:43.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/zlib/zconf.h	2018-06-06 10:06:12.361134439 +0300
@@ -8,9 +8,6 @@
 #ifndef ZCONF_H
 #define ZCONF_H
 
-/* This include does prefixing as below, but with an updated set of names */
-#include "names.h"
-
 /*
  * If you *really* need a unique prefix for all types and library functions,
  * compile with -DZ_PREFIX. The "standard" zlib should be compiled without it.
diff -Naur chromium-67.0.3396.62/third_party/zlib/zconf.h.nozmangle chromium-67.0.3396.62.patched/third_party/zlib/zconf.h.nozmangle
--- chromium-67.0.3396.62/third_party/zlib/zconf.h.nozmangle	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/third_party/zlib/zconf.h.nozmangle	2018-05-30 11:43:43.000000000 +0300
@@ -0,0 +1,537 @@
+/* zconf.h -- configuration of the zlib compression library
+ * Copyright (C) 1995-2016 Jean-loup Gailly, Mark Adler
+ * For conditions of distribution and use, see copyright notice in zlib.h
+ */
+
+/* @(#) $Id$ */
+
+#ifndef ZCONF_H
+#define ZCONF_H
+
+/* This include does prefixing as below, but with an updated set of names */
+#include "names.h"
+
+/*
+ * If you *really* need a unique prefix for all types and library functions,
+ * compile with -DZ_PREFIX. The "standard" zlib should be compiled without it.
+ * Even better than compiling with -DZ_PREFIX would be to use configure to set
+ * this permanently in zconf.h using "./configure --zprefix".
+ */
+#ifdef Z_PREFIX     /* may be set to #if 1 by ./configure */
+#  define Z_PREFIX_SET
+
+/* all linked symbols and init macros */
+#  define _dist_code            z__dist_code
+#  define _length_code          z__length_code
+#  define _tr_align             z__tr_align
+#  define _tr_flush_bits        z__tr_flush_bits
+#  define _tr_flush_block       z__tr_flush_block
+#  define _tr_init              z__tr_init
+#  define _tr_stored_block      z__tr_stored_block
+#  define _tr_tally             z__tr_tally
+#  define adler32               z_adler32
+#  define adler32_combine       z_adler32_combine
+#  define adler32_combine64     z_adler32_combine64
+#  define adler32_z             z_adler32_z
+#  ifndef Z_SOLO
+#    define compress              z_compress
+#    define compress2             z_compress2
+#    define compressBound         z_compressBound
+#  endif
+#  define crc32                 z_crc32
+#  define crc32_combine         z_crc32_combine
+#  define crc32_combine64       z_crc32_combine64
+#  define crc32_z               z_crc32_z
+#  define deflate               z_deflate
+#  define deflateBound          z_deflateBound
+#  define deflateCopy           z_deflateCopy
+#  define deflateEnd            z_deflateEnd
+#  define deflateGetDictionary  z_deflateGetDictionary
+#  define deflateInit           z_deflateInit
+#  define deflateInit2          z_deflateInit2
+#  define deflateInit2_         z_deflateInit2_
+#  define deflateInit_          z_deflateInit_
+#  define deflateParams         z_deflateParams
+#  define deflatePending        z_deflatePending
+#  define deflatePrime          z_deflatePrime
+#  define deflateReset          z_deflateReset
+#  define deflateResetKeep      z_deflateResetKeep
+#  define deflateSetDictionary  z_deflateSetDictionary
+#  define deflateSetHeader      z_deflateSetHeader
+#  define deflateTune           z_deflateTune
+#  define deflate_copyright     z_deflate_copyright
+#  define get_crc_table         z_get_crc_table
+#  ifndef Z_SOLO
+#    define gz_error              z_gz_error
+#    define gz_intmax             z_gz_intmax
+#    define gz_strwinerror        z_gz_strwinerror
+#    define gzbuffer              z_gzbuffer
+#    define gzclearerr            z_gzclearerr
+#    define gzclose               z_gzclose
+#    define gzclose_r             z_gzclose_r
+#    define gzclose_w             z_gzclose_w
+#    define gzdirect              z_gzdirect
+#    define gzdopen               z_gzdopen
+#    define gzeof                 z_gzeof
+#    define gzerror               z_gzerror
+#    define gzflush               z_gzflush
+#    define gzfread               z_gzfread
+#    define gzfwrite              z_gzfwrite
+#    define gzgetc                z_gzgetc
+#    define gzgetc_               z_gzgetc_
+#    define gzgets                z_gzgets
+#    define gzoffset              z_gzoffset
+#    define gzoffset64            z_gzoffset64
+#    define gzopen                z_gzopen
+#    define gzopen64              z_gzopen64
+#    ifdef _WIN32
+#      define gzopen_w              z_gzopen_w
+#    endif
+#    define gzprintf              z_gzprintf
+#    define gzputc                z_gzputc
+#    define gzputs                z_gzputs
+#    define gzread                z_gzread
+#    define gzrewind              z_gzrewind
+#    define gzseek                z_gzseek
+#    define gzseek64              z_gzseek64
+#    define gzsetparams           z_gzsetparams
+#    define gztell                z_gztell
+#    define gztell64              z_gztell64
+#    define gzungetc              z_gzungetc
+#    define gzvprintf             z_gzvprintf
+#    define gzwrite               z_gzwrite
+#  endif
+#  define inflate               z_inflate
+#  define inflateBack           z_inflateBack
+#  define inflateBackEnd        z_inflateBackEnd
+#  define inflateBackInit       z_inflateBackInit
+#  define inflateBackInit_      z_inflateBackInit_
+#  define inflateCodesUsed      z_inflateCodesUsed
+#  define inflateCopy           z_inflateCopy
+#  define inflateEnd            z_inflateEnd
+#  define inflateGetDictionary  z_inflateGetDictionary
+#  define inflateGetHeader      z_inflateGetHeader
+#  define inflateInit           z_inflateInit
+#  define inflateInit2          z_inflateInit2
+#  define inflateInit2_         z_inflateInit2_
+#  define inflateInit_          z_inflateInit_
+#  define inflateMark           z_inflateMark
+#  define inflatePrime          z_inflatePrime
+#  define inflateReset          z_inflateReset
+#  define inflateReset2         z_inflateReset2
+#  define inflateResetKeep      z_inflateResetKeep
+#  define inflateSetDictionary  z_inflateSetDictionary
+#  define inflateSync           z_inflateSync
+#  define inflateSyncPoint      z_inflateSyncPoint
+#  define inflateUndermine      z_inflateUndermine
+#  define inflateValidate       z_inflateValidate
+#  define inflate_copyright     z_inflate_copyright
+#  define inflate_fast          z_inflate_fast
+#  define inflate_table         z_inflate_table
+#  ifndef Z_SOLO
+#    define uncompress            z_uncompress
+#    define uncompress2           z_uncompress2
+#  endif
+#  define zError                z_zError
+#  ifndef Z_SOLO
+#    define zcalloc               z_zcalloc
+#    define zcfree                z_zcfree
+#  endif
+#  define zlibCompileFlags      z_zlibCompileFlags
+#  define zlibVersion           z_zlibVersion
+
+/* all zlib typedefs in zlib.h and zconf.h */
+#  define Byte                  z_Byte
+#  define Bytef                 z_Bytef
+#  define alloc_func            z_alloc_func
+#  define charf                 z_charf
+#  define free_func             z_free_func
+#  ifndef Z_SOLO
+#    define gzFile                z_gzFile
+#  endif
+#  define gz_header             z_gz_header
+#  define gz_headerp            z_gz_headerp
+#  define in_func               z_in_func
+#  define intf                  z_intf
+#  define out_func              z_out_func
+#  define uInt                  z_uInt
+#  define uIntf                 z_uIntf
+#  define uLong                 z_uLong
+#  define uLongf                z_uLongf
+#  define voidp                 z_voidp
+#  define voidpc                z_voidpc
+#  define voidpf                z_voidpf
+
+/* all zlib structs in zlib.h and zconf.h */
+#  define gz_header_s           z_gz_header_s
+#  define internal_state        z_internal_state
+
+#endif
+
+#if defined(__MSDOS__) && !defined(MSDOS)
+#  define MSDOS
+#endif
+#if (defined(OS_2) || defined(__OS2__)) && !defined(OS2)
+#  define OS2
+#endif
+#if defined(_WINDOWS) && !defined(WINDOWS)
+#  define WINDOWS
+#endif
+#if defined(_WIN32) || defined(_WIN32_WCE) || defined(__WIN32__)
+#  ifndef WIN32
+#    define WIN32
+#  endif
+#endif
+#if (defined(MSDOS) || defined(OS2) || defined(WINDOWS)) && !defined(WIN32)
+#  if !defined(__GNUC__) && !defined(__FLAT__) && !defined(__386__)
+#    ifndef SYS16BIT
+#      define SYS16BIT
+#    endif
+#  endif
+#endif
+
+/*
+ * Compile with -DMAXSEG_64K if the alloc function cannot allocate more
+ * than 64k bytes at a time (needed on systems with 16-bit int).
+ */
+#ifdef SYS16BIT
+#  define MAXSEG_64K
+#endif
+#ifdef MSDOS
+#  define UNALIGNED_OK
+#endif
+
+#ifdef __STDC_VERSION__
+#  ifndef STDC
+#    define STDC
+#  endif
+#  if __STDC_VERSION__ >= 199901L
+#    ifndef STDC99
+#      define STDC99
+#    endif
+#  endif
+#endif
+#if !defined(STDC) && (defined(__STDC__) || defined(__cplusplus))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(__GNUC__) || defined(__BORLANDC__))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(MSDOS) || defined(WINDOWS) || defined(WIN32))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(OS2) || defined(__HOS_AIX__))
+#  define STDC
+#endif
+
+#if defined(__OS400__) && !defined(STDC)    /* iSeries (formerly AS/400). */
+#  define STDC
+#endif
+
+#ifndef STDC
+#  ifndef const /* cannot use !defined(STDC) && !defined(const) on Mac */
+#    define const       /* note: need a more gentle solution here */
+#  endif
+#endif
+
+#if defined(ZLIB_CONST) && !defined(z_const)
+#  define z_const const
+#else
+#  define z_const
+#endif
+
+#ifdef Z_SOLO
+   typedef unsigned long z_size_t;
+#else
+#  define z_longlong long long
+#  if defined(NO_SIZE_T)
+     typedef unsigned NO_SIZE_T z_size_t;
+#  elif defined(STDC)
+#    include <stddef.h>
+     typedef size_t z_size_t;
+#  else
+     typedef unsigned long z_size_t;
+#  endif
+#  undef z_longlong
+#endif
+
+/* Maximum value for memLevel in deflateInit2 */
+#ifndef MAX_MEM_LEVEL
+#  ifdef MAXSEG_64K
+#    define MAX_MEM_LEVEL 8
+#  else
+#    define MAX_MEM_LEVEL 9
+#  endif
+#endif
+
+/* Maximum value for windowBits in deflateInit2 and inflateInit2.
+ * WARNING: reducing MAX_WBITS makes minigzip unable to extract .gz files
+ * created by gzip. (Files created by minigzip can still be extracted by
+ * gzip.)
+ */
+#ifndef MAX_WBITS
+#  define MAX_WBITS   15 /* 32K LZ77 window */
+#endif
+
+/* The memory requirements for deflate are (in bytes):
+            (1 << (windowBits+2)) +  (1 << (memLevel+9))
+ that is: 128K for windowBits=15  +  128K for memLevel = 8  (default values)
+ plus a few kilobytes for small objects. For example, if you want to reduce
+ the default memory requirements from 256K to 128K, compile with
+     make CFLAGS="-O -DMAX_WBITS=14 -DMAX_MEM_LEVEL=7"
+ Of course this will generally degrade compression (there's no free lunch).
+
+   The memory requirements for inflate are (in bytes) 1 << windowBits
+ that is, 32K for windowBits=15 (default value) plus about 7 kilobytes
+ for small objects.
+*/
+
+                        /* Type declarations */
+
+#ifndef OF /* function prototypes */
+#  ifdef STDC
+#    define OF(args)  args
+#  else
+#    define OF(args)  ()
+#  endif
+#endif
+
+#ifndef Z_ARG /* function prototypes for stdarg */
+#  if defined(STDC) || defined(Z_HAVE_STDARG_H)
+#    define Z_ARG(args)  args
+#  else
+#    define Z_ARG(args)  ()
+#  endif
+#endif
+
+/* The following definitions for FAR are needed only for MSDOS mixed
+ * model programming (small or medium model with some far allocations).
+ * This was tested only with MSC; for other MSDOS compilers you may have
+ * to define NO_MEMCPY in zutil.h.  If you don't need the mixed model,
+ * just define FAR to be empty.
+ */
+#ifdef SYS16BIT
+#  if defined(M_I86SM) || defined(M_I86MM)
+     /* MSC small or medium model */
+#    define SMALL_MEDIUM
+#    ifdef _MSC_VER
+#      define FAR _far
+#    else
+#      define FAR far
+#    endif
+#  endif
+#  if (defined(__SMALL__) || defined(__MEDIUM__))
+     /* Turbo C small or medium model */
+#    define SMALL_MEDIUM
+#    ifdef __BORLANDC__
+#      define FAR _far
+#    else
+#      define FAR far
+#    endif
+#  endif
+#endif
+
+#if defined(WINDOWS) || defined(WIN32)
+   /* If building or using zlib as a DLL, define ZLIB_DLL.
+    * This is not mandatory, but it offers a little performance increase.
+    */
+#  ifdef ZLIB_DLL
+#    if defined(WIN32) && (!defined(__BORLANDC__) || (__BORLANDC__ >= 0x500))
+#      ifdef ZLIB_INTERNAL
+#        define ZEXTERN extern __declspec(dllexport)
+#      else
+#        define ZEXTERN extern __declspec(dllimport)
+#      endif
+#    endif
+#  endif  /* ZLIB_DLL */
+   /* If building or using zlib with the WINAPI/WINAPIV calling convention,
+    * define ZLIB_WINAPI.
+    * Caution: the standard ZLIB1.DLL is NOT compiled using ZLIB_WINAPI.
+    */
+#  ifdef ZLIB_WINAPI
+#    ifdef FAR
+#      undef FAR
+#    endif
+#    include <windows.h>
+     /* No need for _export, use ZLIB.DEF instead. */
+     /* For complete Windows compatibility, use WINAPI, not __stdcall. */
+#    define ZEXPORT WINAPI
+#    ifdef WIN32
+#      define ZEXPORTVA WINAPIV
+#    else
+#      define ZEXPORTVA FAR CDECL
+#    endif
+#  endif
+#endif
+
+#if defined (__BEOS__)
+#  ifdef ZLIB_DLL
+#    ifdef ZLIB_INTERNAL
+#      define ZEXPORT   __declspec(dllexport)
+#      define ZEXPORTVA __declspec(dllexport)
+#    else
+#      define ZEXPORT   __declspec(dllimport)
+#      define ZEXPORTVA __declspec(dllimport)
+#    endif
+#  endif
+#endif
+
+#ifndef ZEXTERN
+#  define ZEXTERN extern
+#endif
+#ifndef ZEXPORT
+#  define ZEXPORT
+#endif
+#ifndef ZEXPORTVA
+#  define ZEXPORTVA
+#endif
+
+#ifndef FAR
+#  define FAR
+#endif
+
+#if !defined(__MACTYPES__)
+typedef unsigned char  Byte;  /* 8 bits */
+#endif
+typedef unsigned int   uInt;  /* 16 bits or more */
+typedef unsigned long  uLong; /* 32 bits or more */
+
+#ifdef SMALL_MEDIUM
+   /* Borland C/C++ and some old MSC versions ignore FAR inside typedef */
+#  define Bytef Byte FAR
+#else
+   typedef Byte  FAR Bytef;
+#endif
+typedef char  FAR charf;
+typedef int   FAR intf;
+typedef uInt  FAR uIntf;
+typedef uLong FAR uLongf;
+
+#ifdef STDC
+   typedef void const *voidpc;
+   typedef void FAR   *voidpf;
+   typedef void       *voidp;
+#else
+   typedef Byte const *voidpc;
+   typedef Byte FAR   *voidpf;
+   typedef Byte       *voidp;
+#endif
+
+#if !defined(Z_U4) && !defined(Z_SOLO) && defined(STDC)
+#  include <limits.h>
+#  if (UINT_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned
+#  elif (ULONG_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned long
+#  elif (USHRT_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned short
+#  endif
+#endif
+
+#ifdef Z_U4
+   typedef Z_U4 z_crc_t;
+#else
+   typedef unsigned long z_crc_t;
+#endif
+
+#if !defined(_WIN32)
+#  define Z_HAVE_UNISTD_H
+#endif
+
+#ifdef HAVE_STDARG_H    /* may be set to #if 1 by ./configure */
+#  define Z_HAVE_STDARG_H
+#endif
+
+#ifdef STDC
+#  ifndef Z_SOLO
+#    include <sys/types.h>      /* for off_t */
+#  endif
+#endif
+
+#if defined(STDC) || defined(Z_HAVE_STDARG_H)
+#  ifndef Z_SOLO
+#    include <stdarg.h>         /* for va_list */
+#  endif
+#endif
+
+#ifdef _WIN32
+#  ifndef Z_SOLO
+#    include <stddef.h>         /* for wchar_t */
+#  endif
+#endif
+
+/* a little trick to accommodate both "#define _LARGEFILE64_SOURCE" and
+ * "#define _LARGEFILE64_SOURCE 1" as requesting 64-bit operations, (even
+ * though the former does not conform to the LFS document), but considering
+ * both "#undef _LARGEFILE64_SOURCE" and "#define _LARGEFILE64_SOURCE 0" as
+ * equivalently requesting no 64-bit operations
+ */
+#if defined(_LARGEFILE64_SOURCE) && -_LARGEFILE64_SOURCE - -1 == 1
+#  undef _LARGEFILE64_SOURCE
+#endif
+
+#if defined(__WATCOMC__) && !defined(Z_HAVE_UNISTD_H)
+#  define Z_HAVE_UNISTD_H
+#endif
+#ifndef Z_SOLO
+#  if defined(Z_HAVE_UNISTD_H) || defined(_LARGEFILE64_SOURCE)
+#    include <unistd.h>         /* for SEEK_*, off_t, and _LFS64_LARGEFILE */
+#    ifdef VMS
+#      include <unixio.h>       /* for off_t */
+#    endif
+#    ifndef z_off_t
+#      define z_off_t off_t
+#    endif
+#  endif
+#endif
+
+#if defined(_LFS64_LARGEFILE) && _LFS64_LARGEFILE-0
+#  define Z_LFS64
+#endif
+
+#if defined(_LARGEFILE64_SOURCE) && defined(Z_LFS64)
+#  define Z_LARGE64
+#endif
+
+#if defined(_FILE_OFFSET_BITS) && _FILE_OFFSET_BITS-0 == 64 && defined(Z_LFS64)
+#  define Z_WANT64
+#endif
+
+#if !defined(SEEK_SET) && !defined(Z_SOLO)
+#  define SEEK_SET        0       /* Seek from beginning of file.  */
+#  define SEEK_CUR        1       /* Seek from current position.  */
+#  define SEEK_END        2       /* Set file pointer to EOF plus "offset" */
+#endif
+
+#ifndef z_off_t
+#  define z_off_t long
+#endif
+
+#if !defined(_WIN32) && defined(Z_LARGE64)
+#  define z_off64_t off64_t
+#else
+#  if defined(_WIN32) && !defined(__GNUC__) && !defined(Z_SOLO)
+#    define z_off64_t __int64
+#  else
+#    define z_off64_t z_off_t
+#  endif
+#endif
+
+/* MVS linker does not support external names larger than 8 bytes */
+#if defined(__MVS__)
+  #pragma map(deflateInit_,"DEIN")
+  #pragma map(deflateInit2_,"DEIN2")
+  #pragma map(deflateEnd,"DEEND")
+  #pragma map(deflateBound,"DEBND")
+  #pragma map(inflateInit_,"ININ")
+  #pragma map(inflateInit2_,"ININ2")
+  #pragma map(inflateEnd,"INEND")
+  #pragma map(inflateSync,"INSY")
+  #pragma map(inflateSetDictionary,"INSEDI")
+  #pragma map(compressBound,"CMBND")
+  #pragma map(inflate_table,"INTABL")
+  #pragma map(inflate_fast,"INFA")
+  #pragma map(inflate_copyright,"INCOPY")
+#endif
+
+#endif /* ZCONF_H */
diff -Naur chromium-67.0.3396.62/tools/gn/bootstrap/bootstrap.py chromium-67.0.3396.62.patched/tools/gn/bootstrap/bootstrap.py
--- chromium-67.0.3396.62/tools/gn/bootstrap/bootstrap.py	2018-05-30 11:43:43.000000000 +0300
+++ chromium-67.0.3396.62.patched/tools/gn/bootstrap/bootstrap.py	2018-06-06 10:06:12.365134376 +0300
@@ -399,6 +399,11 @@
   cflags = os.environ.get('CFLAGS', '').split()
   cflags_cc = os.environ.get('CXXFLAGS', '').split()
   ldflags = os.environ.get('LDFLAGS', '').split()
+
+  # Work around GCC8 bug gcc#84286
+  cflags.extend(['-fabi-version=11'])
+  cflags_cc.extend(['-fabi-version=11'])
+
   include_dirs = [root_gen_dir, SRC_ROOT]
   libs = []
 
diff -Naur chromium-67.0.3396.62/tools/gn/bootstrap/bootstrap.py.fabi11 chromium-67.0.3396.62.patched/tools/gn/bootstrap/bootstrap.py.fabi11
--- chromium-67.0.3396.62/tools/gn/bootstrap/bootstrap.py.fabi11	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/tools/gn/bootstrap/bootstrap.py.fabi11	2018-05-30 11:43:43.000000000 +0300
@@ -0,0 +1,1009 @@
+#!/usr/bin/env python
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# This file isn't officially supported by the Chromium project. It's maintained
+# on a best-effort basis by volunteers, so some things may be broken from time
+# to time. If you encounter errors, it's most often due to files in base that
+# have been added or moved since somebody last tried this script. Generally
+# such errors are easy to diagnose.
+
+"""Bootstraps gn.
+
+It is done by first building it manually in a temporary directory, then building
+it with its own BUILD.gn to the final destination.
+"""
+
+import contextlib
+import errno
+import logging
+import optparse
+import os
+import platform
+import shutil
+import subprocess
+import sys
+import tempfile
+
+BOOTSTRAP_DIR = os.path.dirname(os.path.abspath(__file__))
+GN_ROOT = os.path.dirname(BOOTSTRAP_DIR)
+SRC_ROOT = os.path.dirname(os.path.dirname(GN_ROOT))
+
+is_win = sys.platform.startswith('win')
+is_linux = sys.platform.startswith('linux')
+is_mac = sys.platform.startswith('darwin')
+is_aix = sys.platform.startswith('aix')
+is_posix = is_linux or is_mac or is_aix
+
+def check_call(cmd, **kwargs):
+  logging.debug('Running: %s', ' '.join(cmd))
+
+  subprocess.check_call(cmd, cwd=GN_ROOT, **kwargs)
+
+def check_output(cmd, cwd=GN_ROOT, **kwargs):
+  logging.debug('Running: %s', ' '.join(cmd))
+
+  return subprocess.check_output(cmd, cwd=cwd, **kwargs)
+
+def mkdir_p(path):
+  try:
+    os.makedirs(path)
+  except OSError as e:
+    if e.errno == errno.EEXIST and os.path.isdir(path):
+      pass
+    else: raise
+
+@contextlib.contextmanager
+def scoped_tempdir():
+  path = tempfile.mkdtemp()
+  try:
+    yield path
+  finally:
+    shutil.rmtree(path)
+
+
+def run_build(tempdir, options):
+  if options.build_path:
+    build_rel = options.build_path
+  elif options.debug:
+    build_rel = os.path.join('out', 'Debug')
+  else:
+    build_rel = os.path.join('out', 'Release')
+  build_root = os.path.join(SRC_ROOT, build_rel)
+
+  windows_x64_toolchain = None
+  if is_win:
+    windows_x64_toolchain = windows_prepare_toolchain(tempdir)
+    os.environ["PATH"] = windows_x64_toolchain["paths"]
+
+  print 'Building gn manually in a temporary directory for bootstrapping...'
+  build_gn_with_ninja_manually(tempdir, options, windows_x64_toolchain)
+  temp_gn = os.path.join(tempdir, 'gn')
+  out_gn = os.path.join(build_root, 'gn')
+
+  if is_win:
+    temp_gn += '.exe'
+    out_gn += '.exe'
+
+  if options.no_rebuild:
+    mkdir_p(build_root)
+    shutil.copy2(temp_gn, out_gn)
+  else:
+    print 'Building gn using itself to %s...' % build_rel
+    build_gn_with_gn(temp_gn, build_root, options)
+
+  if options.output:
+    # Preserve the executable permission bit.
+    shutil.copy2(out_gn, options.output)
+
+def windows_target_build_arch():
+    # Target build architecture set by vcvarsall.bat
+    target_arch = os.environ.get('Platform')
+    if target_arch in ['x64', 'x86']: return target_arch
+
+    if platform.machine().lower() in ['x86_64', 'amd64']: return 'x64'
+    return 'x86'
+
+def windows_prepare_toolchain(tempdir):
+
+  def CallPythonScopeScript(command, **kwargs):
+    response = check_output(command, **kwargs)
+
+    _globals = {"__builtins__":None}
+    _locals = {}
+    exec(response, _globals, _locals)
+
+    return _locals
+
+  toolchain_paths = CallPythonScopeScript(
+      [sys.executable,
+       os.path.join(SRC_ROOT, "build", "vs_toolchain.py"),
+      "get_toolchain_dir"],
+      cwd=tempdir)
+
+  windows_x64_toolchain =  CallPythonScopeScript(
+      [sys.executable,
+       os.path.join(SRC_ROOT, "build", "toolchain",
+                    "win", "setup_toolchain.py"),
+       toolchain_paths["vs_path"],
+       toolchain_paths["sdk_path"],
+       toolchain_paths["runtime_dirs"],
+       "x64",
+       "true"
+      ],
+      cwd=tempdir)
+
+  return windows_x64_toolchain
+
+def main(argv):
+  parser = optparse.OptionParser(description=sys.modules[__name__].__doc__)
+  parser.add_option('-d', '--debug', action='store_true',
+                    help='Do a debug build. Defaults to release build.')
+  parser.add_option('-o', '--output',
+                    help='place output in PATH', metavar='PATH')
+  parser.add_option('-s', '--no-rebuild', action='store_true',
+                    help='Do not rebuild GN with GN.')
+  parser.add_option('--no-clean', action='store_true',
+                    help='Re-used build directory instead of using new '
+                         'temporary location each time')
+  parser.add_option('--gn-gen-args', help='Args to pass to gn gen --args')
+  parser.add_option('--build-path', help='The directory in which to build gn, '
+                    'relative to the src directory. (eg. out/Release)'
+                    'In the no-clean mode an absolute path will also force '
+                    'the out_bootstrap to be located in the parent directory')
+  parser.add_option('-v', '--verbose', action='store_true',
+                    help='Log more details')
+  options, args = parser.parse_args(argv)
+
+  if args:
+    parser.error('Unrecognized command line arguments: %s.' % ', '.join(args))
+
+  logging.basicConfig(level=logging.DEBUG if options.verbose else logging.ERROR)
+
+  try:
+    if options.no_clean:
+      out_bootstrap_dir = SRC_ROOT
+      if options.build_path and os.path.isabs(options.build_path):
+        out_bootstrap_dir = os.path.dirname(options.build_path)
+      build_dir = os.path.join(out_bootstrap_dir, 'out_bootstrap')
+      if not os.path.exists(build_dir):
+        os.makedirs(build_dir)
+      return run_build(build_dir, options)
+    else:
+      with scoped_tempdir() as tempdir:
+        return run_build(tempdir, options)
+  except subprocess.CalledProcessError as e:
+    print >> sys.stderr, str(e)
+    return 1
+  return 0
+
+def write_compiled_message(root_gen_dir, source):
+  path = os.path.join(root_gen_dir, os.path.dirname(source))
+  mkdir_p(path)
+  check_call([
+      'mc.exe',
+      '-r', path, '-h', path,
+      '-u', '-um',
+      os.path.join(SRC_ROOT, source),
+  ])
+
+def write_buildflag_header_manually(root_gen_dir, header, flags):
+  mkdir_p(os.path.join(root_gen_dir, os.path.dirname(header)))
+
+  # Don't use tempfile.NamedTemporaryFile() here.
+  # It doesn't work correctly on Windows.
+  # see: http://bugs.python.org/issue14243
+  temp_path = os.path.join(root_gen_dir, header + '.tmp')
+  with open(temp_path, 'w') as f:
+    f.write('--flags')
+    for name,value in flags.items():
+      f.write(' ' + name + '=' + value)
+
+  check_call([
+      sys.executable,
+      os.path.join(SRC_ROOT, 'build', 'write_buildflag_header.py'),
+      '--output', header,
+      '--gen-dir', root_gen_dir,
+      '--definitions', temp_path,
+  ])
+
+  os.remove(temp_path)
+
+def write_build_date_header(root_gen_dir):
+  check_call([
+       sys.executable,
+       os.path.join(SRC_ROOT, 'build', 'write_build_date_header.py'),
+       os.path.join(root_gen_dir, 'base/generated_build_date.h'),
+       'default',
+  ])
+
+def build_gn_with_ninja_manually(tempdir, options, windows_x64_toolchain):
+  root_gen_dir = os.path.join(tempdir, 'gen')
+  mkdir_p(root_gen_dir)
+
+  write_buildflag_header_manually(
+      root_gen_dir,
+      'base/synchronization/synchronization_buildflags.h',
+      {'ENABLE_MUTEX_PRIORITY_INHERITANCE': 'false'})
+
+  write_buildflag_header_manually(root_gen_dir, 'base/allocator/buildflags.h',
+      {'USE_ALLOCATOR_SHIM': 'true' if is_linux else 'false'})
+
+  write_buildflag_header_manually(root_gen_dir,
+                                  'base/debug/debugging_buildflags.h',
+      {
+          'ENABLE_LOCATION_SOURCE': 'false',
+          'ENABLE_PROFILING': 'false',
+          'CAN_UNWIND_WITH_FRAME_POINTERS': 'false',
+          'UNSAFE_DEVELOPER_BUILD': 'false',
+          'CAN_UNWIND_WITH_CFI_TABLE': 'false',
+      })
+
+  write_buildflag_header_manually(root_gen_dir,
+                                  'base/memory/protected_memory_buildflags.h',
+                                  { 'USE_LLD': 'false' })
+
+  write_buildflag_header_manually(root_gen_dir, 'base/cfi_buildflags.h',
+      {
+          'CFI_CAST_CHECK': 'false',
+          'CFI_ICALL_CHECK': 'false',
+          'CFI_ENFORCEMENT_TRAP': 'false',
+          'CFI_ENFORCEMENT_DIAGNOSTIC': 'false'
+      })
+
+  write_build_date_header(root_gen_dir)
+
+  if is_mac:
+    # //base/build_time.cc needs base/generated_build_date.h,
+    # and this file is only included for Mac builds.
+    mkdir_p(os.path.join(root_gen_dir, 'base'))
+    check_call([
+        sys.executable,
+        os.path.join(SRC_ROOT, 'build', 'write_build_date_header.py'),
+        os.path.join(root_gen_dir, 'base', 'generated_build_date.h'),
+        'default'
+    ])
+
+  if is_win:
+    write_buildflag_header_manually(root_gen_dir,
+                                    'base/win/base_win_buildflags.h',
+        {'SINGLE_MODULE_MODE_HANDLE_VERIFIER': 'true'})
+
+    write_compiled_message(root_gen_dir,
+        'base/trace_event/etw_manifest/chrome_events_win.man')
+
+  write_buildflag_header_manually(
+      root_gen_dir, 'base/android/library_loader.h',
+      {'USE_LLD': 'false', 'SUPPORTS_CODE_ORDERING': 'false'})
+
+  write_gn_ninja(os.path.join(tempdir, 'build.ninja'),
+                 root_gen_dir, options, windows_x64_toolchain)
+  cmd = ['ninja', '-C', tempdir, '-w', 'dupbuild=err']
+  if options.verbose:
+    cmd.append('-v')
+
+  if is_win:
+    cmd.append('gn.exe')
+  else:
+    cmd.append('gn')
+
+  check_call(cmd)
+
+def write_generic_ninja(path, static_libraries, executables,
+                        cc, cxx, ar, ld,
+                        cflags=[], cflags_cc=[], ldflags=[],
+                        include_dirs=[], solibs=[]):
+  ninja_header_lines = [
+    'cc = ' + cc,
+    'cxx = ' + cxx,
+    'ar = ' + ar,
+    'ld = ' + ld,
+    '',
+  ]
+
+  if is_win:
+    template_filename = 'build_vs.ninja.template'
+  elif is_mac:
+    template_filename = 'build_mac.ninja.template'
+  elif is_aix:
+    template_filename = 'build_aix.ninja.template'
+  else:
+    template_filename = 'build.ninja.template'
+
+  with open(os.path.join(GN_ROOT, 'bootstrap', template_filename)) as f:
+    ninja_template = f.read()
+
+  if is_win:
+    executable_ext = '.exe'
+    library_ext = '.lib'
+    object_ext = '.obj'
+  else:
+    executable_ext = ''
+    library_ext = '.a'
+    object_ext = '.o'
+
+  def escape_path_ninja(path):
+      return path.replace('$ ', '$$ ').replace(' ', '$ ').replace(':', '$:')
+
+  def src_to_obj(path):
+    return escape_path_ninja('%s' % os.path.splitext(path)[0] + object_ext)
+
+  def library_to_a(library):
+    return '%s%s' % (library, library_ext)
+
+  ninja_lines = []
+  def build_source(src_file, settings):
+    ninja_lines.extend([
+        'build %s: %s %s' % (src_to_obj(src_file),
+                             settings['tool'],
+                             escape_path_ninja(
+                                 os.path.join(SRC_ROOT, src_file))),
+        '  includes = %s' % ' '.join(
+            ['-I' + escape_path_ninja(dirname) for dirname in
+             include_dirs + settings.get('include_dirs', [])]),
+        '  cflags = %s' % ' '.join(cflags + settings.get('cflags', [])),
+        '  cflags_cc = %s' %
+            ' '.join(cflags_cc + settings.get('cflags_cc', [])),
+    ])
+
+  for library, settings in static_libraries.iteritems():
+    for src_file in settings['sources']:
+      build_source(src_file, settings)
+
+    ninja_lines.append('build %s: alink_thin %s' % (
+        library_to_a(library),
+        ' '.join([src_to_obj(src_file) for src_file in settings['sources']])))
+
+  for executable, settings in executables.iteritems():
+    for src_file in settings['sources']:
+      build_source(src_file, settings)
+
+    ninja_lines.extend([
+      'build %s%s: link %s | %s' % (
+          executable, executable_ext,
+          ' '.join([src_to_obj(src_file) for src_file in settings['sources']]),
+          ' '.join([library_to_a(library) for library in settings['libs']])),
+      '  ldflags = %s' % ' '.join(ldflags),
+      '  solibs = %s' % ' '.join(solibs),
+      '  libs = %s' % ' '.join(
+          [library_to_a(library) for library in settings['libs']]),
+    ])
+
+  ninja_lines.append('')  # Make sure the file ends with a newline.
+
+  with open(path, 'w') as f:
+    f.write('\n'.join(ninja_header_lines))
+    f.write(ninja_template)
+    f.write('\n'.join(ninja_lines))
+
+def write_gn_ninja(path, root_gen_dir, options, windows_x64_toolchain):
+  if is_win:
+    CCPATH = windows_x64_toolchain["vc_bin_dir"]
+
+    cc = os.environ.get('CC', os.path.join(CCPATH, 'cl.exe'))
+    cxx = os.environ.get('CXX', os.path.join(CCPATH, 'cl.exe'))
+    ld = os.environ.get('LD', os.path.join(CCPATH, 'link.exe'))
+    ar = os.environ.get('AR', os.path.join(CCPATH, 'lib.exe'))
+  elif is_aix:
+    cc = os.environ.get('CC', 'gcc')
+    cxx = os.environ.get('CXX', 'c++')
+    ld = os.environ.get('LD', cxx)
+    ar = os.environ.get('AR', 'ar -X64')
+  else:
+    cc = os.environ.get('CC', 'cc')
+    cxx = os.environ.get('CXX', 'c++')
+    ld = cxx
+    ar = os.environ.get('AR', 'ar')
+
+  cflags = os.environ.get('CFLAGS', '').split()
+  cflags_cc = os.environ.get('CXXFLAGS', '').split()
+  ldflags = os.environ.get('LDFLAGS', '').split()
+  include_dirs = [root_gen_dir, SRC_ROOT]
+  libs = []
+
+  # //base/allocator/allocator_extension.cc needs this macro defined,
+  # otherwise there would be link errors.
+  cflags.extend(['-DNO_TCMALLOC', '-D__STDC_FORMAT_MACROS'])
+
+  if is_posix:
+    if options.debug:
+      cflags.extend(['-O0', '-g'])
+    else:
+      # The linux::ppc64 BE binary doesn't "work" when
+      # optimization level is set to 2 (0 works fine).
+      # Note that the current bootstrap script has no way to detect host_cpu.
+      # This can be easily fixed once we start building using a GN binary,
+      # as the optimization flag can then just be set using the
+      # logic inside //build/toolchain.
+      cflags.extend(['-O2', '-g0'])
+
+    cflags.extend([
+        '-D_FILE_OFFSET_BITS=64',
+        '-D__STDC_CONSTANT_MACROS', '-D__STDC_FORMAT_MACROS',
+        '-pthread',
+        '-pipe',
+        '-fno-exceptions'
+    ])
+    cflags_cc.extend(['-std=c++14', '-Wno-c++11-narrowing'])
+    if is_aix:
+     cflags.extend(['-maix64'])
+     ldflags.extend([ '-maix64 -Wl,-bbigtoc' ])
+  elif is_win:
+    if not options.debug:
+      cflags.extend(['/Ox', '/DNDEBUG', '/GL'])
+      ldflags.extend(['/LTCG', '/OPT:REF', '/OPT:ICF'])
+
+    cflags.extend([
+        '/FS',
+        '/Gy',
+        '/W3', '/wd4244',
+        '/Zi',
+        '/DWIN32_LEAN_AND_MEAN', '/DNOMINMAX',
+        '/D_CRT_SECURE_NO_DEPRECATE', '/D_SCL_SECURE_NO_DEPRECATE',
+        '/D_WIN32_WINNT=0x0A00', '/DWINVER=0x0A00',
+        '/DUNICODE', '/D_UNICODE',
+    ])
+    cflags_cc.extend([
+        '/GR-',
+        '/D_HAS_EXCEPTIONS=0',
+    ])
+
+    target_arch = windows_target_build_arch()
+    if target_arch == 'x64':
+        ldflags.extend(['/MACHINE:x64'])
+    else:
+        ldflags.extend(['/MACHINE:x86'])
+
+  static_libraries = {
+      'base': {'sources': [], 'tool': 'cxx', 'include_dirs': []},
+      'dynamic_annotations': {'sources': [], 'tool': 'cc', 'include_dirs': []},
+      'gn_lib': {'sources': [], 'tool': 'cxx', 'include_dirs': []},
+  }
+
+  executables = {
+      'gn': {'sources': ['tools/gn/gn_main.cc'],
+             'tool': 'cxx', 'include_dirs': [], 'libs': []},
+  }
+
+  for name in os.listdir(GN_ROOT):
+    if not name.endswith('.cc'):
+      continue
+    if name.endswith('_unittest.cc'):
+      continue
+    if name == 'run_all_unittests.cc':
+      continue
+    if name == 'test_with_scheduler.cc':
+      continue
+    if name == 'gn_main.cc':
+      continue
+    full_path = os.path.join(GN_ROOT, name)
+    static_libraries['gn_lib']['sources'].append(
+        os.path.relpath(full_path, SRC_ROOT))
+
+  static_libraries['dynamic_annotations']['sources'].extend([
+      'base/third_party/dynamic_annotations/dynamic_annotations.c',
+      'base/third_party/superfasthash/superfasthash.c',
+  ])
+  static_libraries['base']['sources'].extend([
+      'base/allocator/allocator_check.cc',
+      'base/allocator/allocator_extension.cc',
+      'base/at_exit.cc',
+      'base/base_paths.cc',
+      'base/base_switches.cc',
+      'base/build_time.cc',
+      'base/callback_helpers.cc',
+      'base/callback_internal.cc',
+      'base/command_line.cc',
+      'base/debug/activity_tracker.cc',
+      'base/debug/alias.cc',
+      'base/debug/crash_logging.cc',
+      'base/debug/dump_without_crashing.cc',
+      'base/debug/stack_trace.cc',
+      'base/debug/task_annotator.cc',
+      'base/debug/thread_heap_usage_tracker.cc',
+      'base/environment.cc',
+      'base/feature_list.cc',
+      'base/files/file.cc',
+      'base/files/file_enumerator.cc',
+      'base/files/file_path.cc',
+      'base/files/file_path_constants.cc',
+      'base/files/file_tracing.cc',
+      'base/files/file_util.cc',
+      'base/files/important_file_writer.cc',
+      'base/files/memory_mapped_file.cc',
+      'base/files/scoped_file.cc',
+      'base/hash.cc',
+      'base/json/json_parser.cc',
+      'base/json/json_reader.cc',
+      'base/json/json_string_value_serializer.cc',
+      'base/json/json_writer.cc',
+      'base/json/string_escape.cc',
+      'base/lazy_instance_helpers.cc',
+      'base/location.cc',
+      'base/logging.cc',
+      'base/md5.cc',
+      'base/memory/ref_counted.cc',
+      'base/memory/ref_counted_memory.cc',
+      'base/memory/shared_memory_handle.cc',
+      'base/memory/shared_memory_tracker.cc',
+      'base/memory/weak_ptr.cc',
+      'base/message_loop/incoming_task_queue.cc',
+      'base/message_loop/message_loop.cc',
+      'base/message_loop/message_loop_task_runner.cc',
+      'base/message_loop/message_pump.cc',
+      'base/message_loop/message_pump_default.cc',
+      'base/message_loop/watchable_io_message_pump_posix.cc',
+      'base/metrics/bucket_ranges.cc',
+      'base/metrics/dummy_histogram.cc',
+      'base/metrics/field_trial.cc',
+      'base/metrics/field_trial_param_associator.cc',
+      'base/metrics/field_trial_params.cc',
+      'base/metrics/histogram.cc',
+      'base/metrics/histogram_base.cc',
+      'base/metrics/histogram_functions.cc',
+      'base/metrics/histogram_samples.cc',
+      'base/metrics/histogram_snapshot_manager.cc',
+      'base/metrics/metrics_hashes.cc',
+      'base/metrics/persistent_histogram_allocator.cc',
+      'base/metrics/persistent_memory_allocator.cc',
+      'base/metrics/persistent_sample_map.cc',
+      'base/metrics/sample_map.cc',
+      'base/metrics/sample_vector.cc',
+      'base/metrics/sparse_histogram.cc',
+      'base/metrics/statistics_recorder.cc',
+      'base/observer_list_threadsafe.cc',
+      'base/path_service.cc',
+      'base/pending_task.cc',
+      'base/pickle.cc',
+      'base/process/kill.cc',
+      'base/process/memory.cc',
+      'base/process/process_handle.cc',
+      'base/process/process_iterator.cc',
+      'base/process/process_metrics.cc',
+      'base/rand_util.cc',
+      'base/run_loop.cc',
+      'base/sequence_token.cc',
+      'base/sequence_checker_impl.cc',
+      'base/sequenced_task_runner.cc',
+      'base/sha1.cc',
+      'base/strings/pattern.cc',
+      'base/strings/string_number_conversions.cc',
+      'base/strings/string_piece.cc',
+      'base/strings/string_split.cc',
+      'base/strings/string_util.cc',
+      'base/strings/string_util_constants.cc',
+      'base/strings/stringprintf.cc',
+      'base/strings/utf_string_conversion_utils.cc',
+      'base/strings/utf_string_conversions.cc',
+      'base/synchronization/atomic_flag.cc',
+      'base/synchronization/lock.cc',
+      'base/sys_info.cc',
+      'base/task_runner.cc',
+      'base/task_scheduler/delayed_task_manager.cc',
+      'base/task_scheduler/environment_config.cc',
+      'base/task_scheduler/post_task.cc',
+      'base/task_scheduler/priority_queue.cc',
+      'base/task_scheduler/scheduler_lock_impl.cc',
+      'base/task_scheduler/scheduler_single_thread_task_runner_manager.cc',
+      'base/task_scheduler/scheduler_worker.cc',
+      'base/task_scheduler/scheduler_worker_pool.cc',
+      'base/task_scheduler/scheduler_worker_pool_impl.cc',
+      'base/task_scheduler/scheduler_worker_pool_params.cc',
+      'base/task_scheduler/scheduler_worker_stack.cc',
+      'base/task_scheduler/scoped_set_task_priority_for_current_thread.cc',
+      'base/task_scheduler/sequence.cc',
+      'base/task_scheduler/sequence_sort_key.cc',
+      'base/task_scheduler/task.cc',
+      'base/task_scheduler/task_scheduler.cc',
+      'base/task_scheduler/task_scheduler_impl.cc',
+      'base/task_scheduler/task_tracker.cc',
+      'base/task_scheduler/task_traits.cc',
+      'base/third_party/dmg_fp/dtoa_wrapper.cc',
+      'base/third_party/dmg_fp/g_fmt.cc',
+      'base/third_party/icu/icu_utf.cc',
+      'base/third_party/nspr/prtime.cc',
+      'base/threading/post_task_and_reply_impl.cc',
+      'base/threading/scoped_blocking_call.cc',
+      'base/threading/sequence_local_storage_map.cc',
+      'base/threading/sequenced_task_runner_handle.cc',
+      'base/threading/simple_thread.cc',
+      'base/threading/thread.cc',
+      'base/threading/thread_checker_impl.cc',
+      'base/threading/thread_collision_warner.cc',
+      'base/threading/thread_id_name_manager.cc',
+      'base/threading/thread_local_storage.cc',
+      'base/threading/thread_restrictions.cc',
+      'base/threading/thread_task_runner_handle.cc',
+      'base/time/clock.cc',
+      'base/time/default_clock.cc',
+      'base/time/default_tick_clock.cc',
+      'base/time/tick_clock.cc',
+      'base/time/time.cc',
+      'base/timer/elapsed_timer.cc',
+      'base/timer/timer.cc',
+      'base/trace_event/category_registry.cc',
+      'base/trace_event/event_name_filter.cc',
+      'base/trace_event/heap_profiler_allocation_context.cc',
+      'base/trace_event/heap_profiler_allocation_context_tracker.cc',
+      'base/trace_event/heap_profiler_allocation_register.cc',
+      'base/trace_event/heap_profiler_event_filter.cc',
+      'base/trace_event/heap_profiler_heap_dump_writer.cc',
+      'base/trace_event/heap_profiler_serialization_state.cc',
+      'base/trace_event/heap_profiler_stack_frame_deduplicator.cc',
+      'base/trace_event/heap_profiler_type_name_deduplicator.cc',
+      'base/trace_event/malloc_dump_provider.cc',
+      'base/trace_event/memory_allocator_dump.cc',
+      'base/trace_event/memory_allocator_dump_guid.cc',
+      'base/trace_event/memory_dump_manager.cc',
+      'base/trace_event/memory_dump_provider_info.cc',
+      'base/trace_event/memory_dump_request_args.cc',
+      'base/trace_event/memory_dump_scheduler.cc',
+      'base/trace_event/memory_infra_background_whitelist.cc',
+      'base/trace_event/memory_peak_detector.cc',
+      'base/trace_event/memory_usage_estimator.cc',
+      'base/trace_event/process_memory_dump.cc',
+      'base/trace_event/sharded_allocation_register.cc',
+      'base/trace_event/trace_buffer.cc',
+      'base/trace_event/trace_config.cc',
+      'base/trace_event/trace_config_category_filter.cc',
+      'base/trace_event/trace_event_argument.cc',
+      'base/trace_event/trace_event_filter.cc',
+      'base/trace_event/trace_event_impl.cc',
+      'base/trace_event/trace_event_memory_overhead.cc',
+      'base/trace_event/trace_log.cc',
+      'base/trace_event/trace_log_constants.cc',
+      'base/trace_event/tracing_agent.cc',
+      'base/unguessable_token.cc',
+      'base/value_iterators.cc',
+      'base/values.cc',
+      'base/vlog.cc',
+  ])
+
+  if is_posix:
+    static_libraries['base']['sources'].extend([
+        'base/base_paths_posix.cc',
+        'base/debug/debugger_posix.cc',
+        'base/debug/stack_trace_posix.cc',
+        'base/files/file_enumerator_posix.cc',
+        'base/files/file_descriptor_watcher_posix.cc',
+        'base/files/file_posix.cc',
+        'base/files/file_util_posix.cc',
+        'base/files/memory_mapped_file_posix.cc',
+        'base/memory/shared_memory_helper.cc',
+        'base/message_loop/message_pump_libevent.cc',
+        'base/posix/file_descriptor_shuffle.cc',
+        'base/posix/global_descriptors.cc',
+        'base/posix/safe_strerror.cc',
+        'base/process/kill_posix.cc',
+        'base/process/process_handle_posix.cc',
+        'base/process/process_metrics_posix.cc',
+        'base/process/process_posix.cc',
+        'base/rand_util_posix.cc',
+        'base/strings/string16.cc',
+        'base/synchronization/condition_variable_posix.cc',
+        'base/synchronization/lock_impl_posix.cc',
+        'base/sys_info_posix.cc',
+        'base/task_scheduler/task_tracker_posix.cc',
+        'base/threading/platform_thread_internal_posix.cc',
+        'base/threading/platform_thread_posix.cc',
+        'base/threading/thread_local_storage_posix.cc',
+        'base/time/time_conversion_posix.cc',
+        'base/trace_event/heap_profiler_allocation_register_posix.cc',
+    ])
+    static_libraries['libevent'] = {
+        'sources': [
+            'base/third_party/libevent/buffer.c',
+            'base/third_party/libevent/evbuffer.c',
+            'base/third_party/libevent/evdns.c',
+            'base/third_party/libevent/event.c',
+            'base/third_party/libevent/event_tagging.c',
+            'base/third_party/libevent/evrpc.c',
+            'base/third_party/libevent/evutil.c',
+            'base/third_party/libevent/http.c',
+            'base/third_party/libevent/log.c',
+            'base/third_party/libevent/poll.c',
+            'base/third_party/libevent/select.c',
+            'base/third_party/libevent/signal.c',
+            'base/third_party/libevent/strlcpy.c',
+        ],
+        'tool': 'cc',
+        'include_dirs': [],
+        'cflags': cflags + ['-DHAVE_CONFIG_H'],
+    }
+
+  if is_linux or is_aix:
+    static_libraries['xdg_user_dirs'] = {
+        'sources': [
+            'base/third_party/xdg_user_dirs/xdg_user_dir_lookup.cc',
+        ],
+        'tool': 'cxx',
+    }
+    static_libraries['base']['sources'].extend([
+        'base/memory/shared_memory_handle_posix.cc',
+        'base/memory/shared_memory_posix.cc',
+        'base/nix/xdg_util.cc',
+        'base/process/internal_linux.cc',
+        'base/process/memory_linux.cc',
+        'base/process/process_handle_linux.cc',
+        'base/process/process_info_linux.cc',
+        'base/process/process_iterator_linux.cc',
+        'base/process/process_linux.cc',
+        'base/process/process_metrics_linux.cc',
+        'base/strings/sys_string_conversions_posix.cc',
+        'base/synchronization/waitable_event_posix.cc',
+        'base/sys_info_linux.cc',
+        'base/time/time_exploded_posix.cc',
+        'base/time/time_now_posix.cc',
+        'base/threading/platform_thread_linux.cc',
+    ])
+    if is_linux:
+      libcxx_root = SRC_ROOT + '/buildtools/third_party/libc++/trunk'
+      libcxxabi_root = SRC_ROOT + '/buildtools/third_party/libc++abi/trunk'
+      cflags_cc.extend([
+          '-nostdinc++',
+          '-isystem' + libcxx_root + '/include',
+          '-isystem' + libcxxabi_root + '/include',
+      ])
+      ldflags.extend(['-nodefaultlibs'])
+      libs.extend([
+          '-lc',
+          '-lgcc_s',
+          '-lm',
+          '-lpthread',
+      ])
+      static_libraries['libc++'] = {
+          'sources': [
+              libcxx_root + '/src/algorithm.cpp',
+              libcxx_root + '/src/any.cpp',
+              libcxx_root + '/src/bind.cpp',
+              libcxx_root + '/src/chrono.cpp',
+              libcxx_root + '/src/condition_variable.cpp',
+              libcxx_root + '/src/debug.cpp',
+              libcxx_root + '/src/exception.cpp',
+              libcxx_root + '/src/functional.cpp',
+              libcxx_root + '/src/future.cpp',
+              libcxx_root + '/src/hash.cpp',
+              libcxx_root + '/src/ios.cpp',
+              libcxx_root + '/src/iostream.cpp',
+              libcxx_root + '/src/locale.cpp',
+              libcxx_root + '/src/memory.cpp',
+              libcxx_root + '/src/mutex.cpp',
+              libcxx_root + '/src/new.cpp',
+              libcxx_root + '/src/optional.cpp',
+              libcxx_root + '/src/random.cpp',
+              libcxx_root + '/src/regex.cpp',
+              libcxx_root + '/src/shared_mutex.cpp',
+              libcxx_root + '/src/stdexcept.cpp',
+              libcxx_root + '/src/string.cpp',
+              libcxx_root + '/src/strstream.cpp',
+              libcxx_root + '/src/system_error.cpp',
+              libcxx_root + '/src/thread.cpp',
+              libcxx_root + '/src/typeinfo.cpp',
+              libcxx_root + '/src/utility.cpp',
+              libcxx_root + '/src/valarray.cpp',
+              libcxx_root + '/src/variant.cpp',
+              libcxx_root + '/src/vector.cpp',
+          ],
+          'tool': 'cxx',
+          'cflags': cflags + [
+              '-D_LIBCPP_NO_EXCEPTIONS',
+              '-D_LIBCPP_BUILDING_LIBRARY',
+              '-DLIBCXX_BUILDING_LIBCXXABI',
+          ]
+      }
+      static_libraries['libc++abi'] = {
+          'sources': [
+              libcxxabi_root + '/src/abort_message.cpp',
+              libcxxabi_root + '/src/cxa_aux_runtime.cpp',
+              libcxxabi_root + '/src/cxa_default_handlers.cpp',
+              libcxxabi_root + '/src/cxa_demangle.cpp',
+              libcxxabi_root + '/src/cxa_exception_storage.cpp',
+              libcxxabi_root + '/src/cxa_guard.cpp',
+              libcxxabi_root + '/src/cxa_handlers.cpp',
+              libcxxabi_root + '/src/cxa_noexception.cpp',
+              libcxxabi_root + '/src/cxa_unexpected.cpp',
+              libcxxabi_root + '/src/cxa_vector.cpp',
+              libcxxabi_root + '/src/cxa_virtual.cpp',
+              libcxxabi_root + '/src/fallback_malloc.cpp',
+              libcxxabi_root + '/src/private_typeinfo.cpp',
+              libcxxabi_root + '/src/stdlib_exception.cpp',
+              libcxxabi_root + '/src/stdlib_stdexcept.cpp',
+              libcxxabi_root + '/src/stdlib_typeinfo.cpp',
+          ],
+          'tool': 'cxx',
+          'cflags': cflags + [
+              '-DLIBCXXABI_SILENT_TERMINATE',
+              '-D_LIBCXXABI_NO_EXCEPTIONS',
+          ]
+      }
+      static_libraries['base']['sources'].extend([
+        'base/allocator/allocator_shim.cc',
+        'base/allocator/allocator_shim_default_dispatch_to_glibc.cc',
+      ])
+      libs.extend(['-lrt', '-latomic'])
+      static_libraries['libevent']['include_dirs'].extend([
+          os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'linux')
+      ])
+      static_libraries['libevent']['sources'].extend([
+         'base/third_party/libevent/epoll.c',
+      ])
+    else:
+      ldflags.extend(['-pthread'])
+      libs.extend(['-lrt'])
+      static_libraries['base']['sources'].extend([
+          'base/process/internal_aix.cc'
+      ])
+      static_libraries['libevent']['include_dirs'].extend([
+          os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'aix')
+      ])
+      static_libraries['libevent']['include_dirs'].extend([
+          os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'compat')
+      ])
+
+  if is_mac:
+    static_libraries['base']['sources'].extend([
+        'base/base_paths_mac.mm',
+        'base/files/file_util_mac.mm',
+        'base/mac/bundle_locations.mm',
+        'base/mac/call_with_eh_frame.cc',
+        'base/mac/call_with_eh_frame_asm.S',
+        'base/mac/foundation_util.mm',
+        'base/mac/mach_logging.cc',
+        'base/mac/scoped_mach_port.cc',
+        'base/mac/scoped_mach_vm.cc',
+        'base/mac/scoped_nsautorelease_pool.mm',
+        'base/memory/shared_memory_handle_mac.cc',
+        'base/memory/shared_memory_mac.cc',
+        'base/message_loop/message_pump_mac.mm',
+        'base/process/process_handle_mac.cc',
+        'base/process/process_info_mac.cc',
+        'base/process/process_iterator_mac.cc',
+        'base/process/process_metrics_mac.cc',
+        'base/strings/sys_string_conversions_mac.mm',
+        'base/synchronization/waitable_event_mac.cc',
+        'base/sys_info_mac.mm',
+        'base/time/time_exploded_posix.cc',
+        'base/time/time_mac.cc',
+        'base/threading/platform_thread_mac.mm',
+    ])
+    static_libraries['libevent']['include_dirs'].extend([
+        os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'mac')
+    ])
+    static_libraries['libevent']['sources'].extend([
+        'base/third_party/libevent/kqueue.c',
+    ])
+
+    libs.extend([
+        '-framework', 'AppKit',
+        '-framework', 'CoreFoundation',
+        '-framework', 'Foundation',
+        '-framework', 'Security',
+    ])
+
+  if is_win:
+    static_libraries['base']['sources'].extend([
+        "base/allocator/partition_allocator/address_space_randomization.cc",
+        'base/allocator/partition_allocator/page_allocator.cc',
+        "base/allocator/partition_allocator/spin_lock.cc",
+        'base/base_paths_win.cc',
+        'base/cpu.cc',
+        'base/debug/close_handle_hook_win.cc',
+        'base/debug/debugger.cc',
+        'base/debug/debugger_win.cc',
+        'base/debug/profiler.cc',
+        'base/debug/stack_trace_win.cc',
+        'base/file_version_info_win.cc',
+        'base/files/file_enumerator_win.cc',
+        'base/files/file_path_watcher_win.cc',
+        'base/files/file_util_win.cc',
+        'base/files/file_win.cc',
+        'base/files/memory_mapped_file_win.cc',
+        'base/guid.cc',
+        'base/logging_win.cc',
+        'base/memory/memory_pressure_monitor_win.cc',
+        'base/memory/shared_memory_handle_win.cc',
+        'base/memory/shared_memory_win.cc',
+        'base/message_loop/message_pump_win.cc',
+        'base/native_library_win.cc',
+        'base/power_monitor/power_monitor_device_source_win.cc',
+        'base/process/kill_win.cc',
+        'base/process/launch_win.cc',
+        'base/process/memory_win.cc',
+        'base/process/process_handle_win.cc',
+        'base/process/process_info_win.cc',
+        'base/process/process_iterator_win.cc',
+        'base/process/process_metrics_win.cc',
+        'base/process/process_win.cc',
+        'base/profiler/native_stack_sampler_win.cc',
+        'base/profiler/win32_stack_frame_unwinder.cc',
+        'base/rand_util_win.cc',
+        'base/strings/sys_string_conversions_win.cc',
+        'base/sync_socket_win.cc',
+        'base/synchronization/condition_variable_win.cc',
+        'base/synchronization/lock_impl_win.cc',
+        'base/synchronization/waitable_event_watcher_win.cc',
+        'base/synchronization/waitable_event_win.cc',
+        'base/sys_info_win.cc',
+        'base/threading/platform_thread_win.cc',
+        'base/threading/thread_local_storage_win.cc',
+        'base/time/time_win.cc',
+        'base/timer/hi_res_timer_manager_win.cc',
+        'base/trace_event/heap_profiler_allocation_register_win.cc',
+        'base/trace_event/trace_event_etw_export_win.cc',
+        'base/win/core_winrt_util.cc',
+        'base/win/enum_variant.cc',
+        'base/win/event_trace_controller.cc',
+        'base/win/event_trace_provider.cc',
+        'base/win/i18n.cc',
+        'base/win/iat_patch_function.cc',
+        'base/win/iunknown_impl.cc',
+        'base/win/message_window.cc',
+        'base/win/object_watcher.cc',
+        'base/win/pe_image.cc',
+        'base/win/process_startup_helper.cc',
+        'base/win/registry.cc',
+        'base/win/resource_util.cc',
+        'base/win/scoped_bstr.cc',
+        'base/win/scoped_com_initializer.cc',
+        'base/win/scoped_handle.cc',
+        'base/win/scoped_handle_verifier.cc',
+        'base/win/scoped_process_information.cc',
+        'base/win/scoped_variant.cc',
+        'base/win/scoped_winrt_initializer.cc',
+        'base/win/shortcut.cc',
+        'base/win/startup_information.cc',
+        'base/win/wait_chain.cc',
+        'base/win/win_util.cc',
+        'base/win/windows_version.cc',
+        'base/win/wrapped_window_proc.cc',
+    ])
+
+    libs.extend([
+        'advapi32.lib',
+        'dbghelp.lib',
+        'kernel32.lib',
+        'ole32.lib',
+        'shell32.lib',
+        'user32.lib',
+        'userenv.lib',
+        'version.lib',
+        'winmm.lib',
+        'ws2_32.lib',
+        'Shlwapi.lib',
+    ])
+
+  # we just build static libraries that GN needs
+  executables['gn']['libs'].extend(static_libraries.keys())
+
+  write_generic_ninja(path, static_libraries, executables, cc, cxx, ar, ld,
+                      cflags, cflags_cc, ldflags, include_dirs, libs)
+
+def build_gn_with_gn(temp_gn, build_dir, options):
+  gn_gen_args = options.gn_gen_args or ''
+  if not options.debug:
+    gn_gen_args += ' is_debug=false'
+  cmd = [temp_gn, 'gen', build_dir, '--args=%s' % gn_gen_args,
+          "--root="+SRC_ROOT
+         ]
+  check_call(cmd)
+
+  cmd = ['ninja', '-C', build_dir, '-w', 'dupbuild=err']
+  if options.verbose:
+    cmd.append('-v')
+  cmd.append('gn')
+  check_call(cmd)
+
+  # build.ninja currently refers back to gn from the temporary directory.
+  # Regenerate the build files using the gn we just built so that the reference
+  # gets updated to "./gn".
+  cmd = [os.path.join(build_dir, 'gn'), 'gen', build_dir,
+         '--args=%s' % gn_gen_args]
+  check_call(cmd)
+
+  if not options.debug and not is_win:
+    check_call(['strip', os.path.join(build_dir, 'gn')])
+
+
+if __name__ == '__main__':
+  sys.exit(main(sys.argv[1:]))
diff -Naur chromium-67.0.3396.62/tools/gn/BUILD.gn chromium-67.0.3396.62.patched/tools/gn/BUILD.gn
--- chromium-67.0.3396.62/tools/gn/BUILD.gn	2018-05-30 11:43:43.000000000 +0300
+++ chromium-67.0.3396.62.patched/tools/gn/BUILD.gn	2018-06-06 10:06:12.337134821 +0300
@@ -269,7 +269,6 @@
 
   deps = [
     ":gn_lib",
-    ":last_commit_position",
     "//base",
     "//build/config:exe_and_shlib_deps",
     "//build/win:default_exe_manifest",
diff -Naur chromium-67.0.3396.62/tools/gn/BUILD.gn.lastcommit chromium-67.0.3396.62.patched/tools/gn/BUILD.gn.lastcommit
--- chromium-67.0.3396.62/tools/gn/BUILD.gn.lastcommit	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/tools/gn/BUILD.gn.lastcommit	2018-05-30 11:43:43.000000000 +0300
@@ -0,0 +1,375 @@
+# Copyright (c) 2013 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/jumbo.gni")
+import("//testing/test.gni")
+import("//testing/libfuzzer/fuzzer_test.gni")
+
+defines = [ "GN_BUILD" ]
+
+jumbo_static_library("gn_lib") {
+  configs += [ "//build/config:precompiled_headers" ]
+
+  sources = [
+    "action_target_generator.cc",
+    "action_target_generator.h",
+    "action_values.cc",
+    "action_values.h",
+    "analyzer.cc",
+    "analyzer.h",
+    "args.cc",
+    "args.h",
+    "binary_target_generator.cc",
+    "binary_target_generator.h",
+    "build_settings.cc",
+    "build_settings.h",
+    "builder.cc",
+    "builder.h",
+    "builder_record.cc",
+    "builder_record.h",
+    "bundle_data.cc",
+    "bundle_data.h",
+    "bundle_data_target_generator.cc",
+    "bundle_data_target_generator.h",
+    "bundle_file_rule.cc",
+    "bundle_file_rule.h",
+    "c_include_iterator.cc",
+    "c_include_iterator.h",
+    "command_analyze.cc",
+    "command_args.cc",
+    "command_check.cc",
+    "command_clean.cc",
+    "command_desc.cc",
+    "command_format.cc",
+    "command_format.h",
+    "command_gen.cc",
+    "command_help.cc",
+    "command_ls.cc",
+    "command_path.cc",
+    "command_refs.cc",
+    "commands.cc",
+    "commands.h",
+    "config.cc",
+    "config.h",
+    "config_values.cc",
+    "config_values.h",
+    "config_values_extractors.cc",
+    "config_values_extractors.h",
+    "config_values_generator.cc",
+    "config_values_generator.h",
+    "copy_target_generator.cc",
+    "copy_target_generator.h",
+    "create_bundle_target_generator.cc",
+    "create_bundle_target_generator.h",
+    "deps_iterator.cc",
+    "deps_iterator.h",
+    "desc_builder.cc",
+    "desc_builder.h",
+    "eclipse_writer.cc",
+    "eclipse_writer.h",
+    "err.cc",
+    "err.h",
+    "escape.cc",
+    "escape.h",
+    "exec_process.cc",
+    "exec_process.h",
+    "filesystem_utils.cc",
+    "filesystem_utils.h",
+    "function_exec_script.cc",
+    "function_foreach.cc",
+    "function_forward_variables_from.cc",
+    "function_get_label_info.cc",
+    "function_get_path_info.cc",
+    "function_get_target_outputs.cc",
+    "function_process_file_template.cc",
+    "function_read_file.cc",
+    "function_rebase_path.cc",
+    "function_set_default_toolchain.cc",
+    "function_set_defaults.cc",
+    "function_template.cc",
+    "function_toolchain.cc",
+    "function_write_file.cc",
+    "functions.cc",
+    "functions.h",
+    "functions_target.cc",
+    "group_target_generator.cc",
+    "group_target_generator.h",
+    "header_checker.cc",
+    "header_checker.h",
+    "import_manager.cc",
+    "import_manager.h",
+    "inherited_libraries.cc",
+    "inherited_libraries.h",
+    "input_conversion.cc",
+    "input_conversion.h",
+    "input_file.cc",
+    "input_file.h",
+    "input_file_manager.cc",
+    "input_file_manager.h",
+    "item.cc",
+    "item.h",
+    "json_project_writer.cc",
+    "json_project_writer.h",
+    "label.cc",
+    "label.h",
+    "label_pattern.cc",
+    "label_pattern.h",
+    "label_ptr.h",
+    "lib_file.cc",
+    "lib_file.h",
+    "loader.cc",
+    "loader.h",
+    "location.cc",
+    "location.h",
+    "ninja_action_target_writer.cc",
+    "ninja_action_target_writer.h",
+    "ninja_binary_target_writer.cc",
+    "ninja_binary_target_writer.h",
+    "ninja_build_writer.cc",
+    "ninja_build_writer.h",
+    "ninja_bundle_data_target_writer.cc",
+    "ninja_bundle_data_target_writer.h",
+    "ninja_copy_target_writer.cc",
+    "ninja_copy_target_writer.h",
+    "ninja_create_bundle_target_writer.cc",
+    "ninja_create_bundle_target_writer.h",
+    "ninja_group_target_writer.cc",
+    "ninja_group_target_writer.h",
+    "ninja_target_writer.cc",
+    "ninja_target_writer.h",
+    "ninja_toolchain_writer.cc",
+    "ninja_toolchain_writer.h",
+    "ninja_utils.cc",
+    "ninja_utils.h",
+    "ninja_writer.cc",
+    "ninja_writer.h",
+    "operators.cc",
+    "operators.h",
+    "output_file.cc",
+    "output_file.h",
+    "parse_node_value_adapter.cc",
+    "parse_node_value_adapter.h",
+    "parse_tree.cc",
+    "parse_tree.h",
+    "parser.cc",
+    "parser.h",
+    "path_output.cc",
+    "path_output.h",
+    "pattern.cc",
+    "pattern.h",
+    "pool.cc",
+    "pool.h",
+    "qt_creator_writer.cc",
+    "qt_creator_writer.h",
+    "runtime_deps.cc",
+    "runtime_deps.h",
+    "scheduler.cc",
+    "scheduler.h",
+    "scope.cc",
+    "scope.h",
+    "scope_per_file_provider.cc",
+    "scope_per_file_provider.h",
+    "settings.cc",
+    "settings.h",
+    "setup.cc",
+    "setup.h",
+    "source_dir.cc",
+    "source_dir.h",
+    "source_file.cc",
+    "source_file.h",
+    "source_file_type.cc",
+    "source_file_type.h",
+    "standard_out.cc",
+    "standard_out.h",
+    "string_utils.cc",
+    "string_utils.h",
+    "substitution_list.cc",
+    "substitution_list.h",
+    "substitution_pattern.cc",
+    "substitution_pattern.h",
+    "substitution_type.cc",
+    "substitution_type.h",
+    "substitution_writer.cc",
+    "substitution_writer.h",
+    "switches.cc",
+    "switches.h",
+    "target.cc",
+    "target.h",
+    "target_generator.cc",
+    "target_generator.h",
+    "template.cc",
+    "template.h",
+    "token.cc",
+    "token.h",
+    "tokenizer.cc",
+    "tokenizer.h",
+    "tool.cc",
+    "tool.h",
+    "toolchain.cc",
+    "toolchain.h",
+    "trace.cc",
+    "trace.h",
+    "unique_vector.h",
+    "value.cc",
+    "value.h",
+    "value_extractors.cc",
+    "value_extractors.h",
+    "variables.cc",
+    "variables.h",
+    "visibility.cc",
+    "visibility.h",
+    "visual_studio_utils.cc",
+    "visual_studio_utils.h",
+    "visual_studio_writer.cc",
+    "visual_studio_writer.h",
+    "xcode_object.cc",
+    "xcode_object.h",
+    "xcode_writer.cc",
+    "xcode_writer.h",
+    "xml_element_writer.cc",
+    "xml_element_writer.h",
+  ]
+
+  deps = [
+    "//base",
+    "//base/third_party/dynamic_annotations",
+  ]
+}
+
+action("last_commit_position") {
+  script = "last_commit_position.py"
+
+  # This dependency forces a re-run when the code is synced.
+  inputs = [
+    "//build/util/LASTCHANGE",
+  ]
+
+  outfile = "$target_gen_dir/last_commit_position.h"
+  outputs = [
+    outfile,
+  ]
+
+  args = [
+    rebase_path("//", root_build_dir),
+    rebase_path(outfile, root_build_dir),
+    "TOOLS_GN_LAST_COMMIT_POSITION_H_",
+  ]
+}
+
+# Note for Windows debugging: GN is super-multithreaded and uses a lot of STL.
+# Iterator debugging on Windows does locking for every access, which ends up
+# slowing down debug runtime from 0:36 to 9:40. If you want to run debug builds
+# of GN over the large Chrome build, you will want to set the arg:
+#   enable_iterator_debugging = false
+executable("gn") {
+  sources = [
+    "gn_main.cc",
+  ]
+
+  deps = [
+    ":gn_lib",
+    ":last_commit_position",
+    "//base",
+    "//build/config:exe_and_shlib_deps",
+    "//build/win:default_exe_manifest",
+  ]
+}
+
+test("gn_unittests") {
+  deps = [
+    ":gn_unittests_sources",
+  ]
+
+  data = [
+    "format_test_data/",
+  ]
+}
+
+jumbo_source_set("gn_unittests_sources") {
+  testonly = true
+
+  sources = [
+    "action_target_generator_unittest.cc",
+    "analyzer_unittest.cc",
+    "args_unittest.cc",
+    "builder_unittest.cc",
+    "c_include_iterator_unittest.cc",
+    "command_format_unittest.cc",
+    "config_unittest.cc",
+    "config_values_extractors_unittest.cc",
+    "escape_unittest.cc",
+    "exec_process_unittest.cc",
+    "filesystem_utils_unittest.cc",
+    "function_foreach_unittest.cc",
+    "function_forward_variables_from_unittest.cc",
+    "function_get_label_info_unittest.cc",
+    "function_get_path_info_unittest.cc",
+    "function_get_target_outputs_unittest.cc",
+    "function_process_file_template_unittest.cc",
+    "function_rebase_path_unittest.cc",
+    "function_template_unittest.cc",
+    "function_toolchain_unittest.cc",
+    "function_write_file_unittest.cc",
+    "functions_target_unittest.cc",
+    "functions_unittest.cc",
+    "header_checker_unittest.cc",
+    "inherited_libraries_unittest.cc",
+    "input_conversion_unittest.cc",
+    "label_pattern_unittest.cc",
+    "label_unittest.cc",
+    "loader_unittest.cc",
+    "ninja_action_target_writer_unittest.cc",
+    "ninja_binary_target_writer_unittest.cc",
+    "ninja_build_writer_unittest.cc",
+    "ninja_bundle_data_target_writer_unittest.cc",
+    "ninja_copy_target_writer_unittest.cc",
+    "ninja_create_bundle_target_writer_unittest.cc",
+    "ninja_group_target_writer_unittest.cc",
+    "ninja_target_writer_unittest.cc",
+    "ninja_toolchain_writer_unittest.cc",
+    "operators_unittest.cc",
+    "parse_tree_unittest.cc",
+    "parser_unittest.cc",
+    "path_output_unittest.cc",
+    "pattern_unittest.cc",
+    "runtime_deps_unittest.cc",
+    "scope_per_file_provider_unittest.cc",
+    "scope_unittest.cc",
+    "source_dir_unittest.cc",
+    "source_file_unittest.cc",
+    "string_utils_unittest.cc",
+    "substitution_pattern_unittest.cc",
+    "substitution_writer_unittest.cc",
+    "target_unittest.cc",
+    "template_unittest.cc",
+    "test_with_scheduler.cc",
+    "test_with_scheduler.h",
+    "test_with_scope.cc",
+    "test_with_scope.h",
+    "tokenizer_unittest.cc",
+    "unique_vector_unittest.cc",
+    "value_unittest.cc",
+    "visibility_unittest.cc",
+    "visual_studio_utils_unittest.cc",
+    "visual_studio_writer_unittest.cc",
+    "xcode_object_unittest.cc",
+    "xml_element_writer_unittest.cc",
+  ]
+
+  public_deps = [
+    ":gn_lib",
+    "//base/test:run_all_unittests",
+    "//base/test:test_support",
+    "//testing/gtest",
+  ]
+}
+
+fuzzer_test("gn_parser_fuzzer") {
+  sources = [
+    "parser_fuzzer.cc",
+  ]
+  deps = [
+    ":gn_lib",
+  ]
+}
diff -Naur chromium-67.0.3396.62/tools/gn/gn_main.cc chromium-67.0.3396.62.patched/tools/gn/gn_main.cc
--- chromium-67.0.3396.62/tools/gn/gn_main.cc	2018-05-30 11:43:43.000000000 +0300
+++ chromium-67.0.3396.62.patched/tools/gn/gn_main.cc	2018-06-06 10:06:12.337134821 +0300
@@ -19,13 +19,7 @@
 #include "tools/gn/standard_out.h"
 #include "tools/gn/switches.h"
 
-// Only the GN-generated build makes this header for now.
-// TODO(brettw) consider adding this if we need it in GYP.
-#if defined(GN_BUILD)
-#include "tools/gn/last_commit_position.h"
-#else
 #define LAST_COMMIT_POSITION "UNKNOWN"
-#endif
 
 namespace {
 
diff -Naur chromium-67.0.3396.62/tools/gn/gn_main.cc.lastcommit chromium-67.0.3396.62.patched/tools/gn/gn_main.cc.lastcommit
--- chromium-67.0.3396.62/tools/gn/gn_main.cc.lastcommit	1970-01-01 03:00:00.000000000 +0300
+++ chromium-67.0.3396.62.patched/tools/gn/gn_main.cc.lastcommit	2018-05-30 11:43:43.000000000 +0300
@@ -0,0 +1,144 @@
+// Copyright (c) 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include <algorithm>
+#include <string>
+
+#include "base/at_exit.h"
+#include "base/command_line.h"
+#include "base/message_loop/message_loop.h"
+#include "base/strings/string_number_conversions.h"
+#include "base/strings/utf_string_conversions.h"
+#include "base/sys_info.h"
+#include "base/task_scheduler/task_scheduler.h"
+#include "build/build_config.h"
+#include "tools/gn/commands.h"
+#include "tools/gn/err.h"
+#include "tools/gn/location.h"
+#include "tools/gn/standard_out.h"
+#include "tools/gn/switches.h"
+
+// Only the GN-generated build makes this header for now.
+// TODO(brettw) consider adding this if we need it in GYP.
+#if defined(GN_BUILD)
+#include "tools/gn/last_commit_position.h"
+#else
+#define LAST_COMMIT_POSITION "UNKNOWN"
+#endif
+
+namespace {
+
+std::vector<std::string> GetArgs(const base::CommandLine& cmdline) {
+  base::CommandLine::StringVector in_args = cmdline.GetArgs();
+#if defined(OS_WIN)
+  std::vector<std::string> out_args;
+  for (const auto& arg : in_args)
+    out_args.push_back(base::WideToUTF8(arg));
+  return out_args;
+#else
+  return in_args;
+#endif
+}
+
+int GetThreadCount() {
+  std::string thread_count =
+      base::CommandLine::ForCurrentProcess()->GetSwitchValueASCII(
+          switches::kThreads);
+
+  // See if an override was specified on the command line.
+  int result;
+  if (!thread_count.empty() && base::StringToInt(thread_count, &result) &&
+      result >= 1) {
+    return result;
+  }
+
+  // Base the default number of worker threads on number of cores in the
+  // system. When building large projects, the speed can be limited by how fast
+  // the main thread can dispatch work and connect the dependency graph. If
+  // there are too many worker threads, the main thread can be starved and it
+  // will run slower overall.
+  //
+  // One less worker thread than the number of physical CPUs seems to be a
+  // good value, both theoretically and experimentally. But always use at
+  // least some workers to prevent us from being too sensitive to I/O latency
+  // on low-end systems.
+  //
+  // The minimum thread count is based on measuring the optimal threads for the
+  // Chrome build on a several-year-old 4-core MacBook.
+  // Almost all CPUs now are hyperthreaded.
+  int num_cores = base::SysInfo::NumberOfProcessors() / 2;
+  return std::max(num_cores - 1, 8);
+}
+
+void StartTaskScheduler() {
+  constexpr base::TimeDelta kSuggestedReclaimTime =
+      base::TimeDelta::FromSeconds(30);
+
+  constexpr int kBackgroundMaxThreads = 1;
+  constexpr int kBackgroundBlockingMaxThreads = 2;
+  const int kForegroundMaxThreads =
+      std::max(1, base::SysInfo::NumberOfProcessors());
+  const int foreground_blocking_max_threads = GetThreadCount();
+
+  base::TaskScheduler::Create("gn");
+  base::TaskScheduler::GetInstance()->Start(
+      {{kBackgroundMaxThreads, kSuggestedReclaimTime},
+       {kBackgroundBlockingMaxThreads, kSuggestedReclaimTime},
+       {kForegroundMaxThreads, kSuggestedReclaimTime},
+       {foreground_blocking_max_threads, kSuggestedReclaimTime}});
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  base::AtExitManager at_exit;
+#if defined(OS_WIN)
+  base::CommandLine::set_slash_is_not_a_switch();
+#endif
+  base::CommandLine::Init(argc, argv);
+
+  const base::CommandLine& cmdline = *base::CommandLine::ForCurrentProcess();
+  std::vector<std::string> args = GetArgs(cmdline);
+
+  std::string command;
+  if (cmdline.HasSwitch("help") || cmdline.HasSwitch("h")) {
+    // Make "-h" and "--help" default to help command.
+    command = commands::kHelp;
+  } else if (cmdline.HasSwitch(switches::kVersion)) {
+    // Make "--version" print the version and exit.
+    OutputString(std::string(LAST_COMMIT_POSITION) + "\n");
+    exit(0);
+  } else if (args.empty()) {
+    // No command, print error and exit.
+    Err(Location(), "No command specified.",
+        "Most commonly you want \"gn gen <out_dir>\" to make a build dir.\n"
+        "Or try \"gn help\" for more commands.").PrintToStdout();
+    return 1;
+  } else {
+    command = args[0];
+    args.erase(args.begin());
+  }
+
+  const commands::CommandInfoMap& command_map = commands::GetCommands();
+  commands::CommandInfoMap::const_iterator found_command =
+      command_map.find(command);
+
+  int retval;
+  if (found_command != command_map.end()) {
+    base::MessageLoop message_loop;
+    StartTaskScheduler();
+    retval = found_command->second.runner(args);
+    base::TaskScheduler::GetInstance()->Shutdown();
+  } else {
+    Err(Location(), "Command \"" + command + "\" unknown.").PrintToStdout();
+    OutputString(
+        "Available commands (type \"gn help <command>\" for more details):\n");
+    for (const auto& cmd : commands::GetCommands())
+      PrintShortHelp(cmd.second.help_short);
+
+    retval = 1;
+  }
+
+  exit(retval);  // Don't free memory, it can be really slow!
+}

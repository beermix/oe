diff -Naur chromium-65.0.3325.181-orig/base/numerics/safe_math_shared_impl.h chromium-65.0.3325.181.patched/base/numerics/safe_math_shared_impl.h
--- chromium-65.0.3325.181-orig/base/numerics/safe_math_shared_impl.h	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/numerics/safe_math_shared_impl.h	2018-04-27 11:31:20.587828309 +0300
@@ -21,8 +21,7 @@
 #if !defined(__native_client__) &&                         \
     ((defined(__clang__) &&                                \
       ((__clang_major__ > 3) ||                            \
-       (__clang_major__ == 3 && __clang_minor__ >= 4))) || \
-     (defined(__GNUC__) && __GNUC__ >= 5))
+       (__clang_major__ == 3 && __clang_minor__ >= 4))))
 #include "base/numerics/safe_math_clang_gcc_impl.h"
 #define BASE_HAS_OPTIMIZED_SAFE_MATH (1)
 #else
diff -Naur chromium-65.0.3325.181-orig/base/numerics/safe_math_shared_impl.h.nogccoptmath chromium-65.0.3325.181.patched/base/numerics/safe_math_shared_impl.h.nogccoptmath
--- chromium-65.0.3325.181-orig/base/numerics/safe_math_shared_impl.h.nogccoptmath	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/numerics/safe_math_shared_impl.h.nogccoptmath	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,237 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_NUMERICS_SAFE_MATH_SHARED_IMPL_H_
+#define BASE_NUMERICS_SAFE_MATH_SHARED_IMPL_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <cassert>
+#include <climits>
+#include <cmath>
+#include <cstdlib>
+#include <limits>
+#include <type_traits>
+
+#include "base/numerics/safe_conversions.h"
+
+// Where available use builtin math overflow support on Clang and GCC.
+#if !defined(__native_client__) &&                         \
+    ((defined(__clang__) &&                                \
+      ((__clang_major__ > 3) ||                            \
+       (__clang_major__ == 3 && __clang_minor__ >= 4))) || \
+     (defined(__GNUC__) && __GNUC__ >= 5))
+#include "base/numerics/safe_math_clang_gcc_impl.h"
+#define BASE_HAS_OPTIMIZED_SAFE_MATH (1)
+#else
+#define BASE_HAS_OPTIMIZED_SAFE_MATH (0)
+#endif
+
+namespace base {
+namespace internal {
+
+// These are the non-functioning boilerplate implementations of the optimized
+// safe math routines.
+#if !BASE_HAS_OPTIMIZED_SAFE_MATH
+template <typename T, typename U>
+struct CheckedAddFastOp {
+  static const bool is_supported = false;
+  template <typename V>
+  static constexpr bool Do(T, U, V*) {
+    // Force a compile failure if instantiated.
+    return CheckOnFailure::template HandleFailure<bool>();
+  }
+};
+
+template <typename T, typename U>
+struct CheckedSubFastOp {
+  static const bool is_supported = false;
+  template <typename V>
+  static constexpr bool Do(T, U, V*) {
+    // Force a compile failure if instantiated.
+    return CheckOnFailure::template HandleFailure<bool>();
+  }
+};
+
+template <typename T, typename U>
+struct CheckedMulFastOp {
+  static const bool is_supported = false;
+  template <typename V>
+  static constexpr bool Do(T, U, V*) {
+    // Force a compile failure if instantiated.
+    return CheckOnFailure::template HandleFailure<bool>();
+  }
+};
+
+template <typename T, typename U>
+struct ClampedAddFastOp {
+  static const bool is_supported = false;
+  template <typename V>
+  static constexpr V Do(T, U) {
+    // Force a compile failure if instantiated.
+    return CheckOnFailure::template HandleFailure<V>();
+  }
+};
+
+template <typename T, typename U>
+struct ClampedSubFastOp {
+  static const bool is_supported = false;
+  template <typename V>
+  static constexpr V Do(T, U) {
+    // Force a compile failure if instantiated.
+    return CheckOnFailure::template HandleFailure<V>();
+  }
+};
+
+template <typename T, typename U>
+struct ClampedMulFastOp {
+  static const bool is_supported = false;
+  template <typename V>
+  static constexpr V Do(T, U) {
+    // Force a compile failure if instantiated.
+    return CheckOnFailure::template HandleFailure<V>();
+  }
+};
+
+template <typename T>
+struct ClampedNegFastOp {
+  static const bool is_supported = false;
+  static constexpr T Do(T) {
+    // Force a compile failure if instantiated.
+    return CheckOnFailure::template HandleFailure<T>();
+  }
+};
+#endif  // BASE_HAS_OPTIMIZED_SAFE_MATH
+#undef BASE_HAS_OPTIMIZED_SAFE_MATH
+
+// This is used for UnsignedAbs, where we need to support floating-point
+// template instantiations even though we don't actually support the operations.
+// However, there is no corresponding implementation of e.g. SafeUnsignedAbs,
+// so the float versions will not compile.
+template <typename Numeric,
+          bool IsInteger = std::is_integral<Numeric>::value,
+          bool IsFloat = std::is_floating_point<Numeric>::value>
+struct UnsignedOrFloatForSize;
+
+template <typename Numeric>
+struct UnsignedOrFloatForSize<Numeric, true, false> {
+  using type = typename std::make_unsigned<Numeric>::type;
+};
+
+template <typename Numeric>
+struct UnsignedOrFloatForSize<Numeric, false, true> {
+  using type = Numeric;
+};
+
+// Wrap the unary operations to allow SFINAE when instantiating integrals versus
+// floating points. These don't perform any overflow checking. Rather, they
+// exhibit well-defined overflow semantics and rely on the caller to detect
+// if an overflow occured.
+
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+constexpr T NegateWrapper(T value) {
+  using UnsignedT = typename std::make_unsigned<T>::type;
+  // This will compile to a NEG on Intel, and is normal negation on ARM.
+  return static_cast<T>(UnsignedT(0) - static_cast<UnsignedT>(value));
+}
+
+template <
+    typename T,
+    typename std::enable_if<std::is_floating_point<T>::value>::type* = nullptr>
+constexpr T NegateWrapper(T value) {
+  return -value;
+}
+
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+constexpr typename std::make_unsigned<T>::type InvertWrapper(T value) {
+  return ~value;
+}
+
+template <typename T,
+          typename std::enable_if<std::is_integral<T>::value>::type* = nullptr>
+constexpr T AbsWrapper(T value) {
+  return static_cast<T>(SafeUnsignedAbs(value));
+}
+
+template <
+    typename T,
+    typename std::enable_if<std::is_floating_point<T>::value>::type* = nullptr>
+constexpr T AbsWrapper(T value) {
+  return value < 0 ? -value : value;
+}
+
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R>
+struct MathWrapper {
+  using math = M<typename UnderlyingType<L>::type,
+                 typename UnderlyingType<R>::type,
+                 void>;
+  using type = typename math::result_type;
+};
+
+// These variadic templates work out the return types.
+// TODO(jschuh): Rip all this out once we have C++14 non-trailing auto support.
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R,
+          typename... Args>
+struct ResultType;
+
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R>
+struct ResultType<M, L, R> {
+  using type = typename MathWrapper<M, L, R>::type;
+};
+
+template <template <typename, typename, typename> class M,
+          typename L,
+          typename R,
+          typename... Args>
+struct ResultType {
+  using type =
+      typename ResultType<M, typename ResultType<M, L, R>::type, Args...>::type;
+};
+
+// The following macros are just boilerplate for the standard arithmetic
+// operator overloads and variadic function templates. A macro isn't the nicest
+// solution, but it beats rewriting these over and over again.
+#define BASE_NUMERIC_ARITHMETIC_VARIADIC(CLASS, CL_ABBR, OP_NAME)       \
+  template <typename L, typename R, typename... Args>                   \
+  constexpr CLASS##Numeric<                                             \
+      typename ResultType<CLASS##OP_NAME##Op, L, R, Args...>::type>     \
+      CL_ABBR##OP_NAME(const L lhs, const R rhs, const Args... args) {  \
+    return CL_ABBR##MathOp<CLASS##OP_NAME##Op, L, R, Args...>(lhs, rhs, \
+                                                              args...); \
+  }
+
+#define BASE_NUMERIC_ARITHMETIC_OPERATORS(CLASS, CL_ABBR, OP_NAME, OP, CMP_OP) \
+  /* Binary arithmetic operator for all CLASS##Numeric operations. */          \
+  template <typename L, typename R,                                            \
+            typename std::enable_if<Is##CLASS##Op<L, R>::value>::type* =       \
+                nullptr>                                                       \
+  constexpr CLASS##Numeric<                                                    \
+      typename MathWrapper<CLASS##OP_NAME##Op, L, R>::type>                    \
+  operator OP(const L lhs, const R rhs) {                                      \
+    return decltype(lhs OP rhs)::template MathOp<CLASS##OP_NAME##Op>(lhs,      \
+                                                                     rhs);     \
+  }                                                                            \
+  /* Assignment arithmetic operator implementation from CLASS##Numeric. */     \
+  template <typename L>                                                        \
+  template <typename R>                                                        \
+  constexpr CLASS##Numeric<L>& CLASS##Numeric<L>::operator CMP_OP(             \
+      const R rhs) {                                                           \
+    return MathOp<CLASS##OP_NAME##Op>(rhs);                                    \
+  }                                                                            \
+  /* Variadic arithmetic functions that return CLASS##Numeric. */              \
+  BASE_NUMERIC_ARITHMETIC_VARIADIC(CLASS, CL_ABBR, OP_NAME)
+
+}  // namespace internal
+}  // namespace base
+
+#endif  // BASE_NUMERICS_SAFE_MATH_SHARED_IMPL_H_
diff -Naur chromium-65.0.3325.181-orig/base/optional.h.affirmative chromium-65.0.3325.181.patched/base/optional.h.affirmative
--- chromium-65.0.3325.181-orig/base/optional.h.affirmative	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/optional.h.affirmative	2018-04-27 11:31:20.639827760 +0300
@@ -0,0 +1,657 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_OPTIONAL_H_
+#define BASE_OPTIONAL_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "base/logging.h"
+#include "base/template_util.h"
+
+namespace base {
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place_t
+struct in_place_t {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt_t
+struct nullopt_t {
+  constexpr explicit nullopt_t(int) {}
+};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place
+constexpr in_place_t in_place = {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt
+constexpr nullopt_t nullopt(0);
+
+namespace internal {
+
+template <typename T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorageBase {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_null_(false), value_(std::forward<Args>(args)...) {}
+
+  // When T is not trivially destructible we must call its
+  // destructor before deallocating its memory.
+  // Note that this hides the (implicitly declared) move constructor, which
+  // would be used for constexpr move constructor in OptionalStorage<T>.
+  // It is needed iff T is trivially move constructible. However, the current
+  // is_trivially_{copy,move}_constructible implementation requires
+  // is_trivially_destructible (which looks a bug, cf:
+  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51452 and
+  // http://cplusplus.github.io/LWG/lwg-active.html#2116), so it is not
+  // necessary for this case at the moment. Please see also the destructor
+  // comment in "is_trivially_destructible = true" specialization below.
+  ~OptionalStorageBase() {
+    if (!is_null_)
+      value_.~T();
+  }
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(is_null_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_null_ = false;
+  }
+
+  bool is_null_ = true;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+template <typename T>
+struct OptionalStorageBase<T, true /* trivially destructible */> {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_null_(false), value_(std::forward<Args>(args)...) {}
+
+  // When T is trivially destructible (i.e. its destructor does nothing) there
+  // is no need to call it. Implicitly defined destructor is trivial, because
+  // both members (bool and union containing only variants which are trivially
+  // destructible) are trivially destructible.
+  // Explicitly-defaulted destructor is also trivial, but do not use it here,
+  // because it hides the implicit move constructor. It is needed to implement
+  // constexpr move constructor in OptionalStorage iff T is trivially move
+  // constructible. Note that, if T is trivially move constructible, the move
+  // constructor of OptionalStorageBase<T> is also implicitly defined and it is
+  // trivially move constructor. If T is not trivially move constructible,
+  // "not declaring move constructor without destructor declaration" here means
+  // "delete move constructor", which works because any move constructor of
+  // OptionalStorage will not refer to it in that case.
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(is_null_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_null_ = false;
+  }
+
+  bool is_null_ = true;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+// Implement conditional constexpr copy and move constructors. These are
+// constexpr if is_trivially_{copy,move}_constructible<T>::value is true
+// respectively. If each is true, the corresponding constructor is defined as
+// "= default;", which generates a constexpr constructor (In this case,
+// the condition of constexpr-ness is satisfied because the base class also has
+// compiler generated constexpr {copy,move} constructors). Note that
+// placement-new is prohibited in constexpr.
+template <typename T,
+          bool = is_trivially_copy_constructible<T>::value,
+          bool = std::is_trivially_move_constructible<T>::value>
+struct OptionalStorage : OptionalStorageBase<T> {
+  // This is no trivially {copy,move} constructible case. Other cases are
+  // defined below as specializations.
+
+  // Accessing the members of template base class requires explicit
+  // declaration.
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+
+  // Inherit constructors (specifically, the in_place constructor).
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  // User defined constructor deletes the default constructor.
+  // Define it explicitly.
+  OptionalStorage() = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (!other.is_null_)
+      Init(other.value_);
+  }
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (!other.is_null_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       false /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(const OptionalStorage& other) = default;
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (!other.is_null_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       false /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(OptionalStorage&& other) = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (!other.is_null_)
+      Init(other.value_);
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  // If both trivially {copy,move} constructible are true, it is not necessary
+  // to use user-defined constructors. So, just inheriting constructors
+  // from the base class works.
+  using OptionalStorageBase<T>::OptionalStorageBase;
+};
+
+// Base class to support conditionally usable copy-/move- constructors
+// and assign operators.
+template <typename T>
+class OptionalBase {
+  // This class provides implementation rather than public API, so everything
+  // should be hidden. Often we use composition, but we cannot in this case
+  // because of C++ language restriction.
+ protected:
+  constexpr OptionalBase() = default;
+  constexpr OptionalBase(const OptionalBase& other) = default;
+  constexpr OptionalBase(OptionalBase&& other) = default;
+
+  template <class... Args>
+  constexpr explicit OptionalBase(in_place_t, Args&&... args)
+      : storage_(in_place, std::forward<Args>(args)...) {}
+
+  ~OptionalBase() = default;
+
+  OptionalBase& operator=(const OptionalBase& other) {
+    if (other.storage_.is_null_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(other.storage_.value_);
+    return *this;
+  }
+
+  OptionalBase& operator=(OptionalBase&& other) {
+    if (other.storage_.is_null_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(std::move(other.storage_.value_));
+    return *this;
+  }
+
+  void InitOrAssign(const T& value) {
+    if (storage_.is_null_)
+      storage_.Init(value);
+    else
+      storage_.value_ = value;
+  }
+
+  void InitOrAssign(T&& value) {
+    if (storage_.is_null_)
+      storage_.Init(std::move(value));
+    else
+      storage_.value_ = std::move(value);
+  }
+
+  void FreeIfNeeded() {
+    if (storage_.is_null_)
+      return;
+    storage_.value_.~T();
+    storage_.is_null_ = true;
+  }
+
+  OptionalStorage<T> storage_;
+};
+
+}  // namespace internal
+
+// base::Optional is a Chromium version of the C++17 optional class:
+// std::optional documentation:
+// http://en.cppreference.com/w/cpp/utility/optional
+// Chromium documentation:
+// https://chromium.googlesource.com/chromium/src/+/master/docs/optional.md
+//
+// These are the differences between the specification and the implementation:
+// - Constructors do not use 'constexpr' as it is a C++14 extension.
+// - 'constexpr' might be missing in some places for reasons specified locally.
+// - No exceptions are thrown, because they are banned from Chromium.
+// - All the non-members are in the 'base' namespace instead of 'std'.
+template <typename T>
+class Optional : public internal::OptionalBase<T> {
+ public:
+  using value_type = T;
+
+  // Defer default/copy/move constructor implementation to OptionalBase.
+  // TODO(hidehiko): Implement conditional enabling.
+  constexpr Optional() = default;
+  constexpr Optional(const Optional& other) = default;
+  constexpr Optional(Optional&& other) = default;
+
+  constexpr Optional(nullopt_t) {}
+
+  constexpr Optional(const T& value)
+      : internal::OptionalBase<T>(in_place, value) {}
+
+  constexpr Optional(T&& value)
+      : internal::OptionalBase<T>(in_place, std::move(value)) {}
+
+  template <class... Args>
+  constexpr explicit Optional(in_place_t, Args&&... args)
+      : internal::OptionalBase<T>(in_place, std::forward<Args>(args)...) {}
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  constexpr explicit Optional(in_place_t,
+                              std::initializer_list<U> il,
+                              Args&&... args)
+      : internal::OptionalBase<T>(in_place, il, std::forward<Args>(args)...) {}
+
+  ~Optional() = default;
+
+  // Defer copy-/move- assign operator implementation to OptionalBase.
+  // TOOD(hidehiko): Implement conditional enabling.
+  Optional& operator=(const Optional& other) = default;
+  Optional& operator=(Optional&& other) = default;
+
+  Optional& operator=(nullopt_t) {
+    FreeIfNeeded();
+    return *this;
+  }
+
+  template <class U>
+  typename std::enable_if<std::is_same<std::decay_t<U>, T>::value,
+                          Optional&>::type
+  operator=(U&& value) {
+    InitOrAssign(std::forward<U>(value));
+    return *this;
+  }
+
+  constexpr const T* operator->() const {
+    DCHECK(!storage_.is_null_);
+    return &value();
+  }
+
+  constexpr T* operator->() {
+    DCHECK(!storage_.is_null_);
+    return &value();
+  }
+
+  constexpr const T& operator*() const& { return value(); }
+
+  constexpr T& operator*() & { return value(); }
+
+  constexpr const T&& operator*() const&& { return std::move(value()); }
+
+  constexpr T&& operator*() && { return std::move(value()); }
+
+  constexpr explicit operator bool() const { return !storage_.is_null_; }
+
+  constexpr bool has_value() const { return !storage_.is_null_; }
+
+  constexpr T& value() & {
+    DCHECK(!storage_.is_null_);
+    return storage_.value_;
+  }
+
+  constexpr const T& value() const & {
+    DCHECK(!storage_.is_null_);
+    return storage_.value_;
+  }
+
+  constexpr T&& value() && {
+    DCHECK(!storage_.is_null_);
+    return std::move(storage_.value_);
+  }
+
+  constexpr const T&& value() const && {
+    DCHECK(!storage_.is_null_);
+    return std::move(storage_.value_);
+  }
+
+  template <class U>
+  constexpr T value_or(U&& default_value) const& {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_copy_constructible<T>::value,
+    //               "T must be copy constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_null_ ? static_cast<T>(std::forward<U>(default_value))
+                             : value();
+  }
+
+  template <class U>
+  T value_or(U&& default_value) && {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_move_constructible<T>::value,
+    //               "T must be move constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_null_ ? static_cast<T>(std::forward<U>(default_value))
+                             : std::move(value());
+  }
+
+  void swap(Optional& other) {
+    if (storage_.is_null_ && other.storage_.is_null_)
+      return;
+
+    if (storage_.is_null_ != other.storage_.is_null_) {
+      if (storage_.is_null_) {
+        storage_.Init(std::move(other.storage_.value_));
+        other.FreeIfNeeded();
+      } else {
+        other.storage_.Init(std::move(storage_.value_));
+        FreeIfNeeded();
+      }
+      return;
+    }
+
+    DCHECK(!storage_.is_null_ && !other.storage_.is_null_);
+    using std::swap;
+    swap(**this, *other);
+  }
+
+  void reset() {
+    FreeIfNeeded();
+  }
+
+  template <class... Args>
+  void emplace(Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(std::forward<Args>(args)...);
+  }
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(il, std::forward<Args>(args)...);
+    return storage_.value_;
+  }
+
+ private:
+  // Accessing template base class's protected member needs explicit
+  // declaration to do so.
+  using internal::OptionalBase<T>::FreeIfNeeded;
+  using internal::OptionalBase<T>::InitOrAssign;
+  using internal::OptionalBase<T>::storage_;
+};
+
+// Here after defines comparation operators. The definition follows
+// http://en.cppreference.com/w/cpp/utility/optional/operator_cmp
+// while bool() casting is replaced by has_value() to meet the chromium
+// style guide.
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs == *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs != *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs < *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return true;
+  if (!rhs.has_value())
+    return false;
+  return *lhs <= *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return false;
+  if (!rhs.has_value())
+    return true;
+  return *lhs > *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs >= *rhs;
+}
+
+template <class T>
+constexpr bool operator==(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator==(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator!=(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator!=(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<(const Optional<T>& opt, nullopt_t) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator<(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<=(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator<=(nullopt_t, const Optional<T>& opt) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator>(nullopt_t, const Optional<T>& opt) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator>=(const Optional<T>& opt, nullopt_t) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>=(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt == value : false;
+}
+
+template <class T, class U>
+constexpr bool operator==(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value == *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt != value : true;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value != *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt < value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value < *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt <= value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value <= *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt > value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value > *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt >= value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value >= *opt : true;
+}
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return Optional<typename std::decay<T>::type>(std::forward<T>(value));
+}
+
+template <class T, class U, class... Args>
+constexpr Optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return Optional<T>(in_place, il, std::forward<Args>(args)...);
+}
+
+template <class T>
+void swap(Optional<T>& lhs, Optional<T>& rhs) {
+  lhs.swap(rhs);
+}
+
+}  // namespace base
+
+namespace std {
+
+template <class T>
+struct hash<base::Optional<T>> {
+  size_t operator()(const base::Optional<T>& opt) const {
+    return opt == base::nullopt ? 0 : std::hash<T>()(*opt);
+  }
+};
+
+}  // namespace std
+
+#endif  // BASE_OPTIONAL_H_
diff -Naur chromium-65.0.3325.181-orig/base/optional.h.conditional chromium-65.0.3325.181.patched/base/optional.h.conditional
--- chromium-65.0.3325.181-orig/base/optional.h.conditional	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/optional.h.conditional	2018-04-27 11:31:20.639827760 +0300
@@ -0,0 +1,659 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_OPTIONAL_H_
+#define BASE_OPTIONAL_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "base/logging.h"
+#include "base/template_util.h"
+
+namespace base {
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place_t
+struct in_place_t {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt_t
+struct nullopt_t {
+  constexpr explicit nullopt_t(int) {}
+};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place
+constexpr in_place_t in_place = {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt
+constexpr nullopt_t nullopt(0);
+
+namespace internal {
+
+template <typename T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorageBase {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is not trivially destructible we must call its
+  // destructor before deallocating its memory.
+  // Note that this hides the (implicitly declared) move constructor, which
+  // would be used for constexpr move constructor in OptionalStorage<T>.
+  // It is needed iff T is trivially move constructible. However, the current
+  // is_trivially_{copy,move}_constructible implementation requires
+  // is_trivially_destructible (which looks a bug, cf:
+  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51452 and
+  // http://cplusplus.github.io/LWG/lwg-active.html#2116), so it is not
+  // necessary for this case at the moment. Please see also the destructor
+  // comment in "is_trivially_destructible = true" specialization below.
+  ~OptionalStorageBase() {
+    if (is_populated_)
+      value_.~T();
+  }
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+template <typename T>
+struct OptionalStorageBase<T, true /* trivially destructible */> {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is trivially destructible (i.e. its destructor does nothing) there
+  // is no need to call it. Implicitly defined destructor is trivial, because
+  // both members (bool and union containing only variants which are trivially
+  // destructible) are trivially destructible.
+  // Explicitly-defaulted destructor is also trivial, but do not use it here,
+  // because it hides the implicit move constructor. It is needed to implement
+  // constexpr move constructor in OptionalStorage iff T is trivially move
+  // constructible. Note that, if T is trivially move constructible, the move
+  // constructor of OptionalStorageBase<T> is also implicitly defined and it is
+  // trivially move constructor. If T is not trivially move constructible,
+  // "not declaring move constructor without destructor declaration" here means
+  // "delete move constructor", which works because any move constructor of
+  // OptionalStorage will not refer to it in that case.
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+// Implement conditional constexpr copy and move constructors. These are
+// constexpr if is_trivially_{copy,move}_constructible<T>::value is true
+// respectively. If each is true, the corresponding constructor is defined as
+// "= default;", which generates a constexpr constructor (In this case,
+// the condition of constexpr-ness is satisfied because the base class also has
+// compiler generated constexpr {copy,move} constructors). Note that
+// placement-new is prohibited in constexpr.
+template <typename T,
+          bool = is_trivially_copy_constructible<T>::value,
+          bool = std::is_trivially_move_constructible<T>::value>
+struct OptionalStorage : OptionalStorageBase<T> {
+  // This is no trivially {copy,move} constructible case. Other cases are
+  // defined below as specializations.
+
+  // Accessing the members of template base class requires explicit
+  // declaration.
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+
+  // Inherit constructors (specifically, the in_place constructor).
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  // User defined constructor deletes the default constructor.
+  // Define it explicitly.
+  OptionalStorage() = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       false /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(const OptionalStorage& other) = default;
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       false /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(OptionalStorage&& other) = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  // If both trivially {copy,move} constructible are true, it is not necessary
+  // to use user-defined constructors. So, just inheriting constructors
+  // from the base class works.
+  using OptionalStorageBase<T>::OptionalStorageBase;
+};
+
+// Base class to support conditionally usable copy-/move- constructors
+// and assign operators.
+template <typename T>
+class OptionalBase {
+  // This class provides implementation rather than public API, so everything
+  // should be hidden. Often we use composition, but we cannot in this case
+  // because of C++ language restriction.
+ protected:
+  constexpr OptionalBase() = default;
+  constexpr OptionalBase(const OptionalBase& other) = default;
+  constexpr OptionalBase(OptionalBase&& other) = default;
+
+  template <class... Args>
+  constexpr explicit OptionalBase(in_place_t, Args&&... args)
+      : storage_(in_place, std::forward<Args>(args)...) {}
+
+  ~OptionalBase() = default;
+
+  OptionalBase& operator=(const OptionalBase& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(other.storage_.value_);
+    return *this;
+  }
+
+  OptionalBase& operator=(OptionalBase&& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(std::move(other.storage_.value_));
+    return *this;
+  }
+
+  void InitOrAssign(const T& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(value);
+    else
+      storage_.value_ = value;
+  }
+
+  void InitOrAssign(T&& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(std::move(value));
+    else
+      storage_.value_ = std::move(value);
+  }
+
+  void FreeIfNeeded() {
+    if (!storage_.is_populated_)
+      return;
+    storage_.value_.~T();
+    storage_.is_populated_ = false;
+  }
+
+  OptionalStorage<T> storage_;
+};
+
+}  // namespace internal
+
+// base::Optional is a Chromium version of the C++17 optional class:
+// std::optional documentation:
+// http://en.cppreference.com/w/cpp/utility/optional
+// Chromium documentation:
+// https://chromium.googlesource.com/chromium/src/+/master/docs/optional.md
+//
+// These are the differences between the specification and the implementation:
+// - Constructors do not use 'constexpr' as it is a C++14 extension.
+// - 'constexpr' might be missing in some places for reasons specified locally.
+// - No exceptions are thrown, because they are banned from Chromium.
+// - All the non-members are in the 'base' namespace instead of 'std'.
+template <typename T>
+class Optional : public internal::OptionalBase<T> {
+ public:
+  using value_type = T;
+
+  // Defer default/copy/move constructor implementation to OptionalBase.
+  // TODO(hidehiko): Implement conditional enabling.
+  constexpr Optional() = default;
+  constexpr Optional(const Optional& other) = default;
+  constexpr Optional(Optional&& other) = default;
+
+  constexpr Optional(nullopt_t) {}
+
+  constexpr Optional(const T& value)
+      : internal::OptionalBase<T>(in_place, value) {}
+
+  constexpr Optional(T&& value)
+      : internal::OptionalBase<T>(in_place, std::move(value)) {}
+
+  template <class... Args>
+  constexpr explicit Optional(in_place_t, Args&&... args)
+      : internal::OptionalBase<T>(in_place, std::forward<Args>(args)...) {}
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  constexpr explicit Optional(in_place_t,
+                              std::initializer_list<U> il,
+                              Args&&... args)
+      : internal::OptionalBase<T>(in_place, il, std::forward<Args>(args)...) {}
+
+  ~Optional() = default;
+
+  // Defer copy-/move- assign operator implementation to OptionalBase.
+  // TOOD(hidehiko): Implement conditional enabling.
+  Optional& operator=(const Optional& other) = default;
+  Optional& operator=(Optional&& other) = default;
+
+  Optional& operator=(nullopt_t) {
+    FreeIfNeeded();
+    return *this;
+  }
+
+  template <class U>
+  typename std::enable_if<std::is_same<std::decay_t<U>, T>::value,
+                          Optional&>::type
+  operator=(U&& value) {
+    InitOrAssign(std::forward<U>(value));
+    return *this;
+  }
+
+  constexpr const T* operator->() const {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr T* operator->() {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr const T& operator*() const& { return value(); }
+
+  constexpr T& operator*() & { return value(); }
+
+  constexpr const T&& operator*() const&& { return std::move(value()); }
+
+  constexpr T&& operator*() && { return std::move(value()); }
+
+  constexpr explicit operator bool() const { return storage_.is_populated_; }
+
+  constexpr bool has_value() const { return storage_.is_populated_; }
+
+  constexpr T& value() & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr const T& value() const & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr T&& value() && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  constexpr const T&& value() const && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  template <class U>
+  constexpr T value_or(U&& default_value) const& {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_copy_constructible<T>::value,
+    //               "T must be copy constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? value()
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  template <class U>
+  T value_or(U&& default_value) && {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_move_constructible<T>::value,
+    //               "T must be move constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? std::move(value())
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  void swap(Optional& other) {
+    if (!storage_.is_populated_ && !other.storage_.is_populated_)
+      return;
+
+    if (storage_.is_populated_ != other.storage_.is_populated_) {
+      if (storage_.is_populated_) {
+        other.storage_.Init(std::move(storage_.value_));
+        FreeIfNeeded();
+      } else {
+        storage_.Init(std::move(other.storage_.value_));
+        other.FreeIfNeeded();
+      }
+      return;
+    }
+
+    DCHECK(storage_.is_populated_ && other.storage_.is_populated_);
+    using std::swap;
+    swap(**this, *other);
+  }
+
+  void reset() {
+    FreeIfNeeded();
+  }
+
+  template <class... Args>
+  void emplace(Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(std::forward<Args>(args)...);
+  }
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(il, std::forward<Args>(args)...);
+    return storage_.value_;
+  }
+
+ private:
+  // Accessing template base class's protected member needs explicit
+  // declaration to do so.
+  using internal::OptionalBase<T>::FreeIfNeeded;
+  using internal::OptionalBase<T>::InitOrAssign;
+  using internal::OptionalBase<T>::storage_;
+};
+
+// Here after defines comparation operators. The definition follows
+// http://en.cppreference.com/w/cpp/utility/optional/operator_cmp
+// while bool() casting is replaced by has_value() to meet the chromium
+// style guide.
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs == *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs != *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs < *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return true;
+  if (!rhs.has_value())
+    return false;
+  return *lhs <= *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return false;
+  if (!rhs.has_value())
+    return true;
+  return *lhs > *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs >= *rhs;
+}
+
+template <class T>
+constexpr bool operator==(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator==(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator!=(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator!=(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<(const Optional<T>& opt, nullopt_t) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator<(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<=(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator<=(nullopt_t, const Optional<T>& opt) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator>(nullopt_t, const Optional<T>& opt) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator>=(const Optional<T>& opt, nullopt_t) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>=(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt == value : false;
+}
+
+template <class T, class U>
+constexpr bool operator==(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value == *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt != value : true;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value != *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt < value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value < *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt <= value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value <= *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt > value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value > *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt >= value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value >= *opt : true;
+}
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return Optional<typename std::decay<T>::type>(std::forward<T>(value));
+}
+
+template <class T, class U, class... Args>
+constexpr Optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return Optional<T>(in_place, il, std::forward<Args>(args)...);
+}
+
+template <class T>
+void swap(Optional<T>& lhs, Optional<T>& rhs) {
+  lhs.swap(rhs);
+}
+
+}  // namespace base
+
+namespace std {
+
+template <class T>
+struct hash<base::Optional<T>> {
+  size_t operator()(const base::Optional<T>& opt) const {
+    return opt == base::nullopt ? 0 : std::hash<T>()(*opt);
+  }
+};
+
+}  // namespace std
+
+#endif  // BASE_OPTIONAL_H_
diff -Naur chromium-65.0.3325.181-orig/base/optional.h.converting chromium-65.0.3325.181.patched/base/optional.h.converting
--- chromium-65.0.3325.181-orig/base/optional.h.converting	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/optional.h.converting	2018-04-27 11:31:20.643827718 +0300
@@ -0,0 +1,716 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_OPTIONAL_H_
+#define BASE_OPTIONAL_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "base/logging.h"
+#include "base/template_util.h"
+
+namespace base {
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place_t
+struct in_place_t {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt_t
+struct nullopt_t {
+  constexpr explicit nullopt_t(int) {}
+};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place
+constexpr in_place_t in_place = {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt
+constexpr nullopt_t nullopt(0);
+
+namespace internal {
+
+template <typename T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorageBase {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is not trivially destructible we must call its
+  // destructor before deallocating its memory.
+  // Note that this hides the (implicitly declared) move constructor, which
+  // would be used for constexpr move constructor in OptionalStorage<T>.
+  // It is needed iff T is trivially move constructible. However, the current
+  // is_trivially_{copy,move}_constructible implementation requires
+  // is_trivially_destructible (which looks a bug, cf:
+  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51452 and
+  // http://cplusplus.github.io/LWG/lwg-active.html#2116), so it is not
+  // necessary for this case at the moment. Please see also the destructor
+  // comment in "is_trivially_destructible = true" specialization below.
+  ~OptionalStorageBase() {
+    if (is_populated_)
+      value_.~T();
+  }
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+template <typename T>
+struct OptionalStorageBase<T, true /* trivially destructible */> {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is trivially destructible (i.e. its destructor does nothing) there
+  // is no need to call it. Implicitly defined destructor is trivial, because
+  // both members (bool and union containing only variants which are trivially
+  // destructible) are trivially destructible.
+  // Explicitly-defaulted destructor is also trivial, but do not use it here,
+  // because it hides the implicit move constructor. It is needed to implement
+  // constexpr move constructor in OptionalStorage iff T is trivially move
+  // constructible. Note that, if T is trivially move constructible, the move
+  // constructor of OptionalStorageBase<T> is also implicitly defined and it is
+  // trivially move constructor. If T is not trivially move constructible,
+  // "not declaring move constructor without destructor declaration" here means
+  // "delete move constructor", which works because any move constructor of
+  // OptionalStorage will not refer to it in that case.
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+// Implement conditional constexpr copy and move constructors. These are
+// constexpr if is_trivially_{copy,move}_constructible<T>::value is true
+// respectively. If each is true, the corresponding constructor is defined as
+// "= default;", which generates a constexpr constructor (In this case,
+// the condition of constexpr-ness is satisfied because the base class also has
+// compiler generated constexpr {copy,move} constructors). Note that
+// placement-new is prohibited in constexpr.
+template <typename T,
+          bool = is_trivially_copy_constructible<T>::value,
+          bool = std::is_trivially_move_constructible<T>::value>
+struct OptionalStorage : OptionalStorageBase<T> {
+  // This is no trivially {copy,move} constructible case. Other cases are
+  // defined below as specializations.
+
+  // Accessing the members of template base class requires explicit
+  // declaration.
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+
+  // Inherit constructors (specifically, the in_place constructor).
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  // User defined constructor deletes the default constructor.
+  // Define it explicitly.
+  OptionalStorage() = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       false /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(const OptionalStorage& other) = default;
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       false /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(OptionalStorage&& other) = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  // If both trivially {copy,move} constructible are true, it is not necessary
+  // to use user-defined constructors. So, just inheriting constructors
+  // from the base class works.
+  using OptionalStorageBase<T>::OptionalStorageBase;
+};
+
+// Base class to support conditionally usable copy-/move- constructors
+// and assign operators.
+template <typename T>
+class OptionalBase {
+  // This class provides implementation rather than public API, so everything
+  // should be hidden. Often we use composition, but we cannot in this case
+  // because of C++ language restriction.
+ protected:
+  constexpr OptionalBase() = default;
+  constexpr OptionalBase(const OptionalBase& other) = default;
+  constexpr OptionalBase(OptionalBase&& other) = default;
+
+  template <class... Args>
+  constexpr explicit OptionalBase(in_place_t, Args&&... args)
+      : storage_(in_place, std::forward<Args>(args)...) {}
+
+  ~OptionalBase() = default;
+
+  OptionalBase& operator=(const OptionalBase& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(other.storage_.value_);
+    return *this;
+  }
+
+  OptionalBase& operator=(OptionalBase&& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(std::move(other.storage_.value_));
+    return *this;
+  }
+
+  void InitOrAssign(const T& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(value);
+    else
+      storage_.value_ = value;
+  }
+
+  void InitOrAssign(T&& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(std::move(value));
+    else
+      storage_.value_ = std::move(value);
+  }
+
+  void FreeIfNeeded() {
+    if (!storage_.is_populated_)
+      return;
+    storage_.value_.~T();
+    storage_.is_populated_ = false;
+  }
+
+  OptionalStorage<T> storage_;
+};
+
+// The following {Copy,Move}{Constructible,Assignable} structs are helpers to
+// implement constructor/assign-operator overloading. Specifically, if T is
+// is not movable but copyable, Optional<T>'s move constructor should not
+// participate in overload resolution. This inheritance trick implements that.
+template <bool is_copy_constructible>
+struct CopyConstructible {};
+
+template <>
+struct CopyConstructible<false> {
+  constexpr CopyConstructible() = default;
+  constexpr CopyConstructible(const CopyConstructible&) = delete;
+  constexpr CopyConstructible(CopyConstructible&&) = default;
+  CopyConstructible& operator=(const CopyConstructible&) = default;
+  CopyConstructible& operator=(CopyConstructible&&) = default;
+};
+
+template <bool is_move_constructible>
+struct MoveConstructible {};
+
+template <>
+struct MoveConstructible<false> {
+  constexpr MoveConstructible() = default;
+  constexpr MoveConstructible(const MoveConstructible&) = default;
+  constexpr MoveConstructible(MoveConstructible&&) = delete;
+  MoveConstructible& operator=(const MoveConstructible&) = default;
+  MoveConstructible& operator=(MoveConstructible&&) = default;
+};
+
+template <bool is_copy_assignable>
+struct CopyAssignable {};
+
+template <>
+struct CopyAssignable<false> {
+  constexpr CopyAssignable() = default;
+  constexpr CopyAssignable(const CopyAssignable&) = default;
+  constexpr CopyAssignable(CopyAssignable&&) = default;
+  CopyAssignable& operator=(const CopyAssignable&) = delete;
+  CopyAssignable& operator=(CopyAssignable&&) = default;
+};
+
+template <bool is_move_assignable>
+struct MoveAssignable {};
+
+template <>
+struct MoveAssignable<false> {
+  constexpr MoveAssignable() = default;
+  constexpr MoveAssignable(const MoveAssignable&) = default;
+  constexpr MoveAssignable(MoveAssignable&&) = default;
+  MoveAssignable& operator=(const MoveAssignable&) = default;
+  MoveAssignable& operator=(MoveAssignable&&) = delete;
+};
+
+}  // namespace internal
+
+// base::Optional is a Chromium version of the C++17 optional class:
+// std::optional documentation:
+// http://en.cppreference.com/w/cpp/utility/optional
+// Chromium documentation:
+// https://chromium.googlesource.com/chromium/src/+/master/docs/optional.md
+//
+// These are the differences between the specification and the implementation:
+// - Constructors do not use 'constexpr' as it is a C++14 extension.
+// - 'constexpr' might be missing in some places for reasons specified locally.
+// - No exceptions are thrown, because they are banned from Chromium.
+// - All the non-members are in the 'base' namespace instead of 'std'.
+template <typename T>
+class Optional
+    : public internal::OptionalBase<T>,
+      public internal::CopyConstructible<std::is_copy_constructible<T>::value>,
+      public internal::MoveConstructible<std::is_move_constructible<T>::value>,
+      public internal::CopyAssignable<std::is_copy_constructible<T>::value &&
+                                      std::is_copy_assignable<T>::value>,
+      public internal::MoveAssignable<std::is_move_constructible<T>::value &&
+                                      std::is_move_assignable<T>::value> {
+ public:
+  using value_type = T;
+
+  // Defer default/copy/move constructor implementation to OptionalBase.
+  constexpr Optional() = default;
+  constexpr Optional(const Optional& other) = default;
+  constexpr Optional(Optional&& other) = default;
+
+  constexpr Optional(nullopt_t) {}
+
+  constexpr Optional(const T& value)
+      : internal::OptionalBase<T>(in_place, value) {}
+
+  constexpr Optional(T&& value)
+      : internal::OptionalBase<T>(in_place, std::move(value)) {}
+
+  template <class... Args>
+  constexpr explicit Optional(in_place_t, Args&&... args)
+      : internal::OptionalBase<T>(in_place, std::forward<Args>(args)...) {}
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  constexpr explicit Optional(in_place_t,
+                              std::initializer_list<U> il,
+                              Args&&... args)
+      : internal::OptionalBase<T>(in_place, il, std::forward<Args>(args)...) {}
+
+  ~Optional() = default;
+
+  // Defer copy-/move- assign operator implementation to OptionalBase.
+  Optional& operator=(const Optional& other) = default;
+  Optional& operator=(Optional&& other) = default;
+
+  Optional& operator=(nullopt_t) {
+    FreeIfNeeded();
+    return *this;
+  }
+
+  template <class U>
+  typename std::enable_if<std::is_same<std::decay_t<U>, T>::value,
+                          Optional&>::type
+  operator=(U&& value) {
+    InitOrAssign(std::forward<U>(value));
+    return *this;
+  }
+
+  constexpr const T* operator->() const {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr T* operator->() {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr const T& operator*() const& { return value(); }
+
+  constexpr T& operator*() & { return value(); }
+
+  constexpr const T&& operator*() const&& { return std::move(value()); }
+
+  constexpr T&& operator*() && { return std::move(value()); }
+
+  constexpr explicit operator bool() const { return storage_.is_populated_; }
+
+  constexpr bool has_value() const { return storage_.is_populated_; }
+
+  constexpr T& value() & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr const T& value() const & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr T&& value() && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  constexpr const T&& value() const && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  template <class U>
+  constexpr T value_or(U&& default_value) const& {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_copy_constructible<T>::value,
+    //               "T must be copy constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? value()
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  template <class U>
+  T value_or(U&& default_value) && {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_move_constructible<T>::value,
+    //               "T must be move constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? std::move(value())
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  void swap(Optional& other) {
+    if (!storage_.is_populated_ && !other.storage_.is_populated_)
+      return;
+
+    if (storage_.is_populated_ != other.storage_.is_populated_) {
+      if (storage_.is_populated_) {
+        other.storage_.Init(std::move(storage_.value_));
+        FreeIfNeeded();
+      } else {
+        storage_.Init(std::move(other.storage_.value_));
+        other.FreeIfNeeded();
+      }
+      return;
+    }
+
+    DCHECK(storage_.is_populated_ && other.storage_.is_populated_);
+    using std::swap;
+    swap(**this, *other);
+  }
+
+  void reset() {
+    FreeIfNeeded();
+  }
+
+  template <class... Args>
+  void emplace(Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(std::forward<Args>(args)...);
+  }
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(il, std::forward<Args>(args)...);
+    return storage_.value_;
+  }
+
+ private:
+  // Accessing template base class's protected member needs explicit
+  // declaration to do so.
+  using internal::OptionalBase<T>::FreeIfNeeded;
+  using internal::OptionalBase<T>::InitOrAssign;
+  using internal::OptionalBase<T>::storage_;
+};
+
+// Here after defines comparation operators. The definition follows
+// http://en.cppreference.com/w/cpp/utility/optional/operator_cmp
+// while bool() casting is replaced by has_value() to meet the chromium
+// style guide.
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs == *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs != *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs < *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return true;
+  if (!rhs.has_value())
+    return false;
+  return *lhs <= *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return false;
+  if (!rhs.has_value())
+    return true;
+  return *lhs > *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs >= *rhs;
+}
+
+template <class T>
+constexpr bool operator==(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator==(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator!=(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator!=(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<(const Optional<T>& opt, nullopt_t) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator<(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<=(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator<=(nullopt_t, const Optional<T>& opt) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator>(nullopt_t, const Optional<T>& opt) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator>=(const Optional<T>& opt, nullopt_t) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>=(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt == value : false;
+}
+
+template <class T, class U>
+constexpr bool operator==(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value == *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt != value : true;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value != *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt < value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value < *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt <= value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value <= *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt > value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value > *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt >= value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value >= *opt : true;
+}
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return Optional<typename std::decay<T>::type>(std::forward<T>(value));
+}
+
+template <class T, class U, class... Args>
+constexpr Optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return Optional<T>(in_place, il, std::forward<Args>(args)...);
+}
+
+template <class T>
+void swap(Optional<T>& lhs, Optional<T>& rhs) {
+  lhs.swap(rhs);
+}
+
+}  // namespace base
+
+namespace std {
+
+template <class T>
+struct hash<base::Optional<T>> {
+  size_t operator()(const base::Optional<T>& opt) const {
+    return opt == base::nullopt ? 0 : std::hash<T>()(*opt);
+  }
+};
+
+}  // namespace std
+
+#endif  // BASE_OPTIONAL_H_
diff -Naur chromium-65.0.3325.181-orig/base/optional.h.gcc7-itcc chromium-65.0.3325.181.patched/base/optional.h.gcc7-itcc
--- chromium-65.0.3325.181-orig/base/optional.h.gcc7-itcc	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/optional.h.gcc7-itcc	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,638 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_OPTIONAL_H_
+#define BASE_OPTIONAL_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "base/logging.h"
+
+namespace base {
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place_t
+struct in_place_t {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt_t
+struct nullopt_t {
+  constexpr explicit nullopt_t(int) {}
+};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place
+constexpr in_place_t in_place = {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt
+constexpr nullopt_t nullopt(0);
+
+namespace internal {
+
+template <typename T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorageBase {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_null_(false), value_(std::forward<Args>(args)...) {}
+
+  // When T is not trivially destructible we must call its
+  // destructor before deallocating its memory.
+  ~OptionalStorageBase() {
+    if (!is_null_)
+      value_.~T();
+  }
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(is_null_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_null_ = false;
+  }
+
+  bool is_null_ = true;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+template <typename T>
+struct OptionalStorageBase<T, true /* trivially destructible */> {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_null_(false), value_(std::forward<Args>(args)...) {}
+
+  // When T is trivially destructible (i.e. its destructor does nothing) there
+  // is no need to call it. Explicitly defaulting the destructor means it's not
+  // user-provided. Those two together make this destructor trivial.
+  ~OptionalStorageBase() = default;
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(is_null_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_null_ = false;
+  }
+
+  bool is_null_ = true;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+// Implement conditional constexpr copy and move constructors. These are
+// constexpr if is_trivially_{copy,move}_constructible<T>::value is true
+// respectively. If each is true, the corresponding constructor is defined as
+// "= default;", which generates a constexpr constructor (In this case,
+// the condition of constexpr-ness is satisfied because the base class also has
+// compiler generated constexpr {copy,move} constructors). Note that
+// placement-new is prohibited in constexpr.
+template <typename T,
+          bool = std::is_trivially_copy_constructible<T>::value,
+          bool = std::is_trivially_move_constructible<T>::value>
+struct OptionalStorage : OptionalStorageBase<T> {
+  // This is no trivially {copy,move} constructible case. Other cases are
+  // defined below as specializations.
+
+  // Accessing the members of template base class requires explicit
+  // declaration.
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+
+  // Inherit constructors (specifically, the in_place constructor).
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  // User defined constructor deletes the default constructor.
+  // Define it explicitly.
+  OptionalStorage() = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (!other.is_null_)
+      Init(other.value_);
+  }
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (!other.is_null_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       false /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(const OptionalStorage& other) = default;
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (!other.is_null_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       false /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(OptionalStorage&& other) = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (!other.is_null_)
+      Init(other.value_);
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  // If both trivially {copy,move} constructible are true, it is not necessary
+  // to use user-defined constructors. So, just inheriting constructors
+  // from the base class works.
+  using OptionalStorageBase<T>::OptionalStorageBase;
+};
+
+// Base class to support conditionally usable copy-/move- constructors
+// and assign operators.
+template <typename T>
+class OptionalBase {
+  // This class provides implementation rather than public API, so everything
+  // should be hidden. Often we use composition, but we cannot in this case
+  // because of C++ language restriction.
+ protected:
+  constexpr OptionalBase() = default;
+  constexpr OptionalBase(const OptionalBase& other) = default;
+  constexpr OptionalBase(OptionalBase&& other) = default;
+
+  template <class... Args>
+  constexpr explicit OptionalBase(in_place_t, Args&&... args)
+      : storage_(in_place, std::forward<Args>(args)...) {}
+
+  ~OptionalBase() = default;
+
+  OptionalBase& operator=(const OptionalBase& other) {
+    if (other.storage_.is_null_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(other.storage_.value_);
+    return *this;
+  }
+
+  OptionalBase& operator=(OptionalBase&& other) {
+    if (other.storage_.is_null_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(std::move(other.storage_.value_));
+    return *this;
+  }
+
+  void InitOrAssign(const T& value) {
+    if (storage_.is_null_)
+      storage_.Init(value);
+    else
+      storage_.value_ = value;
+  }
+
+  void InitOrAssign(T&& value) {
+    if (storage_.is_null_)
+      storage_.Init(std::move(value));
+    else
+      storage_.value_ = std::move(value);
+  }
+
+  void FreeIfNeeded() {
+    if (storage_.is_null_)
+      return;
+    storage_.value_.~T();
+    storage_.is_null_ = true;
+  }
+
+  OptionalStorage<T> storage_;
+};
+
+}  // namespace internal
+
+// base::Optional is a Chromium version of the C++17 optional class:
+// std::optional documentation:
+// http://en.cppreference.com/w/cpp/utility/optional
+// Chromium documentation:
+// https://chromium.googlesource.com/chromium/src/+/master/docs/optional.md
+//
+// These are the differences between the specification and the implementation:
+// - Constructors do not use 'constexpr' as it is a C++14 extension.
+// - 'constexpr' might be missing in some places for reasons specified locally.
+// - No exceptions are thrown, because they are banned from Chromium.
+// - All the non-members are in the 'base' namespace instead of 'std'.
+template <typename T>
+class Optional : public internal::OptionalBase<T> {
+ public:
+  using value_type = T;
+
+  // Defer default/copy/move constructor implementation to OptionalBase.
+  // TODO(hidehiko): Implement conditional enabling.
+  constexpr Optional() = default;
+  constexpr Optional(const Optional& other) = default;
+  constexpr Optional(Optional&& other) = default;
+
+  constexpr Optional(nullopt_t) {}
+
+  constexpr Optional(const T& value)
+      : internal::OptionalBase<T>(in_place, value) {}
+
+  constexpr Optional(T&& value)
+      : internal::OptionalBase<T>(in_place, std::move(value)) {}
+
+  template <class... Args>
+  constexpr explicit Optional(in_place_t, Args&&... args)
+      : internal::OptionalBase<T>(in_place, std::forward<Args>(args)...) {}
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  constexpr explicit Optional(in_place_t,
+                              std::initializer_list<U> il,
+                              Args&&... args)
+      : internal::OptionalBase<T>(in_place, il, std::forward<Args>(args)...) {}
+
+  ~Optional() = default;
+
+  // Defer copy-/move- assign operator implementation to OptionalBase.
+  // TOOD(hidehiko): Implement conditional enabling.
+  Optional& operator=(const Optional& other) = default;
+  Optional& operator=(Optional&& other) = default;
+
+  Optional& operator=(nullopt_t) {
+    FreeIfNeeded();
+    return *this;
+  }
+
+  template <class U>
+  typename std::enable_if<std::is_same<std::decay_t<U>, T>::value,
+                          Optional&>::type
+  operator=(U&& value) {
+    InitOrAssign(std::forward<U>(value));
+    return *this;
+  }
+
+  constexpr const T* operator->() const {
+    DCHECK(!storage_.is_null_);
+    return &value();
+  }
+
+  constexpr T* operator->() {
+    DCHECK(!storage_.is_null_);
+    return &value();
+  }
+
+  constexpr const T& operator*() const& { return value(); }
+
+  constexpr T& operator*() & { return value(); }
+
+  constexpr const T&& operator*() const&& { return std::move(value()); }
+
+  constexpr T&& operator*() && { return std::move(value()); }
+
+  constexpr explicit operator bool() const { return !storage_.is_null_; }
+
+  constexpr bool has_value() const { return !storage_.is_null_; }
+
+  constexpr T& value() & {
+    DCHECK(!storage_.is_null_);
+    return storage_.value_;
+  }
+
+  constexpr const T& value() const & {
+    DCHECK(!storage_.is_null_);
+    return storage_.value_;
+  }
+
+  constexpr T&& value() && {
+    DCHECK(!storage_.is_null_);
+    return std::move(storage_.value_);
+  }
+
+  constexpr const T&& value() const && {
+    DCHECK(!storage_.is_null_);
+    return std::move(storage_.value_);
+  }
+
+  template <class U>
+  constexpr T value_or(U&& default_value) const& {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_copy_constructible<T>::value,
+    //               "T must be copy constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_null_ ? static_cast<T>(std::forward<U>(default_value))
+                             : value();
+  }
+
+  template <class U>
+  T value_or(U&& default_value) && {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_move_constructible<T>::value,
+    //               "T must be move constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_null_ ? static_cast<T>(std::forward<U>(default_value))
+                             : std::move(value());
+  }
+
+  void swap(Optional& other) {
+    if (storage_.is_null_ && other.storage_.is_null_)
+      return;
+
+    if (storage_.is_null_ != other.storage_.is_null_) {
+      if (storage_.is_null_) {
+        storage_.Init(std::move(other.storage_.value_));
+        other.FreeIfNeeded();
+      } else {
+        other.storage_.Init(std::move(storage_.value_));
+        FreeIfNeeded();
+      }
+      return;
+    }
+
+    DCHECK(!storage_.is_null_ && !other.storage_.is_null_);
+    using std::swap;
+    swap(**this, *other);
+  }
+
+  void reset() {
+    FreeIfNeeded();
+  }
+
+  template <class... Args>
+  void emplace(Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(std::forward<Args>(args)...);
+  }
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(il, std::forward<Args>(args)...);
+    return storage_.value_;
+  }
+
+ private:
+  // Accessing template base class's protected member needs explicit
+  // declaration to do so.
+  using internal::OptionalBase<T>::FreeIfNeeded;
+  using internal::OptionalBase<T>::InitOrAssign;
+  using internal::OptionalBase<T>::storage_;
+};
+
+// Here after defines comparation operators. The definition follows
+// http://en.cppreference.com/w/cpp/utility/optional/operator_cmp
+// while bool() casting is replaced by has_value() to meet the chromium
+// style guide.
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs == *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs != *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs < *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return true;
+  if (!rhs.has_value())
+    return false;
+  return *lhs <= *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return false;
+  if (!rhs.has_value())
+    return true;
+  return *lhs > *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs >= *rhs;
+}
+
+template <class T>
+constexpr bool operator==(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator==(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator!=(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator!=(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<(const Optional<T>& opt, nullopt_t) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator<(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<=(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator<=(nullopt_t, const Optional<T>& opt) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator>(nullopt_t, const Optional<T>& opt) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator>=(const Optional<T>& opt, nullopt_t) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>=(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt == value : false;
+}
+
+template <class T, class U>
+constexpr bool operator==(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value == *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt != value : true;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value != *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt < value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value < *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt <= value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value <= *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt > value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value > *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt >= value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value >= *opt : true;
+}
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return Optional<typename std::decay<T>::type>(std::forward<T>(value));
+}
+
+template <class T, class U, class... Args>
+constexpr Optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return Optional<T>(in_place, il, std::forward<Args>(args)...);
+}
+
+template <class T>
+void swap(Optional<T>& lhs, Optional<T>& rhs) {
+  lhs.swap(rhs);
+}
+
+}  // namespace base
+
+namespace std {
+
+template <class T>
+struct hash<base::Optional<T>> {
+  size_t operator()(const base::Optional<T>& opt) const {
+    return opt == base::nullopt ? 0 : std::hash<T>()(*opt);
+  }
+};
+
+}  // namespace std
+
+#endif  // BASE_OPTIONAL_H_
diff -Naur chromium-65.0.3325.181-orig/base/optional.h.ncnm chromium-65.0.3325.181.patched/base/optional.h.ncnm
--- chromium-65.0.3325.181-orig/base/optional.h.ncnm	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/optional.h.ncnm	2018-04-27 11:31:20.643827718 +0300
@@ -0,0 +1,821 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_OPTIONAL_H_
+#define BASE_OPTIONAL_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "base/logging.h"
+#include "base/template_util.h"
+
+namespace base {
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place_t
+struct in_place_t {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt_t
+struct nullopt_t {
+  constexpr explicit nullopt_t(int) {}
+};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place
+constexpr in_place_t in_place = {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt
+constexpr nullopt_t nullopt(0);
+
+// Forward declaration, which is refered by following helpers.
+template <typename T>
+class Optional;
+
+namespace internal {
+
+template <typename T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorageBase {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is not trivially destructible we must call its
+  // destructor before deallocating its memory.
+  // Note that this hides the (implicitly declared) move constructor, which
+  // would be used for constexpr move constructor in OptionalStorage<T>.
+  // It is needed iff T is trivially move constructible. However, the current
+  // is_trivially_{copy,move}_constructible implementation requires
+  // is_trivially_destructible (which looks a bug, cf:
+  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51452 and
+  // http://cplusplus.github.io/LWG/lwg-active.html#2116), so it is not
+  // necessary for this case at the moment. Please see also the destructor
+  // comment in "is_trivially_destructible = true" specialization below.
+  ~OptionalStorageBase() {
+    if (is_populated_)
+      value_.~T();
+  }
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+template <typename T>
+struct OptionalStorageBase<T, true /* trivially destructible */> {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is trivially destructible (i.e. its destructor does nothing) there
+  // is no need to call it. Implicitly defined destructor is trivial, because
+  // both members (bool and union containing only variants which are trivially
+  // destructible) are trivially destructible.
+  // Explicitly-defaulted destructor is also trivial, but do not use it here,
+  // because it hides the implicit move constructor. It is needed to implement
+  // constexpr move constructor in OptionalStorage iff T is trivially move
+  // constructible. Note that, if T is trivially move constructible, the move
+  // constructor of OptionalStorageBase<T> is also implicitly defined and it is
+  // trivially move constructor. If T is not trivially move constructible,
+  // "not declaring move constructor without destructor declaration" here means
+  // "delete move constructor", which works because any move constructor of
+  // OptionalStorage will not refer to it in that case.
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+// Implement conditional constexpr copy and move constructors. These are
+// constexpr if is_trivially_{copy,move}_constructible<T>::value is true
+// respectively. If each is true, the corresponding constructor is defined as
+// "= default;", which generates a constexpr constructor (In this case,
+// the condition of constexpr-ness is satisfied because the base class also has
+// compiler generated constexpr {copy,move} constructors). Note that
+// placement-new is prohibited in constexpr.
+template <typename T,
+          bool = is_trivially_copy_constructible<T>::value,
+          bool = std::is_trivially_move_constructible<T>::value>
+struct OptionalStorage : OptionalStorageBase<T> {
+  // This is no trivially {copy,move} constructible case. Other cases are
+  // defined below as specializations.
+
+  // Accessing the members of template base class requires explicit
+  // declaration.
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+
+  // Inherit constructors (specifically, the in_place constructor).
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  // User defined constructor deletes the default constructor.
+  // Define it explicitly.
+  OptionalStorage() = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       false /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(const OptionalStorage& other) = default;
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       false /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(OptionalStorage&& other) = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  // If both trivially {copy,move} constructible are true, it is not necessary
+  // to use user-defined constructors. So, just inheriting constructors
+  // from the base class works.
+  using OptionalStorageBase<T>::OptionalStorageBase;
+};
+
+// Base class to support conditionally usable copy-/move- constructors
+// and assign operators.
+template <typename T>
+class OptionalBase {
+  // This class provides implementation rather than public API, so everything
+  // should be hidden. Often we use composition, but we cannot in this case
+  // because of C++ language restriction.
+ protected:
+  constexpr OptionalBase() = default;
+  constexpr OptionalBase(const OptionalBase& other) = default;
+  constexpr OptionalBase(OptionalBase&& other) = default;
+
+  template <class... Args>
+  constexpr explicit OptionalBase(in_place_t, Args&&... args)
+      : storage_(in_place, std::forward<Args>(args)...) {}
+
+  // Implementation of converting constructors.
+  template <typename U>
+  explicit OptionalBase(const OptionalBase<U>& other) {
+    if (other.storage_.is_populated_)
+      storage_.Init(other.storage_.value_);
+  }
+
+  template <typename U>
+  explicit OptionalBase(OptionalBase<U>&& other) {
+    if (other.storage_.is_populated_)
+      storage_.Init(std::move(other.storage_.value_));
+  }
+
+  ~OptionalBase() = default;
+
+  OptionalBase& operator=(const OptionalBase& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(other.storage_.value_);
+    return *this;
+  }
+
+  OptionalBase& operator=(OptionalBase&& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(std::move(other.storage_.value_));
+    return *this;
+  }
+
+  void InitOrAssign(const T& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(value);
+    else
+      storage_.value_ = value;
+  }
+
+  void InitOrAssign(T&& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(std::move(value));
+    else
+      storage_.value_ = std::move(value);
+  }
+
+  void FreeIfNeeded() {
+    if (!storage_.is_populated_)
+      return;
+    storage_.value_.~T();
+    storage_.is_populated_ = false;
+  }
+
+  // For implementing conversion, allow access to other typed OptionalBase
+  // class.
+  template <typename U>
+  friend class OptionalBase;
+
+  OptionalStorage<T> storage_;
+};
+
+// The following {Copy,Move}{Constructible,Assignable} structs are helpers to
+// implement constructor/assign-operator overloading. Specifically, if T is
+// is not movable but copyable, Optional<T>'s move constructor should not
+// participate in overload resolution. This inheritance trick implements that.
+template <bool is_copy_constructible>
+struct CopyConstructible {};
+
+template <>
+struct CopyConstructible<false> {
+  constexpr CopyConstructible() = default;
+  constexpr CopyConstructible(const CopyConstructible&) = delete;
+  constexpr CopyConstructible(CopyConstructible&&) = default;
+  CopyConstructible& operator=(const CopyConstructible&) = default;
+  CopyConstructible& operator=(CopyConstructible&&) = default;
+};
+
+template <bool is_move_constructible>
+struct MoveConstructible {};
+
+template <>
+struct MoveConstructible<false> {
+  constexpr MoveConstructible() = default;
+  constexpr MoveConstructible(const MoveConstructible&) = default;
+  constexpr MoveConstructible(MoveConstructible&&) = delete;
+  MoveConstructible& operator=(const MoveConstructible&) = default;
+  MoveConstructible& operator=(MoveConstructible&&) = default;
+};
+
+template <bool is_copy_assignable>
+struct CopyAssignable {};
+
+template <>
+struct CopyAssignable<false> {
+  constexpr CopyAssignable() = default;
+  constexpr CopyAssignable(const CopyAssignable&) = default;
+  constexpr CopyAssignable(CopyAssignable&&) = default;
+  CopyAssignable& operator=(const CopyAssignable&) = delete;
+  CopyAssignable& operator=(CopyAssignable&&) = default;
+};
+
+template <bool is_move_assignable>
+struct MoveAssignable {};
+
+template <>
+struct MoveAssignable<false> {
+  constexpr MoveAssignable() = default;
+  constexpr MoveAssignable(const MoveAssignable&) = default;
+  constexpr MoveAssignable(MoveAssignable&&) = default;
+  MoveAssignable& operator=(const MoveAssignable&) = default;
+  MoveAssignable& operator=(MoveAssignable&&) = delete;
+};
+
+// Helper to conditionally enable converting constructors.
+template <typename T, typename U>
+struct IsConvertibleFromOptional
+    : std::integral_constant<
+          bool,
+          std::is_constructible<T, Optional<U>&>::value ||
+              std::is_constructible<T, const Optional<U>&>::value ||
+              std::is_constructible<T, Optional<U>&&>::value ||
+              std::is_constructible<T, const Optional<U>&&>::value ||
+              std::is_convertible<Optional<U>&, T>::value ||
+              std::is_convertible<const Optional<U>&, T>::value ||
+              std::is_convertible<Optional<U>&&, T>::value ||
+              std::is_convertible<const Optional<U>&&, T>::value> {};
+
+// Forward compatibility for C++20.
+template <typename T>
+using RemoveCvRefT = std::remove_cv_t<std::remove_reference_t<T>>;
+
+}  // namespace internal
+
+// base::Optional is a Chromium version of the C++17 optional class:
+// std::optional documentation:
+// http://en.cppreference.com/w/cpp/utility/optional
+// Chromium documentation:
+// https://chromium.googlesource.com/chromium/src/+/master/docs/optional.md
+//
+// These are the differences between the specification and the implementation:
+// - Constructors do not use 'constexpr' as it is a C++14 extension.
+// - 'constexpr' might be missing in some places for reasons specified locally.
+// - No exceptions are thrown, because they are banned from Chromium.
+// - All the non-members are in the 'base' namespace instead of 'std'.
+//
+// Note that T cannot have a constructor T(Optional<T>) etc. Optional<T> checks
+// T's constructor (specifically via IsConvertibleFromOptional), and in the
+// check whether T can be constructible from Optional<T>, which is recursive
+// so it does not work. As of Feb 2018, std::optional C++17 implementation in
+// both clang and gcc has same limitation. MSVC SFINAE looks to have different
+// behavior, but anyway it reports an error, too.
+template <typename T>
+class Optional
+    : public internal::OptionalBase<T>,
+      public internal::CopyConstructible<std::is_copy_constructible<T>::value>,
+      public internal::MoveConstructible<std::is_move_constructible<T>::value>,
+      public internal::CopyAssignable<std::is_copy_constructible<T>::value &&
+                                      std::is_copy_assignable<T>::value>,
+      public internal::MoveAssignable<std::is_move_constructible<T>::value &&
+                                      std::is_move_assignable<T>::value> {
+ public:
+  using value_type = T;
+
+  // Defer default/copy/move constructor implementation to OptionalBase.
+  constexpr Optional() = default;
+  constexpr Optional(const Optional& other) = default;
+  constexpr Optional(Optional&& other) = default;
+
+  constexpr Optional(nullopt_t) {}  // NOLINT(runtime/explicit)
+
+  // Converting copy constructor. "explicit" only if
+  // std::is_convertible<const U&, T>::value is false. It is implemented by
+  // declaring two almost same constructors, but that condition in enable_if_t
+  // is different, so that either one is chosen, thanks to SFINAE.
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, const U&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           std::is_convertible<const U&, T>::value,
+                       bool> = false>
+  Optional(const Optional<U>& other) : internal::OptionalBase<T>(other) {}
+
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, const U&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           !std::is_convertible<const U&, T>::value,
+                       bool> = false>
+  explicit Optional(const Optional<U>& other)
+      : internal::OptionalBase<T>(other) {}
+
+  // Converting move constructor. Similar to converting copy constructor,
+  // declaring two (explicit and non-explicit) constructors.
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, U&&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           std::is_convertible<U&&, T>::value,
+                       bool> = false>
+  Optional(Optional<U>&& other) : internal::OptionalBase<T>(std::move(other)) {}
+
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, U&&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           !std::is_convertible<U&&, T>::value,
+                       bool> = false>
+  explicit Optional(Optional<U>&& other)
+      : internal::OptionalBase<T>(std::move(other)) {}
+
+  template <class... Args>
+  constexpr explicit Optional(in_place_t, Args&&... args)
+      : internal::OptionalBase<T>(in_place, std::forward<Args>(args)...) {}
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  constexpr explicit Optional(in_place_t,
+                              std::initializer_list<U> il,
+                              Args&&... args)
+      : internal::OptionalBase<T>(in_place, il, std::forward<Args>(args)...) {}
+
+  // Forward value constructor. Similar to converting constructors,
+  // conditionally explicit.
+  template <
+      typename U = value_type,
+      std::enable_if_t<
+          std::is_constructible<T, U&&>::value &&
+              !std::is_same<internal::RemoveCvRefT<U>, in_place_t>::value &&
+              !std::is_same<internal::RemoveCvRefT<U>, Optional<T>>::value &&
+              std::is_convertible<U&&, T>::value,
+          bool> = false>
+  constexpr Optional(U&& value)
+      : internal::OptionalBase<T>(in_place, std::forward<U>(value)) {}
+
+  template <
+      typename U = value_type,
+      std::enable_if_t<
+          std::is_constructible<T, U&&>::value &&
+              !std::is_same<internal::RemoveCvRefT<U>, in_place_t>::value &&
+              !std::is_same<internal::RemoveCvRefT<U>, Optional<T>>::value &&
+              !std::is_convertible<U&&, T>::value,
+          bool> = false>
+  constexpr explicit Optional(U&& value)
+      : internal::OptionalBase<T>(in_place, std::forward<U>(value)) {}
+
+  ~Optional() = default;
+
+  // Defer copy-/move- assign operator implementation to OptionalBase.
+  Optional& operator=(const Optional& other) = default;
+  Optional& operator=(Optional&& other) = default;
+
+  Optional& operator=(nullopt_t) {
+    FreeIfNeeded();
+    return *this;
+  }
+
+  template <class U>
+  typename std::enable_if<std::is_same<std::decay_t<U>, T>::value,
+                          Optional&>::type
+  operator=(U&& value) {
+    InitOrAssign(std::forward<U>(value));
+    return *this;
+  }
+
+  constexpr const T* operator->() const {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr T* operator->() {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr const T& operator*() const& { return value(); }
+
+  constexpr T& operator*() & { return value(); }
+
+  constexpr const T&& operator*() const&& { return std::move(value()); }
+
+  constexpr T&& operator*() && { return std::move(value()); }
+
+  constexpr explicit operator bool() const { return storage_.is_populated_; }
+
+  constexpr bool has_value() const { return storage_.is_populated_; }
+
+  constexpr T& value() & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr const T& value() const & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr T&& value() && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  constexpr const T&& value() const && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  template <class U>
+  constexpr T value_or(U&& default_value) const& {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_copy_constructible<T>::value,
+    //               "T must be copy constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? value()
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  template <class U>
+  T value_or(U&& default_value) && {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_move_constructible<T>::value,
+    //               "T must be move constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? std::move(value())
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  void swap(Optional& other) {
+    if (!storage_.is_populated_ && !other.storage_.is_populated_)
+      return;
+
+    if (storage_.is_populated_ != other.storage_.is_populated_) {
+      if (storage_.is_populated_) {
+        other.storage_.Init(std::move(storage_.value_));
+        FreeIfNeeded();
+      } else {
+        storage_.Init(std::move(other.storage_.value_));
+        other.FreeIfNeeded();
+      }
+      return;
+    }
+
+    DCHECK(storage_.is_populated_ && other.storage_.is_populated_);
+    using std::swap;
+    swap(**this, *other);
+  }
+
+  void reset() {
+    FreeIfNeeded();
+  }
+
+  template <class... Args>
+  void emplace(Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(std::forward<Args>(args)...);
+  }
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(il, std::forward<Args>(args)...);
+    return storage_.value_;
+  }
+
+ private:
+  // Accessing template base class's protected member needs explicit
+  // declaration to do so.
+  using internal::OptionalBase<T>::FreeIfNeeded;
+  using internal::OptionalBase<T>::InitOrAssign;
+  using internal::OptionalBase<T>::storage_;
+};
+
+// Here after defines comparation operators. The definition follows
+// http://en.cppreference.com/w/cpp/utility/optional/operator_cmp
+// while bool() casting is replaced by has_value() to meet the chromium
+// style guide.
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs == *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs != *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs < *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return true;
+  if (!rhs.has_value())
+    return false;
+  return *lhs <= *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return false;
+  if (!rhs.has_value())
+    return true;
+  return *lhs > *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs >= *rhs;
+}
+
+template <class T>
+constexpr bool operator==(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator==(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator!=(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator!=(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<(const Optional<T>& opt, nullopt_t) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator<(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<=(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator<=(nullopt_t, const Optional<T>& opt) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator>(nullopt_t, const Optional<T>& opt) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator>=(const Optional<T>& opt, nullopt_t) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>=(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt == value : false;
+}
+
+template <class T, class U>
+constexpr bool operator==(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value == *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt != value : true;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value != *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt < value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value < *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt <= value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value <= *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt > value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value > *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt >= value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value >= *opt : true;
+}
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return Optional<typename std::decay<T>::type>(std::forward<T>(value));
+}
+
+template <class T, class U, class... Args>
+constexpr Optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return Optional<T>(in_place, il, std::forward<Args>(args)...);
+}
+
+template <class T>
+void swap(Optional<T>& lhs, Optional<T>& rhs) {
+  lhs.swap(rhs);
+}
+
+}  // namespace base
+
+namespace std {
+
+template <class T>
+struct hash<base::Optional<T>> {
+  size_t operator()(const base::Optional<T>& opt) const {
+    return opt == base::nullopt ? 0 : std::hash<T>()(*opt);
+  }
+};
+
+}  // namespace std
+
+#endif  // BASE_OPTIONAL_H_
diff -Naur chromium-65.0.3325.181-orig/base/optional.h.noncopyable chromium-65.0.3325.181.patched/base/optional.h.noncopyable
--- chromium-65.0.3325.181-orig/base/optional.h.noncopyable	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/optional.h.noncopyable	2018-04-27 11:31:20.611828057 +0300
@@ -0,0 +1,639 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_OPTIONAL_H_
+#define BASE_OPTIONAL_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "base/logging.h"
+#include "base/template_util.h"
+
+namespace base {
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place_t
+struct in_place_t {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt_t
+struct nullopt_t {
+  constexpr explicit nullopt_t(int) {}
+};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place
+constexpr in_place_t in_place = {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt
+constexpr nullopt_t nullopt(0);
+
+namespace internal {
+
+template <typename T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorageBase {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_null_(false), value_(std::forward<Args>(args)...) {}
+
+  // When T is not trivially destructible we must call its
+  // destructor before deallocating its memory.
+  ~OptionalStorageBase() {
+    if (!is_null_)
+      value_.~T();
+  }
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(is_null_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_null_ = false;
+  }
+
+  bool is_null_ = true;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+template <typename T>
+struct OptionalStorageBase<T, true /* trivially destructible */> {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_null_(false), value_(std::forward<Args>(args)...) {}
+
+  // When T is trivially destructible (i.e. its destructor does nothing) there
+  // is no need to call it. Explicitly defaulting the destructor means it's not
+  // user-provided. Those two together make this destructor trivial.
+  ~OptionalStorageBase() = default;
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(is_null_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_null_ = false;
+  }
+
+  bool is_null_ = true;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+// Implement conditional constexpr copy and move constructors. These are
+// constexpr if is_trivially_{copy,move}_constructible<T>::value is true
+// respectively. If each is true, the corresponding constructor is defined as
+// "= default;", which generates a constexpr constructor (In this case,
+// the condition of constexpr-ness is satisfied because the base class also has
+// compiler generated constexpr {copy,move} constructors). Note that
+// placement-new is prohibited in constexpr.
+template <typename T,
+          bool = is_trivially_copy_constructible<T>::value,
+          bool = std::is_trivially_move_constructible<T>::value>
+struct OptionalStorage : OptionalStorageBase<T> {
+  // This is no trivially {copy,move} constructible case. Other cases are
+  // defined below as specializations.
+
+  // Accessing the members of template base class requires explicit
+  // declaration.
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+
+  // Inherit constructors (specifically, the in_place constructor).
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  // User defined constructor deletes the default constructor.
+  // Define it explicitly.
+  OptionalStorage() = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (!other.is_null_)
+      Init(other.value_);
+  }
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (!other.is_null_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       false /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(const OptionalStorage& other) = default;
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (!other.is_null_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       false /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_null_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(OptionalStorage&& other) = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (!other.is_null_)
+      Init(other.value_);
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  // If both trivially {copy,move} constructible are true, it is not necessary
+  // to use user-defined constructors. So, just inheriting constructors
+  // from the base class works.
+  using OptionalStorageBase<T>::OptionalStorageBase;
+};
+
+// Base class to support conditionally usable copy-/move- constructors
+// and assign operators.
+template <typename T>
+class OptionalBase {
+  // This class provides implementation rather than public API, so everything
+  // should be hidden. Often we use composition, but we cannot in this case
+  // because of C++ language restriction.
+ protected:
+  constexpr OptionalBase() = default;
+  constexpr OptionalBase(const OptionalBase& other) = default;
+  constexpr OptionalBase(OptionalBase&& other) = default;
+
+  template <class... Args>
+  constexpr explicit OptionalBase(in_place_t, Args&&... args)
+      : storage_(in_place, std::forward<Args>(args)...) {}
+
+  ~OptionalBase() = default;
+
+  OptionalBase& operator=(const OptionalBase& other) {
+    if (other.storage_.is_null_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(other.storage_.value_);
+    return *this;
+  }
+
+  OptionalBase& operator=(OptionalBase&& other) {
+    if (other.storage_.is_null_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(std::move(other.storage_.value_));
+    return *this;
+  }
+
+  void InitOrAssign(const T& value) {
+    if (storage_.is_null_)
+      storage_.Init(value);
+    else
+      storage_.value_ = value;
+  }
+
+  void InitOrAssign(T&& value) {
+    if (storage_.is_null_)
+      storage_.Init(std::move(value));
+    else
+      storage_.value_ = std::move(value);
+  }
+
+  void FreeIfNeeded() {
+    if (storage_.is_null_)
+      return;
+    storage_.value_.~T();
+    storage_.is_null_ = true;
+  }
+
+  OptionalStorage<T> storage_;
+};
+
+}  // namespace internal
+
+// base::Optional is a Chromium version of the C++17 optional class:
+// std::optional documentation:
+// http://en.cppreference.com/w/cpp/utility/optional
+// Chromium documentation:
+// https://chromium.googlesource.com/chromium/src/+/master/docs/optional.md
+//
+// These are the differences between the specification and the implementation:
+// - Constructors do not use 'constexpr' as it is a C++14 extension.
+// - 'constexpr' might be missing in some places for reasons specified locally.
+// - No exceptions are thrown, because they are banned from Chromium.
+// - All the non-members are in the 'base' namespace instead of 'std'.
+template <typename T>
+class Optional : public internal::OptionalBase<T> {
+ public:
+  using value_type = T;
+
+  // Defer default/copy/move constructor implementation to OptionalBase.
+  // TODO(hidehiko): Implement conditional enabling.
+  constexpr Optional() = default;
+  constexpr Optional(const Optional& other) = default;
+  constexpr Optional(Optional&& other) = default;
+
+  constexpr Optional(nullopt_t) {}
+
+  constexpr Optional(const T& value)
+      : internal::OptionalBase<T>(in_place, value) {}
+
+  constexpr Optional(T&& value)
+      : internal::OptionalBase<T>(in_place, std::move(value)) {}
+
+  template <class... Args>
+  constexpr explicit Optional(in_place_t, Args&&... args)
+      : internal::OptionalBase<T>(in_place, std::forward<Args>(args)...) {}
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  constexpr explicit Optional(in_place_t,
+                              std::initializer_list<U> il,
+                              Args&&... args)
+      : internal::OptionalBase<T>(in_place, il, std::forward<Args>(args)...) {}
+
+  ~Optional() = default;
+
+  // Defer copy-/move- assign operator implementation to OptionalBase.
+  // TOOD(hidehiko): Implement conditional enabling.
+  Optional& operator=(const Optional& other) = default;
+  Optional& operator=(Optional&& other) = default;
+
+  Optional& operator=(nullopt_t) {
+    FreeIfNeeded();
+    return *this;
+  }
+
+  template <class U>
+  typename std::enable_if<std::is_same<std::decay_t<U>, T>::value,
+                          Optional&>::type
+  operator=(U&& value) {
+    InitOrAssign(std::forward<U>(value));
+    return *this;
+  }
+
+  constexpr const T* operator->() const {
+    DCHECK(!storage_.is_null_);
+    return &value();
+  }
+
+  constexpr T* operator->() {
+    DCHECK(!storage_.is_null_);
+    return &value();
+  }
+
+  constexpr const T& operator*() const& { return value(); }
+
+  constexpr T& operator*() & { return value(); }
+
+  constexpr const T&& operator*() const&& { return std::move(value()); }
+
+  constexpr T&& operator*() && { return std::move(value()); }
+
+  constexpr explicit operator bool() const { return !storage_.is_null_; }
+
+  constexpr bool has_value() const { return !storage_.is_null_; }
+
+  constexpr T& value() & {
+    DCHECK(!storage_.is_null_);
+    return storage_.value_;
+  }
+
+  constexpr const T& value() const & {
+    DCHECK(!storage_.is_null_);
+    return storage_.value_;
+  }
+
+  constexpr T&& value() && {
+    DCHECK(!storage_.is_null_);
+    return std::move(storage_.value_);
+  }
+
+  constexpr const T&& value() const && {
+    DCHECK(!storage_.is_null_);
+    return std::move(storage_.value_);
+  }
+
+  template <class U>
+  constexpr T value_or(U&& default_value) const& {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_copy_constructible<T>::value,
+    //               "T must be copy constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_null_ ? static_cast<T>(std::forward<U>(default_value))
+                             : value();
+  }
+
+  template <class U>
+  T value_or(U&& default_value) && {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_move_constructible<T>::value,
+    //               "T must be move constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_null_ ? static_cast<T>(std::forward<U>(default_value))
+                             : std::move(value());
+  }
+
+  void swap(Optional& other) {
+    if (storage_.is_null_ && other.storage_.is_null_)
+      return;
+
+    if (storage_.is_null_ != other.storage_.is_null_) {
+      if (storage_.is_null_) {
+        storage_.Init(std::move(other.storage_.value_));
+        other.FreeIfNeeded();
+      } else {
+        other.storage_.Init(std::move(storage_.value_));
+        FreeIfNeeded();
+      }
+      return;
+    }
+
+    DCHECK(!storage_.is_null_ && !other.storage_.is_null_);
+    using std::swap;
+    swap(**this, *other);
+  }
+
+  void reset() {
+    FreeIfNeeded();
+  }
+
+  template <class... Args>
+  void emplace(Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(std::forward<Args>(args)...);
+  }
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(il, std::forward<Args>(args)...);
+    return storage_.value_;
+  }
+
+ private:
+  // Accessing template base class's protected member needs explicit
+  // declaration to do so.
+  using internal::OptionalBase<T>::FreeIfNeeded;
+  using internal::OptionalBase<T>::InitOrAssign;
+  using internal::OptionalBase<T>::storage_;
+};
+
+// Here after defines comparation operators. The definition follows
+// http://en.cppreference.com/w/cpp/utility/optional/operator_cmp
+// while bool() casting is replaced by has_value() to meet the chromium
+// style guide.
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs == *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs != *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs < *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return true;
+  if (!rhs.has_value())
+    return false;
+  return *lhs <= *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return false;
+  if (!rhs.has_value())
+    return true;
+  return *lhs > *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs >= *rhs;
+}
+
+template <class T>
+constexpr bool operator==(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator==(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator!=(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator!=(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<(const Optional<T>& opt, nullopt_t) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator<(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<=(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator<=(nullopt_t, const Optional<T>& opt) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator>(nullopt_t, const Optional<T>& opt) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator>=(const Optional<T>& opt, nullopt_t) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>=(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt == value : false;
+}
+
+template <class T, class U>
+constexpr bool operator==(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value == *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt != value : true;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value != *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt < value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value < *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt <= value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value <= *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt > value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value > *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt >= value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value >= *opt : true;
+}
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return Optional<typename std::decay<T>::type>(std::forward<T>(value));
+}
+
+template <class T, class U, class... Args>
+constexpr Optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return Optional<T>(in_place, il, std::forward<Args>(args)...);
+}
+
+template <class T>
+void swap(Optional<T>& lhs, Optional<T>& rhs) {
+  lhs.swap(rhs);
+}
+
+}  // namespace base
+
+namespace std {
+
+template <class T>
+struct hash<base::Optional<T>> {
+  size_t operator()(const base::Optional<T>& opt) const {
+    return opt == base::nullopt ? 0 : std::hash<T>()(*opt);
+  }
+};
+
+}  // namespace std
+
+#endif  // BASE_OPTIONAL_H_
diff -Naur chromium-65.0.3325.181-orig/base/optional.h.vforward chromium-65.0.3325.181.patched/base/optional.h.vforward
--- chromium-65.0.3325.181-orig/base/optional.h.vforward	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/optional.h.vforward	2018-04-27 11:31:20.643827718 +0300
@@ -0,0 +1,792 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_OPTIONAL_H_
+#define BASE_OPTIONAL_H_
+
+#include <type_traits>
+#include <utility>
+
+#include "base/logging.h"
+#include "base/template_util.h"
+
+namespace base {
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place_t
+struct in_place_t {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt_t
+struct nullopt_t {
+  constexpr explicit nullopt_t(int) {}
+};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/in_place
+constexpr in_place_t in_place = {};
+
+// Specification:
+// http://en.cppreference.com/w/cpp/utility/optional/nullopt
+constexpr nullopt_t nullopt(0);
+
+// Forward declaration, which is refered by following helpers.
+template <typename T>
+class Optional;
+
+namespace internal {
+
+template <typename T, bool = std::is_trivially_destructible<T>::value>
+struct OptionalStorageBase {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is not trivially destructible we must call its
+  // destructor before deallocating its memory.
+  // Note that this hides the (implicitly declared) move constructor, which
+  // would be used for constexpr move constructor in OptionalStorage<T>.
+  // It is needed iff T is trivially move constructible. However, the current
+  // is_trivially_{copy,move}_constructible implementation requires
+  // is_trivially_destructible (which looks a bug, cf:
+  // https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51452 and
+  // http://cplusplus.github.io/LWG/lwg-active.html#2116), so it is not
+  // necessary for this case at the moment. Please see also the destructor
+  // comment in "is_trivially_destructible = true" specialization below.
+  ~OptionalStorageBase() {
+    if (is_populated_)
+      value_.~T();
+  }
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+template <typename T>
+struct OptionalStorageBase<T, true /* trivially destructible */> {
+  // Initializing |empty_| here instead of using default member initializing
+  // to avoid errors in g++ 4.8.
+  constexpr OptionalStorageBase() : empty_('\0') {}
+
+  template <class... Args>
+  constexpr explicit OptionalStorageBase(in_place_t, Args&&... args)
+      : is_populated_(true), value_(std::forward<Args>(args)...) {}
+
+  // When T is trivially destructible (i.e. its destructor does nothing) there
+  // is no need to call it. Implicitly defined destructor is trivial, because
+  // both members (bool and union containing only variants which are trivially
+  // destructible) are trivially destructible.
+  // Explicitly-defaulted destructor is also trivial, but do not use it here,
+  // because it hides the implicit move constructor. It is needed to implement
+  // constexpr move constructor in OptionalStorage iff T is trivially move
+  // constructible. Note that, if T is trivially move constructible, the move
+  // constructor of OptionalStorageBase<T> is also implicitly defined and it is
+  // trivially move constructor. If T is not trivially move constructible,
+  // "not declaring move constructor without destructor declaration" here means
+  // "delete move constructor", which works because any move constructor of
+  // OptionalStorage will not refer to it in that case.
+
+  template <class... Args>
+  void Init(Args&&... args) {
+    DCHECK(!is_populated_);
+    ::new (&value_) T(std::forward<Args>(args)...);
+    is_populated_ = true;
+  }
+
+  bool is_populated_ = false;
+  union {
+    // |empty_| exists so that the union will always be initialized, even when
+    // it doesn't contain a value. Union members must be initialized for the
+    // constructor to be 'constexpr'.
+    char empty_;
+    T value_;
+  };
+};
+
+// Implement conditional constexpr copy and move constructors. These are
+// constexpr if is_trivially_{copy,move}_constructible<T>::value is true
+// respectively. If each is true, the corresponding constructor is defined as
+// "= default;", which generates a constexpr constructor (In this case,
+// the condition of constexpr-ness is satisfied because the base class also has
+// compiler generated constexpr {copy,move} constructors). Note that
+// placement-new is prohibited in constexpr.
+template <typename T,
+          bool = is_trivially_copy_constructible<T>::value,
+          bool = std::is_trivially_move_constructible<T>::value>
+struct OptionalStorage : OptionalStorageBase<T> {
+  // This is no trivially {copy,move} constructible case. Other cases are
+  // defined below as specializations.
+
+  // Accessing the members of template base class requires explicit
+  // declaration.
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+
+  // Inherit constructors (specifically, the in_place constructor).
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  // User defined constructor deletes the default constructor.
+  // Define it explicitly.
+  OptionalStorage() = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       false /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(const OptionalStorage& other) = default;
+
+  OptionalStorage(OptionalStorage&& other) {
+    if (other.is_populated_)
+      Init(std::move(other.value_));
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       false /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  using OptionalStorageBase<T>::is_populated_;
+  using OptionalStorageBase<T>::value_;
+  using OptionalStorageBase<T>::Init;
+  using OptionalStorageBase<T>::OptionalStorageBase;
+
+  OptionalStorage() = default;
+  OptionalStorage(OptionalStorage&& other) = default;
+
+  OptionalStorage(const OptionalStorage& other) {
+    if (other.is_populated_)
+      Init(other.value_);
+  }
+};
+
+template <typename T>
+struct OptionalStorage<T,
+                       true /* trivially copy constructible */,
+                       true /* trivially move constructible */>
+    : OptionalStorageBase<T> {
+  // If both trivially {copy,move} constructible are true, it is not necessary
+  // to use user-defined constructors. So, just inheriting constructors
+  // from the base class works.
+  using OptionalStorageBase<T>::OptionalStorageBase;
+};
+
+// Base class to support conditionally usable copy-/move- constructors
+// and assign operators.
+template <typename T>
+class OptionalBase {
+  // This class provides implementation rather than public API, so everything
+  // should be hidden. Often we use composition, but we cannot in this case
+  // because of C++ language restriction.
+ protected:
+  constexpr OptionalBase() = default;
+  constexpr OptionalBase(const OptionalBase& other) = default;
+  constexpr OptionalBase(OptionalBase&& other) = default;
+
+  template <class... Args>
+  constexpr explicit OptionalBase(in_place_t, Args&&... args)
+      : storage_(in_place, std::forward<Args>(args)...) {}
+
+  // Implementation of converting constructors.
+  template <typename U>
+  explicit OptionalBase(const OptionalBase<U>& other) {
+    if (other.storage_.is_populated_)
+      storage_.Init(other.storage_.value_);
+  }
+
+  template <typename U>
+  explicit OptionalBase(OptionalBase<U>&& other) {
+    if (other.storage_.is_populated_)
+      storage_.Init(std::move(other.storage_.value_));
+  }
+
+  ~OptionalBase() = default;
+
+  OptionalBase& operator=(const OptionalBase& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(other.storage_.value_);
+    return *this;
+  }
+
+  OptionalBase& operator=(OptionalBase&& other) {
+    if (!other.storage_.is_populated_) {
+      FreeIfNeeded();
+      return *this;
+    }
+
+    InitOrAssign(std::move(other.storage_.value_));
+    return *this;
+  }
+
+  void InitOrAssign(const T& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(value);
+    else
+      storage_.value_ = value;
+  }
+
+  void InitOrAssign(T&& value) {
+    if (!storage_.is_populated_)
+      storage_.Init(std::move(value));
+    else
+      storage_.value_ = std::move(value);
+  }
+
+  void FreeIfNeeded() {
+    if (!storage_.is_populated_)
+      return;
+    storage_.value_.~T();
+    storage_.is_populated_ = false;
+  }
+
+  // For implementing conversion, allow access to other typed OptionalBase
+  // class.
+  template <typename U>
+  friend class OptionalBase;
+
+  OptionalStorage<T> storage_;
+};
+
+// The following {Copy,Move}{Constructible,Assignable} structs are helpers to
+// implement constructor/assign-operator overloading. Specifically, if T is
+// is not movable but copyable, Optional<T>'s move constructor should not
+// participate in overload resolution. This inheritance trick implements that.
+template <bool is_copy_constructible>
+struct CopyConstructible {};
+
+template <>
+struct CopyConstructible<false> {
+  constexpr CopyConstructible() = default;
+  constexpr CopyConstructible(const CopyConstructible&) = delete;
+  constexpr CopyConstructible(CopyConstructible&&) = default;
+  CopyConstructible& operator=(const CopyConstructible&) = default;
+  CopyConstructible& operator=(CopyConstructible&&) = default;
+};
+
+template <bool is_move_constructible>
+struct MoveConstructible {};
+
+template <>
+struct MoveConstructible<false> {
+  constexpr MoveConstructible() = default;
+  constexpr MoveConstructible(const MoveConstructible&) = default;
+  constexpr MoveConstructible(MoveConstructible&&) = delete;
+  MoveConstructible& operator=(const MoveConstructible&) = default;
+  MoveConstructible& operator=(MoveConstructible&&) = default;
+};
+
+template <bool is_copy_assignable>
+struct CopyAssignable {};
+
+template <>
+struct CopyAssignable<false> {
+  constexpr CopyAssignable() = default;
+  constexpr CopyAssignable(const CopyAssignable&) = default;
+  constexpr CopyAssignable(CopyAssignable&&) = default;
+  CopyAssignable& operator=(const CopyAssignable&) = delete;
+  CopyAssignable& operator=(CopyAssignable&&) = default;
+};
+
+template <bool is_move_assignable>
+struct MoveAssignable {};
+
+template <>
+struct MoveAssignable<false> {
+  constexpr MoveAssignable() = default;
+  constexpr MoveAssignable(const MoveAssignable&) = default;
+  constexpr MoveAssignable(MoveAssignable&&) = default;
+  MoveAssignable& operator=(const MoveAssignable&) = default;
+  MoveAssignable& operator=(MoveAssignable&&) = delete;
+};
+
+// Helper to conditionally enable converting constructors.
+template <typename T, typename U>
+struct IsConvertibleFromOptional
+    : std::integral_constant<
+          bool,
+          std::is_constructible<T, Optional<U>&>::value ||
+              std::is_constructible<T, const Optional<U>&>::value ||
+              std::is_constructible<T, Optional<U>&&>::value ||
+              std::is_constructible<T, const Optional<U>&&>::value ||
+              std::is_convertible<Optional<U>&, T>::value ||
+              std::is_convertible<const Optional<U>&, T>::value ||
+              std::is_convertible<Optional<U>&&, T>::value ||
+              std::is_convertible<const Optional<U>&&, T>::value> {};
+
+}  // namespace internal
+
+// base::Optional is a Chromium version of the C++17 optional class:
+// std::optional documentation:
+// http://en.cppreference.com/w/cpp/utility/optional
+// Chromium documentation:
+// https://chromium.googlesource.com/chromium/src/+/master/docs/optional.md
+//
+// These are the differences between the specification and the implementation:
+// - Constructors do not use 'constexpr' as it is a C++14 extension.
+// - 'constexpr' might be missing in some places for reasons specified locally.
+// - No exceptions are thrown, because they are banned from Chromium.
+// - All the non-members are in the 'base' namespace instead of 'std'.
+template <typename T>
+class Optional
+    : public internal::OptionalBase<T>,
+      public internal::CopyConstructible<std::is_copy_constructible<T>::value>,
+      public internal::MoveConstructible<std::is_move_constructible<T>::value>,
+      public internal::CopyAssignable<std::is_copy_constructible<T>::value &&
+                                      std::is_copy_assignable<T>::value>,
+      public internal::MoveAssignable<std::is_move_constructible<T>::value &&
+                                      std::is_move_assignable<T>::value> {
+ public:
+  using value_type = T;
+
+  // Defer default/copy/move constructor implementation to OptionalBase.
+  constexpr Optional() = default;
+  constexpr Optional(const Optional& other) = default;
+  constexpr Optional(Optional&& other) = default;
+
+  constexpr Optional(nullopt_t) {}  // NOLINT(runtime/explicit)
+
+  // Converting copy constructor. "explicit" only if
+  // std::is_convertible<const U&, T>::value is false. It is implemented by
+  // declaring two almost same constructors, but that condition in enable_if_t
+  // is different, so that either one is chosen, thanks to SFINAE.
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, const U&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           std::is_convertible<const U&, T>::value,
+                       bool> = false>
+  Optional(const Optional<U>& other) : internal::OptionalBase<T>(other) {}
+
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, const U&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           !std::is_convertible<const U&, T>::value,
+                       bool> = false>
+  explicit Optional(const Optional<U>& other)
+      : internal::OptionalBase<T>(other) {}
+
+  // Converting move constructor. Similar to converting copy constructor,
+  // declaring two (explicit and non-explicit) constructors.
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, U&&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           std::is_convertible<U&&, T>::value,
+                       bool> = false>
+  Optional(Optional<U>&& other) : internal::OptionalBase<T>(std::move(other)) {}
+
+  template <
+      typename U,
+      std::enable_if_t<std::is_constructible<T, U&&>::value &&
+                           !internal::IsConvertibleFromOptional<T, U>::value &&
+                           !std::is_convertible<U&&, T>::value,
+                       bool> = false>
+  explicit Optional(Optional<U>&& other)
+      : internal::OptionalBase<T>(std::move(other)) {}
+
+  constexpr Optional(const T& value)
+      : internal::OptionalBase<T>(in_place, value) {}
+
+  constexpr Optional(T&& value)
+      : internal::OptionalBase<T>(in_place, std::move(value)) {}
+
+  template <class... Args>
+  constexpr explicit Optional(in_place_t, Args&&... args)
+      : internal::OptionalBase<T>(in_place, std::forward<Args>(args)...) {}
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  constexpr explicit Optional(in_place_t,
+                              std::initializer_list<U> il,
+                              Args&&... args)
+      : internal::OptionalBase<T>(in_place, il, std::forward<Args>(args)...) {}
+
+  ~Optional() = default;
+
+  // Defer copy-/move- assign operator implementation to OptionalBase.
+  Optional& operator=(const Optional& other) = default;
+  Optional& operator=(Optional&& other) = default;
+
+  Optional& operator=(nullopt_t) {
+    FreeIfNeeded();
+    return *this;
+  }
+
+  template <class U>
+  typename std::enable_if<std::is_same<std::decay_t<U>, T>::value,
+                          Optional&>::type
+  operator=(U&& value) {
+    InitOrAssign(std::forward<U>(value));
+    return *this;
+  }
+
+  constexpr const T* operator->() const {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr T* operator->() {
+    DCHECK(storage_.is_populated_);
+    return &value();
+  }
+
+  constexpr const T& operator*() const& { return value(); }
+
+  constexpr T& operator*() & { return value(); }
+
+  constexpr const T&& operator*() const&& { return std::move(value()); }
+
+  constexpr T&& operator*() && { return std::move(value()); }
+
+  constexpr explicit operator bool() const { return storage_.is_populated_; }
+
+  constexpr bool has_value() const { return storage_.is_populated_; }
+
+  constexpr T& value() & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr const T& value() const & {
+    DCHECK(storage_.is_populated_);
+    return storage_.value_;
+  }
+
+  constexpr T&& value() && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  constexpr const T&& value() const && {
+    DCHECK(storage_.is_populated_);
+    return std::move(storage_.value_);
+  }
+
+  template <class U>
+  constexpr T value_or(U&& default_value) const& {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_copy_constructible<T>::value,
+    //               "T must be copy constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? value()
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  template <class U>
+  T value_or(U&& default_value) && {
+    // TODO(mlamouri): add the following assert when possible:
+    // static_assert(std::is_move_constructible<T>::value,
+    //               "T must be move constructible");
+    static_assert(std::is_convertible<U, T>::value,
+                  "U must be convertible to T");
+    return storage_.is_populated_
+               ? std::move(value())
+               : static_cast<T>(std::forward<U>(default_value));
+  }
+
+  void swap(Optional& other) {
+    if (!storage_.is_populated_ && !other.storage_.is_populated_)
+      return;
+
+    if (storage_.is_populated_ != other.storage_.is_populated_) {
+      if (storage_.is_populated_) {
+        other.storage_.Init(std::move(storage_.value_));
+        FreeIfNeeded();
+      } else {
+        storage_.Init(std::move(other.storage_.value_));
+        other.FreeIfNeeded();
+      }
+      return;
+    }
+
+    DCHECK(storage_.is_populated_ && other.storage_.is_populated_);
+    using std::swap;
+    swap(**this, *other);
+  }
+
+  void reset() {
+    FreeIfNeeded();
+  }
+
+  template <class... Args>
+  void emplace(Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(std::forward<Args>(args)...);
+  }
+
+  template <
+      class U,
+      class... Args,
+      class = std::enable_if_t<std::is_constructible<value_type,
+                                                     std::initializer_list<U>&,
+                                                     Args...>::value>>
+  T& emplace(std::initializer_list<U> il, Args&&... args) {
+    FreeIfNeeded();
+    storage_.Init(il, std::forward<Args>(args)...);
+    return storage_.value_;
+  }
+
+ private:
+  // Accessing template base class's protected member needs explicit
+  // declaration to do so.
+  using internal::OptionalBase<T>::FreeIfNeeded;
+  using internal::OptionalBase<T>::InitOrAssign;
+  using internal::OptionalBase<T>::storage_;
+};
+
+// Here after defines comparation operators. The definition follows
+// http://en.cppreference.com/w/cpp/utility/optional/operator_cmp
+// while bool() casting is replaced by has_value() to meet the chromium
+// style guide.
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs == *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (lhs.has_value() != rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs != *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return false;
+  if (!lhs.has_value())
+    return true;
+  return *lhs < *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return true;
+  if (!rhs.has_value())
+    return false;
+  return *lhs <= *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!lhs.has_value())
+    return false;
+  if (!rhs.has_value())
+    return true;
+  return *lhs > *rhs;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& lhs, const Optional<U>& rhs) {
+  if (!rhs.has_value())
+    return true;
+  if (!lhs.has_value())
+    return false;
+  return *lhs >= *rhs;
+}
+
+template <class T>
+constexpr bool operator==(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator==(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator!=(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator!=(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<(const Optional<T>& opt, nullopt_t) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator<(nullopt_t, const Optional<T>& opt) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator<=(const Optional<T>& opt, nullopt_t) {
+  return !opt;
+}
+
+template <class T>
+constexpr bool operator<=(nullopt_t, const Optional<T>& opt) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>(const Optional<T>& opt, nullopt_t) {
+  return opt.has_value();
+}
+
+template <class T>
+constexpr bool operator>(nullopt_t, const Optional<T>& opt) {
+  return false;
+}
+
+template <class T>
+constexpr bool operator>=(const Optional<T>& opt, nullopt_t) {
+  return true;
+}
+
+template <class T>
+constexpr bool operator>=(nullopt_t, const Optional<T>& opt) {
+  return !opt;
+}
+
+template <class T, class U>
+constexpr bool operator==(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt == value : false;
+}
+
+template <class T, class U>
+constexpr bool operator==(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value == *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt != value : true;
+}
+
+template <class T, class U>
+constexpr bool operator!=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value != *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt < value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value < *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt <= value : true;
+}
+
+template <class T, class U>
+constexpr bool operator<=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value <= *opt : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt > value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value > *opt : true;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const Optional<T>& opt, const U& value) {
+  return opt.has_value() ? *opt >= value : false;
+}
+
+template <class T, class U>
+constexpr bool operator>=(const U& value, const Optional<T>& opt) {
+  return opt.has_value() ? value >= *opt : true;
+}
+
+template <class T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return Optional<typename std::decay<T>::type>(std::forward<T>(value));
+}
+
+template <class T, class U, class... Args>
+constexpr Optional<T> make_optional(std::initializer_list<U> il,
+                                    Args&&... args) {
+  return Optional<T>(in_place, il, std::forward<Args>(args)...);
+}
+
+template <class T>
+void swap(Optional<T>& lhs, Optional<T>& rhs) {
+  lhs.swap(rhs);
+}
+
+}  // namespace base
+
+namespace std {
+
+template <class T>
+struct hash<base::Optional<T>> {
+  size_t operator()(const base::Optional<T>& opt) const {
+    return opt == base::nullopt ? 0 : std::hash<T>()(*opt);
+  }
+};
+
+}  // namespace std
+
+#endif  // BASE_OPTIONAL_H_
diff -Naur chromium-65.0.3325.181-orig/base/template_util.h.gcc7-itcc chromium-65.0.3325.181.patched/base/template_util.h.gcc7-itcc
--- chromium-65.0.3325.181-orig/base/template_util.h.gcc7-itcc	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/base/template_util.h.gcc7-itcc	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,135 @@
+// Copyright (c) 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef BASE_TEMPLATE_UTIL_H_
+#define BASE_TEMPLATE_UTIL_H_
+
+#include <stddef.h>
+#include <iosfwd>
+#include <iterator>
+#include <type_traits>
+#include <utility>
+
+#include "build/build_config.h"
+
+// Some versions of libstdc++ have partial support for type_traits, but misses
+// a smaller subset while removing some of the older non-standard stuff. Assume
+// that all versions below 5.0 fall in this category, along with one 5.0
+// experimental release. Test for this by consulting compiler major version,
+// the only reliable option available, so theoretically this could fail should
+// you attempt to mix an earlier version of libstdc++ with >= GCC5. But
+// that's unlikely to work out, especially as GCC5 changed ABI.
+#define CR_GLIBCXX_5_0_0 20150123
+#if (defined(__GNUC__) && __GNUC__ < 5) || \
+    (defined(__GLIBCXX__) && __GLIBCXX__ == CR_GLIBCXX_5_0_0)
+#define CR_USE_FALLBACKS_FOR_OLD_EXPERIMENTAL_GLIBCXX
+#endif
+
+// This hacks around using gcc with libc++ which has some incompatibilies.
+// - is_trivially_* doesn't work: https://llvm.org/bugs/show_bug.cgi?id=27538
+// TODO(danakj): Remove this when android builders are all using a newer version
+// of gcc, or the android ndk is updated to a newer libc++ that works with older
+// gcc versions.
+#if !defined(__clang__) && defined(_LIBCPP_VERSION)
+#define CR_USE_FALLBACKS_FOR_GCC_WITH_LIBCXX
+#endif
+
+namespace base {
+
+template <class T> struct is_non_const_reference : std::false_type {};
+template <class T> struct is_non_const_reference<T&> : std::true_type {};
+template <class T> struct is_non_const_reference<const T&> : std::false_type {};
+
+namespace internal {
+
+// Implementation detail of base::void_t below.
+template <typename...>
+struct make_void {
+  using type = void;
+};
+
+}  // namespace internal
+
+// base::void_t is an implementation of std::void_t from C++17.
+//
+// We use |base::internal::make_void| as a helper struct to avoid a C++14
+// defect:
+//   http://en.cppreference.com/w/cpp/types/void_t
+//   http://open-std.org/JTC1/SC22/WG21/docs/cwg_defects.html#1558
+template <typename... Ts>
+using void_t = typename ::base::internal::make_void<Ts...>::type;
+
+namespace internal {
+
+// Uses expression SFINAE to detect whether using operator<< would work.
+template <typename T, typename = void>
+struct SupportsOstreamOperator : std::false_type {};
+template <typename T>
+struct SupportsOstreamOperator<T,
+                               decltype(void(std::declval<std::ostream&>()
+                                             << std::declval<T>()))>
+    : std::true_type {};
+
+// Used to detech whether the given type is an iterator.  This is normally used
+// with std::enable_if to provide disambiguation for functions that take
+// templatzed iterators as input.
+template <typename T, typename = void>
+struct is_iterator : std::false_type {};
+
+template <typename T>
+struct is_iterator<T,
+                   void_t<typename std::iterator_traits<T>::iterator_category>>
+    : std::true_type {};
+
+}  // namespace internal
+
+// is_trivially_copyable is especially hard to get right.
+// - Older versions of libstdc++ will fail to have it like they do for other
+//   type traits. This has become a subset of the second point, but used to be
+//   handled independently.
+// - An experimental release of gcc includes most of type_traits but misses
+//   is_trivially_copyable, so we still have to avoid using libstdc++ in this
+//   case, which is covered by CR_USE_FALLBACKS_FOR_OLD_EXPERIMENTAL_GLIBCXX.
+// - When compiling libc++ from before r239653, with a gcc compiler, the
+//   std::is_trivially_copyable can fail. So we need to work around that by not
+//   using the one in libc++ in this case. This is covered by the
+//   CR_USE_FALLBACKS_FOR_GCC_WITH_LIBCXX define, and is discussed in
+//   https://llvm.org/bugs/show_bug.cgi?id=27538#c1 where they point out that
+//   in libc++'s commit r239653 this is fixed by libc++ checking for gcc 5.1.
+// - In both of the above cases we are using the gcc compiler. When defining
+//   this ourselves on compiler intrinsics, the __is_trivially_copyable()
+//   intrinsic is not available on gcc before version 5.1 (see the discussion in
+//   https://llvm.org/bugs/show_bug.cgi?id=27538#c1 again), so we must check for
+//   that version.
+// - When __is_trivially_copyable() is not available because we are on gcc older
+//   than 5.1, we need to fall back to something, so we use __has_trivial_copy()
+//   instead based on what was done one-off in bit_cast() previously.
+
+// TODO(crbug.com/554293): Remove this when all platforms have this in the std
+// namespace and it works with gcc as needed.
+#if defined(CR_USE_FALLBACKS_FOR_OLD_EXPERIMENTAL_GLIBCXX) || \
+    defined(CR_USE_FALLBACKS_FOR_GCC_WITH_LIBCXX)
+template <typename T>
+struct is_trivially_copyable {
+// TODO(danakj): Remove this when android builders are all using a newer version
+// of gcc, or the android ndk is updated to a newer libc++ that does this for
+// us.
+#if _GNUC_VER >= 501
+  static constexpr bool value = __is_trivially_copyable(T);
+#else
+  static constexpr bool value =
+      __has_trivial_copy(T) && __has_trivial_destructor(T);
+#endif
+};
+#else
+template <class T>
+using is_trivially_copyable = std::is_trivially_copyable<T>;
+#endif
+
+}  // namespace base
+
+#undef CR_USE_FALLBACKS_FOR_GCC_WITH_LIBCXX
+#undef CR_USE_FALLBACKS_FOR_OLD_EXPERIMENTAL_GLIBCXX
+
+#endif  // BASE_TEMPLATE_UTIL_H_
diff -Naur chromium-65.0.3325.181-orig/build/config/clang/clang.gni.system-clang chromium-65.0.3325.181.patched/build/config/clang/clang.gni.system-clang
--- chromium-65.0.3325.181-orig/build/config/clang/clang.gni.system-clang	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/config/clang/clang.gni.system-clang	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,13 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/toolchain/toolchain.gni")
+
+declare_args() {
+  # Indicates if the build should use the Chrome-specific plugins for enforcing
+  # coding guidelines, etc. Only used when compiling with Clang.
+  clang_use_chrome_plugins = is_clang && !is_nacl && !use_xcode_clang
+
+  clang_base_path = "//third_party/llvm-build/Release+Asserts"
+}
diff -Naur chromium-65.0.3325.181-orig/build/linux/unbundle/libjpeg.gn chromium-65.0.3325.181.patched/build/linux/unbundle/libjpeg.gn
--- chromium-65.0.3325.181-orig/build/linux/unbundle/libjpeg.gn	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/linux/unbundle/libjpeg.gn	2018-04-27 11:31:20.503829193 +0300
@@ -16,6 +16,10 @@
   libs = [ "jpeg" ]
 }
 
+config("system_libjpeg") {
+  defines = [ "USE_SYSTEM_LIBJPEG=1" ]
+}
+
 source_set("simd") {
 }
 
diff -Naur chromium-65.0.3325.181-orig/build/linux/unbundle/libjpeg.gn.gnsystem chromium-65.0.3325.181.patched/build/linux/unbundle/libjpeg.gn.gnsystem
--- chromium-65.0.3325.181-orig/build/linux/unbundle/libjpeg.gn.gnsystem	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/linux/unbundle/libjpeg.gn.gnsystem	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,26 @@
+# Copyright 2016 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/shim_headers.gni")
+
+shim_headers("libjpeg_shim") {
+  root_path = "."
+  headers = [ "jpeglib.h" ]
+}
+
+source_set("libjpeg") {
+  deps = [
+    ":libjpeg_shim",
+  ]
+  libs = [ "jpeg" ]
+}
+
+source_set("simd") {
+}
+
+source_set("simd_asm") {
+}
+
+config("libjpeg_config") {
+}
diff -Naur chromium-65.0.3325.181-orig/build/linux/unbundle/libusb.gn chromium-65.0.3325.181.patched/build/linux/unbundle/libusb.gn
--- chromium-65.0.3325.181-orig/build/linux/unbundle/libusb.gn	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/linux/unbundle/libusb.gn	2018-04-27 11:31:20.503829193 +0300
@@ -0,0 +1,24 @@
+# Copyright 2016 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/linux/pkg_config.gni")
+import("//build/shim_headers.gni")
+
+pkg_config("system_libusb") {
+  packages = [ "libusb-1.0" ]
+}
+
+shim_headers("libusb_shim") {
+  root_path = "src/libusb"
+  headers = [
+    "libusb.h",
+  ]
+}
+
+source_set("libusb") {
+  deps = [
+    ":libusb_shim",
+  ]
+  public_configs = [ ":system_libusb" ]
+}
diff -Naur chromium-65.0.3325.181-orig/build/linux/unbundle/opus.gn chromium-65.0.3325.181.patched/build/linux/unbundle/opus.gn
--- chromium-65.0.3325.181-orig/build/linux/unbundle/opus.gn	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/linux/unbundle/opus.gn	2018-04-27 11:31:20.503829193 +0300
@@ -1,3 +1,164 @@
+# Copyright 2016 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/linux/pkg_config.gni")
+import("//build/shim_headers.gni")
+import("//testing/test.gni")
+
+pkg_config("system_opus") {
+  packages = [ "opus" ]
+}
+
+shim_headers("opus_shim") {
+  root_path = "src/include"
+  headers = [
+    "opus_custom.h",
+    "opus_defines.h",
+    "opus_multistream.h",
+    "opus_types.h",
+    "opus.h",
+  ]
+}
+
+source_set("opus") {
+  deps = [
+    ":opus_shim",
+  ]
+  public_configs = [ ":system_opus" ]
+}
+
+config("opus_test_config") {
+  include_dirs = [
+    "src/celt",
+    "src/silk",
+  ]
+
+  if (is_win) {
+    defines = [ "inline=__inline" ]
+  }
+  if (is_android) {
+    libs = [ "log" ]
+  }
+  if (is_clang) {
+    cflags = [ "-Wno-absolute-value" ]
+  }
+}
+
+executable("opus_compare") {
+  sources = [
+    "src/src/opus_compare.c",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    "//build/config/compiler:no_chromium_code",
+    ":opus_test_config",
+  ]
+
+  deps = [
+    ":opus",
+    "//build/config/sanitizers:deps",
+    "//build/win:default_exe_manifest",
+  ]
+}
+
+executable("opus_demo") {
+  sources = [
+    "src/src/opus_demo.c",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    "//build/config/compiler:no_chromium_code",
+    ":opus_test_config",
+  ]
+
+  deps = [
+    ":opus",
+    "//build/config/sanitizers:deps",
+    "//build/win:default_exe_manifest",
+  ]
+}
+
+test("test_opus_api") {
+  sources = [
+    "src/tests/test_opus_api.c",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    "//build/config/compiler:no_chromium_code",
+    ":opus_test_config",
+  ]
+
+  deps = [
+    ":opus",
+  ]
+}
+
+test("test_opus_encode") {
+  sources = [
+    "src/tests/test_opus_encode.c",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    "//build/config/compiler:no_chromium_code",
+    ":opus_test_config",
+  ]
+
+  deps = [
+    ":opus",
+  ]
+}
+
+# GN orders flags on a target before flags from configs. The default config
+# adds -Wall, and this flag have to be after -Wall -- so they need to
+# come from a config and can't be on the target directly.
+config("test_opus_decode_config") {
+  # test_opus_decode passes a null pointer to opus_decode() for an argument
+  # marked as requiring a non-null value by the nonnull function attribute,
+  # and expects opus_decode() to fail. Disable the -Wnonnull option to avoid
+  # a compilation error if -Werror is specified.
+  if (is_posix) {
+    cflags = [ "-Wno-nonnull" ]
+  }
+}
+
+test("test_opus_decode") {
+  sources = [
+    "src/tests/test_opus_decode.c",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    "//build/config/compiler:no_chromium_code",
+    ":opus_test_config",
+    ":test_opus_decode_config",
+  ]
+
+  deps = [
+    ":opus",
+  ]
+}
+
+test("test_opus_padding") {
+  sources = [
+    "src/tests/test_opus_padding.c",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    "//build/config/compiler:no_chromium_code",
+    ":opus_test_config",
+  ]
+
+  deps = [
+    ":opus",
+  ]
+}
+
 # Copyright 2017 The Chromium Authors. All rights reserved.
 # Use of this source code is governed by a BSD-style license that can be
 # found in the LICENSE file.
diff -Naur chromium-65.0.3325.181-orig/build/linux/unbundle/opus.gn.gnsystem chromium-65.0.3325.181.patched/build/linux/unbundle/opus.gn.gnsystem
--- chromium-65.0.3325.181-orig/build/linux/unbundle/opus.gn.gnsystem	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/linux/unbundle/opus.gn.gnsystem	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,45 @@
+# Copyright 2017 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/linux/pkg_config.gni")
+import("//build/shim_headers.gni")
+
+pkg_config("opus_config") {
+  packages = [ "opus" ]
+}
+
+shim_headers("opus_shim") {
+  root_path = "src/include"
+  headers = [
+    "opus.h",
+    "opus_defines.h",
+    "opus_multistream.h",
+    "opus_types.h",
+  ]
+}
+
+source_set("opus") {
+  deps = [
+    ":opus_shim",
+  ]
+  public_configs = [ ":opus_config" ]
+}
+
+source_set("opus_compare") {
+}
+
+source_set("opus_demo") {
+}
+
+source_set("test_opus_api") {
+}
+
+source_set("test_opus_decode") {
+}
+
+source_set("test_opus_encode") {
+}
+
+source_set("test_opus_padding") {
+}
diff -Naur chromium-65.0.3325.181-orig/build/linux/unbundle/replace_gn_files.py chromium-65.0.3325.181.patched/build/linux/unbundle/replace_gn_files.py
--- chromium-65.0.3325.181-orig/build/linux/unbundle/replace_gn_files.py	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/linux/unbundle/replace_gn_files.py	2018-04-27 11:31:20.507829150 +0300
@@ -27,6 +27,7 @@
   'libevent': 'base/third_party/libevent/BUILD.gn',
   'libjpeg': 'build/secondary/third_party/libjpeg_turbo/BUILD.gn',
   'libpng': 'third_party/libpng/BUILD.gn',
+  'libusb': 'third_party/libusb/BUILD.gn',
   'libvpx': 'third_party/libvpx/BUILD.gn',
   'libwebp': 'third_party/libwebp/BUILD.gn',
   'libxml': 'third_party/libxml/BUILD.gn',
diff -Naur chromium-65.0.3325.181-orig/build/linux/unbundle/replace_gn_files.py.gnsystem chromium-65.0.3325.181.patched/build/linux/unbundle/replace_gn_files.py.gnsystem
--- chromium-65.0.3325.181-orig/build/linux/unbundle/replace_gn_files.py.gnsystem	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/linux/unbundle/replace_gn_files.py.gnsystem	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,84 @@
+#!/usr/bin/env python
+# Copyright 2016 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+"""
+Replaces GN files in tree with files from here that
+make the build use system libraries.
+"""
+
+from __future__ import print_function
+
+import argparse
+import os
+import shutil
+import sys
+
+
+REPLACEMENTS = {
+  'ffmpeg': 'third_party/ffmpeg/BUILD.gn',
+  'flac': 'third_party/flac/BUILD.gn',
+  'fontconfig': 'third_party/fontconfig/BUILD.gn',
+  'freetype': 'build/config/freetype/freetype.gni',
+  'harfbuzz-ng': 'third_party/harfbuzz-ng/harfbuzz.gni',
+  'icu': 'third_party/icu/BUILD.gn',
+  'libdrm': 'third_party/libdrm/BUILD.gn',
+  'libevent': 'base/third_party/libevent/BUILD.gn',
+  'libjpeg': 'build/secondary/third_party/libjpeg_turbo/BUILD.gn',
+  'libpng': 'third_party/libpng/BUILD.gn',
+  'libvpx': 'third_party/libvpx/BUILD.gn',
+  'libwebp': 'third_party/libwebp/BUILD.gn',
+  'libxml': 'third_party/libxml/BUILD.gn',
+  'libxslt': 'third_party/libxslt/BUILD.gn',
+  'openh264': 'third_party/openh264/BUILD.gn',
+  'opus': 'third_party/opus/BUILD.gn',
+  're2': 'third_party/re2/BUILD.gn',
+  'snappy': 'third_party/snappy/BUILD.gn',
+  'yasm': 'third_party/yasm/yasm_assemble.gni',
+  'zlib': 'third_party/zlib/BUILD.gn',
+}
+
+
+def DoMain(argv):
+  my_dirname = os.path.dirname(__file__)
+  source_tree_root = os.path.abspath(
+    os.path.join(my_dirname, '..', '..', '..'))
+
+  parser = argparse.ArgumentParser()
+  parser.add_argument('--system-libraries', nargs='*', default=[])
+  parser.add_argument('--undo', action='store_true')
+
+  args = parser.parse_args(argv)
+
+  handled_libraries = set()
+  for lib, path in REPLACEMENTS.items():
+    if lib not in args.system_libraries:
+      continue
+    handled_libraries.add(lib)
+
+    if args.undo:
+      # Restore original file, and also remove the backup.
+      # This is meant to restore the source tree to its original state.
+      os.rename(os.path.join(source_tree_root, path + '.orig'),
+                os.path.join(source_tree_root, path))
+    else:
+      # Create a backup copy for --undo.
+      shutil.copyfile(os.path.join(source_tree_root, path),
+                      os.path.join(source_tree_root, path + '.orig'))
+
+      # Copy the GN file from directory of this script to target path.
+      shutil.copyfile(os.path.join(my_dirname, '%s.gn' % lib),
+                      os.path.join(source_tree_root, path))
+
+  unhandled_libraries = set(args.system_libraries) - handled_libraries
+  if unhandled_libraries:
+    print('Unrecognized system libraries requested: %s' % ', '.join(
+        sorted(unhandled_libraries)), file=sys.stderr)
+    return 1
+
+  return 0
+
+
+if __name__ == '__main__':
+  sys.exit(DoMain(sys.argv[1:]))
diff -Naur chromium-65.0.3325.181-orig/build/toolchain/linux/BUILD.gn chromium-65.0.3325.181.patched/build/toolchain/linux/BUILD.gn
--- chromium-65.0.3325.181-orig/build/toolchain/linux/BUILD.gn	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/build/toolchain/linux/BUILD.gn	2018-04-27 11:31:20.519829024 +0300
@@ -31,6 +31,7 @@
   ld = cxx
   readelf = "${toolprefix}readelf"
   nm = "${toolprefix}nm"
+  extra_cppflags = "-fno-delete-null-pointer-checks"
 
   toolchain_args = {
     current_cpu = "arm64"
@@ -49,6 +50,7 @@
   ld = cxx
   readelf = "${toolprefix}readelf"
   nm = "${toolprefix}nm"
+  extra_cppflags = "-fno-delete-null-pointer-checks"
 
   toolchain_args = {
     current_cpu = "arm"
@@ -99,6 +101,7 @@
   nm = "nm"
   ar = "ar"
   ld = cxx
+  extra_cppflags = "-fno-delete-null-pointer-checks -g1"
 
   # Output linker map files for binary size analysis.
   enable_linker_map = true
@@ -152,6 +155,7 @@
   nm = "nm"
   ar = "ar"
   ld = cxx
+  extra_cppflags = "-fno-delete-null-pointer-checks"
 
   # Output linker map files for binary size analysis.
   enable_linker_map = true
@@ -186,6 +190,7 @@
   ld = cxx
   readelf = "${toolprefix}readelf"
   nm = "${toolprefix}nm"
+  extra_cppflags = "-fno-delete-null-pointer-checks"
 
   toolchain_args = {
     cc_wrapper = ""
diff -Naur chromium-65.0.3325.181-orig/cc/blink/web_layer_impl.h chromium-65.0.3325.181.patched/cc/blink/web_layer_impl.h
--- chromium-65.0.3325.181-orig/cc/blink/web_layer_impl.h	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/blink/web_layer_impl.h	2018-04-27 11:31:20.523828981 +0300
@@ -67,7 +67,7 @@
   void SetIsRootForIsolatedGroup(bool root) override;
   bool IsRootForIsolatedGroup() override;
   void SetHitTestableWithoutDrawsContent(bool should_hit_test) override;
-  void SetOpaque(bool opaque) override;
+  CC_BLINK_EXPORT void SetOpaque(bool opaque) override;
   bool Opaque() const override;
   void SetPosition(const blink::WebFloatPoint& position) override;
   blink::WebFloatPoint GetPosition() const override;
diff -Naur chromium-65.0.3325.181-orig/cc/blink/web_layer_impl.h.setopaque chromium-65.0.3325.181.patched/cc/blink/web_layer_impl.h.setopaque
--- chromium-65.0.3325.181-orig/cc/blink/web_layer_impl.h.setopaque	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/blink/web_layer_impl.h.setopaque	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,149 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef CC_BLINK_WEB_LAYER_IMPL_H_
+#define CC_BLINK_WEB_LAYER_IMPL_H_
+
+#include <stddef.h>
+#include <stdint.h>
+
+#include <memory>
+#include <string>
+#include <utility>
+
+#include "base/macros.h"
+#include "base/memory/ref_counted.h"
+#include "cc/blink/cc_blink_export.h"
+#include "cc/layers/layer_client.h"
+#include "third_party/WebKit/public/platform/WebColor.h"
+#include "third_party/WebKit/public/platform/WebDoublePoint.h"
+#include "third_party/WebKit/public/platform/WebFloatPoint.h"
+#include "third_party/WebKit/public/platform/WebFloatSize.h"
+#include "third_party/WebKit/public/platform/WebLayer.h"
+#include "third_party/WebKit/public/platform/WebPoint.h"
+#include "third_party/WebKit/public/platform/WebRect.h"
+#include "third_party/WebKit/public/platform/WebSize.h"
+#include "third_party/WebKit/public/platform/WebString.h"
+#include "third_party/WebKit/public/platform/WebVector.h"
+#include "third_party/skia/include/core/SkMatrix44.h"
+
+namespace cc {
+class FilterOperations;
+class Layer;
+}
+
+namespace cc_blink {
+
+class CC_BLINK_EXPORT WebLayerImpl : public blink::WebLayer {
+ public:
+  WebLayerImpl();
+  explicit WebLayerImpl(scoped_refptr<cc::Layer>);
+  ~WebLayerImpl() override;
+
+  cc::Layer* layer() const;
+
+  // WebLayer implementation.
+  int Id() const override;
+  void InvalidateRect(const blink::WebRect&) override;
+  void Invalidate() override;
+  void AddChild(blink::WebLayer* child) override;
+  void InsertChild(blink::WebLayer* child, size_t index) override;
+  void ReplaceChild(blink::WebLayer* reference,
+                    blink::WebLayer* new_layer) override;
+  void RemoveFromParent() override;
+  void RemoveAllChildren() override;
+  void SetBounds(const blink::WebSize& bounds) override;
+  blink::WebSize Bounds() const override;
+  void SetMasksToBounds(bool masks_to_bounds) override;
+  bool MasksToBounds() const override;
+  void SetMaskLayer(blink::WebLayer* mask) override;
+  void SetOpacity(float opacity) override;
+  float Opacity() const override;
+  void SetContentsOpaqueIsFixed(bool fixed) override;
+
+  void SetBlendMode(blink::WebBlendMode blend_mode) override;
+  blink::WebBlendMode BlendMode() const override;
+  void SetIsRootForIsolatedGroup(bool root) override;
+  bool IsRootForIsolatedGroup() override;
+  void SetHitTestableWithoutDrawsContent(bool should_hit_test) override;
+  void SetOpaque(bool opaque) override;
+  bool Opaque() const override;
+  void SetPosition(const blink::WebFloatPoint& position) override;
+  blink::WebFloatPoint GetPosition() const override;
+  void SetTransform(const SkMatrix44& transform) override;
+  void SetTransformOrigin(const blink::WebFloatPoint3D& point) override;
+  blink::WebFloatPoint3D TransformOrigin() const override;
+  SkMatrix44 Transform() const override;
+  void SetDrawsContent(bool draws_content) override;
+  bool DrawsContent() const override;
+  void SetDoubleSided(bool double_sided) override;
+  void SetShouldFlattenTransform(bool flatten) override;
+  void SetRenderingContext(int context) override;
+  void SetUseParentBackfaceVisibility(bool visible) override;
+  void SetBackgroundColor(blink::WebColor color) override;
+  blink::WebColor BackgroundColor() const override;
+  void SetFilters(const cc::FilterOperations& filters) override;
+  void SetFiltersOrigin(const blink::WebFloatPoint& origin) override;
+  void SetBackgroundFilters(const cc::FilterOperations& filters) override;
+  bool HasTickingAnimationForTesting() override;
+  void SetScrollable(const blink::WebSize&) override;
+  blink::WebSize ScrollContainerBoundsForTesting() const override;
+  void SetScrollPosition(blink::WebFloatPoint position) override;
+  blink::WebFloatPoint ScrollPosition() const override;
+  bool Scrollable() const override;
+  void SetUserScrollable(bool horizontal, bool vertical) override;
+  bool UserScrollableHorizontal() const override;
+  bool UserScrollableVertical() const override;
+  void AddMainThreadScrollingReasons(
+      uint32_t main_thread_scrolling_reasons) override;
+  void ClearMainThreadScrollingReasons(
+      uint32_t main_thread_scrolling_reasons_to_clear) override;
+  uint32_t MainThreadScrollingReasons() override;
+  bool ShouldScrollOnMainThread() const override;
+  void SetNonFastScrollableRegion(
+      const blink::WebVector<blink::WebRect>& region) override;
+  blink::WebVector<blink::WebRect> NonFastScrollableRegion() const override;
+  void SetTouchEventHandlerRegion(
+      const blink::WebVector<blink::WebTouchInfo>& touch_info) override;
+  blink::WebVector<blink::WebRect> TouchEventHandlerRegion() const override;
+  blink::WebVector<blink::WebRect>
+      TouchEventHandlerRegionForTouchActionForTesting(
+          cc::TouchAction) const override;
+  void SetIsContainerForFixedPositionLayers(bool is_container) override;
+  bool IsContainerForFixedPositionLayers() const override;
+  void SetIsResizedByBrowserControls(bool) override;
+  void SetPositionConstraint(
+      const blink::WebLayerPositionConstraint& constraint) override;
+  blink::WebLayerPositionConstraint PositionConstraint() const override;
+  void SetStickyPositionConstraint(
+      const blink::WebLayerStickyPositionConstraint& constraint) override;
+  blink::WebLayerStickyPositionConstraint StickyPositionConstraint()
+      const override;
+  void SetScrollClient(blink::WebLayerScrollClient* client) override;
+  void SetScrollOffsetFromImplSideForTesting(const gfx::ScrollOffset&) override;
+  void SetLayerClient(cc::LayerClient* client) override;
+  const cc::Layer* CcLayer() const override;
+  cc::Layer* CcLayer() override;
+  void SetElementId(const cc::ElementId&) override;
+  cc::ElementId GetElementId() const override;
+  void SetHasWillChangeTransformHint(bool has_will_change) override;
+  void ShowScrollbars() override;
+  void SetOverscrollBehavior(const blink::WebOverscrollBehavior&) override;
+  void SetSnapContainerData(base::Optional<cc::SnapContainerData>) override;
+
+  void SetScrollParent(blink::WebLayer* parent) override;
+  void SetClipParent(blink::WebLayer* parent) override;
+
+ protected:
+  scoped_refptr<cc::Layer> layer_;
+
+  bool contents_opaque_is_fixed_;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(WebLayerImpl);
+};
+
+}  // namespace cc_blink
+
+#endif  // CC_BLINK_WEB_LAYER_IMPL_H_
diff -Naur chromium-65.0.3325.181-orig/cc/paint/raw_memory_transfer_cache_entry.cc chromium-65.0.3325.181.patched/cc/paint/raw_memory_transfer_cache_entry.cc
--- chromium-65.0.3325.181-orig/cc/paint/raw_memory_transfer_cache_entry.cc	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/paint/raw_memory_transfer_cache_entry.cc	2018-04-27 11:31:20.599828183 +0300
@@ -3,7 +3,7 @@
 // found in the LICENSE file.
 
 #include "cc/paint/raw_memory_transfer_cache_entry.h"
-
+#include <memory.h>
 #include <string.h>
 
 namespace cc {
diff -Naur chromium-65.0.3325.181-orig/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix chromium-65.0.3325.181.patched/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix
--- chromium-65.0.3325.181-orig/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/paint/raw_memory_transfer_cache_entry.cc.memcpyfix	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,52 @@
+// Copyright (c) 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "cc/paint/raw_memory_transfer_cache_entry.h"
+
+#include <string.h>
+
+namespace cc {
+
+ClientRawMemoryTransferCacheEntry::ClientRawMemoryTransferCacheEntry(
+    std::vector<uint8_t> data)
+    : id_(s_next_id_.GetNext()), data_(std::move(data)) {}
+ClientRawMemoryTransferCacheEntry::~ClientRawMemoryTransferCacheEntry() =
+    default;
+
+// static
+base::AtomicSequenceNumber ClientRawMemoryTransferCacheEntry::s_next_id_;
+
+size_t ClientRawMemoryTransferCacheEntry::SerializedSize() const {
+  return data_.size();
+}
+
+uint32_t ClientRawMemoryTransferCacheEntry::Id() const {
+  return id_;
+}
+
+bool ClientRawMemoryTransferCacheEntry::Serialize(
+    base::span<uint8_t> data) const {
+  if (data.size() != data_.size())
+    return false;
+
+  memcpy(data.data(), data_.data(), data.size());
+  return true;
+}
+
+ServiceRawMemoryTransferCacheEntry::ServiceRawMemoryTransferCacheEntry() =
+    default;
+ServiceRawMemoryTransferCacheEntry::~ServiceRawMemoryTransferCacheEntry() =
+    default;
+
+size_t ServiceRawMemoryTransferCacheEntry::CachedSize() const {
+  return data_.size();
+}
+
+bool ServiceRawMemoryTransferCacheEntry::Deserialize(GrContext* context,
+                                                     base::span<uint8_t> data) {
+  data_ = std::vector<uint8_t>(data.begin(), data.end());
+  return true;
+}
+
+}  // namespace cc
diff -Naur chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.cc chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.cc
--- chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.cc	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.cc	2018-04-27 11:31:20.651827635 +0300
@@ -92,7 +92,6 @@
 }
 
 PlaybackImageProvider::Settings::Settings() = default;
-PlaybackImageProvider::Settings::Settings(const Settings& other) = default;
 PlaybackImageProvider::Settings::~Settings() = default;
 
 }  // namespace cc
diff -Naur chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.cc.pipcc chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.cc.pipcc
--- chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.cc.pipcc	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.cc.pipcc	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,98 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "cc/raster/playback_image_provider.h"
+
+#include "base/memory/ptr_util.h"
+#include "cc/tiles/image_decode_cache.h"
+
+namespace cc {
+namespace {
+void UnrefImageFromCache(DrawImage draw_image,
+                         ImageDecodeCache* cache,
+                         DecodedDrawImage decoded_draw_image) {
+  cache->DrawWithImageFinished(draw_image, decoded_draw_image);
+}
+
+}  // namespace
+
+PlaybackImageProvider::PlaybackImageProvider(
+    ImageDecodeCache* cache,
+    const gfx::ColorSpace& target_color_space,
+    base::Optional<Settings> settings)
+    : cache_(cache),
+      target_color_space_(target_color_space),
+      settings_(std::move(settings)) {
+  DCHECK(cache_);
+}
+
+PlaybackImageProvider::~PlaybackImageProvider() {
+  DCHECK(!in_raster_);
+}
+
+PlaybackImageProvider::PlaybackImageProvider(PlaybackImageProvider&& other) =
+    default;
+
+PlaybackImageProvider& PlaybackImageProvider::operator=(
+    PlaybackImageProvider&& other) = default;
+
+void PlaybackImageProvider::BeginRaster() {
+  DCHECK(decoded_at_raster_.empty());
+  DCHECK(!in_raster_);
+  in_raster_ = true;
+
+  if (!settings_.has_value())
+    return;
+
+  for (auto& draw_image : settings_->at_raster_images)
+    decoded_at_raster_.push_back(GetDecodedDrawImage(draw_image));
+}
+
+void PlaybackImageProvider::EndRaster() {
+  DCHECK(in_raster_);
+  decoded_at_raster_.clear();
+  in_raster_ = false;
+}
+
+ImageProvider::ScopedDecodedDrawImage
+PlaybackImageProvider::GetDecodedDrawImage(const DrawImage& draw_image) {
+  DCHECK(in_raster_);
+
+  // Return an empty decoded image if we are skipping all images during this
+  // raster.
+  if (!settings_.has_value())
+    return ScopedDecodedDrawImage();
+
+  const PaintImage& paint_image = draw_image.paint_image();
+
+  if (settings_->images_to_skip.count(paint_image.stable_id()) != 0) {
+    DCHECK(paint_image.GetSkImage()->isLazyGenerated());
+    return ScopedDecodedDrawImage();
+  }
+
+  if (!paint_image.GetSkImage()->isLazyGenerated()) {
+    return ScopedDecodedDrawImage(
+        DecodedDrawImage(paint_image.GetSkImage(), SkSize::Make(0, 0),
+                         SkSize::Make(1.f, 1.f), draw_image.filter_quality()));
+  }
+
+  const auto& it =
+      settings_->image_to_current_frame_index.find(paint_image.stable_id());
+  size_t frame_index = it == settings_->image_to_current_frame_index.end()
+                           ? paint_image.frame_index()
+                           : it->second;
+
+  DrawImage adjusted_image(draw_image, 1.f, frame_index, target_color_space_);
+  auto decoded_draw_image = cache_->GetDecodedImageForDraw(adjusted_image);
+
+  return ScopedDecodedDrawImage(
+      decoded_draw_image,
+      base::BindOnce(&UnrefImageFromCache, std::move(adjusted_image), cache_));
+}
+
+PlaybackImageProvider::Settings::Settings() = default;
+PlaybackImageProvider::Settings::Settings(const Settings& other) = default;
+PlaybackImageProvider::Settings::~Settings() = default;
+
+}  // namespace cc
diff -Naur chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.h chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.h
--- chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.h	2018-03-21 01:05:14.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.h	2018-04-27 11:31:20.651827635 +0300
@@ -20,7 +20,6 @@
  public:
   struct CC_EXPORT Settings {
     Settings();
-    Settings(const Settings& other);
     ~Settings();
 
     // The set of image ids to skip during raster.
diff -Naur chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.h.pipcc chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.h.pipcc
--- chromium-65.0.3325.181-orig/cc/raster/playback_image_provider.h.pipcc	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/cc/raster/playback_image_provider.h.pipcc	2018-03-21 01:05:14.000000000 +0300
@@ -0,0 +1,68 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef CC_RASTER_PLAYBACK_IMAGE_PROVIDER_H_
+#define CC_RASTER_PLAYBACK_IMAGE_PROVIDER_H_
+
+#include "base/containers/flat_map.h"
+#include "cc/cc_export.h"
+#include "cc/paint/image_id.h"
+#include "cc/paint/image_provider.h"
+#include "ui/gfx/color_space.h"
+
+namespace cc {
+class ImageDecodeCache;
+
+// PlaybackImageProvider is used to replace lazy generated PaintImages with
+// decoded images for raster from the ImageDecodeCache.
+class CC_EXPORT PlaybackImageProvider : public ImageProvider {
+ public:
+  struct CC_EXPORT Settings {
+    Settings();
+    Settings(const Settings& other);
+    ~Settings();
+
+    // The set of image ids to skip during raster.
+    PaintImageIdFlatSet images_to_skip;
+
+    // The set of images which must be decoded by the provider before beginning
+    // raster. The images are decoded and locked by the provider in BeginRaster
+    // and unlocked in EndRaster.
+    std::vector<DrawImage> at_raster_images;
+
+    // The frame index to use for the given image id. If no index is provided,
+    // the frame index provided in the PaintImage will be used.
+    base::flat_map<PaintImage::Id, size_t> image_to_current_frame_index;
+  };
+
+  // If no settings are provided, all images are skipped during rasterization.
+  PlaybackImageProvider(ImageDecodeCache* cache,
+                        const gfx::ColorSpace& target_color_space,
+                        base::Optional<Settings> settings);
+  ~PlaybackImageProvider() override;
+
+  void BeginRaster() override;
+  void EndRaster() override;
+
+  PlaybackImageProvider(PlaybackImageProvider&& other);
+  PlaybackImageProvider& operator=(PlaybackImageProvider&& other);
+
+  // ImageProvider implementation.
+  ScopedDecodedDrawImage GetDecodedDrawImage(
+      const DrawImage& draw_image) override;
+
+ private:
+  ImageDecodeCache* cache_;
+  gfx::ColorSpace target_color_space_;
+  base::Optional<Settings> settings_;
+
+  bool in_raster_ = false;
+  std::vector<ImageProvider::ScopedDecodedDrawImage> decoded_at_raster_;
+
+  DISALLOW_COPY_AND_ASSIGN(PlaybackImageProvider);
+};
+
+}  // namespace cc
+
+#endif  // CC_RASTER_PLAYBACK_IMAGE_PROVIDER_H_
diff -Naur chromium-65.0.3325.181-orig/chrome/browser/first_run/first_run_internal_linux.cc chromium-65.0.3325.181.patched/chrome/browser/first_run/first_run_internal_linux.cc
--- chromium-65.0.3325.181-orig/chrome/browser/first_run/first_run_internal_linux.cc	2018-03-21 01:05:17.000000000 +0300
+++ chromium-65.0.3325.181.patched/chrome/browser/first_run/first_run_internal_linux.cc	2018-04-27 11:31:20.487829360 +0300
@@ -19,9 +19,9 @@
 
 base::FilePath MasterPrefsPath() {
   // The standard location of the master prefs is next to the chrome binary.
+  // ...but we patch it to use /etc/chromium
   base::FilePath master_prefs;
-  if (!PathService::Get(base::DIR_EXE, &master_prefs))
-    return base::FilePath();
+  master_prefs = base::FilePath("/etc/chromium");
   return master_prefs.AppendASCII(installer::kDefaultMasterPrefs);
 }
 
diff -Naur chromium-65.0.3325.181-orig/chrome/browser/first_run/first_run_internal_linux.cc.etc chromium-65.0.3325.181.patched/chrome/browser/first_run/first_run_internal_linux.cc.etc
--- chromium-65.0.3325.181-orig/chrome/browser/first_run/first_run_internal_linux.cc.etc	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/chrome/browser/first_run/first_run_internal_linux.cc.etc	2018-03-21 01:05:17.000000000 +0300
@@ -0,0 +1,29 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "chrome/browser/first_run/first_run_internal.h"
+
+#include "base/base_paths.h"
+#include "base/files/file_path.h"
+#include "base/path_service.h"
+#include "chrome/installer/util/master_preferences.h"
+
+namespace first_run {
+namespace internal {
+
+bool IsOrganicFirstRun() {
+  // We treat all installs as organic.
+  return true;
+}
+
+base::FilePath MasterPrefsPath() {
+  // The standard location of the master prefs is next to the chrome binary.
+  base::FilePath master_prefs;
+  if (!PathService::Get(base::DIR_EXE, &master_prefs))
+    return base::FilePath();
+  return master_prefs.AppendASCII(installer::kDefaultMasterPrefs);
+}
+
+}  // namespace internal
+}  // namespace first_run
diff -Naur chromium-65.0.3325.181-orig/chrome/browser/vr/sample_queue.cc.gentoo-stdint chromium-65.0.3325.181.patched/chrome/browser/vr/sample_queue.cc.gentoo-stdint
--- chromium-65.0.3325.181-orig/chrome/browser/vr/sample_queue.cc.gentoo-stdint	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/chrome/browser/vr/sample_queue.cc.gentoo-stdint	2018-03-21 01:05:19.000000000 +0300
@@ -0,0 +1,31 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "chrome/browser/vr/sample_queue.h"
+
+namespace vr {
+
+SampleQueue::SampleQueue(size_t window_size) : window_size_(window_size) {
+  samples_.reserve(window_size);
+}
+
+SampleQueue::~SampleQueue() = default;
+
+void SampleQueue::AddSample(int64_t value) {
+  sum_ += value;
+
+  if (samples_.size() < window_size_) {
+    samples_.push_back(value);
+  } else {
+    sum_ -= samples_[current_index_];
+    samples_[current_index_] = value;
+  }
+
+  ++current_index_;
+  if (current_index_ >= window_size_) {
+    current_index_ = 0;
+  }
+}
+
+}  // namespace vr
diff -Naur chromium-65.0.3325.181-orig/chrome/test/data/webui_test_resources.grd chromium-65.0.3325.181.patched/chrome/test/data/webui_test_resources.grd
--- chromium-65.0.3325.181-orig/chrome/test/data/webui_test_resources.grd	2018-03-21 01:05:21.000000000 +0300
+++ chromium-65.0.3325.181.patched/chrome/test/data/webui_test_resources.grd	2018-04-27 11:31:20.475829486 +0300
@@ -8,7 +8,6 @@
   </outputs>
   <release seq="1">
     <includes>
-      <include name="IDR_WEBUI_TEST_I18N_PROCESS_CSS_TEST" file="webui/i18n_process_css_test.html" flattenhtml="true" allowexternalscript="true" type="BINDATA" />
     </includes>
   </release>
 </grit>
diff -Naur chromium-65.0.3325.181-orig/chrome/test/data/webui_test_resources.grd.notest chromium-65.0.3325.181.patched/chrome/test/data/webui_test_resources.grd.notest
--- chromium-65.0.3325.181-orig/chrome/test/data/webui_test_resources.grd.notest	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/chrome/test/data/webui_test_resources.grd.notest	2018-03-21 01:05:21.000000000 +0300
@@ -0,0 +1,14 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<grit latest_public_release="0" current_release="1" output_all_resource_defines="false">
+  <outputs>
+    <output filename="test/data/grit/webui_test_resources.h" type="rc_header">
+      <emit emit_type='prepend'></emit>
+    </output>
+    <output filename="webui_test_resources.pak" type="data_package" />
+  </outputs>
+  <release seq="1">
+    <includes>
+      <include name="IDR_WEBUI_TEST_I18N_PROCESS_CSS_TEST" file="webui/i18n_process_css_test.html" flattenhtml="true" allowexternalscript="true" type="BINDATA" />
+    </includes>
+  </release>
+</grit>
diff -Naur chromium-65.0.3325.181-orig/components/assist_ranker/ranker_example_util.cc.gentoo-math chromium-65.0.3325.181.patched/components/assist_ranker/ranker_example_util.cc.gentoo-math
--- chromium-65.0.3325.181-orig/components/assist_ranker/ranker_example_util.cc.gentoo-math	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/components/assist_ranker/ranker_example_util.cc.gentoo-math	2018-03-21 01:05:21.000000000 +0300
@@ -0,0 +1,160 @@
+// Copyright 2017 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/assist_ranker/ranker_example_util.h"
+#include "base/bit_cast.h"
+#include "base/format_macros.h"
+#include "base/logging.h"
+#include "base/metrics/metrics_hashes.h"
+#include "base/strings/stringprintf.h"
+
+namespace assist_ranker {
+namespace {
+const uint64_t MASK32Bits = (1LL << 32) - 1;
+constexpr int kFloatMainDigits = 23;
+// Returns lower 32 bits of the hash of the input.
+int32_t StringToIntBits(const std::string& str) {
+  return base::HashMetricName(str) & MASK32Bits;
+}
+
+// Converts float to int32
+int32_t FloatToIntBits(float f) {
+  if (std::numeric_limits<float>::is_iec559) {
+    // Directly bit_cast if float follows ieee754 standard.
+    return bit_cast<int32_t>(f);
+  } else {
+    // Otherwise, manually calculate sign, exp and mantissa.
+    // For sign.
+    const uint32_t sign = f < 0;
+
+    // For exponent.
+    int exp;
+    f = std::abs(std::frexp(f, &exp));
+    // Add 126 to get non-negative format of exp.
+    // This should not be 127 because the return of frexp is different from
+    // ieee754 with a multiple of 2.
+    const uint32_t exp_u = exp + 126;
+
+    // Get mantissa.
+    const uint32_t mantissa = std::ldexp(f * 2.0f - 1.0f, kFloatMainDigits);
+    // Set each bits and return.
+    return (sign << 31) | (exp_u << kFloatMainDigits) | mantissa;
+  }
+}
+
+// Pair type, value and index into one int64.
+int64_t PairInt(const uint64_t type,
+                const uint32_t value,
+                const uint64_t index) {
+  return (type << 56) | (index << 32) | static_cast<uint64_t>(value);
+}
+
+}  // namespace
+
+bool SafeGetFeature(const std::string& key,
+                    const RankerExample& example,
+                    Feature* feature) {
+  auto p_feature = example.features().find(key);
+  if (p_feature != example.features().end()) {
+    if (feature)
+      *feature = p_feature->second;
+    return true;
+  }
+  return false;
+}
+
+bool GetFeatureValueAsFloat(const std::string& key,
+                            const RankerExample& example,
+                            float* value) {
+  Feature feature;
+  if (!SafeGetFeature(key, example, &feature)) {
+    return false;
+  }
+  switch (feature.feature_type_case()) {
+    case Feature::kBoolValue:
+      *value = static_cast<float>(feature.bool_value());
+      break;
+    case Feature::kInt32Value:
+      *value = static_cast<float>(feature.int32_value());
+      break;
+    case Feature::kFloatValue:
+      *value = feature.float_value();
+      break;
+    default:
+      return false;
+  }
+  return true;
+}
+
+bool FeatureToInt64(const Feature& feature,
+                    int64_t* const res,
+                    const int index) {
+  int32_t value = -1;
+  int32_t type = feature.feature_type_case();
+  switch (type) {
+    case Feature::kBoolValue:
+      value = static_cast<int32_t>(feature.bool_value());
+      break;
+    case Feature::kFloatValue:
+      value = FloatToIntBits(feature.float_value());
+      break;
+    case Feature::kInt32Value:
+      value = feature.int32_value();
+      break;
+    case Feature::kStringValue:
+      value = StringToIntBits(feature.string_value());
+      break;
+    case Feature::kStringList:
+      if (index >= 0 && index < feature.string_list().string_value_size()) {
+        value = StringToIntBits(feature.string_list().string_value(index));
+      } else {
+        DVLOG(3) << "Invalid index for string list: " << index;
+        NOTREACHED();
+        return false;
+      }
+      break;
+    default:
+      DVLOG(3) << "Feature type is supported for logging: " << type;
+      NOTREACHED();
+      return false;
+  }
+  *res = PairInt(type, value, index);
+  return true;
+  }
+
+bool GetOneHotValue(const std::string& key,
+                    const RankerExample& example,
+                    std::string* value) {
+  Feature feature;
+  if (!SafeGetFeature(key, example, &feature)) {
+    return false;
+  }
+  if (feature.feature_type_case() != Feature::kStringValue) {
+    DVLOG(1) << "Feature " << key
+             << " exists, but is not the right type (Expected: "
+             << Feature::kStringValue
+             << " vs. Actual: " << feature.feature_type_case() << ")";
+    return false;
+  }
+  *value = feature.string_value();
+  return true;
+}
+
+// Converts string to a hex hash string.
+std::string HashFeatureName(const std::string& feature_name) {
+  uint64_t feature_key = base::HashMetricName(feature_name);
+  return base::StringPrintf("%016" PRIx64, feature_key);
+}
+
+RankerExample HashExampleFeatureNames(const RankerExample& example) {
+  RankerExample hashed_example;
+  auto& output_features = *hashed_example.mutable_features();
+  for (const auto& feature : example.features()) {
+    output_features[HashFeatureName(feature.first)] = feature.second;
+  }
+  *hashed_example.mutable_target() = example.target();
+  return hashed_example;
+}
+
+}  // namespace assist_ranker
diff -Naur chromium-65.0.3325.181-orig/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc chromium-65.0.3325.181.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc
--- chromium-65.0.3325.181-orig/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc	2018-03-21 01:05:22.000000000 +0300
+++ chromium-65.0.3325.181.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc	2018-04-27 11:31:20.479829444 +0300
@@ -156,6 +156,14 @@
 }
 
 void NaClSandbox::CheckForExpectedNumberOfOpenFds() {
+  // Whatever logic this code is using is wrong more often than it is right.
+  // If you set expected_num_fds to 6, it finds 7.
+  // If you set expected_num_fds to 7, it finds 6.
+  // Code like this makes a packager drink. And not the good stuff either.
+  // Instead, we're just going to smile and tell it to never care about the
+  // number of FDs open. Stupid code. We hates it.
+
+#if 0  
   // We expect to have the following FDs open:
   //  1-3) stdin, stdout, stderr.
   //  4) The /dev/urandom FD used by base::GetUrandomFD().
@@ -174,6 +182,8 @@
   }
 
   CHECK_EQ(expected_num_fds, sandbox::ProcUtil::CountOpenFds(proc_fd_.get()));
+#endif
+
 }
 
 void NaClSandbox::InitializeLayerTwoSandbox(bool uses_nonsfi_mode) {
diff -Naur chromium-65.0.3325.181-orig/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count chromium-65.0.3325.181.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count
--- chromium-65.0.3325.181-orig/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/components/nacl/loader/sandbox_linux/nacl_sandbox_linux.cc.ignore-fd-count	2018-03-21 01:05:22.000000000 +0300
@@ -0,0 +1,249 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "components/nacl/loader/sandbox_linux/nacl_sandbox_linux.h"
+
+#include <errno.h>
+#include <fcntl.h>
+#include <stdint.h>
+#include <sys/prctl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+
+#include <limits>
+#include <memory>
+#include <utility>
+
+#include "base/callback.h"
+#include "base/command_line.h"
+#include "base/compiler_specific.h"
+#include "base/files/scoped_file.h"
+#include "base/logging.h"
+#include "base/posix/eintr_wrapper.h"
+#include "build/build_config.h"
+#include "components/nacl/common/nacl_switches.h"
+#include "components/nacl/loader/nonsfi/nonsfi_sandbox.h"
+#include "components/nacl/loader/sandbox_linux/nacl_bpf_sandbox_linux.h"
+#include "content/public/common/content_switches.h"
+#include "sandbox/linux/seccomp-bpf/sandbox_bpf.h"
+#include "sandbox/linux/services/credentials.h"
+#include "sandbox/linux/services/namespace_sandbox.h"
+#include "sandbox/linux/services/proc_util.h"
+#include "sandbox/linux/services/resource_limits.h"
+#include "sandbox/linux/services/thread_helpers.h"
+#include "sandbox/linux/suid/client/setuid_sandbox_client.h"
+#include "services/service_manager/sandbox/switches.h"
+
+namespace nacl {
+
+namespace {
+
+// This is a simplistic check of whether we are sandboxed.
+bool IsSandboxed() {
+  int proc_fd = open("/proc/self/exe", O_RDONLY);
+  if (proc_fd >= 0) {
+    PCHECK(0 == IGNORE_EINTR(close(proc_fd)));
+    return false;
+  }
+  return true;
+}
+
+bool MaybeSetProcessNonDumpable() {
+  const base::CommandLine& command_line =
+      *base::CommandLine::ForCurrentProcess();
+  if (command_line.HasSwitch(
+          service_manager::switches::kAllowSandboxDebugging)) {
+    return true;
+  }
+
+  if (prctl(PR_SET_DUMPABLE, 0, 0, 0, 0) != 0) {
+    PLOG(ERROR) << "Failed to set non-dumpable flag";
+    return false;
+  }
+
+  return prctl(PR_GET_DUMPABLE) == 0;
+}
+
+void RestrictAddressSpaceUsage() {
+#if defined(ADDRESS_SANITIZER) || defined(MEMORY_SANITIZER) || \
+    defined(THREAD_SANITIZER)
+  // Sanitizers need to reserve huge chunks of the address space.
+  return;
+#endif
+
+  // Add a limit to the brk() heap that would prevent allocations that can't be
+  // indexed by an int. This helps working around typical security bugs.
+  // This could almost certainly be set to zero. GLibc's allocator and others
+  // would fall-back to mmap if brk() fails.
+  const rlim_t kNewDataSegmentMaxSize = std::numeric_limits<int>::max();
+  CHECK(sandbox::ResourceLimits::Lower(RLIMIT_DATA, kNewDataSegmentMaxSize));
+
+#if defined(ARCH_CPU_64_BITS)
+  // NaCl's x86-64 sandbox allocated 88GB address of space during startup:
+  // - The main sandbox is 4GB
+  // - There are two guard regions of 40GB each.
+  // - 4GB are allocated extra to have a 4GB-aligned address.
+  // See https://crbug.com/455839
+  //
+  // Set the limit to 128 GB and have some margin.
+  const rlim_t kNewAddressSpaceLimit = 1UL << 37;
+#else
+  // Some architectures such as X86 allow 32 bits processes to switch to 64
+  // bits when running under 64 bits kernels. Set a limit in case this happens.
+  const rlim_t kNewAddressSpaceLimit = std::numeric_limits<uint32_t>::max();
+#endif
+  CHECK(sandbox::ResourceLimits::Lower(RLIMIT_AS, kNewAddressSpaceLimit));
+}
+
+}  // namespace
+
+NaClSandbox::NaClSandbox()
+    : layer_one_enabled_(false),
+      layer_one_sealed_(false),
+      layer_two_enabled_(false),
+      layer_two_is_nonsfi_(false),
+      proc_fd_(-1),
+      setuid_sandbox_client_(sandbox::SetuidSandboxClient::Create()) {
+  proc_fd_.reset(
+      HANDLE_EINTR(open("/proc", O_DIRECTORY | O_RDONLY | O_CLOEXEC)));
+  PCHECK(proc_fd_.is_valid());
+}
+
+NaClSandbox::~NaClSandbox() {
+}
+
+bool NaClSandbox::IsSingleThreaded() {
+  CHECK(proc_fd_.is_valid());
+  return sandbox::ThreadHelpers::IsSingleThreaded(proc_fd_.get());
+}
+
+bool NaClSandbox::HasOpenDirectory() {
+  CHECK(proc_fd_.is_valid());
+  return sandbox::ProcUtil::HasOpenDirectory(proc_fd_.get());
+}
+
+void NaClSandbox::InitializeLayerOneSandbox() {
+  // Check that IsSandboxed() works. We should not be sandboxed at this point.
+  CHECK(!IsSandboxed()) << "Unexpectedly sandboxed!";
+
+  if (setuid_sandbox_client_->IsSuidSandboxChild()) {
+    setuid_sandbox_client_->CloseDummyFile();
+
+    // Make sure that no directory file descriptor is open, as it would bypass
+    // the setuid sandbox model.
+    CHECK(!HasOpenDirectory());
+
+    // Get sandboxed.
+    CHECK(setuid_sandbox_client_->ChrootMe());
+    CHECK(MaybeSetProcessNonDumpable());
+    CHECK(IsSandboxed());
+    layer_one_enabled_ = true;
+  } else if (sandbox::NamespaceSandbox::InNewUserNamespace()) {
+    CHECK(sandbox::Credentials::MoveToNewUserNS());
+    CHECK(sandbox::Credentials::DropFileSystemAccess(proc_fd_.get()));
+
+    // We do not drop CAP_SYS_ADMIN because we need it to place each child
+    // process in its own PID namespace later on.
+    std::vector<sandbox::Credentials::Capability> caps;
+    caps.push_back(sandbox::Credentials::Capability::SYS_ADMIN);
+    CHECK(sandbox::Credentials::SetCapabilities(proc_fd_.get(), caps));
+
+    CHECK(IsSandboxed());
+    layer_one_enabled_ = true;
+  }
+}
+
+void NaClSandbox::CheckForExpectedNumberOfOpenFds() {
+  // We expect to have the following FDs open:
+  //  1-3) stdin, stdout, stderr.
+  //  4) The /dev/urandom FD used by base::GetUrandomFD().
+  //  5) A dummy pipe FD used to overwrite kSandboxIPCChannel.
+  //  6) The socket for the Chrome IPC channel that's connected to the
+  //     browser process, kPrimaryIPCChannel.
+  // We also have an fd for /proc (proc_fd_), but CountOpenFds excludes this.
+  //
+  // This sanity check ensures that dynamically loaded libraries don't
+  // leave any FDs open before we enable the sandbox.
+  int expected_num_fds = 6;
+  if (setuid_sandbox_client_->IsSuidSandboxChild()) {
+    // When using the setuid sandbox, there is one additional socket used for
+    // ChrootMe(). After ChrootMe(), it is no longer connected to anything.
+    ++expected_num_fds;
+  }
+
+  CHECK_EQ(expected_num_fds, sandbox::ProcUtil::CountOpenFds(proc_fd_.get()));
+}
+
+void NaClSandbox::InitializeLayerTwoSandbox(bool uses_nonsfi_mode) {
+  // seccomp-bpf only applies to the current thread, so it's critical to only
+  // have a single thread running here.
+  DCHECK(!layer_one_sealed_);
+  CHECK(IsSingleThreaded());
+  CheckForExpectedNumberOfOpenFds();
+
+  RestrictAddressSpaceUsage();
+
+  // Pass proc_fd_ ownership to the BPF sandbox, which guarantees it will
+  // be closed. There is no point in keeping it around since the BPF policy
+  // will prevent its usage.
+#if defined(OS_NACL_NONSFI)
+  CHECK(uses_nonsfi_mode);
+  layer_two_enabled_ = nacl::nonsfi::InitializeBPFSandbox(std::move(proc_fd_));
+  layer_two_is_nonsfi_ = true;
+#else
+  CHECK(!uses_nonsfi_mode);
+  layer_two_enabled_ = nacl::InitializeBPFSandbox(std::move(proc_fd_));
+#endif
+}
+
+void NaClSandbox::SealLayerOneSandbox() {
+  if (proc_fd_.is_valid() && !layer_two_enabled_) {
+    // If nothing prevents us, check that there is no superfluous directory
+    // open.
+    CHECK(!HasOpenDirectory());
+  }
+  proc_fd_.reset();
+  layer_one_sealed_ = true;
+}
+
+void NaClSandbox::CheckSandboxingStateWithPolicy() {
+  static const char kItIsDangerousMsg[] = " this is dangerous.";
+  static const char kItIsNotAllowedMsg[] =
+      " this is not allowed in this configuration.";
+
+  const bool no_sandbox_for_nonsfi_ok =
+#if defined(ADDRESS_SANITIZER) || defined(THREAD_SANITIZER) || \
+    defined(MEMORY_SANITIZER) || defined(LEAK_SANITIZER)
+      // Sanitizer tests run with --no-sandbox, but without
+      // --nacl-dangerous-no-sandbox-nonsfi. Allow that case.
+      true;
+#else
+      base::CommandLine::ForCurrentProcess()->HasSwitch(
+          switches::kNaClDangerousNoSandboxNonSfi);
+#endif
+
+  const bool can_be_no_sandbox =
+      !layer_two_is_nonsfi_ || no_sandbox_for_nonsfi_ok;
+
+  if (!layer_one_enabled_ || !layer_one_sealed_) {
+    static const char kNoSuidMsg[] =
+        "The SUID sandbox is not engaged for NaCl:";
+    if (can_be_no_sandbox)
+      LOG(ERROR) << kNoSuidMsg << kItIsDangerousMsg;
+    else
+      LOG(FATAL) << kNoSuidMsg << kItIsNotAllowedMsg;
+  }
+
+  if (!layer_two_enabled_) {
+    static const char kNoBpfMsg[] =
+        "The seccomp-bpf sandbox is not engaged for NaCl:";
+    if (can_be_no_sandbox)
+      LOG(ERROR) << kNoBpfMsg << kItIsDangerousMsg;
+    else
+      LOG(FATAL) << kNoBpfMsg << kItIsNotAllowedMsg;
+  }
+}
+
+}  // namespace nacl
diff -Naur chromium-65.0.3325.181-orig/components/policy/core/browser/browser_policy_connector_base.h chromium-65.0.3325.181.patched/components/policy/core/browser/browser_policy_connector_base.h
--- chromium-65.0.3325.181-orig/components/policy/core/browser/browser_policy_connector_base.h	2018-03-21 01:05:22.000000000 +0300
+++ chromium-65.0.3325.181.patched/components/policy/core/browser/browser_policy_connector_base.h	2018-04-27 11:31:20.659827552 +0300
@@ -12,13 +12,13 @@
 #include "base/macros.h"
 #include "base/optional.h"
 #include "components/policy/core/browser/configuration_policy_handler_list.h"
+#include "components/policy/core/common/configuration_policy_provider.h"
 #include "components/policy/core/common/schema.h"
 #include "components/policy/core/common/schema_registry.h"
 #include "components/policy/policy_export.h"
 
 namespace policy {
 
-class ConfigurationPolicyProvider;
 class PolicyService;
 class PolicyServiceImpl;
 
diff -Naur chromium-65.0.3325.181-orig/components/policy/core/browser/browser_policy_connector_base.h.fully-declare chromium-65.0.3325.181.patched/components/policy/core/browser/browser_policy_connector_base.h.fully-declare
--- chromium-65.0.3325.181-orig/components/policy/core/browser/browser_policy_connector_base.h.fully-declare	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/components/policy/core/browser/browser_policy_connector_base.h.fully-declare	2018-03-21 01:05:22.000000000 +0300
@@ -0,0 +1,122 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef COMPONENTS_POLICY_CORE_BROWSER_BROWSER_POLICY_CONNECTOR_BASE_H_
+#define COMPONENTS_POLICY_CORE_BROWSER_BROWSER_POLICY_CONNECTOR_BASE_H_
+
+#include <memory>
+#include <vector>
+
+#include "base/callback_forward.h"
+#include "base/macros.h"
+#include "base/optional.h"
+#include "components/policy/core/browser/configuration_policy_handler_list.h"
+#include "components/policy/core/common/schema.h"
+#include "components/policy/core/common/schema_registry.h"
+#include "components/policy/policy_export.h"
+
+namespace policy {
+
+class ConfigurationPolicyProvider;
+class PolicyService;
+class PolicyServiceImpl;
+
+// The BrowserPolicyConnectorBase keeps and initializes some core elements of
+// the policy component, mainly the PolicyProviders and the PolicyService.
+class POLICY_EXPORT BrowserPolicyConnectorBase {
+ public:
+  // Invoke Shutdown() before deleting, see below.
+  virtual ~BrowserPolicyConnectorBase();
+
+  // Stops the policy providers and cleans up the connector before it can be
+  // safely deleted. This must be invoked before the destructor and while the
+  // threads are still running. The policy providers are still valid but won't
+  // update anymore after this call. Subclasses can override this for cleanup
+  // and should call the parent method.
+  virtual void Shutdown();
+
+  // Returns true if SetPolicyProviders() has been called but Shutdown() hasn't
+  // been yet.
+  bool is_initialized() const { return is_initialized_; }
+
+  // Returns a handle to the Chrome schema.
+  const Schema& GetChromeSchema() const;
+
+  // Returns the global CombinedSchemaRegistry. SchemaRegistries from Profiles
+  // should be tracked by the global registry, so that the global policy
+  // providers also load policies for the components of each Profile.
+  CombinedSchemaRegistry* GetSchemaRegistry();
+
+  // Returns the browser-global PolicyService, that contains policies for the
+  // whole browser.
+  PolicyService* GetPolicyService();
+
+  const ConfigurationPolicyHandlerList* GetHandlerList() const;
+
+  // Sets a |provider| that will be included in PolicyServices returned by
+  // GetPolicyService. This is a static method because local state is
+  // created immediately after the connector, and tests don't have a chance to
+  // inject the provider otherwise. |provider| must outlive the connector, and
+  // its ownership is not taken though the connector will initialize and shut it
+  // down.
+  static void SetPolicyProviderForTesting(
+      ConfigurationPolicyProvider* provider);
+  ConfigurationPolicyProvider* GetPolicyProviderForTesting();
+
+  // Adds a callback that is notified the the ResourceBundle is loaded.
+  void NotifyWhenResourceBundleReady(base::OnceClosure closure);
+
+ protected:
+  // Builds an uninitialized BrowserPolicyConnectorBase. SetPolicyProviders()
+  // should be called to create and start the policy components.
+  explicit BrowserPolicyConnectorBase(
+      const HandlerListFactory& handler_list_factory);
+
+  // Sets the set of providers, in decreasing order of priority. May only be
+  // called once.
+  void SetPolicyProviders(
+      std::vector<std::unique_ptr<ConfigurationPolicyProvider>> providers);
+
+  // Must be called when ui::ResourceBundle has been loaded, results in running
+  // any callbacks scheduled in NotifyWhenResourceBundleReady().
+  void OnResourceBundleCreated();
+
+ private:
+  // Returns the providers to pass to the PolicyService. Generally this is the
+  // same as |policy_providers_|, unless SetPolicyProviderForTesting() has been
+  // called.
+  std::vector<ConfigurationPolicyProvider*> GetProvidersForPolicyService();
+
+  // Whether SetPolicyProviders() but not Shutdown() has been invoked.
+  bool is_initialized_;
+
+  // Used to convert policies to preferences. The providers declared below
+  // may trigger policy updates during shutdown, which will result in
+  // |handler_list_| being consulted for policy translation.
+  // Therefore, it's important to destroy |handler_list_| after the providers.
+  std::unique_ptr<ConfigurationPolicyHandlerList> handler_list_;
+
+  // The Chrome schema. This wraps the structure generated by
+  // generate_policy_source.py at compile time.
+  Schema chrome_schema_;
+
+  // The global SchemaRegistry, which will track all the other registries.
+  CombinedSchemaRegistry schema_registry_;
+
+  // The browser-global policy providers, in decreasing order of priority.
+  base::Optional<std::vector<std::unique_ptr<ConfigurationPolicyProvider>>>
+      policy_providers_;
+
+  // Must be deleted before all the policy providers.
+  std::unique_ptr<PolicyServiceImpl> policy_service_;
+
+  // Callbacks scheduled via NotifyWhenResourceBundleReady().
+  std::vector<base::OnceClosure> resource_bundle_callbacks_;
+
+  DISALLOW_COPY_AND_ASSIGN(BrowserPolicyConnectorBase);
+};
+
+}  // namespace policy
+
+#endif  // COMPONENTS_POLICY_CORE_BROWSER_BROWSER_POLICY_CONNECTOR_BASE_H_
diff -Naur chromium-65.0.3325.181-orig/content/browser/appcache/appcache_request_handler.cc chromium-65.0.3325.181.patched/content/browser/appcache/appcache_request_handler.cc
--- chromium-65.0.3325.181-orig/content/browser/appcache/appcache_request_handler.cc	2018-03-21 01:05:23.000000000 +0300
+++ chromium-65.0.3325.181.patched/content/browser/appcache/appcache_request_handler.cc	2018-04-27 11:31:20.651827635 +0300
@@ -639,7 +639,7 @@
 
   SubresourceLoaderParams params;
   params.loader_factory_info = factory_ptr.PassInterface();
-  return params;
+  return base::Optional<SubresourceLoaderParams>(std::move(params));
 }
 
 void AppCacheRequestHandler::MaybeCreateSubresourceLoader(
diff -Naur chromium-65.0.3325.181-orig/content/browser/appcache/appcache_request_handler.cc.explicit-std-move chromium-65.0.3325.181.patched/content/browser/appcache/appcache_request_handler.cc.explicit-std-move
--- chromium-65.0.3325.181-orig/content/browser/appcache/appcache_request_handler.cc.explicit-std-move	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/content/browser/appcache/appcache_request_handler.cc.explicit-std-move	2018-03-21 01:05:23.000000000 +0300
@@ -0,0 +1,700 @@
+// Copyright (c) 2011 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "content/browser/appcache/appcache_request_handler.h"
+
+#include <utility>
+
+#include "base/bind.h"
+#include "base/command_line.h"
+#include "content/browser/appcache/appcache.h"
+#include "content/browser/appcache/appcache_backend_impl.h"
+#include "content/browser/appcache/appcache_host.h"
+#include "content/browser/appcache/appcache_navigation_handle_core.h"
+#include "content/browser/appcache/appcache_policy.h"
+#include "content/browser/appcache/appcache_request.h"
+#include "content/browser/appcache/appcache_subresource_url_factory.h"
+#include "content/browser/appcache/appcache_url_loader_job.h"
+#include "content/browser/appcache/appcache_url_loader_request.h"
+#include "content/browser/appcache/appcache_url_request_job.h"
+#include "content/browser/service_worker/service_worker_request_handler.h"
+#include "content/common/navigation_subresource_loader_params.h"
+#include "content/public/common/content_features.h"
+#include "net/url_request/url_request.h"
+#include "net/url_request/url_request_job.h"
+
+namespace content {
+
+namespace {
+
+bool g_running_in_tests = false;
+
+}  // namespace
+
+AppCacheRequestHandler::AppCacheRequestHandler(
+    AppCacheHost* host,
+    ResourceType resource_type,
+    bool should_reset_appcache,
+    std::unique_ptr<AppCacheRequest> request)
+    : host_(host),
+      resource_type_(resource_type),
+      should_reset_appcache_(should_reset_appcache),
+      is_waiting_for_cache_selection_(false),
+      found_group_id_(0),
+      found_cache_id_(0),
+      found_network_namespace_(false),
+      cache_entry_not_found_(false),
+      is_delivering_network_response_(false),
+      maybe_load_resource_executed_(false),
+      old_process_id_(0),
+      old_host_id_(kAppCacheNoHostId),
+      cache_id_(kAppCacheNoCacheId),
+      service_(host_->service()),
+      request_(std::move(request)),
+      weak_factory_(this) {
+  DCHECK(host_);
+  DCHECK(service_);
+  host_->AddObserver(this);
+  service_->AddObserver(this);
+}
+
+AppCacheRequestHandler::~AppCacheRequestHandler() {
+  if (host_) {
+    storage()->CancelDelegateCallbacks(this);
+    host_->RemoveObserver(this);
+  }
+  if (service_)
+    service_->RemoveObserver(this);
+
+  if (job_ && job_->AsURLLoaderJob())
+    job_->AsURLLoaderJob()->DeleteIfNeeded();
+}
+
+AppCacheStorage* AppCacheRequestHandler::storage() const {
+  DCHECK(host_);
+  return host_->storage();
+}
+
+AppCacheJob* AppCacheRequestHandler::MaybeLoadResource(
+    net::NetworkDelegate* network_delegate) {
+  maybe_load_resource_executed_ = true;
+  if (!host_ ||
+      !AppCacheRequest::IsSchemeAndMethodSupportedForAppCache(request_.get()) ||
+      cache_entry_not_found_) {
+    return nullptr;
+  }
+
+  // This method can get called multiple times over the life
+  // of a request. The case we detect here is having scheduled
+  // delivery of a "network response" using a job set up on an
+  // earlier call through this method. To send the request through
+  // to the network involves restarting the request altogether,
+  // which will call through to our interception layer again.
+  // This time through, we return NULL so the request hits the wire.
+  if (is_delivering_network_response_) {
+    is_delivering_network_response_ = false;
+    return nullptr;
+  }
+
+  // Clear out our 'found' fields since we're starting a request for a
+  // new resource, any values in those fields are no longer valid.
+  found_entry_ = AppCacheEntry();
+  found_fallback_entry_ = AppCacheEntry();
+  found_cache_id_ = kAppCacheNoCacheId;
+  found_manifest_url_ = GURL();
+  found_network_namespace_ = false;
+
+  std::unique_ptr<AppCacheJob> job;
+  if (is_main_resource())
+    job = MaybeLoadMainResource(network_delegate);
+  else
+    job = MaybeLoadSubResource(network_delegate);
+
+  // If its been setup to deliver a network response, we can just delete
+  // it now and return NULL instead to achieve that since it couldn't
+  // have been started yet.
+  if (job && job->IsDeliveringNetworkResponse()) {
+    DCHECK(!job->IsStarted());
+    if (job->AsURLLoaderJob()) {
+      job.release();  // AppCacheURLLoaderJob always deletes itself.
+      job_ = nullptr;
+    } else {
+      job.reset();
+    }
+  }
+
+  return job.release();
+}
+
+AppCacheJob* AppCacheRequestHandler::MaybeLoadFallbackForRedirect(
+    net::NetworkDelegate* network_delegate,
+    const GURL& location) {
+  if (!host_ ||
+      !AppCacheRequest::IsSchemeAndMethodSupportedForAppCache(request_.get()) ||
+      cache_entry_not_found_)
+    return nullptr;
+  if (is_main_resource())
+    return nullptr;
+  // TODO(vabr) This is a temporary fix (see crbug/141114). We should get rid of
+  // it once a more general solution to crbug/121325 is in place.
+  if (!maybe_load_resource_executed_)
+    return nullptr;
+  if (request_->GetURL().GetOrigin() == location.GetOrigin())
+    return nullptr;
+
+  DCHECK(!job_.get());  // our jobs never generate redirects
+
+  std::unique_ptr<AppCacheJob> job;
+  if (found_fallback_entry_.has_response_id()) {
+    // 6.9.6, step 4: If this results in a redirect to another origin,
+    // get the resource of the fallback entry.
+    job = CreateJob(network_delegate);
+    DeliverAppCachedResponse(found_fallback_entry_, found_cache_id_,
+                             found_manifest_url_, true,
+                             found_namespace_entry_url_);
+  } else if (!found_network_namespace_) {
+    // 6.9.6, step 6: Fail the resource load.
+    job = CreateJob(network_delegate);
+    DeliverErrorResponse();
+  } else {
+    // 6.9.6 step 3 and 5: Fetch the resource normally.
+  }
+
+  return job.release();
+}
+
+AppCacheJob* AppCacheRequestHandler::MaybeLoadFallbackForResponse(
+    net::NetworkDelegate* network_delegate) {
+  if (!host_ ||
+      !AppCacheRequest::IsSchemeAndMethodSupportedForAppCache(request_.get()) ||
+      cache_entry_not_found_)
+    return nullptr;
+  if (!found_fallback_entry_.has_response_id())
+    return nullptr;
+
+  if (request_->IsCancelled()) {
+    // 6.9.6, step 4: But not if the user canceled the download.
+    return nullptr;
+  }
+
+  // We don't fallback for responses that we delivered.
+  if (job_.get()) {
+    if (!base::FeatureList::IsEnabled(features::kNetworkService)) {
+      DCHECK(!job_->IsDeliveringNetworkResponse());
+      return nullptr;
+    } else if (job_->IsDeliveringAppCacheResponse() ||
+               job_->IsDeliveringErrorResponse()) {
+      return nullptr;
+    }
+  }
+
+  if (request_->IsSuccess()) {
+    int code_major = request_->GetResponseCode() / 100;
+    if (code_major !=4 && code_major != 5)
+      return nullptr;
+
+    // Servers can override the fallback behavior with a response header.
+    const std::string kFallbackOverrideHeader(
+        "x-chromium-appcache-fallback-override");
+    const std::string kFallbackOverrideValue(
+        "disallow-fallback");
+    std::string header_value;
+    header_value = request_->GetResponseHeaderByName(kFallbackOverrideHeader);
+    if (header_value == kFallbackOverrideValue)
+      return nullptr;
+  }
+
+  // 6.9.6, step 4: If this results in a 4xx or 5xx status code
+  // or there were network errors, get the resource of the fallback entry.
+
+  std::unique_ptr<AppCacheJob> job = CreateJob(network_delegate);
+
+  DeliverAppCachedResponse(found_fallback_entry_, found_cache_id_,
+                           found_manifest_url_, true,
+                           found_namespace_entry_url_);
+  return job.release();
+}
+
+void AppCacheRequestHandler::GetExtraResponseInfo(int64_t* cache_id,
+                                                  GURL* manifest_url) {
+  *cache_id = cache_id_;
+  *manifest_url = manifest_url_;
+}
+
+void AppCacheRequestHandler::PrepareForCrossSiteTransfer(int old_process_id) {
+  if (!host_)
+    return;
+  AppCacheBackendImpl* backend = host_->service()->GetBackend(old_process_id);
+  DCHECK(backend) << "appcache detected likely storage partition mismatch";
+  old_process_id_ = old_process_id;
+  old_host_id_ = host_->host_id();
+  host_for_cross_site_transfer_ = backend->TransferHostOut(host_->host_id());
+  DCHECK_EQ(host_, host_for_cross_site_transfer_.get());
+}
+
+void AppCacheRequestHandler::CompleteCrossSiteTransfer(
+    int new_process_id, int new_host_id) {
+  if (!host_for_cross_site_transfer_.get())
+    return;
+  DCHECK_EQ(host_, host_for_cross_site_transfer_.get());
+  AppCacheBackendImpl* backend = host_->service()->GetBackend(new_process_id);
+  DCHECK(backend) << "appcache detected likely storage partition mismatch";
+  backend->TransferHostIn(new_host_id,
+                          std::move(host_for_cross_site_transfer_));
+}
+
+void AppCacheRequestHandler::MaybeCompleteCrossSiteTransferInOldProcess(
+    int old_process_id) {
+  if (!host_ || !host_for_cross_site_transfer_.get() ||
+      old_process_id != old_process_id_) {
+    return;
+  }
+  CompleteCrossSiteTransfer(old_process_id_, old_host_id_);
+}
+
+// static
+std::unique_ptr<AppCacheRequestHandler>
+AppCacheRequestHandler::InitializeForNavigationNetworkService(
+    const network::ResourceRequest& request,
+    AppCacheNavigationHandleCore* appcache_handle_core,
+    URLLoaderFactoryGetter* url_loader_factory_getter) {
+  std::unique_ptr<AppCacheRequestHandler> handler =
+      appcache_handle_core->host()->CreateRequestHandler(
+          AppCacheURLLoaderRequest::Create(request),
+          static_cast<ResourceType>(request.resource_type),
+          request.should_reset_appcache);
+  handler->network_url_loader_factory_getter_ = url_loader_factory_getter;
+  handler->appcache_host_ = appcache_handle_core->host()->GetWeakPtr();
+  return handler;
+}
+
+void AppCacheRequestHandler::OnDestructionImminent(AppCacheHost* host) {
+  storage()->CancelDelegateCallbacks(this);
+  host_ = nullptr;  // no need to RemoveObserver, the host is being deleted
+
+  // Since the host is being deleted, we don't have to complete any job
+  // that is current running. It's destined for the bit bucket anyway.
+  if (job_.get()) {
+    if (job_->AsURLRequestJob())
+      job_->AsURLRequestJob()->Kill();
+    job_.reset();
+  }
+}
+
+void AppCacheRequestHandler::OnServiceDestructionImminent(
+    AppCacheServiceImpl* service) {
+  service_ = nullptr;
+  if (!host_) {
+    DCHECK(!host_for_cross_site_transfer_);
+    DCHECK(!job_);
+    return;
+  }
+  host_->RemoveObserver(this);
+  OnDestructionImminent(host_);
+  host_for_cross_site_transfer_.reset();
+}
+
+void AppCacheRequestHandler::DeliverAppCachedResponse(
+    const AppCacheEntry& entry,
+    int64_t cache_id,
+    const GURL& manifest_url,
+    bool is_fallback,
+    const GURL& namespace_entry_url) {
+  DCHECK(host_ && job_.get() && job_->IsWaiting());
+  DCHECK(entry.has_response_id());
+
+  // Cache information about the response, for use by GetExtraResponseInfo.
+  cache_id_ = cache_id;
+  manifest_url_ = manifest_url;
+
+  if (IsResourceTypeFrame(resource_type_) && !namespace_entry_url.is_empty())
+    host_->NotifyMainResourceIsNamespaceEntry(namespace_entry_url);
+
+  job_->DeliverAppCachedResponse(manifest_url, cache_id, entry, is_fallback);
+}
+
+void AppCacheRequestHandler::DeliverErrorResponse() {
+  DCHECK(job_.get() && job_->IsWaiting());
+  DCHECK_EQ(kAppCacheNoCacheId, cache_id_);
+  DCHECK(manifest_url_.is_empty());
+  job_->DeliverErrorResponse();
+}
+
+void AppCacheRequestHandler::DeliverNetworkResponse() {
+  DCHECK(job_.get() && job_->IsWaiting());
+  DCHECK_EQ(kAppCacheNoCacheId, cache_id_);
+  DCHECK(manifest_url_.is_empty());
+  job_->DeliverNetworkResponse();
+}
+
+void AppCacheRequestHandler::OnPrepareToRestartURLRequest() {
+  DCHECK(job_->AsURLRequestJob());
+  DCHECK(job_->IsDeliveringNetworkResponse() || job_->IsCacheEntryNotFound());
+
+  // Any information about the source of the response is no longer relevant.
+  cache_id_ = kAppCacheNoCacheId;
+  manifest_url_ = GURL();
+
+  cache_entry_not_found_ = job_->IsCacheEntryNotFound();
+  is_delivering_network_response_ = job_->IsDeliveringNetworkResponse();
+
+  storage()->CancelDelegateCallbacks(this);
+
+  job_.reset();
+}
+
+std::unique_ptr<AppCacheJob> AppCacheRequestHandler::CreateJob(
+    net::NetworkDelegate* network_delegate) {
+  std::unique_ptr<AppCacheJob> job;
+  if (base::FeatureList::IsEnabled(features::kNetworkService)) {
+    job.reset(new AppCacheURLLoaderJob(request_->AsURLLoaderRequest(),
+                                       storage(), std::move(loader_callback_)));
+  } else {
+    job.reset(new AppCacheURLRequestJob(
+        request_->GetURLRequest(), network_delegate, storage(), host_,
+        is_main_resource(),
+        base::BindOnce(&AppCacheRequestHandler::OnPrepareToRestartURLRequest,
+                       base::Unretained(this))));
+  }
+  job_ = job->GetWeakPtr();
+  return job;
+}
+
+// Main-resource handling ----------------------------------------------
+
+std::unique_ptr<AppCacheJob> AppCacheRequestHandler::MaybeLoadMainResource(
+    net::NetworkDelegate* network_delegate) {
+  DCHECK(!job_.get());
+  DCHECK(host_);
+
+  // If a page falls into the scope of a ServiceWorker, any matching AppCaches
+  // should be ignored. This depends on the ServiceWorker handler being invoked
+  // prior to the AppCache handler.
+  // TODO(ananta/michaeln)
+  // We need to handle this for AppCache requests initiated for the network
+  // service
+  if (request_->GetURLRequest() &&
+      ServiceWorkerRequestHandler::IsControlledByServiceWorker(
+          request_->GetURLRequest())) {
+    host_->enable_cache_selection(false);
+    return nullptr;
+  }
+
+  if (storage()->IsInitialized() &&
+      service_->storage()->usage_map()->find(request_->GetURL().GetOrigin()) ==
+          service_->storage()->usage_map()->end()) {
+    return nullptr;
+  }
+
+  host_->enable_cache_selection(true);
+
+  const AppCacheHost* spawning_host =
+      (resource_type_ == RESOURCE_TYPE_SHARED_WORKER) ?
+      host_ : host_->GetSpawningHost();
+  GURL preferred_manifest_url = spawning_host ?
+      spawning_host->preferred_manifest_url() : GURL();
+
+  // We may have to wait for our storage query to complete, but
+  // this query can also complete syncrhonously.
+  std::unique_ptr<AppCacheJob> job = CreateJob(network_delegate);
+  storage()->FindResponseForMainRequest(request_->GetURL(),
+                                        preferred_manifest_url, this);
+  return job;
+}
+
+void AppCacheRequestHandler::OnMainResponseFound(
+    const GURL& url,
+    const AppCacheEntry& entry,
+    const GURL& namespace_entry_url,
+    const AppCacheEntry& fallback_entry,
+    int64_t cache_id,
+    int64_t group_id,
+    const GURL& manifest_url) {
+  DCHECK(host_);
+  DCHECK(is_main_resource());
+  DCHECK(!entry.IsForeign());
+  DCHECK(!fallback_entry.IsForeign());
+  DCHECK(!(entry.has_response_id() && fallback_entry.has_response_id()));
+
+  // Request may have been canceled, but not yet deleted, while waiting on
+  // the cache.
+  if (!job_.get())
+    return;
+
+  AppCachePolicy* policy = host_->service()->appcache_policy();
+  bool was_blocked_by_policy = !manifest_url.is_empty() && policy &&
+      !policy->CanLoadAppCache(manifest_url, host_->first_party_url());
+
+  if (was_blocked_by_policy) {
+    if (IsResourceTypeFrame(resource_type_)) {
+      host_->NotifyMainResourceBlocked(manifest_url);
+    } else {
+      DCHECK_EQ(resource_type_, RESOURCE_TYPE_SHARED_WORKER);
+      host_->frontend()->OnContentBlocked(host_->host_id(), manifest_url);
+    }
+    DeliverNetworkResponse();
+    return;
+  }
+
+  if (should_reset_appcache_ && !manifest_url.is_empty()) {
+    host_->service()->DeleteAppCacheGroup(
+        manifest_url, net::CompletionCallback());
+    DeliverNetworkResponse();
+    return;
+  }
+
+  if (IsMainResourceType(resource_type_) && cache_id != kAppCacheNoCacheId) {
+    // AppCacheHost loads and holds a reference to the main resource cache
+    // for two reasons, firstly to preload the cache into the working set
+    // in advance of subresource loads happening, secondly to prevent the
+    // AppCache from falling out of the working set on frame navigations.
+    host_->LoadMainResourceCache(cache_id);
+    host_->set_preferred_manifest_url(manifest_url);
+  }
+
+  // 6.11.1 Navigating across documents, steps 10 and 14.
+
+  found_entry_ = entry;
+  found_namespace_entry_url_ = namespace_entry_url;
+  found_fallback_entry_ = fallback_entry;
+  found_cache_id_ = cache_id;
+  found_group_id_ = group_id;
+  found_manifest_url_ = manifest_url;
+  found_network_namespace_ = false;  // not applicable to main requests
+
+  if (found_entry_.has_response_id()) {
+    DCHECK(!found_fallback_entry_.has_response_id());
+    DeliverAppCachedResponse(found_entry_, found_cache_id_, found_manifest_url_,
+                             false, found_namespace_entry_url_);
+  } else {
+    DeliverNetworkResponse();
+  }
+}
+
+// NetworkService loading:
+void AppCacheRequestHandler::RunLoaderCallbackForMainResource(
+    LoaderCallback callback,
+    StartLoaderCallback start_loader_callback) {
+  // For now let |this| always also return the subresource loader
+  // if (and only if) this returns a non-null |start_loader_callback|
+  // for handling the main resource.
+  if (start_loader_callback)
+    should_create_subresource_loader_ = true;
+  std::move(callback).Run(std::move(start_loader_callback));
+}
+
+// Sub-resource handling ----------------------------------------------
+
+std::unique_ptr<AppCacheJob> AppCacheRequestHandler::MaybeLoadSubResource(
+    net::NetworkDelegate* network_delegate) {
+  DCHECK(!job_.get());
+
+  if (host_->is_selection_pending()) {
+    // We have to wait until cache selection is complete and the
+    // selected cache is loaded.
+    is_waiting_for_cache_selection_ = true;
+    return CreateJob(network_delegate);
+  }
+
+  if (!host_->associated_cache() ||
+      !host_->associated_cache()->is_complete() ||
+      host_->associated_cache()->owning_group()->is_being_deleted()) {
+    return nullptr;
+  }
+
+  std::unique_ptr<AppCacheJob> job = CreateJob(network_delegate);
+  ContinueMaybeLoadSubResource();
+  return job;
+}
+
+void AppCacheRequestHandler::ContinueMaybeLoadSubResource() {
+  // 6.9.6 Changes to the networking model
+  // If the resource is not to be fetched using the HTTP GET mechanism or
+  // equivalent ... then fetch the resource normally.
+  DCHECK(job_.get());
+  DCHECK(host_->associated_cache() && host_->associated_cache()->is_complete());
+
+  const GURL& url = request_->GetURL();
+  AppCache* cache = host_->associated_cache();
+  storage()->FindResponseForSubRequest(
+      host_->associated_cache(), url,
+      &found_entry_, &found_fallback_entry_, &found_network_namespace_);
+
+  if (found_entry_.has_response_id()) {
+    // Step 2: If there's an entry, get it instead.
+    DCHECK(!found_network_namespace_ &&
+           !found_fallback_entry_.has_response_id());
+    found_cache_id_ = cache->cache_id();
+    found_group_id_ = cache->owning_group()->group_id();
+    found_manifest_url_ = cache->owning_group()->manifest_url();
+    DeliverAppCachedResponse(found_entry_, found_cache_id_, found_manifest_url_,
+                             false, GURL());
+    return;
+  }
+
+  if (found_fallback_entry_.has_response_id()) {
+    // Step 4: Fetch the resource normally, if this results
+    // in certain conditions, then use the fallback.
+    DCHECK(!found_network_namespace_ &&
+           !found_entry_.has_response_id());
+    found_cache_id_ = cache->cache_id();
+    found_manifest_url_ = cache->owning_group()->manifest_url();
+    DeliverNetworkResponse();
+    return;
+  }
+
+  if (found_network_namespace_) {
+    // Step 3 and 5: Fetch the resource normally.
+    DCHECK(!found_entry_.has_response_id() &&
+           !found_fallback_entry_.has_response_id());
+    DeliverNetworkResponse();
+    return;
+  }
+
+  // Step 6: Fail the resource load.
+  DeliverErrorResponse();
+}
+
+void AppCacheRequestHandler::OnCacheSelectionComplete(AppCacheHost* host) {
+  DCHECK(host == host_);
+
+  // Request may have been canceled, but not yet deleted, while waiting on
+  // the cache.
+  if (!job_.get())
+    return;
+
+  if (is_main_resource())
+    return;
+  if (!is_waiting_for_cache_selection_)
+    return;
+
+  is_waiting_for_cache_selection_ = false;
+
+  if (!host_->associated_cache() ||
+      !host_->associated_cache()->is_complete()) {
+    DeliverNetworkResponse();
+    return;
+  }
+
+  ContinueMaybeLoadSubResource();
+}
+
+void AppCacheRequestHandler::MaybeCreateLoader(
+    const network::ResourceRequest& resource_request,
+    ResourceContext* resource_context,
+    LoaderCallback callback) {
+  loader_callback_ =
+      base::BindOnce(&AppCacheRequestHandler::RunLoaderCallbackForMainResource,
+                     weak_factory_.GetWeakPtr(), std::move(callback));
+  request_->AsURLLoaderRequest()->set_request(resource_request);
+  MaybeLoadResource(nullptr);
+  // If a job is created, the job assumes ownership of the callback and
+  // the responsibility to call it. If no job is created, we call it with
+  // an empty StartLoaderCallback to let our client we have no loader for
+  // this resource request.
+  if (loader_callback_)
+    std::move(loader_callback_).Run(StartLoaderCallback());
+}
+
+bool AppCacheRequestHandler::MaybeCreateLoaderForResponse(
+    const network::ResourceResponseHead& response,
+    network::mojom::URLLoaderPtr* loader,
+    network::mojom::URLLoaderClientRequest* client_request) {
+  // The sync interface of this method is inherited from the
+  // URLLoaderRequestHandler class. The LoaderCallback created here is invoked
+  // synchronously in fallback cases, and only when there really is a loader
+  // to start.
+  bool was_called = false;
+  loader_callback_ = base::BindOnce(
+      [](network::mojom::URLLoaderPtr* loader,
+         network::mojom::URLLoaderClientRequest* client_request,
+         bool* was_called, StartLoaderCallback start_function) {
+        *was_called = true;
+        network::mojom::URLLoaderClientPtr client;
+        *client_request = mojo::MakeRequest(&client);
+        std::move(start_function)
+            .Run(mojo::MakeRequest(loader), std::move(client));
+      },
+      loader, client_request, &was_called);
+  request_->AsURLLoaderRequest()->set_response(response);
+  if (!MaybeLoadFallbackForResponse(nullptr)) {
+    DCHECK(!was_called);
+    loader_callback_.Reset();
+    return false;
+  }
+  DCHECK(was_called);
+  return true;
+}
+
+base::Optional<SubresourceLoaderParams>
+AppCacheRequestHandler::MaybeCreateSubresourceLoaderParams() {
+  if (!should_create_subresource_loader_)
+    return base::nullopt;
+
+  // The factory is destroyed when the renderer drops the connection.
+  network::mojom::URLLoaderFactoryPtr factory_ptr;
+  AppCacheSubresourceURLFactory::CreateURLLoaderFactory(
+      network_url_loader_factory_getter_.get(), appcache_host_, &factory_ptr);
+
+  SubresourceLoaderParams params;
+  params.loader_factory_info = factory_ptr.PassInterface();
+  return params;
+}
+
+void AppCacheRequestHandler::MaybeCreateSubresourceLoader(
+    const network::ResourceRequest& resource_request,
+    LoaderCallback loader_callback) {
+  DCHECK(!job_);
+  DCHECK(!is_main_resource());
+  // Subresource loads start out just like a main resource loads, but they go
+  // down different branches along the way to completion.
+  MaybeCreateLoader(resource_request, nullptr, std::move(loader_callback));
+}
+
+void AppCacheRequestHandler::MaybeFallbackForSubresourceResponse(
+    const network::ResourceResponseHead& response,
+    LoaderCallback loader_callback) {
+  DCHECK(!job_);
+  DCHECK(!is_main_resource());
+  loader_callback_ = std::move(loader_callback);
+  request_->AsURLLoaderRequest()->set_response(response);
+  MaybeLoadFallbackForResponse(nullptr);
+  if (loader_callback_)
+    std::move(loader_callback_).Run(StartLoaderCallback());
+}
+
+void AppCacheRequestHandler::MaybeFallbackForSubresourceRedirect(
+    const net::RedirectInfo& redirect_info,
+    LoaderCallback loader_callback) {
+  DCHECK(!job_);
+  DCHECK(!is_main_resource());
+  loader_callback_ = std::move(loader_callback);
+  MaybeLoadFallbackForRedirect(nullptr, redirect_info.new_url);
+  if (loader_callback_)
+    std::move(loader_callback_).Run(StartLoaderCallback());
+}
+
+void AppCacheRequestHandler::MaybeFollowSubresourceRedirect(
+    const net::RedirectInfo& redirect_info,
+    LoaderCallback loader_callback) {
+  DCHECK(!job_);
+  DCHECK(!is_main_resource());
+  loader_callback_ = std::move(loader_callback);
+  request_->AsURLLoaderRequest()->UpdateWithRedirectInfo(redirect_info);
+  MaybeLoadResource(nullptr);
+  if (loader_callback_)
+    std::move(loader_callback_).Run(StartLoaderCallback());
+}
+
+// static
+void AppCacheRequestHandler::SetRunningInTests(bool in_tests) {
+  g_running_in_tests = in_tests;
+}
+
+// static
+bool AppCacheRequestHandler::IsRunningInTests() {
+  return g_running_in_tests;
+}
+
+}  // namespace content
diff -Naur chromium-65.0.3325.181-orig/content/browser/service_worker/service_worker_controllee_request_handler.cc chromium-65.0.3325.181.patched/content/browser/service_worker/service_worker_controllee_request_handler.cc
--- chromium-65.0.3325.181-orig/content/browser/service_worker/service_worker_controllee_request_handler.cc	2018-03-21 01:05:24.000000000 +0300
+++ chromium-65.0.3325.181.patched/content/browser/service_worker/service_worker_controllee_request_handler.cc	2018-04-27 11:31:20.655827593 +0300
@@ -271,7 +271,7 @@
   controller_info->object_info = provider_host_->GetOrCreateServiceWorkerHandle(
       provider_host_->controller());
   params.controller_service_worker_info = std::move(controller_info);
-  return params;
+  return base::Optional<SubresourceLoaderParams>(std::move(params));
 }
 
 void ServiceWorkerControlleeRequestHandler::PrepareForMainResource(
diff -Naur chromium-65.0.3325.181-orig/content/browser/service_worker/service_worker_controllee_request_handler.cc.explicit-std-move chromium-65.0.3325.181.patched/content/browser/service_worker/service_worker_controllee_request_handler.cc.explicit-std-move
--- chromium-65.0.3325.181-orig/content/browser/service_worker/service_worker_controllee_request_handler.cc.explicit-std-move	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/content/browser/service_worker/service_worker_controllee_request_handler.cc.explicit-std-move	2018-03-21 01:05:24.000000000 +0300
@@ -0,0 +1,583 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "content/browser/service_worker/service_worker_controllee_request_handler.h"
+
+#include <memory>
+#include <set>
+#include <string>
+
+#include "base/trace_event/trace_event.h"
+#include "components/offline_pages/features/features.h"
+#include "content/browser/service_worker/service_worker_context_core.h"
+#include "content/browser/service_worker/service_worker_metrics.h"
+#include "content/browser/service_worker/service_worker_provider_host.h"
+#include "content/browser/service_worker/service_worker_registration.h"
+#include "content/browser/service_worker/service_worker_response_info.h"
+#include "content/browser/service_worker/service_worker_url_job_wrapper.h"
+#include "content/browser/service_worker/service_worker_url_request_job.h"
+#include "content/common/navigation_subresource_loader_params.h"
+#include "content/common/service_worker/service_worker_utils.h"
+#include "content/public/browser/content_browser_client.h"
+#include "content/public/browser/render_frame_host.h"
+#include "content/public/browser/resource_request_info.h"
+#include "content/public/browser/web_contents.h"
+#include "content/public/common/browser_side_navigation_policy.h"
+#include "content/public/common/content_client.h"
+#include "net/base/load_flags.h"
+#include "net/base/url_util.h"
+#include "net/url_request/url_request.h"
+#include "services/network/public/cpp/resource_request_body.h"
+#include "services/network/public/cpp/resource_response_info.h"
+#include "ui/base/page_transition_types.h"
+
+#if BUILDFLAG(ENABLE_OFFLINE_PAGES)
+#include "components/offline_pages/core/request_header/offline_page_header.h"
+#endif  // BUILDFLAG(ENABLE_OFFLINE_PAGES)
+
+namespace content {
+
+namespace {
+
+bool MaybeForwardToServiceWorker(ServiceWorkerURLJobWrapper* job,
+                                 const ServiceWorkerVersion* version) {
+  DCHECK(job);
+  DCHECK(version);
+  DCHECK_NE(version->fetch_handler_existence(),
+            ServiceWorkerVersion::FetchHandlerExistence::UNKNOWN);
+  if (version->fetch_handler_existence() ==
+      ServiceWorkerVersion::FetchHandlerExistence::EXISTS) {
+    job->ForwardToServiceWorker();
+    return true;
+  }
+
+  job->FallbackToNetworkOrRenderer();
+  return false;
+}
+
+#if BUILDFLAG(ENABLE_OFFLINE_PAGES)
+// A web page, regardless of whether the service worker is used or not, could
+// be downloaded with the offline snapshot captured. The user can then open
+// the downloaded page which is identified by the presence of a specific
+// offline header in the network request. In this case, we want to fall back
+// in order for the subsequent offline page interceptor to bring up the
+// offline snapshot of the page.
+bool ShouldFallbackToLoadOfflinePage(
+    const net::HttpRequestHeaders& extra_request_headers) {
+  std::string offline_header_value;
+  if (!extra_request_headers.GetHeader(offline_pages::kOfflinePageHeader,
+                                       &offline_header_value)) {
+    return false;
+  }
+  offline_pages::OfflinePageHeader offline_header(offline_header_value);
+  return offline_header.reason ==
+         offline_pages::OfflinePageHeader::Reason::DOWNLOAD;
+}
+#endif  // BUILDFLAG(ENABLE_OFFLINE_PAGES)
+
+}  // namespace
+
+ServiceWorkerControlleeRequestHandler::ServiceWorkerControlleeRequestHandler(
+    base::WeakPtr<ServiceWorkerContextCore> context,
+    base::WeakPtr<ServiceWorkerProviderHost> provider_host,
+    base::WeakPtr<storage::BlobStorageContext> blob_storage_context,
+    network::mojom::FetchRequestMode request_mode,
+    network::mojom::FetchCredentialsMode credentials_mode,
+    network::mojom::FetchRedirectMode redirect_mode,
+    const std::string& integrity,
+    bool keepalive,
+    ResourceType resource_type,
+    RequestContextType request_context_type,
+    network::mojom::RequestContextFrameType frame_type,
+    scoped_refptr<network::ResourceRequestBody> body)
+    : ServiceWorkerRequestHandler(context,
+                                  provider_host,
+                                  blob_storage_context,
+                                  resource_type),
+      is_main_resource_load_(
+          ServiceWorkerUtils::IsMainResourceType(resource_type)),
+      is_main_frame_load_(resource_type == RESOURCE_TYPE_MAIN_FRAME),
+      request_mode_(request_mode),
+      credentials_mode_(credentials_mode),
+      redirect_mode_(redirect_mode),
+      integrity_(integrity),
+      keepalive_(keepalive),
+      request_context_type_(request_context_type),
+      frame_type_(frame_type),
+      body_(body),
+      force_update_started_(false),
+      use_network_(false),
+      weak_factory_(this) {}
+
+ServiceWorkerControlleeRequestHandler::
+    ~ServiceWorkerControlleeRequestHandler() {
+  // Navigation triggers an update to occur shortly after the page and
+  // its initial subresources load.
+  if (provider_host_ && provider_host_->active_version()) {
+    if (is_main_resource_load_ && !force_update_started_)
+      provider_host_->active_version()->ScheduleUpdate();
+    else
+      provider_host_->active_version()->DeferScheduledUpdate();
+  }
+
+  if (is_main_resource_load_ && provider_host_)
+    provider_host_->SetAllowAssociation(true);
+}
+
+net::URLRequestJob* ServiceWorkerControlleeRequestHandler::MaybeCreateJob(
+    net::URLRequest* request,
+    net::NetworkDelegate* network_delegate,
+    ResourceContext* resource_context) {
+  ClearJob();
+  ServiceWorkerResponseInfo::ResetDataForRequest(request);
+
+  if (!context_ || !provider_host_) {
+    // We can't do anything other than to fall back to network.
+    return nullptr;
+  }
+
+  // This may get called multiple times for original and redirect requests:
+  // A. original request case: use_network_ is false, no previous location info.
+  // B. redirect or restarted request case:
+  //  a) use_network_ is false if the previous location was forwarded to SW.
+  //  b) use_network_ is false if the previous location was fallback.
+  //  c) use_network_ is true if additional restart was required to fall back.
+
+  // Fall back to network. (Case B-c)
+  if (use_network_) {
+    // Once a subresource request has fallen back to the network once, it will
+    // never be handled by a service worker. This is not true of main frame
+    // requests.
+    if (is_main_resource_load_)
+      use_network_ = false;
+    return nullptr;
+  }
+
+#if BUILDFLAG(ENABLE_OFFLINE_PAGES)
+  // Fall back for the subsequent offline page interceptor to load the offline
+  // snapshot of the page if required.
+  if (ShouldFallbackToLoadOfflinePage(request->extra_request_headers()))
+    return nullptr;
+#endif  // BUILDFLAG(ENABLE_OFFLINE_PAGES)
+
+  // It's for original request (A) or redirect case (B-a or B-b).
+  std::unique_ptr<ServiceWorkerURLRequestJob> job(
+      new ServiceWorkerURLRequestJob(
+          request, network_delegate, provider_host_->client_uuid(),
+          blob_storage_context_, resource_context, request_mode_,
+          credentials_mode_, redirect_mode_, integrity_, keepalive_,
+          resource_type_, request_context_type_, frame_type_, body_,
+          ServiceWorkerFetchType::FETCH, this));
+  url_job_ = std::make_unique<ServiceWorkerURLJobWrapper>(job->GetWeakPtr());
+
+  resource_context_ = resource_context;
+
+  if (is_main_resource_load_)
+    PrepareForMainResource(request->url(), request->site_for_cookies());
+  else
+    PrepareForSubResource();
+
+  if (url_job_->ShouldFallbackToNetwork()) {
+    // If we know we can fallback to network at this point (in case
+    // the storage lookup returned immediately), just destroy the job and return
+    // NULL here to fallback to network.
+
+    // If this is a subresource request, all subsequent requests should also use
+    // the network.
+    if (!is_main_resource_load_)
+      use_network_ = true;
+
+    job.reset();
+    ClearJob();
+  }
+
+  return job.release();
+}
+
+void ServiceWorkerControlleeRequestHandler::MaybeCreateLoader(
+    const network::ResourceRequest& resource_request,
+    ResourceContext* resource_context,
+    LoaderCallback callback) {
+  DCHECK(ServiceWorkerUtils::IsServicificationEnabled());
+  DCHECK(is_main_resource_load_);
+  ClearJob();
+
+  if (!context_ || !provider_host_) {
+    // We can't do anything other than to fall back to network.
+    std::move(callback).Run(StartLoaderCallback());
+    return;
+  }
+
+  // In fallback cases we basically 'forward' the request, so we should
+  // never see use_network_ gets true.
+  DCHECK(!use_network_);
+
+#if BUILDFLAG(ENABLE_OFFLINE_PAGES)
+  // Fall back for the subsequent offline page interceptor to load the offline
+  // snapshot of the page if required.
+  if (ShouldFallbackToLoadOfflinePage(resource_request.headers)) {
+    std::move(callback).Run(StartLoaderCallback());
+    return;
+  }
+#endif  // BUILDFLAG(ENABLE_OFFLINE_PAGES)
+
+  url_job_ = std::make_unique<ServiceWorkerURLJobWrapper>(
+      std::make_unique<ServiceWorkerURLLoaderJob>(
+          std::move(callback), this, resource_request,
+          base::WrapRefCounted(context_->loader_factory_getter())));
+
+  resource_context_ = resource_context;
+
+  PrepareForMainResource(resource_request.url,
+                         resource_request.site_for_cookies);
+
+  if (url_job_->ShouldFallbackToNetwork()) {
+    // We're falling back to the next URLLoaderRequestHandler, forward
+    // the request and clear job now.
+    url_job_->FallbackToNetwork();
+    ClearJob();
+    return;
+  }
+
+  // We will asynchronously continue on DidLookupRegistrationForMainResource.
+}
+
+base::Optional<SubresourceLoaderParams>
+ServiceWorkerControlleeRequestHandler::MaybeCreateSubresourceLoaderParams() {
+  DCHECK(ServiceWorkerUtils::IsServicificationEnabled());
+
+  // We didn't create URLLoader for this request.
+  if (!url_job_)
+    return base::nullopt;
+
+  // DidLookupRegistrationForMainResource() for the request didn't find
+  // a matching service worker for this request, and
+  // ServiceWorkerProviderHost::AssociateRegistration() was not called.
+  if (!provider_host_ || !provider_host_->controller())
+    return base::nullopt;
+
+  // Otherwise let's send the controller service worker information along
+  // with the navigation commit.
+  // Note that |controller_info->endpoint| could be null if the controller
+  // service worker isn't starting up or running, e.g. in no-fetch worker
+  // cases. In that case the renderer frame won't get the controller pointer
+  // upon the navigation commit, and subresource loading will not be intercepted
+  // at least until the frame gets a new controller ptr by SetController.
+  SubresourceLoaderParams params;
+  auto controller_info = mojom::ControllerServiceWorkerInfo::New();
+  controller_info->endpoint =
+      provider_host_->GetControllerServiceWorkerPtr().PassInterface();
+  controller_info->object_info = provider_host_->GetOrCreateServiceWorkerHandle(
+      provider_host_->controller());
+  params.controller_service_worker_info = std::move(controller_info);
+  return params;
+}
+
+void ServiceWorkerControlleeRequestHandler::PrepareForMainResource(
+    const GURL& url,
+    const GURL& site_for_cookies) {
+  DCHECK(!JobWasCanceled());
+  DCHECK(context_);
+  DCHECK(provider_host_);
+  TRACE_EVENT_ASYNC_BEGIN1(
+      "ServiceWorker",
+      "ServiceWorkerControlleeRequestHandler::PrepareForMainResource",
+      url_job_.get(), "URL", url.spec());
+  // The corresponding provider_host may already have associated a registration
+  // in redirect case, unassociate it now.
+  provider_host_->DisassociateRegistration();
+
+  // Also prevent a registrater job for establishing an association to a new
+  // registration while we're finding an existing registration.
+  provider_host_->SetAllowAssociation(false);
+
+  stripped_url_ = net::SimplifyUrlForRequest(url);
+  provider_host_->SetDocumentUrl(stripped_url_);
+  provider_host_->SetTopmostFrameUrl(site_for_cookies);
+  context_->storage()->FindRegistrationForDocument(
+      stripped_url_, base::Bind(&self::DidLookupRegistrationForMainResource,
+                                weak_factory_.GetWeakPtr()));
+}
+
+void ServiceWorkerControlleeRequestHandler::
+    DidLookupRegistrationForMainResource(
+        ServiceWorkerStatusCode status,
+        scoped_refptr<ServiceWorkerRegistration> registration) {
+  // The job may have been canceled before this was invoked.
+  if (JobWasCanceled())
+    return;
+
+  const bool need_to_update = !force_update_started_ && registration &&
+                              context_->force_update_on_page_load();
+
+  if (provider_host_ && !need_to_update)
+    provider_host_->SetAllowAssociation(true);
+  if (status != SERVICE_WORKER_OK || !provider_host_ || !context_) {
+    url_job_->FallbackToNetwork();
+    TRACE_EVENT_ASYNC_END1(
+        "ServiceWorker",
+        "ServiceWorkerControlleeRequestHandler::PrepareForMainResource",
+        url_job_.get(), "Status", status);
+    return;
+  }
+  DCHECK(registration.get());
+
+  base::Callback<WebContents*(void)> web_contents_getter;
+  if (IsBrowserSideNavigationEnabled()) {
+    web_contents_getter = provider_host_->web_contents_getter();
+  } else if (provider_host_->process_id() != -1 &&
+             provider_host_->frame_id() != -1) {
+    web_contents_getter = base::Bind(
+        [](int render_process_id, int render_frame_id) {
+          RenderFrameHost* rfh =
+              RenderFrameHost::FromID(render_process_id, render_frame_id);
+          return WebContents::FromRenderFrameHost(rfh);
+        },
+        provider_host_->process_id(), provider_host_->frame_id());
+  }
+  if (!GetContentClient()->browser()->AllowServiceWorker(
+          registration->pattern(), provider_host_->topmost_frame_url(),
+          resource_context_, web_contents_getter)) {
+    url_job_->FallbackToNetwork();
+    TRACE_EVENT_ASYNC_END2(
+        "ServiceWorker",
+        "ServiceWorkerControlleeRequestHandler::PrepareForMainResource",
+        url_job_.get(), "Status", status, "Info", "ServiceWorker is blocked");
+    return;
+  }
+
+  if (!provider_host_->IsContextSecureForServiceWorker()) {
+    // TODO(falken): Figure out a way to surface in the page's DevTools
+    // console that the service worker was blocked for security.
+    url_job_->FallbackToNetwork();
+    TRACE_EVENT_ASYNC_END1(
+        "ServiceWorker",
+        "ServiceWorkerControlleeRequestHandler::PrepareForMainResource",
+        url_job_.get(), "Info", "Insecure context");
+    return;
+  }
+
+  if (need_to_update) {
+    force_update_started_ = true;
+    context_->UpdateServiceWorker(
+        registration.get(), true /* force_bypass_cache */,
+        true /* skip_script_comparison */,
+        base::Bind(&self::DidUpdateRegistration, weak_factory_.GetWeakPtr(),
+                   registration));
+    return;
+  }
+
+  // Initiate activation of a waiting version.
+  // Usually a register job initiates activation but that
+  // doesn't happen if the browser exits prior to activation
+  // having occurred. This check handles that case.
+  if (registration->waiting_version())
+    registration->ActivateWaitingVersionWhenReady();
+
+  scoped_refptr<ServiceWorkerVersion> active_version =
+      registration->active_version();
+
+  // Wait until it's activated before firing fetch events.
+  if (active_version.get() &&
+      active_version->status() == ServiceWorkerVersion::ACTIVATING) {
+    provider_host_->SetAllowAssociation(false);
+    registration->active_version()->RegisterStatusChangeCallback(base::BindOnce(
+        &self::OnVersionStatusChanged, weak_factory_.GetWeakPtr(),
+        base::RetainedRef(registration), base::RetainedRef(active_version)));
+    TRACE_EVENT_ASYNC_END2(
+        "ServiceWorker",
+        "ServiceWorkerControlleeRequestHandler::PrepareForMainResource",
+        url_job_.get(), "Status", status, "Info",
+        "Wait until finished SW activation");
+    return;
+  }
+
+  // A registration exists, so associate it. Note that the controller is only
+  // set if there's an active version. If there's no active version, we should
+  // still associate so the provider host can use .ready.
+  provider_host_->AssociateRegistration(registration.get(),
+                                        false /* notify_controllerchange */);
+
+  if (!active_version.get() ||
+      active_version->status() != ServiceWorkerVersion::ACTIVATED) {
+    url_job_->FallbackToNetwork();
+    TRACE_EVENT_ASYNC_END2(
+        "ServiceWorker",
+        "ServiceWorkerControlleeRequestHandler::PrepareForMainResource",
+        url_job_.get(), "Status", status, "Info",
+        "ServiceWorkerVersion is not available, so falling back to network");
+    return;
+  }
+
+  DCHECK_NE(active_version->fetch_handler_existence(),
+            ServiceWorkerVersion::FetchHandlerExistence::UNKNOWN);
+  ServiceWorkerMetrics::CountControlledPageLoad(
+      active_version->site_for_uma(), stripped_url_, is_main_frame_load_,
+      url_job_->GetPageTransition(), url_job_->GetURLChainSize());
+
+  bool is_forwarded =
+      MaybeForwardToServiceWorker(url_job_.get(), active_version.get());
+
+  TRACE_EVENT_ASYNC_END2(
+      "ServiceWorker",
+      "ServiceWorkerControlleeRequestHandler::PrepareForMainResource",
+      url_job_.get(), "Status", status, "Info",
+      (is_forwarded) ? "Forwarded to the ServiceWorker"
+                     : "Skipped the ServiceWorker which has no fetch handler");
+}
+
+void ServiceWorkerControlleeRequestHandler::OnVersionStatusChanged(
+    ServiceWorkerRegistration* registration,
+    ServiceWorkerVersion* version) {
+  // The job may have been canceled before this was invoked.
+  if (JobWasCanceled())
+    return;
+
+  if (provider_host_)
+    provider_host_->SetAllowAssociation(true);
+  if (version != registration->active_version() ||
+      version->status() != ServiceWorkerVersion::ACTIVATED ||
+      !provider_host_) {
+    url_job_->FallbackToNetwork();
+    return;
+  }
+
+  DCHECK_NE(version->fetch_handler_existence(),
+            ServiceWorkerVersion::FetchHandlerExistence::UNKNOWN);
+  ServiceWorkerMetrics::CountControlledPageLoad(
+      version->site_for_uma(), stripped_url_, is_main_frame_load_,
+      url_job_->GetPageTransition(), url_job_->GetURLChainSize());
+
+  provider_host_->AssociateRegistration(registration,
+                                        false /* notify_controllerchange */);
+
+  MaybeForwardToServiceWorker(url_job_.get(), version);
+}
+
+void ServiceWorkerControlleeRequestHandler::DidUpdateRegistration(
+    const scoped_refptr<ServiceWorkerRegistration>& original_registration,
+    ServiceWorkerStatusCode status,
+    const std::string& status_message,
+    int64_t registration_id) {
+  DCHECK(force_update_started_);
+
+  // The job may have been canceled before this was invoked.
+  if (JobWasCanceled())
+    return;
+
+  if (!context_) {
+    url_job_->FallbackToNetwork();
+    return;
+  }
+  if (status != SERVICE_WORKER_OK ||
+      !original_registration->installing_version()) {
+    // Update failed. Look up the registration again since the original
+    // registration was possibly unregistered in the meantime.
+    context_->storage()->FindRegistrationForDocument(
+        stripped_url_, base::Bind(&self::DidLookupRegistrationForMainResource,
+                                  weak_factory_.GetWeakPtr()));
+    return;
+  }
+  DCHECK_EQ(original_registration->id(), registration_id);
+  scoped_refptr<ServiceWorkerVersion> new_version =
+      original_registration->installing_version();
+  new_version->ReportForceUpdateToDevTools();
+  new_version->set_skip_waiting(true);
+  new_version->RegisterStatusChangeCallback(base::BindOnce(
+      &self::OnUpdatedVersionStatusChanged, weak_factory_.GetWeakPtr(),
+      original_registration, new_version));
+}
+
+void ServiceWorkerControlleeRequestHandler::OnUpdatedVersionStatusChanged(
+    const scoped_refptr<ServiceWorkerRegistration>& registration,
+    const scoped_refptr<ServiceWorkerVersion>& version) {
+  // The job may have been canceled before this was invoked.
+  if (JobWasCanceled())
+    return;
+
+  if (!context_) {
+    url_job_->FallbackToNetwork();
+    return;
+  }
+  if (version->status() == ServiceWorkerVersion::ACTIVATED ||
+      version->status() == ServiceWorkerVersion::REDUNDANT) {
+    // When the status is REDUNDANT, the update failed (eg: script error), we
+    // continue with the incumbent version.
+    // In case unregister job may have run, look up the registration again.
+    context_->storage()->FindRegistrationForDocument(
+        stripped_url_, base::Bind(&self::DidLookupRegistrationForMainResource,
+                                  weak_factory_.GetWeakPtr()));
+    return;
+  }
+  version->RegisterStatusChangeCallback(
+      base::BindOnce(&self::OnUpdatedVersionStatusChanged,
+                     weak_factory_.GetWeakPtr(), registration, version));
+}
+
+void ServiceWorkerControlleeRequestHandler::PrepareForSubResource() {
+  DCHECK(!JobWasCanceled());
+  DCHECK(context_);
+
+  // When this request handler was created, the provider host had a controller
+  // and hence an active version, but by the time MaybeCreateJob() is called
+  // the active version may have been lost. This happens when
+  // ServiceWorkerRegistration::DeleteVersion() was called to delete the worker
+  // because a permanent failure occurred when trying to start it.
+  //
+  // As this is an exceptional case, just error out.
+  // TODO(falken): Figure out if |active_version| can change to |controller| and
+  // do it or document the findings.
+  if (!provider_host_->active_version()) {
+    url_job_->FailDueToLostController();
+    return;
+  }
+
+  MaybeForwardToServiceWorker(url_job_.get(), provider_host_->active_version());
+}
+
+void ServiceWorkerControlleeRequestHandler::OnPrepareToRestart() {
+  use_network_ = true;
+  ClearJob();
+}
+
+ServiceWorkerVersion*
+ServiceWorkerControlleeRequestHandler::GetServiceWorkerVersion(
+    ServiceWorkerMetrics::URLRequestJobResult* result) {
+  if (!provider_host_) {
+    *result = ServiceWorkerMetrics::REQUEST_JOB_ERROR_NO_PROVIDER_HOST;
+    return nullptr;
+  }
+  if (!provider_host_->active_version()) {
+    *result = ServiceWorkerMetrics::REQUEST_JOB_ERROR_NO_ACTIVE_VERSION;
+    return nullptr;
+  }
+  return provider_host_->active_version();
+}
+
+bool ServiceWorkerControlleeRequestHandler::RequestStillValid(
+    ServiceWorkerMetrics::URLRequestJobResult* result) {
+  // A null |provider_host_| probably means the tab was closed. The null value
+  // would cause problems down the line, so bail out.
+  if (!provider_host_) {
+    *result = ServiceWorkerMetrics::REQUEST_JOB_ERROR_NO_PROVIDER_HOST;
+    return false;
+  }
+  return true;
+}
+
+void ServiceWorkerControlleeRequestHandler::MainResourceLoadFailed() {
+  DCHECK(provider_host_);
+  // Detach the controller so subresource requests also skip the worker.
+  provider_host_->NotifyControllerLost();
+}
+
+void ServiceWorkerControlleeRequestHandler::ClearJob() {
+  url_job_.reset();
+}
+
+bool ServiceWorkerControlleeRequestHandler::JobWasCanceled() const {
+  return !url_job_ || url_job_->WasCanceled();
+}
+
+}  // namespace content
diff -Naur chromium-65.0.3325.181-orig/device/usb/usb_context.cc chromium-65.0.3325.181.patched/device/usb/usb_context.cc
--- chromium-65.0.3325.181-orig/device/usb/usb_context.cc	2018-03-21 01:05:25.000000000 +0300
+++ chromium-65.0.3325.181.patched/device/usb/usb_context.cc	2018-04-27 11:31:20.479829444 +0300
@@ -58,7 +58,11 @@
 
 void UsbContext::UsbEventHandler::Stop() {
   base::subtle::Release_Store(&running_, 0);
+#ifdef LIBUSB_API_VERSION >= 0x01000105
+  libusb_interrupt_event_handler(context_);
+#else
   libusb_interrupt_handle_event(context_);
+#endif
 }
 
 UsbContext::UsbContext(PlatformUsbContext context) : context_(context) {
diff -Naur chromium-65.0.3325.181-orig/device/usb/usb_context.cc.modern-libusbx chromium-65.0.3325.181.patched/device/usb/usb_context.cc.modern-libusbx
--- chromium-65.0.3325.181-orig/device/usb/usb_context.cc.modern-libusbx	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/device/usb/usb_context.cc.modern-libusbx	2018-03-21 01:05:25.000000000 +0300
@@ -0,0 +1,75 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "device/usb/usb_context.h"
+
+#include "base/atomicops.h"
+#include "base/logging.h"
+#include "base/macros.h"
+#include "base/threading/simple_thread.h"
+#include "device/usb/usb_error.h"
+#include "third_party/libusb/src/libusb/interrupt.h"
+#include "third_party/libusb/src/libusb/libusb.h"
+
+namespace device {
+
+// The UsbEventHandler works around a design flaw in the libusb interface. There
+// is currently no way to signal to libusb that any caller into one of the event
+// handler calls should return without handling any events.
+class UsbContext::UsbEventHandler : public base::SimpleThread {
+ public:
+  explicit UsbEventHandler(libusb_context* context);
+  ~UsbEventHandler() override;
+
+  // base::SimpleThread
+  void Run() override;
+
+  void Stop();
+
+ private:
+  base::subtle::Atomic32 running_;
+  libusb_context* context_;
+  DISALLOW_COPY_AND_ASSIGN(UsbEventHandler);
+};
+
+UsbContext::UsbEventHandler::UsbEventHandler(libusb_context* context)
+    : base::SimpleThread("UsbEventHandler"), context_(context) {
+  base::subtle::Release_Store(&running_, 1);
+}
+
+UsbContext::UsbEventHandler::~UsbEventHandler() {
+  libusb_exit(context_);
+}
+
+void UsbContext::UsbEventHandler::Run() {
+  VLOG(1) << "UsbEventHandler started.";
+
+  while (base::subtle::Acquire_Load(&running_)) {
+    const int rv = libusb_handle_events(context_);
+    if (rv != LIBUSB_SUCCESS) {
+      VLOG(1) << "Failed to handle events: "
+              << ConvertPlatformUsbErrorToString(rv);
+    }
+  }
+
+  VLOG(1) << "UsbEventHandler shutting down.";
+}
+
+void UsbContext::UsbEventHandler::Stop() {
+  base::subtle::Release_Store(&running_, 0);
+  libusb_interrupt_handle_event(context_);
+}
+
+UsbContext::UsbContext(PlatformUsbContext context) : context_(context) {
+  // Ownership of the PlatformUsbContext is passed to the event handler thread.
+  event_handler_.reset(new UsbEventHandler(context_));
+  event_handler_->Start();
+}
+
+UsbContext::~UsbContext() {
+  event_handler_->Stop();
+  event_handler_->Join();
+}
+
+}  // namespace device
diff -Naur chromium-65.0.3325.181-orig/gpu/ipc/common/mailbox_struct_traits.h chromium-65.0.3325.181.patched/gpu/ipc/common/mailbox_struct_traits.h
--- chromium-65.0.3325.181-orig/gpu/ipc/common/mailbox_struct_traits.h	2018-03-21 01:05:26.000000000 +0300
+++ chromium-65.0.3325.181.patched/gpu/ipc/common/mailbox_struct_traits.h	2018-04-27 11:31:20.587828309 +0300
@@ -15,7 +15,7 @@
 template <>
 struct StructTraits<gpu::mojom::MailboxDataView, gpu::Mailbox> {
   static base::span<const int8_t> name(const gpu::Mailbox& mailbox) {
-    return mailbox.name;
+    return base::make_span(mailbox.name);
   }
   static bool Read(gpu::mojom::MailboxDataView data, gpu::Mailbox* out);
 };
diff -Naur chromium-65.0.3325.181-orig/gpu/ipc/common/mailbox_struct_traits.h.gcc5-r3 chromium-65.0.3325.181.patched/gpu/ipc/common/mailbox_struct_traits.h.gcc5-r3
--- chromium-65.0.3325.181-orig/gpu/ipc/common/mailbox_struct_traits.h.gcc5-r3	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/gpu/ipc/common/mailbox_struct_traits.h.gcc5-r3	2018-03-21 01:05:26.000000000 +0300
@@ -0,0 +1,25 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef GPU_IPC_COMMON_MAILBOX_STRUCT_TRAITS_H_
+#define GPU_IPC_COMMON_MAILBOX_STRUCT_TRAITS_H_
+
+#include "base/containers/span.h"
+#include "gpu/command_buffer/common/mailbox.h"
+#include "gpu/ipc/common/mailbox.mojom-shared.h"
+#include "mojo/public/cpp/bindings/array_traits.h"
+
+namespace mojo {
+
+template <>
+struct StructTraits<gpu::mojom::MailboxDataView, gpu::Mailbox> {
+  static base::span<const int8_t> name(const gpu::Mailbox& mailbox) {
+    return mailbox.name;
+  }
+  static bool Read(gpu::mojom::MailboxDataView data, gpu::Mailbox* out);
+};
+
+}  // namespace mojo
+
+#endif  // GPU_IPC_COMMON_MAILBOX_STRUCT_TRAITS_H_
diff -Naur chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_ptr_info.h chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h
--- chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_ptr_info.h	2018-03-21 01:05:27.000000000 +0300
+++ chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h	2018-04-27 11:31:20.691827214 +0300
@@ -45,7 +45,7 @@
 
   bool is_valid() const { return handle_.is_valid(); }
 
-  explicit operator bool() const { return handle_; }
+  explicit operator bool() const { return (bool) handle_; }
 
   ScopedInterfaceEndpointHandle PassHandle() {
     return std::move(handle_);
diff -Naur chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix
--- chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_ptr_info.h.boolfix	2018-03-21 01:05:27.000000000 +0300
@@ -0,0 +1,79 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_PTR_INFO_H_
+#define MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_PTR_INFO_H_
+
+#include <stdint.h>
+#include <utility>
+
+#include "base/macros.h"
+#include "mojo/public/cpp/bindings/scoped_interface_endpoint_handle.h"
+
+namespace mojo {
+
+// AssociatedInterfacePtrInfo stores necessary information to construct an
+// associated interface pointer. It is similar to InterfacePtrInfo except that
+// it doesn't own a message pipe handle.
+template <typename Interface>
+class AssociatedInterfacePtrInfo {
+ public:
+  AssociatedInterfacePtrInfo() : version_(0u) {}
+  AssociatedInterfacePtrInfo(std::nullptr_t) : version_(0u) {}
+
+  AssociatedInterfacePtrInfo(AssociatedInterfacePtrInfo&& other)
+      : handle_(std::move(other.handle_)), version_(other.version_) {
+    other.version_ = 0u;
+  }
+
+  AssociatedInterfacePtrInfo(ScopedInterfaceEndpointHandle handle,
+                             uint32_t version)
+      : handle_(std::move(handle)), version_(version) {}
+
+  ~AssociatedInterfacePtrInfo() {}
+
+  AssociatedInterfacePtrInfo& operator=(AssociatedInterfacePtrInfo&& other) {
+    if (this != &other) {
+      handle_ = std::move(other.handle_);
+      version_ = other.version_;
+      other.version_ = 0u;
+    }
+
+    return *this;
+  }
+
+  bool is_valid() const { return handle_.is_valid(); }
+
+  explicit operator bool() const { return handle_; }
+
+  ScopedInterfaceEndpointHandle PassHandle() {
+    return std::move(handle_);
+  }
+  const ScopedInterfaceEndpointHandle& handle() const { return handle_; }
+  void set_handle(ScopedInterfaceEndpointHandle handle) {
+    handle_ = std::move(handle);
+  }
+
+  uint32_t version() const { return version_; }
+  void set_version(uint32_t version) { version_ = version; }
+
+  bool Equals(const AssociatedInterfacePtrInfo& other) const {
+    if (this == &other)
+      return true;
+
+    // Now that the two refer to different objects, they are equivalent if
+    // and only if they are both invalid.
+    return !is_valid() && !other.is_valid();
+  }
+
+ private:
+  ScopedInterfaceEndpointHandle handle_;
+  uint32_t version_;
+
+  DISALLOW_COPY_AND_ASSIGN(AssociatedInterfacePtrInfo);
+};
+
+}  // namespace mojo
+
+#endif  // MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_PTR_INFO_H_
diff -Naur chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_request.h chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_request.h
--- chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_request.h	2018-03-21 01:05:27.000000000 +0300
+++ chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_request.h	2018-04-27 11:31:20.691827214 +0300
@@ -50,7 +50,7 @@
   // handle.
   bool is_pending() const { return handle_.is_valid(); }
 
-  explicit operator bool() const { return handle_; }
+  explicit operator bool() const { return (bool) handle_; }
 
   ScopedInterfaceEndpointHandle PassHandle() { return std::move(handle_); }
 
diff -Naur chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_request.h.boolfix chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_request.h.boolfix
--- chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/associated_interface_request.h.boolfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/associated_interface_request.h.boolfix	2018-03-21 01:05:27.000000000 +0300
@@ -0,0 +1,80 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_REQUEST_H_
+#define MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_REQUEST_H_
+
+#include <string>
+#include <utility>
+
+#include "base/macros.h"
+#include "mojo/public/cpp/bindings/scoped_interface_endpoint_handle.h"
+
+namespace mojo {
+
+// AssociatedInterfaceRequest represents an associated interface request. It is
+// similar to InterfaceRequest except that it doesn't own a message pipe handle.
+template <typename Interface>
+class AssociatedInterfaceRequest {
+ public:
+  // Constructs an empty AssociatedInterfaceRequest, representing that the
+  // client is not requesting an implementation of Interface.
+  AssociatedInterfaceRequest() {}
+  AssociatedInterfaceRequest(decltype(nullptr)) {}
+
+  explicit AssociatedInterfaceRequest(ScopedInterfaceEndpointHandle handle)
+      : handle_(std::move(handle)) {}
+
+  // Takes the interface endpoint handle from another
+  // AssociatedInterfaceRequest.
+  AssociatedInterfaceRequest(AssociatedInterfaceRequest&& other) {
+    handle_ = std::move(other.handle_);
+  }
+
+  AssociatedInterfaceRequest& operator=(AssociatedInterfaceRequest&& other) {
+    if (this != &other)
+      handle_ = std::move(other.handle_);
+    return *this;
+  }
+
+  // Assigning to nullptr resets the AssociatedInterfaceRequest to an empty
+  // state, closing the interface endpoint handle currently bound to it (if
+  // any).
+  AssociatedInterfaceRequest& operator=(decltype(nullptr)) {
+    handle_.reset();
+    return *this;
+  }
+
+  // Indicates whether the request currently contains a valid interface endpoint
+  // handle.
+  bool is_pending() const { return handle_.is_valid(); }
+
+  explicit operator bool() const { return handle_; }
+
+  ScopedInterfaceEndpointHandle PassHandle() { return std::move(handle_); }
+
+  const ScopedInterfaceEndpointHandle& handle() const { return handle_; }
+
+  bool Equals(const AssociatedInterfaceRequest& other) const {
+    if (this == &other)
+      return true;
+
+    // Now that the two refer to different objects, they are equivalent if
+    // and only if they are both invalid.
+    return !is_pending() && !other.is_pending();
+  }
+
+  void ResetWithReason(uint32_t custom_reason, const std::string& description) {
+    handle_.ResetWithReason(custom_reason, description);
+  }
+
+ private:
+  ScopedInterfaceEndpointHandle handle_;
+
+  DISALLOW_COPY_AND_ASSIGN(AssociatedInterfaceRequest);
+};
+
+}  // namespace mojo
+
+#endif  // MOJO_PUBLIC_CPP_BINDINGS_ASSOCIATED_INTERFACE_REQUEST_H_
diff -Naur chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/interface_request.h chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/interface_request.h
--- chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/interface_request.h	2018-03-21 01:05:27.000000000 +0300
+++ chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/interface_request.h	2018-04-27 11:31:20.695827172 +0300
@@ -54,7 +54,7 @@
   // Indicates whether the request currently contains a valid message pipe.
   bool is_pending() const { return handle_.is_valid(); }
 
-  explicit operator bool() const { return handle_; }
+  explicit operator bool() const { return (bool) handle_; }
 
   // Removes the message pipe from the request and returns it.
   ScopedMessagePipeHandle PassMessagePipe() { return std::move(handle_); }
diff -Naur chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/interface_request.h.boolfix chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/interface_request.h.boolfix
--- chromium-65.0.3325.181-orig/mojo/public/cpp/bindings/interface_request.h.boolfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/mojo/public/cpp/bindings/interface_request.h.boolfix	2018-03-21 01:05:27.000000000 +0300
@@ -0,0 +1,166 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef MOJO_PUBLIC_CPP_BINDINGS_INTERFACE_REQUEST_H_
+#define MOJO_PUBLIC_CPP_BINDINGS_INTERFACE_REQUEST_H_
+
+#include <string>
+#include <utility>
+
+#include "base/macros.h"
+#include "base/optional.h"
+#include "base/single_thread_task_runner.h"
+#include "mojo/public/cpp/bindings/disconnect_reason.h"
+#include "mojo/public/cpp/bindings/interface_ptr.h"
+#include "mojo/public/cpp/bindings/pipe_control_message_proxy.h"
+#include "mojo/public/cpp/system/message_pipe.h"
+
+namespace mojo {
+
+// Represents a request from a remote client for an implementation of Interface
+// over a specified message pipe. The implementor of the interface should
+// remove the message pipe by calling PassMessagePipe() and bind it to the
+// implementation. If this is not done, the InterfaceRequest will automatically
+// close the pipe on destruction. Can also represent the absence of a request
+// if the client did not provide a message pipe.
+template <typename Interface>
+class InterfaceRequest {
+ public:
+  // Constructs an empty InterfaceRequest, representing that the client is not
+  // requesting an implementation of Interface.
+  InterfaceRequest() {}
+  InterfaceRequest(decltype(nullptr)) {}
+
+  explicit InterfaceRequest(ScopedMessagePipeHandle handle)
+      : handle_(std::move(handle)) {}
+
+  // Takes the message pipe from another InterfaceRequest.
+  InterfaceRequest(InterfaceRequest&& other) {
+    handle_ = std::move(other.handle_);
+  }
+  InterfaceRequest& operator=(InterfaceRequest&& other) {
+    handle_ = std::move(other.handle_);
+    return *this;
+  }
+
+  // Assigning to nullptr resets the InterfaceRequest to an empty state,
+  // closing the message pipe currently bound to it (if any).
+  InterfaceRequest& operator=(decltype(nullptr)) {
+    handle_.reset();
+    return *this;
+  }
+
+  // Indicates whether the request currently contains a valid message pipe.
+  bool is_pending() const { return handle_.is_valid(); }
+
+  explicit operator bool() const { return handle_; }
+
+  // Removes the message pipe from the request and returns it.
+  ScopedMessagePipeHandle PassMessagePipe() { return std::move(handle_); }
+
+  bool Equals(const InterfaceRequest& other) const {
+    if (this == &other)
+      return true;
+
+    // Now that the two refer to different objects, they are equivalent if
+    // and only if they are both invalid.
+    return !is_pending() && !other.is_pending();
+  }
+
+  void ResetWithReason(uint32_t custom_reason, const std::string& description) {
+    if (!handle_.is_valid())
+      return;
+
+    Message message =
+        PipeControlMessageProxy::ConstructPeerEndpointClosedMessage(
+            kMasterInterfaceId, DisconnectReason(custom_reason, description));
+    MojoResult result = WriteMessageNew(
+        handle_.get(), message.TakeMojoMessage(), MOJO_WRITE_MESSAGE_FLAG_NONE);
+    DCHECK_EQ(MOJO_RESULT_OK, result);
+
+    handle_.reset();
+  }
+
+ private:
+  ScopedMessagePipeHandle handle_;
+
+  DISALLOW_COPY_AND_ASSIGN(InterfaceRequest);
+};
+
+// Creates a new message pipe over which Interface is to be served. Binds the
+// specified InterfacePtr to one end of the message pipe, and returns an
+// InterfaceRequest bound to the other. The InterfacePtr should be passed to
+// the client, and the InterfaceRequest should be passed to whatever will
+// provide the implementation. The implementation should typically be bound to
+// the InterfaceRequest using the Binding or StrongBinding classes. The client
+// may begin to issue calls even before an implementation has been bound, since
+// messages sent over the pipe will just queue up until they are consumed by
+// the implementation.
+//
+// Example #1: Requesting a remote implementation of an interface.
+// ===============================================================
+//
+// Given the following interface:
+//
+//   interface Database {
+//     OpenTable(Table& table);
+//   }
+//
+// The client would have code similar to the following:
+//
+//   DatabasePtr database = ...;  // Connect to database.
+//   TablePtr table;
+//   database->OpenTable(MakeRequest(&table));
+//
+// Upon return from MakeRequest, |table| is ready to have methods called on it.
+//
+// Example #2: Registering a local implementation with a remote service.
+// =====================================================================
+//
+// Given the following interface
+//   interface Collector {
+//     RegisterSource(Source source);
+//   }
+//
+// The client would have code similar to the following:
+//
+//   CollectorPtr collector = ...;  // Connect to Collector.
+//   SourcePtr source;
+//   InterfaceRequest<Source> source_request(&source);
+//   collector->RegisterSource(std::move(source));
+//   CreateSource(std::move(source_request));  // Create implementation locally.
+//
+template <typename Interface>
+InterfaceRequest<Interface> MakeRequest(
+    InterfacePtr<Interface>* ptr,
+    scoped_refptr<base::SingleThreadTaskRunner> runner = nullptr) {
+  MessagePipe pipe;
+  ptr->Bind(InterfacePtrInfo<Interface>(std::move(pipe.handle0), 0u),
+            std::move(runner));
+  return InterfaceRequest<Interface>(std::move(pipe.handle1));
+}
+
+// Similar to the constructor above, but binds one end of the message pipe to
+// an InterfacePtrInfo instance.
+template <typename Interface>
+InterfaceRequest<Interface> MakeRequest(InterfacePtrInfo<Interface>* ptr_info) {
+  MessagePipe pipe;
+  ptr_info->set_handle(std::move(pipe.handle0));
+  ptr_info->set_version(0u);
+  return InterfaceRequest<Interface>(std::move(pipe.handle1));
+}
+
+// Fuses an InterfaceRequest<T> endpoint with an InterfacePtrInfo<T> endpoint.
+// Returns |true| on success or |false| on failure.
+template <typename Interface>
+bool FuseInterface(InterfaceRequest<Interface> request,
+                   InterfacePtrInfo<Interface> proxy_info) {
+  MojoResult result = FuseMessagePipes(request.PassMessagePipe(),
+                                       proxy_info.PassHandle());
+  return result == MOJO_RESULT_OK;
+}
+
+}  // namespace mojo
+
+#endif  // MOJO_PUBLIC_CPP_BINDINGS_INTERFACE_REQUEST_H_
diff -Naur chromium-65.0.3325.181-orig/native_client/src/untrusted/nacl/getcwd.c chromium-65.0.3325.181.patched/native_client/src/untrusted/nacl/getcwd.c
--- chromium-65.0.3325.181-orig/native_client/src/untrusted/nacl/getcwd.c	2018-03-21 01:06:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/native_client/src/untrusted/nacl/getcwd.c	2018-04-27 11:31:20.471829529 +0300
@@ -11,6 +11,10 @@
 
 #include <errno.h>
 #include <limits.h>
+/* Needed for PATH_MAX */
+#ifndef PATH_MAX
+#define PATH_MAX 4096
+#endif
 #include <stdlib.h>
 #include <string.h>
 #include <unistd.h>
diff -Naur chromium-65.0.3325.181-orig/native_client/src/untrusted/nacl/getcwd.c.pathmax chromium-65.0.3325.181.patched/native_client/src/untrusted/nacl/getcwd.c.pathmax
--- chromium-65.0.3325.181-orig/native_client/src/untrusted/nacl/getcwd.c.pathmax	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/native_client/src/untrusted/nacl/getcwd.c.pathmax	2018-03-21 01:06:50.000000000 +0300
@@ -0,0 +1,53 @@
+/*
+ * Copyright 2014 The Native Client Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+/*
+ * getcwd() implementation based on the lower level
+ * __getcwd_without_malloc().
+ */
+
+#include <errno.h>
+#include <limits.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+
+#include "native_client/src/untrusted/nacl/getcwd.h"
+
+char *getcwd(char *buffer, size_t len) {
+  int allocated = 0;
+  int do_realloc = 0;
+
+  /* If buffer is NULL, allocate a buffer. */
+  if (buffer == NULL) {
+    if (len == 0) {
+      len = PATH_MAX;
+      do_realloc = 1;
+    }
+
+    buffer = (char *) malloc(len);
+    if (buffer == NULL) {
+      errno = ENOMEM;
+      return NULL;
+    }
+    allocated = 1;
+  } else if (len == 0) {
+    /* Non-NULL buffer and zero size results in EINVAL */
+    errno = EINVAL;
+    return NULL;
+  }
+
+  char *rtn = __getcwd_without_malloc(buffer, len);
+  if (allocated) {
+    if (rtn == NULL) {
+      free(buffer);
+    } else if (do_realloc) {
+      rtn = (char *) realloc(rtn, strlen(rtn) + 1);
+    }
+  }
+
+  return rtn;
+}
diff -Naur chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/path.h chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/path.h
--- chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/path.h	2018-03-21 01:05:28.000000000 +0300
+++ chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/path.h	2018-04-27 11:31:20.467829570 +0300
@@ -12,6 +12,11 @@
 
 #include "sdk_util/macros.h"
 
+/* Needed for PATH_MAX */
+#ifndef PATH_MAX
+#define PATH_MAX 4096
+#endif
+
 namespace nacl_io {
 
 class Path {
diff -Naur chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/path.h.pathmax chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/path.h.pathmax
--- chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/path.h.pathmax	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/path.h.pathmax	2018-03-21 01:05:28.000000000 +0300
@@ -0,0 +1,64 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef LIBRARIES_NACL_IO_PATH_H_
+#define LIBRARIES_NACL_IO_PATH_H_
+
+#include <limits.h>
+
+#include <string>
+#include <vector>
+
+#include "sdk_util/macros.h"
+
+namespace nacl_io {
+
+class Path {
+ public:
+  Path();
+  Path(const Path& path);
+  explicit Path(const std::string& path);
+
+  // Return true of the first path item is '/'.
+  bool IsAbsolute() const;
+
+  // Return true if this is the root path (i.e. it has no parent)
+  bool IsRoot() const;
+
+  // Return a part of the path
+  std::string Part(size_t index) const;
+
+  // Return the number of path parts
+  size_t Size() const;
+
+  // Update the path.
+  Path& Append(const Path& path);
+  Path& Append(const std::string& path);
+  Path& Set(const std::string& path);
+  Path& MakeRelative();
+
+  // Return the parent path.
+  Path Parent() const;
+  std::string Basename() const;
+
+  std::string Join() const;
+  std::string Range(size_t start, size_t end) const;
+
+  // Operator versions
+  Path& operator=(const Path& p);
+  Path& operator=(const std::string& str);
+  bool operator==(const Path& other);
+  bool operator!=(const Path& other);
+
+ private:
+  // Collapse the string list removing extraneous '.', '..' path components
+  void Normalize();
+
+  size_t len_;
+  char path_[PATH_MAX];
+};
+
+}  // namespace nacl_io
+
+#endif  // PACKAGES_LIBRARIES_NACL_IO_PATH_H_
diff -Naur chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c
--- chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c	2018-03-21 01:05:28.000000000 +0300
+++ chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c	2018-04-27 11:31:20.471829529 +0300
@@ -13,6 +13,11 @@
 
 #include "sdk_util/macros.h"
 
+/* Needed for PATH_MAX */
+#ifndef PATH_MAX
+#define PATH_MAX 4096
+#endif
+
 EXTERN_C_BEGIN
 
 #if defined(__native_client__)
diff -Naur chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax
--- chromium-65.0.3325.181-orig/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/native_client_sdk/src/libraries/nacl_io/syscalls/realpath.c.pathmax	2018-03-21 01:05:28.000000000 +0300
@@ -0,0 +1,131 @@
+/* Copyright 2013 The Chromium Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file. */
+
+#include <assert.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <limits.h>
+#include <stdlib.h>
+#include <string.h>
+#include <sys/stat.h>
+#include <unistd.h>
+
+#include "sdk_util/macros.h"
+
+EXTERN_C_BEGIN
+
+#if defined(__native_client__)
+
+// TODO(binji): glibc has realpath, but it fails for all tests. Investigate.
+
+char* realpath(const char* path, char* resolved_path) {
+  if (path == NULL) {
+    errno = EINVAL;
+    return NULL;
+  }
+
+  int needs_free = 0;
+  if (resolved_path == NULL) {
+    resolved_path = (char*)malloc(PATH_MAX);
+    needs_free = 1;
+  }
+
+  struct stat statbuf;
+  const char* in = path;
+  char* out = resolved_path;
+  char* out_end = resolved_path + PATH_MAX - 1;
+  int done = 0;
+
+  *out = 0;
+
+  if (*in == '/') {
+    // Absolute path.
+    strcat(out, "/");
+    in++;
+    out++;
+  } else {
+    // Relative path.
+    if (getcwd(out, out_end - out) == NULL)
+      goto fail;
+
+    out += strlen(out);
+  }
+
+  if (stat(resolved_path, &statbuf) != 0)
+    goto fail;
+
+  while (!done) {
+    const char* next_slash = strchr(in, '/');
+    size_t namelen;
+    const char* next_in;
+    if (next_slash) {
+      namelen = next_slash - in;
+      next_in = next_slash + 1;
+    } else {
+      namelen = strlen(in);
+      next_in = in + namelen;  // Move to the '\0'
+      done = 1;
+    }
+
+    if (namelen == 0) {
+      // Empty name, do nothing.
+    } else if (namelen == 1 && strncmp(in, ".", 1) == 0) {
+      // Current directory, do nothing.
+    } else if (namelen == 2 && strncmp(in, "..", 2) == 0) {
+      // Parent directory, find previous slash in resolved_path.
+      char* prev_slash = strrchr(resolved_path, '/');
+      assert(prev_slash != NULL);
+
+      out = prev_slash;
+      if (prev_slash == resolved_path) {
+        // Moved to the root. Keep the slash.
+        ++out;
+      }
+
+      *out = 0;
+    } else {
+      // Append a slash if not at root.
+      if (out != resolved_path + 1) {
+        if (out + 1 > out_end) {
+          errno = ENAMETOOLONG;
+          goto fail;
+        }
+
+        strncat(out, "/", namelen);
+        out++;
+      }
+
+      if (out + namelen > out_end) {
+        errno = ENAMETOOLONG;
+        goto fail;
+      }
+
+      strncat(out, in, namelen);
+      out += namelen;
+    }
+
+    in = next_in;
+
+    if (stat(resolved_path, &statbuf) != 0)
+      goto fail;
+
+    // If there is more to the path, then the current path must be a directory.
+    if (!done && !S_ISDIR(statbuf.st_mode)) {
+      errno = ENOTDIR;
+      goto fail;
+    }
+  }
+
+  return resolved_path;
+
+fail:
+  if (needs_free) {
+    free(resolved_path);
+  }
+  return NULL;
+}
+
+EXTERN_C_END
+
+#endif  // defined(__native_client__)
diff -Naur chromium-65.0.3325.181-orig/printing/BUILD.gn chromium-65.0.3325.181.patched/printing/BUILD.gn
--- chromium-65.0.3325.181-orig/printing/BUILD.gn	2018-03-21 01:05:29.000000000 +0300
+++ chromium-65.0.3325.181.patched/printing/BUILD.gn	2018-04-27 11:31:20.483829403 +0300
@@ -150,12 +150,13 @@
                                  ],
                                  "trim string")
 
-      if (cups_version == "1.6" || cups_version == "1.7") {
+      if (cups_version == "1.6" || cups_version == "1.7" || cups_version == "2.2") {
         cflags += [
           # CUPS 1.6 deprecated the PPD APIs, but we will stay with this
           # API for now as supported Linux and Mac OS'es are still using
           # older versions of CUPS. More info: crbug.com/226176
           "-Wno-deprecated-declarations",
+          "-D_PPD_DEPRECATED=",
           # CUPS 1.7 deprecates httpConnectEncrypt(), see the mac section
           # below.
         ]
diff -Naur chromium-65.0.3325.181-orig/printing/BUILD.gn.cups22 chromium-65.0.3325.181.patched/printing/BUILD.gn.cups22
--- chromium-65.0.3325.181-orig/printing/BUILD.gn.cups22	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/printing/BUILD.gn.cups22	2018-03-21 01:05:29.000000000 +0300
@@ -0,0 +1,362 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/features.gni")
+import("//build/config/sysroot.gni")
+import("//build/config/ui.gni")
+import("//pdf/features.gni")
+import("//printing/features/features.gni")
+import("//testing/test.gni")
+if (is_mac) {
+  import("//build/config/mac/mac_sdk.gni")
+}
+if (is_android) {
+  import("//build/config/android/rules.gni")
+}
+
+if ((enable_basic_printing && is_win) || enable_print_preview) {
+  # Windows basic printing or print preview requires pdf enabled.
+  assert(enable_pdf,
+         "Windows basic printing or print preview needs pdf: " +
+             "set enable_pdf=true.")
+}
+
+component("printing") {
+  sources = [
+    "backend/print_backend.cc",
+    "backend/print_backend.h",
+    "backend/print_backend_consts.cc",
+    "backend/print_backend_consts.h",
+    "backend/print_backend_dummy.cc",
+    "backend/printing_info_win.cc",
+    "backend/printing_info_win.h",
+    "emf_win.cc",
+    "emf_win.h",
+    "metafile.cc",
+    "metafile.h",
+    "metafile_skia_wrapper.cc",
+    "metafile_skia_wrapper.h",
+    "native_drawing_context.h",
+    "page_number.cc",
+    "page_number.h",
+    "page_range.cc",
+    "page_range.h",
+    "page_setup.cc",
+    "page_setup.h",
+    "page_size_margins.h",
+    "pdf_metafile_cg_mac.cc",
+    "pdf_metafile_cg_mac.h",
+    "pdf_metafile_skia.cc",
+    "pdf_metafile_skia.h",
+    "pdf_render_settings.h",
+    "print_dialog_gtk_interface.h",
+    "print_job_constants.cc",
+    "print_job_constants.h",
+    "print_settings.cc",
+    "print_settings.h",
+    "print_settings_conversion.cc",
+    "print_settings_conversion.h",
+    "print_settings_initializer_mac.cc",
+    "print_settings_initializer_mac.h",
+    "print_settings_initializer_win.cc",
+    "print_settings_initializer_win.h",
+    "printed_document.cc",
+    "printed_document.h",
+    "printed_document_mac.cc",
+    "printed_document_win.cc",
+    "printing_context.cc",
+    "printing_context.h",
+    "printing_export.h",
+    "printing_utils.cc",
+    "printing_utils.h",
+    "pwg_raster_settings.h",
+    "units.cc",
+    "units.h",
+  ]
+
+  cflags = []
+  defines = [ "PRINTING_IMPLEMENTATION" ]
+
+  public_deps = [
+    "//printing/features",
+  ]
+  deps = [
+    "//base",
+    "//base:i18n",
+    "//base/third_party/dynamic_annotations",
+    "//cc/paint",
+    "//printing/common",
+    "//skia",
+    "//third_party/icu",
+    "//ui/gfx",
+    "//ui/gfx/geometry",
+    "//url",
+  ]
+
+  if (use_aura) {
+    deps += [ "//ui/aura" ]
+  }
+
+  if (is_mac) {
+    # Mac-Aura does not support printing.
+    if (use_aura) {
+      sources -= [ "printed_document_mac.cc" ]
+    } else {
+      sources += [
+        "printing_context_mac.h",
+        "printing_context_mac.mm",
+      ]
+    }
+    libs = [
+      "AppKit.framework",
+      "ApplicationServices.framework",
+      "CoreFoundation.framework",
+      "CoreGraphics.framework",
+    ]
+  }
+
+  if (is_win) {
+    # PRINT_BACKEND_AVAILABLE disables the default dummy implementation of the
+    # print backend and enables a custom implementation instead.
+    defines += [ "PRINT_BACKEND_AVAILABLE" ]
+    sources += [
+      "backend/print_backend_win.cc",
+      "backend/win_helper.cc",
+      "backend/win_helper.h",
+      "printed_page_win.cc",
+      "printed_page_win.h",
+      "printing_context_system_dialog_win.cc",
+      "printing_context_system_dialog_win.h",
+      "printing_context_win.cc",
+      "printing_context_win.h",
+    ]
+  }
+
+  if (use_cups) {
+    configs += [ ":cups" ]
+
+    if (is_linux) {
+      # rebase_path does not accept an empty string
+      if (use_sysroot) {
+        cups_sysroot = rebase_path(sysroot)
+      } else {
+        cups_sysroot = ""
+      }
+      cups_version = exec_script("cups_config_helper.py",
+                                 [
+                                   "--api-version",
+                                   cups_sysroot,
+                                 ],
+                                 "trim string")
+
+      if (cups_version == "1.6" || cups_version == "1.7") {
+        cflags += [
+          # CUPS 1.6 deprecated the PPD APIs, but we will stay with this
+          # API for now as supported Linux and Mac OS'es are still using
+          # older versions of CUPS. More info: crbug.com/226176
+          "-Wno-deprecated-declarations",
+          # CUPS 1.7 deprecates httpConnectEncrypt(), see the mac section
+          # below.
+        ]
+      }
+    }
+
+    if (is_mac) {
+      # The 10.9 SDK includes cups 1.7, which deprecates
+      # httpConnectEncrypt() in favor of httpConnect2(). hhttpConnect2()
+      # is new in 1.7, so it doesn't exist on OS X 10.6-10.8 and we
+      # can't use it until 10.9 is our minimum system version.
+      # (cups_version isn't reliable on OS X, so key the check off of
+      # mac_sdk).
+      # With a 10.8 deployment target, several other APIs are deprecated.
+      # We're still on CUPS 1.4 until Linux no longer needs to support it, see
+      # comment above.
+      cflags += [ "-Wno-deprecated-declarations" ]
+    }
+
+    # PRINT_BACKEND_AVAILABLE disables the default dummy implementation
+    # of the print backend and enables a custom implementation instead.
+    defines += [ "PRINT_BACKEND_AVAILABLE" ]
+
+    if (is_chromeos) {
+      sources += [
+        "backend/cups_connection.cc",
+        "backend/cups_connection.h",
+        "backend/cups_deleters.cc",
+        "backend/cups_deleters.h",
+        "backend/cups_ipp_util.cc",
+        "backend/cups_ipp_util.h",
+        "backend/cups_jobs.cc",
+        "backend/cups_jobs.h",
+        "backend/cups_printer.cc",
+        "backend/cups_printer.h",
+        "backend/print_backend_cups_ipp.cc",
+        "backend/print_backend_cups_ipp.h",
+        "printing_context_chromeos.cc",
+        "printing_context_chromeos.h",
+      ]
+    } else {
+      sources += [
+        "backend/cups_helper.cc",
+        "backend/cups_helper.h",
+        "backend/print_backend_cups.cc",
+        "backend/print_backend_cups.h",
+      ]
+    }
+  }
+
+  if (is_chromeos) {
+    defines += [ "PRINT_BACKEND_AVAILABLE" ]
+
+    sources += [
+      "backend/print_backend_chromeos.cc",
+      "printed_document_chromeos.cc",
+      "printing_context_no_system_dialog.cc",
+      "printing_context_no_system_dialog.h",
+    ]
+  } else if (is_android) {
+    sources += [
+      "printing_context_android.cc",
+      "printing_context_android.h",
+    ]
+
+    deps += [ ":printing_jni_headers" ]
+  } else if (is_linux) {  # Desktop Linux.
+    sources += [
+      "printed_document_linux.cc",
+      "printing_context_linux.cc",
+      "printing_context_linux.h",
+    ]
+  }
+
+  if (!is_android) {
+    sources += [
+      "pdf_transform.cc",
+      "pdf_transform.h",
+    ]
+  }
+}
+
+static_library("test_support") {
+  testonly = true
+  sources = [
+    "backend/test_print_backend.cc",
+    "backend/test_print_backend.h",
+    "image.cc",
+    "image.h",
+    "image_android.cc",
+    "image_linux.cc",
+    "image_mac.cc",
+    "image_win.cc",
+  ]
+  if (is_fuchsia) {
+    sources += [ "image_fuchsia.cc" ]
+  }
+
+  public_deps = [
+    "//printing",
+    "//ui/gfx/geometry",
+  ]
+  deps = [
+    "//base",
+    "//skia",
+    "//ui/gfx",
+  ]
+}
+
+test("printing_unittests") {
+  sources = [
+    "emf_win_unittest.cc",
+    "page_number_unittest.cc",
+    "page_range_unittest.cc",
+    "page_setup_unittest.cc",
+    "pdf_metafile_cg_mac_unittest.cc",
+    "printing_context_win_unittest.cc",
+    "printing_test.h",
+    "printing_utils_unittest.cc",
+    "units_unittest.cc",
+  ]
+
+  deps = [
+    ":printing",
+    "//base/test:run_all_unittests",
+    "//base/test:test_support",
+    "//testing/gtest",
+    "//ui/base",
+    "//ui/gfx",
+    "//ui/gfx:test_support",
+    "//ui/gfx/geometry",
+  ]
+
+  if (!is_android) {
+    sources += [ "pdf_transform_unittest.cc" ]
+  }
+
+  if (is_win || is_mac) {
+    sources += [ "printed_document_unittest.cc" ]
+  }
+
+  if (is_win) {
+    sources += [ "printed_page_win_unittest.cc" ]
+  }
+
+  if (use_cups) {
+    configs += [ ":cups" ]
+
+    if (is_chromeos) {
+      sources += [ "backend/cups_ipp_util_unittest.cc" ]
+    } else {
+      sources += [ "backend/cups_helper_unittest.cc" ]
+    }
+  }
+}
+
+if (use_cups) {
+  config("cups") {
+    defines = [ "USE_CUPS" ]
+
+    if (is_mac) {
+      libs = [ "cups" ]
+      lib_dirs = [ "$mac_sdk_path/usr/lib" ]
+    } else {
+      # rebase_path does not accept an empty string
+      if (use_sysroot) {
+        cups_sysroot = rebase_path(sysroot)
+      } else {
+        cups_sysroot = ""
+      }
+      libs = exec_script("cups_config_helper.py",
+                         [
+                           "--libs-for-gn",
+                           cups_sysroot,
+                         ],
+                         "value")
+    }
+  }
+}
+
+if (is_android) {
+  generate_jni("printing_jni_headers") {
+    sources = [
+      "android/java/src/org/chromium/printing/PrintingContext.java",
+    ]
+    jni_package = "printing"
+  }
+
+  android_library("printing_java") {
+    deps = [
+      "//base:base_java",
+    ]
+    java_files = [
+      "android/java/src/org/chromium/printing/PrintDocumentAdapterWrapper.java",
+      "android/java/src/org/chromium/printing/PrintManagerDelegate.java",
+      "android/java/src/org/chromium/printing/PrintManagerDelegateImpl.java",
+      "android/java/src/org/chromium/printing/Printable.java",
+      "android/java/src/org/chromium/printing/PrintingContext.java",
+      "android/java/src/org/chromium/printing/PrintingContextInterface.java",
+      "android/java/src/org/chromium/printing/PrintingController.java",
+      "android/java/src/org/chromium/printing/PrintingControllerImpl.java",
+    ]
+  }
+}
diff -Naur chromium-65.0.3325.181-orig/printing/backend/print_backend_cups.cc chromium-65.0.3325.181.patched/printing/backend/print_backend_cups.cc
--- chromium-65.0.3325.181-orig/printing/backend/print_backend_cups.cc	2018-03-21 01:05:29.000000000 +0300
+++ chromium-65.0.3325.181.patched/printing/backend/print_backend_cups.cc	2018-04-27 11:31:20.483829403 +0300
@@ -18,6 +18,7 @@
 #include "base/synchronization/lock.h"
 #include "base/values.h"
 #include "printing/backend/cups_helper.h"
+#include <cups/ppd.h>
 #include "printing/backend/print_backend_consts.h"
 #include "url/gurl.h"
 
diff -Naur chromium-65.0.3325.181-orig/printing/backend/print_backend_cups.cc.cups22 chromium-65.0.3325.181.patched/printing/backend/print_backend_cups.cc.cups22
--- chromium-65.0.3325.181-orig/printing/backend/print_backend_cups.cc.cups22	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/printing/backend/print_backend_cups.cc.cups22	2018-03-21 01:05:29.000000000 +0300
@@ -0,0 +1,286 @@
+// Copyright (c) 2012 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "printing/backend/print_backend_cups.h"
+
+#include <cups/ppd.h>
+#include <dlfcn.h>
+#include <errno.h>
+#include <pthread.h>
+
+#include <string>
+
+#include "base/files/file_util.h"
+#include "base/lazy_instance.h"
+#include "base/logging.h"
+#include "base/strings/string_number_conversions.h"
+#include "base/synchronization/lock.h"
+#include "base/values.h"
+#include "printing/backend/cups_helper.h"
+#include "printing/backend/print_backend_consts.h"
+#include "url/gurl.h"
+
+namespace printing {
+
+namespace {
+
+const char kCUPSPrinterInfoOpt[] = "printer-info";
+const char kCUPSPrinterStateOpt[] = "printer-state";
+const char kCUPSPrinterTypeOpt[] = "printer-type";
+
+bool PrinterBasicInfoFromCUPS(const cups_dest_t& printer,
+                              PrinterBasicInfo* printer_info) {
+  // CUPS can have 'printers' that are actually scanners. (not MFC)
+  // At least on Mac. Check for scanners and skip them.
+  const char* type_str =
+      cupsGetOption(kCUPSPrinterTypeOpt, printer.num_options, printer.options);
+  if (type_str) {
+    int type;
+    if (base::StringToInt(type_str, &type) && (type & CUPS_PRINTER_SCANNER))
+      return false;
+  }
+
+  printer_info->printer_name = printer.name;
+  printer_info->is_default = printer.is_default;
+
+  const char* info =
+      cupsGetOption(kCUPSPrinterInfoOpt, printer.num_options, printer.options);
+  if (info)
+    printer_info->printer_description = info;
+
+  const char* state =
+      cupsGetOption(kCUPSPrinterStateOpt, printer.num_options, printer.options);
+  if (state)
+    base::StringToInt(state, &printer_info->printer_status);
+
+  const char* drv_info = cupsGetOption(kDriverNameTagName,
+                                       printer.num_options, printer.options);
+  if (drv_info)
+    printer_info->options[kDriverInfoTagName] = *drv_info;
+
+  // Store printer options.
+  for (int opt_index = 0; opt_index < printer.num_options; ++opt_index) {
+    printer_info->options[printer.options[opt_index].name] =
+        printer.options[opt_index].value;
+  }
+  return true;
+}
+
+}  // namespace
+
+PrintBackendCUPS::PrintBackendCUPS(const GURL& print_server_url,
+                                   http_encryption_t encryption,
+                                   bool blocking)
+    : print_server_url_(print_server_url),
+      cups_encryption_(encryption),
+      blocking_(blocking) {
+}
+
+bool PrintBackendCUPS::EnumeratePrinters(PrinterList* printer_list) {
+  DCHECK(printer_list);
+  printer_list->clear();
+
+  cups_dest_t* destinations = nullptr;
+  int num_dests = GetDests(&destinations);
+  if (!num_dests && cupsLastError() > IPP_OK_EVENTS_COMPLETE) {
+    VLOG(1) << "CUPS: Error getting printers from CUPS server"
+            << ", server: " << print_server_url_
+            << ", error: " << static_cast<int>(cupsLastError());
+    return false;
+  }
+
+  for (int printer_index = 0; printer_index < num_dests; ++printer_index) {
+    const cups_dest_t& printer = destinations[printer_index];
+
+    PrinterBasicInfo printer_info;
+    if (PrinterBasicInfoFromCUPS(printer, &printer_info))
+      printer_list->push_back(printer_info);
+  }
+
+  cupsFreeDests(num_dests, destinations);
+
+  VLOG(1) << "CUPS: Enumerated printers, server: " << print_server_url_
+          << ", # of printers: " << printer_list->size();
+  return true;
+}
+
+std::string PrintBackendCUPS::GetDefaultPrinterName() {
+  // Not using cupsGetDefault() because it lies about the default printer.
+  cups_dest_t* dests;
+  int num_dests = GetDests(&dests);
+  cups_dest_t* dest = cupsGetDest(nullptr, nullptr, num_dests, dests);
+  std::string name = dest ? std::string(dest->name) : std::string();
+  cupsFreeDests(num_dests, dests);
+  return name;
+}
+
+bool PrintBackendCUPS::GetPrinterBasicInfo(const std::string& printer_name,
+                                           PrinterBasicInfo* printer_info) {
+  cups_dest_t* dest = GetNamedDest(printer_name);
+  if (!dest)
+    return false;
+
+  DCHECK_EQ(printer_name, dest->name);
+  bool ret = PrinterBasicInfoFromCUPS(*dest, printer_info);
+  cupsFreeDests(1, dest);
+  return ret;
+}
+
+bool PrintBackendCUPS::GetPrinterSemanticCapsAndDefaults(
+    const std::string& printer_name,
+    PrinterSemanticCapsAndDefaults* printer_info) {
+  PrinterCapsAndDefaults info;
+  if (!GetPrinterCapsAndDefaults(printer_name, &info) )
+    return false;
+
+  return ParsePpdCapabilities(
+      printer_name, info.printer_capabilities, printer_info);
+}
+
+bool PrintBackendCUPS::GetPrinterCapsAndDefaults(
+    const std::string& printer_name,
+    PrinterCapsAndDefaults* printer_info) {
+  DCHECK(printer_info);
+
+  VLOG(1) << "CUPS: Getting caps and defaults, printer name: " << printer_name;
+
+  base::FilePath ppd_path(GetPPD(printer_name.c_str()));
+  // In some cases CUPS failed to get ppd file.
+  if (ppd_path.empty()) {
+    LOG(ERROR) << "CUPS: Failed to get PPD, printer name: " << printer_name;
+    return false;
+  }
+
+  std::string content;
+  bool res = base::ReadFileToString(ppd_path, &content);
+
+  base::DeleteFile(ppd_path, false);
+
+  if (res) {
+    printer_info->printer_capabilities.swap(content);
+    printer_info->caps_mime_type = "application/pagemaker";
+    // In CUPS, printer defaults is a part of PPD file. Nothing to upload here.
+    printer_info->printer_defaults.clear();
+    printer_info->defaults_mime_type.clear();
+  }
+
+  return res;
+}
+
+std::string PrintBackendCUPS::GetPrinterDriverInfo(
+    const std::string& printer_name) {
+  std::string result;
+
+  cups_dest_t* dest = GetNamedDest(printer_name);
+  if (!dest)
+    return result;
+
+  DCHECK_EQ(printer_name, dest->name);
+  const char* info =
+      cupsGetOption(kDriverNameTagName, dest->num_options, dest->options);
+  if (info)
+    result = *info;
+  cupsFreeDests(1, dest);
+  return result;
+}
+
+bool PrintBackendCUPS::IsValidPrinter(const std::string& printer_name) {
+  cups_dest_t* dest = GetNamedDest(printer_name);
+  if (!dest)
+    return false;
+
+  cupsFreeDests(1, dest);
+  return true;
+}
+
+#if !defined(OS_CHROMEOS)
+scoped_refptr<PrintBackend> PrintBackend::CreateInstanceImpl(
+    const base::DictionaryValue* print_backend_settings) {
+  std::string print_server_url_str, cups_blocking;
+  int encryption = HTTP_ENCRYPT_NEVER;
+  if (print_backend_settings) {
+    print_backend_settings->GetString(kCUPSPrintServerURL,
+                                      &print_server_url_str);
+
+    print_backend_settings->GetString(kCUPSBlocking,
+                                      &cups_blocking);
+
+    print_backend_settings->GetInteger(kCUPSEncryption, &encryption);
+  }
+  GURL print_server_url(print_server_url_str);
+  return new PrintBackendCUPS(print_server_url,
+                              static_cast<http_encryption_t>(encryption),
+                              cups_blocking == kValueTrue);
+}
+#endif  // !defined(OS_CHROMEOS)
+
+int PrintBackendCUPS::GetDests(cups_dest_t** dests) {
+  if (print_server_url_.is_empty())  // Use default (local) print server.
+    return cupsGetDests(dests);
+
+  HttpConnectionCUPS http(print_server_url_, cups_encryption_);
+  http.SetBlocking(blocking_);
+  return cupsGetDests2(http.http(), dests);
+}
+
+base::FilePath PrintBackendCUPS::GetPPD(const char* name) {
+  // cupsGetPPD returns a filename stored in a static buffer in CUPS.
+  // Protect this code with lock.
+  CR_DEFINE_STATIC_LOCAL(base::Lock, ppd_lock, ());
+  base::AutoLock ppd_autolock(ppd_lock);
+  base::FilePath ppd_path;
+  const char* ppd_file_path = nullptr;
+  if (print_server_url_.is_empty()) {  // Use default (local) print server.
+    ppd_file_path = cupsGetPPD(name);
+    if (ppd_file_path)
+      ppd_path = base::FilePath(ppd_file_path);
+  } else {
+    // cupsGetPPD2 gets stuck sometimes in an infinite time due to network
+    // configuration/issues. To prevent that, use non-blocking http connection
+    // here.
+    // Note: After looking at CUPS sources, it looks like non-blocking
+    // connection will timeout after 10 seconds of no data period. And it will
+    // return the same way as if data was completely and successfully
+    // downloaded.
+    HttpConnectionCUPS http(print_server_url_, cups_encryption_);
+    http.SetBlocking(blocking_);
+    ppd_file_path = cupsGetPPD2(http.http(), name);
+    // Check if the get full PPD, since non-blocking call may simply return
+    // normally after timeout expired.
+    if (ppd_file_path) {
+      // There is no reliable way right now to detect full and complete PPD
+      // get downloaded. If we reach http timeout, it may simply return
+      // downloaded part as a full response. It might be good enough to check
+      // http->data_remaining or http->_data_remaining, unfortunately http_t
+      // is an internal structure and fields are not exposed in CUPS headers.
+      // httpGetLength or httpGetLength2 returning the full content size.
+      // Comparing file size against that content length might be unreliable
+      // since some http reponses are encoded and content_length > file size.
+      // Let's just check for the obvious CUPS and http errors here.
+      ppd_path = base::FilePath(ppd_file_path);
+      ipp_status_t error_code = cupsLastError();
+      int http_error = httpError(http.http());
+      if (error_code > IPP_OK_EVENTS_COMPLETE || http_error != 0) {
+        LOG(ERROR) << "Error downloading PPD file, name: " << name
+                   << ", CUPS error: " << static_cast<int>(error_code)
+                   << ", HTTP error: " << http_error;
+        base::DeleteFile(ppd_path, false);
+        ppd_path.clear();
+      }
+    }
+  }
+  return ppd_path;
+}
+
+cups_dest_t* PrintBackendCUPS::GetNamedDest(const std::string& printer_name) {
+  // Use default (local) print server.
+  if (print_server_url_.is_empty())
+    return cupsGetNamedDest(CUPS_HTTP_DEFAULT, printer_name.c_str(), nullptr);
+
+  HttpConnectionCUPS http(print_server_url_, cups_encryption_);
+  http.SetBlocking(blocking_);
+  return cupsGetNamedDest(http.http(), printer_name.c_str(), nullptr);
+}
+
+}  // namespace printing
diff -Naur chromium-65.0.3325.181-orig/remoting/host/linux/BUILD.gn chromium-65.0.3325.181.patched/remoting/host/linux/BUILD.gn
--- chromium-65.0.3325.181-orig/remoting/host/linux/BUILD.gn	2018-03-21 01:05:29.000000000 +0300
+++ chromium-65.0.3325.181.patched/remoting/host/linux/BUILD.gn	2018-04-27 11:31:20.595828225 +0300
@@ -62,11 +62,9 @@
     if (is_component_build) {
       sources += [
         "$root_build_dir/libbase.so",
-        "$root_build_dir/libc++.so",
       ]
       deps += [
         "//base:base",
-        "//buildtools/third_party/libc++:libc++",
       ]
     }
   }
diff -Naur chromium-65.0.3325.181-orig/remoting/host/linux/BUILD.gn.nolibc++ chromium-65.0.3325.181.patched/remoting/host/linux/BUILD.gn.nolibc++
--- chromium-65.0.3325.181-orig/remoting/host/linux/BUILD.gn.nolibc++	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/remoting/host/linux/BUILD.gn.nolibc++	2018-03-21 01:05:29.000000000 +0300
@@ -0,0 +1,188 @@
+# Copyright 2016 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//remoting/build/config/remoting_build.gni")
+
+group("all_tests") {
+  testonly = true
+}
+
+if (enable_me2me_host) {
+  executable("remoting_user_session") {
+    sources = [
+      "remoting_user_session.cc",
+    ]
+
+    deps = [
+      "//base",
+      "//build/config:exe_and_shlib_deps",
+    ]
+
+    libs = [ "pam" ]
+  }
+
+  copy("remoting_me2me_host_copy_script") {
+    sources = [
+      "linux_me2me_host.py",
+    ]
+    outputs = [
+      "$root_build_dir/remoting/chrome-remote-desktop",
+    ]
+  }
+
+  copy("remoting_me2me_host_copy_host_wrapper") {
+    sources = [
+      "remoting_me2me_host_wrapper.sh",
+    ]
+    outputs = [
+      "$root_build_dir/remoting/chrome-remote-desktop-host",
+    ]
+  }
+
+  copy("remoting_me2me_host_copy_user_session_wrapper") {
+    sources = [
+      "remoting_user_session_wrapper.sh",
+    ]
+    outputs = [
+      "$root_build_dir/remoting/user-session",
+    ]
+  }
+
+  copy("remoting_me2me_host_copy_user_session") {
+    sources = [
+      "$root_build_dir/remoting_user_session",
+    ]
+    outputs = [
+      "$root_build_dir/remoting/{{source_file_part}}",
+    ]
+    deps = [
+      ":remoting_user_session",
+    ]
+    if (is_component_build) {
+      sources += [
+        "$root_build_dir/libbase.so",
+        "$root_build_dir/libc++.so",
+      ]
+      deps += [
+        "//base:base",
+        "//buildtools/third_party/libc++:libc++",
+      ]
+    }
+  }
+
+  group("remoting_dev_me2me_host") {
+    deps = [
+      ":remoting_me2me_host_copy_host_wrapper",
+      ":remoting_me2me_host_copy_script",
+      ":remoting_me2me_host_copy_user_session",
+      ":remoting_me2me_host_copy_user_session_wrapper",
+      ":remoting_native_messaging_host",
+      "//remoting/host:remoting_me2me_host",
+    ]
+  }
+}
+
+source_set("linux") {
+  sources = [
+    "audio_pipe_reader.cc",
+    "audio_pipe_reader.h",
+    "certificate_watcher.cc",
+    "certificate_watcher.h",
+  ]
+
+  deps = [
+    "//remoting/protocol",
+    "//third_party/webrtc/modules/desktop_capture",
+  ]
+  public_deps = []
+
+  if (use_x11) {
+    deps += [ ":x11" ]
+  }
+  if (is_desktop_linux) {
+    deps += [ "//build/config/linux/gtk" ]
+  }
+}
+
+source_set("x11") {
+  sources = [
+    "unicode_to_keysym.cc",
+    "unicode_to_keysym.h",
+    "x11_character_injector.cc",
+    "x11_character_injector.h",
+    "x11_keyboard_impl.cc",
+    "x11_keyboard_impl.h",
+    "x11_util.cc",
+    "x11_util.h",
+    "x_server_clipboard.cc",
+    "x_server_clipboard.h",
+  ]
+  deps = [
+    "//third_party/webrtc/modules/desktop_capture",
+  ]
+}
+
+executable("remoting_native_messaging_host") {
+  configs += [ "//build/config/compiler:wexit_time_destructors" ]
+
+  sources = [
+    "//remoting/host/setup/me2me_native_messaging_host_entry_point.cc",
+    "//remoting/host/setup/me2me_native_messaging_host_main.cc",
+    "//remoting/host/setup/me2me_native_messaging_host_main.h",
+  ]
+
+  deps = [
+    "//base",
+    "//build/config:exe_and_shlib_deps",
+    "//net",
+    "//remoting/base:breakpad",
+    "//remoting/host",
+    "//remoting/host:remoting_infoplist_strings",
+    "//remoting/host/native_messaging",
+    "//remoting/host/setup",
+  ]
+
+  # The |major|, |build| and |patch| versions are inherited from Chrome.
+  # Since Chrome's |minor| version is always '0', we replace it with a
+  # Chromoting-specific patch version.
+  defines =
+      [ "VERSION=" + "$chrome_version_major" + "." + "$remoting_version_patch" +
+        "." + "$chrome_version_build" + "." + "$chrome_version_patch" ]
+}
+
+source_set("unit_tests") {
+  testonly = true
+
+  sources = [
+    "audio_pipe_reader_unittest.cc",
+    "certificate_watcher_unittest.cc",
+    "unicode_to_keysym_unittest.cc",
+    "x11_character_injector_unittest.cc",
+    "x_server_clipboard_unittest.cc",
+  ]
+
+  if (!use_x11) {
+    sources -= [ "unicode_to_keysym_unittest.cc" ]
+  }
+
+  configs += [ "//remoting/build/config:version" ]
+
+  deps = [
+    "//remoting/host",
+    "//remoting/host:test_support",
+    "//remoting/host/it2me:common",
+    "//remoting/host/native_messaging",
+    "//remoting/host/security_key:unit_tests",
+    "//remoting/host/setup",
+    "//remoting/proto",
+    "//remoting/resources",
+    "//skia",
+    "//testing/gmock",
+    "//testing/gtest",
+  ]
+
+  if (!is_ios) {
+    deps += [ "//components/policy/core/browser:test_support" ]
+  }
+}
diff -Naur chromium-65.0.3325.181-orig/sandbox/linux/BUILD.gn chromium-65.0.3325.181.patched/sandbox/linux/BUILD.gn
--- chromium-65.0.3325.181-orig/sandbox/linux/BUILD.gn	2018-03-21 01:05:29.000000000 +0300
+++ chromium-65.0.3325.181.patched/sandbox/linux/BUILD.gn	2018-04-27 11:31:20.483829403 +0300
@@ -312,11 +312,17 @@
       # For ULLONG_MAX
       "-std=gnu99",
 
+      "-fPIE",
+
       # These files have a suspicious comparison.
       # TODO fix this and re-enable this warning.
       "-Wno-sign-compare",
     ]
 
+    ldflags = [
+      "-pie",
+    ]
+
     import("//build/config/compiler/compiler.gni")
     import("//build/config/sanitizers/sanitizers.gni")
     if (is_component_build || using_sanitizer) {
@@ -326,7 +332,7 @@
       # other flags that executable_config might have.
       configs -= [ "//build/config:executable_config" ]
       if (!use_gold) {
-        ldflags = [ "-Wl,--disable-new-dtags" ]
+        ldflags += [ "-Wl,--disable-new-dtags" ]
       }
     }
 
diff -Naur chromium-65.0.3325.181-orig/sandbox/linux/BUILD.gn.sandboxpie chromium-65.0.3325.181.patched/sandbox/linux/BUILD.gn.sandboxpie
--- chromium-65.0.3325.181-orig/sandbox/linux/BUILD.gn.sandboxpie	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/sandbox/linux/BUILD.gn.sandboxpie	2018-03-21 01:05:29.000000000 +0300
@@ -0,0 +1,477 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/features.gni")
+import("//build/config/nacl/config.gni")
+import("//sandbox/features.gni")
+import("//testing/test.gni")
+
+if (is_android) {
+  import("//build/config/android/rules.gni")
+}
+
+declare_args() {
+  compile_suid_client = is_linux
+
+  compile_credentials = is_linux
+
+  # On Android, use plain GTest.
+  use_base_test_suite = is_linux
+}
+
+if (is_nacl_nonsfi) {
+  config("nacl_nonsfi_warnings") {
+    # There are number of platform specific functions in
+    # seccomp-bpf syscall helpers, which are not being used.
+    cflags = [ "-Wno-unused-function" ]
+  }
+}
+
+# We have two principal targets: sandbox and sandbox_linux_unittests
+# All other targets are listed as dependencies.
+# There is one notable exception: for historical reasons, chrome_sandbox is
+# the setuid sandbox and is its own target.
+
+group("sandbox") {
+  public_deps = [
+    ":sandbox_services",
+  ]
+
+  if (compile_suid_client || is_nacl_nonsfi) {
+    public_deps += [ ":suid_sandbox_client" ]
+  }
+  if (use_seccomp_bpf || is_nacl_nonsfi) {
+    public_deps += [ ":seccomp_bpf" ]
+  }
+  if (is_android) {
+    public_deps += [ ":seccomp_starter_android" ]
+  }
+}
+
+source_set("sandbox_linux_test_utils") {
+  testonly = true
+  sources = [
+    "tests/sandbox_test_runner.cc",
+    "tests/sandbox_test_runner.h",
+    "tests/sandbox_test_runner_function_pointer.cc",
+    "tests/sandbox_test_runner_function_pointer.h",
+    "tests/unit_tests.cc",
+    "tests/unit_tests.h",
+  ]
+
+  deps = [
+    "//testing/gtest",
+  ]
+
+  if (!is_nacl_nonsfi) {
+    sources += [
+      "tests/test_utils.cc",
+      "tests/test_utils.h",
+    ]
+  }
+
+  if (use_seccomp_bpf || is_nacl_nonsfi) {
+    sources += [
+      "seccomp-bpf/bpf_tester_compatibility_delegate.h",
+      "seccomp-bpf/bpf_tests.h",
+      "seccomp-bpf/sandbox_bpf_test_runner.cc",
+      "seccomp-bpf/sandbox_bpf_test_runner.h",
+    ]
+    deps += [ ":seccomp_bpf" ]
+  }
+
+  if (use_base_test_suite) {
+    deps += [ "//base/test:test_support" ]
+    defines = [ "SANDBOX_USES_BASE_TEST_SUITE" ]
+  }
+}
+
+# Sources for sandbox_linux_unittests.
+source_set("sandbox_linux_unittests_sources") {
+  testonly = true
+
+  sources = [
+    "services/proc_util_unittest.cc",
+    "services/resource_limits_unittests.cc",
+    "services/scoped_process_unittest.cc",
+    "services/syscall_wrappers_unittest.cc",
+    "services/thread_helpers_unittests.cc",
+    "services/yama_unittests.cc",
+    "syscall_broker/broker_file_permission_unittest.cc",
+    "syscall_broker/broker_process_unittest.cc",
+    "tests/main.cc",
+    "tests/scoped_temporary_file.cc",
+    "tests/scoped_temporary_file.h",
+    "tests/scoped_temporary_file_unittest.cc",
+    "tests/test_utils_unittest.cc",
+    "tests/unit_tests_unittest.cc",
+  ]
+
+  deps = [
+    ":sandbox",
+    ":sandbox_linux_test_utils",
+    "//base",
+    "//base/third_party/dynamic_annotations",
+    "//testing/gtest",
+  ]
+
+  if (use_base_test_suite) {
+    deps += [ "//base/test:test_support" ]
+    defines = [ "SANDBOX_USES_BASE_TEST_SUITE" ]
+  }
+
+  if (compile_suid_client) {
+    sources += [
+      "suid/client/setuid_sandbox_client_unittest.cc",
+      "suid/client/setuid_sandbox_host_unittest.cc",
+    ]
+  }
+  if (use_seccomp_bpf) {
+    sources += [
+      "bpf_dsl/bpf_dsl_unittest.cc",
+      "bpf_dsl/codegen_unittest.cc",
+      "bpf_dsl/cons_unittest.cc",
+      "bpf_dsl/dump_bpf.cc",
+      "bpf_dsl/dump_bpf.h",
+      "bpf_dsl/syscall_set_unittest.cc",
+      "bpf_dsl/test_trap_registry.cc",
+      "bpf_dsl/test_trap_registry.h",
+      "bpf_dsl/test_trap_registry_unittest.cc",
+      "bpf_dsl/verifier.cc",
+      "bpf_dsl/verifier.h",
+      "integration_tests/bpf_dsl_seccomp_unittest.cc",
+      "integration_tests/seccomp_broker_process_unittest.cc",
+      "seccomp-bpf-helpers/baseline_policy_unittest.cc",
+      "seccomp-bpf-helpers/syscall_parameters_restrictions_unittests.cc",
+      "seccomp-bpf/bpf_tests_unittest.cc",
+      "seccomp-bpf/sandbox_bpf_unittest.cc",
+      "seccomp-bpf/syscall_unittest.cc",
+      "seccomp-bpf/trap_unittest.cc",
+    ]
+    deps += [ ":bpf_dsl_golden" ]
+  }
+  if (compile_credentials) {
+    sources += [
+      "integration_tests/namespace_unix_domain_socket_unittest.cc",
+      "services/credentials_unittest.cc",
+      "services/namespace_utils_unittest.cc",
+    ]
+
+    if (use_base_test_suite) {
+      # Tests that use advanced features not available in stock GTest.
+      sources += [ "services/namespace_sandbox_unittest.cc" ]
+    }
+
+    # For credentials_unittest.cc
+    configs += [ "//build/config/linux:libcap" ]
+  }
+}
+
+action("bpf_dsl_golden") {
+  script = "bpf_dsl/golden/generate.py"
+  inputs = [
+    "bpf_dsl/golden/i386/ArgSizePolicy.txt",
+    "bpf_dsl/golden/i386/BasicPolicy.txt",
+    "bpf_dsl/golden/i386/ElseIfPolicy.txt",
+    "bpf_dsl/golden/i386/MaskingPolicy.txt",
+    "bpf_dsl/golden/i386/MoreBooleanLogicPolicy.txt",
+    "bpf_dsl/golden/i386/NegativeConstantsPolicy.txt",
+    "bpf_dsl/golden/i386/SwitchPolicy.txt",
+    "bpf_dsl/golden/x86-64/ArgSizePolicy.txt",
+    "bpf_dsl/golden/x86-64/BasicPolicy.txt",
+    "bpf_dsl/golden/x86-64/BooleanLogicPolicy.txt",
+    "bpf_dsl/golden/x86-64/ElseIfPolicy.txt",
+    "bpf_dsl/golden/x86-64/MaskingPolicy.txt",
+    "bpf_dsl/golden/x86-64/MoreBooleanLogicPolicy.txt",
+    "bpf_dsl/golden/x86-64/NegativeConstantsPolicy.txt",
+    "bpf_dsl/golden/x86-64/SwitchPolicy.txt",
+  ]
+  outputs = [
+    "$target_gen_dir/bpf_dsl/golden/golden_files.h",
+  ]
+  args =
+      rebase_path(outputs, root_build_dir) + rebase_path(inputs, root_build_dir)
+}
+
+test("sandbox_linux_unittests") {
+  deps = [
+    ":sandbox_linux_unittests_sources",
+    "//build/config:exe_and_shlib_deps",
+  ]
+  if (is_android) {
+    use_raw_android_executable = true
+  }
+}
+
+component("seccomp_bpf") {
+  sources = [
+    "bpf_dsl/bpf_dsl.cc",
+    "bpf_dsl/bpf_dsl.h",
+    "bpf_dsl/bpf_dsl_forward.h",
+    "bpf_dsl/bpf_dsl_impl.h",
+    "bpf_dsl/codegen.cc",
+    "bpf_dsl/codegen.h",
+    "bpf_dsl/cons.h",
+    "bpf_dsl/errorcode.h",
+    "bpf_dsl/linux_syscall_ranges.h",
+    "bpf_dsl/policy.cc",
+    "bpf_dsl/policy.h",
+    "bpf_dsl/policy_compiler.cc",
+    "bpf_dsl/policy_compiler.h",
+    "bpf_dsl/seccomp_macros.h",
+    "bpf_dsl/syscall_set.cc",
+    "bpf_dsl/syscall_set.h",
+    "bpf_dsl/trap_registry.h",
+    "seccomp-bpf-helpers/baseline_policy.cc",
+    "seccomp-bpf-helpers/baseline_policy.h",
+    "seccomp-bpf-helpers/baseline_policy_android.cc",
+    "seccomp-bpf-helpers/baseline_policy_android.h",
+    "seccomp-bpf-helpers/sigsys_handlers.cc",
+    "seccomp-bpf-helpers/sigsys_handlers.h",
+    "seccomp-bpf-helpers/syscall_parameters_restrictions.cc",
+    "seccomp-bpf-helpers/syscall_parameters_restrictions.h",
+    "seccomp-bpf-helpers/syscall_sets.cc",
+    "seccomp-bpf-helpers/syscall_sets.h",
+    "seccomp-bpf/die.cc",
+    "seccomp-bpf/die.h",
+    "seccomp-bpf/sandbox_bpf.cc",
+    "seccomp-bpf/sandbox_bpf.h",
+    "seccomp-bpf/syscall.cc",
+    "seccomp-bpf/syscall.h",
+    "seccomp-bpf/trap.cc",
+    "seccomp-bpf/trap.h",
+  ]
+  defines = [ "SANDBOX_IMPLEMENTATION" ]
+
+  public_deps = [
+    ":sandbox_services_headers",
+    "//sandbox:sandbox_export",
+  ]
+  deps = [
+    ":sandbox_services",
+    "//base",
+    "//base/third_party/dynamic_annotations",
+  ]
+
+  if (is_nacl_nonsfi) {
+    cflags = [ "-fgnu-inline-asm" ]
+    sources -= [
+      "bpf_dsl/bpf_dsl_forward.h",
+      "bpf_dsl/bpf_dsl_impl.h",
+      "bpf_dsl/cons.h",
+      "bpf_dsl/errorcode.h",
+      "bpf_dsl/linux_syscall_ranges.h",
+      "bpf_dsl/seccomp_macros.h",
+      "bpf_dsl/trap_registry.h",
+      "seccomp-bpf-helpers/baseline_policy.cc",
+      "seccomp-bpf-helpers/baseline_policy.h",
+      "seccomp-bpf-helpers/syscall_sets.cc",
+      "seccomp-bpf-helpers/syscall_sets.h",
+    ]
+    configs += [ ":nacl_nonsfi_warnings" ]
+  }
+}
+
+if (is_android) {
+  # This target is available even if use_seccomp_bpf is disabled, but it also
+  # works when it is enabled.
+  component("seccomp_starter_android") {
+    sources = [
+      "seccomp-bpf-helpers/seccomp_starter_android.cc",
+      "seccomp-bpf-helpers/seccomp_starter_android.h",
+    ]
+
+    defines = [ "SANDBOX_IMPLEMENTATION" ]
+
+    deps = [
+      "//base",
+      "//sandbox:sandbox_features",
+    ]
+
+    if (use_seccomp_bpf) {
+      deps += [ ":seccomp_bpf" ]
+    }
+
+    visibility = [ ":*" ]
+  }
+}
+
+if (is_linux) {
+  # The setuid sandbox for Linux.
+  executable("chrome_sandbox") {
+    sources = [
+      "suid/common/sandbox.h",
+      "suid/common/suid_unsafe_environment_variables.h",
+      "suid/process_util.h",
+      "suid/process_util_linux.c",
+      "suid/sandbox.c",
+    ]
+
+    cflags = [
+      # For ULLONG_MAX
+      "-std=gnu99",
+
+      # These files have a suspicious comparison.
+      # TODO fix this and re-enable this warning.
+      "-Wno-sign-compare",
+    ]
+
+    import("//build/config/compiler/compiler.gni")
+    import("//build/config/sanitizers/sanitizers.gni")
+    if (is_component_build || using_sanitizer) {
+      # WARNING! We remove this config so that we don't accidentally
+      # pick up the //build/config:rpath_for_built_shared_libraries
+      # sub-config. However, this means that we need to duplicate any
+      # other flags that executable_config might have.
+      configs -= [ "//build/config:executable_config" ]
+      if (!use_gold) {
+        ldflags = [ "-Wl,--disable-new-dtags" ]
+      }
+    }
+
+    # We also do not want to pick up any of the other sanitizer
+    # flags (i.e. we do not want to build w/ the sanitizers at all).
+    # This is safe to delete unconditionally, because it is part of the
+    # default configs and empty when not using the sanitizers.
+    configs -= [ "//build/config/sanitizers:default_sanitizer_flags" ]
+  }
+}
+
+component("sandbox_services") {
+  sources = [
+    "services/init_process_reaper.cc",
+    "services/init_process_reaper.h",
+    "services/proc_util.cc",
+    "services/proc_util.h",
+    "services/resource_limits.cc",
+    "services/resource_limits.h",
+    "services/scoped_process.cc",
+    "services/scoped_process.h",
+    "services/syscall_wrappers.cc",
+    "services/syscall_wrappers.h",
+    "services/thread_helpers.cc",
+    "services/thread_helpers.h",
+    "services/yama.cc",
+    "services/yama.h",
+    "syscall_broker/broker_channel.cc",
+    "syscall_broker/broker_channel.h",
+    "syscall_broker/broker_client.cc",
+    "syscall_broker/broker_client.h",
+    "syscall_broker/broker_command.cc",
+    "syscall_broker/broker_command.h",
+    "syscall_broker/broker_file_permission.cc",
+    "syscall_broker/broker_file_permission.h",
+    "syscall_broker/broker_host.cc",
+    "syscall_broker/broker_host.h",
+    "syscall_broker/broker_permission_list.cc",
+    "syscall_broker/broker_permission_list.h",
+    "syscall_broker/broker_process.cc",
+    "syscall_broker/broker_process.h",
+  ]
+
+  defines = [ "SANDBOX_IMPLEMENTATION" ]
+
+  public_deps = [
+    "//sandbox:sandbox_export",
+  ]
+  deps = [
+    "//base",
+    "//base/third_party/dynamic_annotations",
+  ]
+
+  if (compile_credentials || is_nacl_nonsfi) {
+    sources += [
+      "services/credentials.cc",
+      "services/credentials.h",
+      "services/namespace_sandbox.cc",
+      "services/namespace_sandbox.h",
+      "services/namespace_utils.cc",
+      "services/namespace_utils.h",
+    ]
+
+    public_deps += [ ":sandbox_services_headers" ]
+  }
+
+  if (is_nacl_nonsfi) {
+    cflags = [ "-fgnu-inline-asm" ]
+
+    sources -= [
+      "services/init_process_reaper.cc",
+      "services/init_process_reaper.h",
+      "services/scoped_process.cc",
+      "services/scoped_process.h",
+      "services/yama.cc",
+      "services/yama.h",
+      "syscall_broker/broker_channel.cc",
+      "syscall_broker/broker_channel.h",
+      "syscall_broker/broker_client.cc",
+      "syscall_broker/broker_client.h",
+      "syscall_broker/broker_command.cc",
+      "syscall_broker/broker_command.h",
+      "syscall_broker/broker_file_permission.cc",
+      "syscall_broker/broker_file_permission.h",
+      "syscall_broker/broker_host.cc",
+      "syscall_broker/broker_host.h",
+      "syscall_broker/broker_permission_list.cc",
+      "syscall_broker/broker_permission_list.h",
+      "syscall_broker/broker_process.cc",
+      "syscall_broker/broker_process.h",
+    ]
+  }
+}
+
+source_set("sandbox_services_headers") {
+  sources = [
+    "system_headers/arm64_linux_syscalls.h",
+    "system_headers/arm64_linux_ucontext.h",
+    "system_headers/arm_linux_syscalls.h",
+    "system_headers/arm_linux_ucontext.h",
+    "system_headers/i386_linux_ucontext.h",
+    "system_headers/linux_filter.h",
+    "system_headers/linux_futex.h",
+    "system_headers/linux_seccomp.h",
+    "system_headers/linux_signal.h",
+    "system_headers/linux_syscalls.h",
+    "system_headers/linux_time.h",
+    "system_headers/linux_ucontext.h",
+    "system_headers/mips64_linux_syscalls.h",
+    "system_headers/mips64_linux_ucontext.h",
+    "system_headers/mips_linux_syscalls.h",
+    "system_headers/mips_linux_ucontext.h",
+    "system_headers/x86_32_linux_syscalls.h",
+    "system_headers/x86_64_linux_syscalls.h",
+    "system_headers/x86_64_linux_ucontext.h",
+  ]
+}
+
+if (compile_suid_client || is_nacl_nonsfi) {
+  component("suid_sandbox_client") {
+    sources = [
+      "suid/client/setuid_sandbox_client.cc",
+      "suid/client/setuid_sandbox_client.h",
+      "suid/client/setuid_sandbox_host.cc",
+      "suid/client/setuid_sandbox_host.h",
+      "suid/common/sandbox.h",
+      "suid/common/suid_unsafe_environment_variables.h",
+    ]
+    defines = [ "SANDBOX_IMPLEMENTATION" ]
+    public_deps = [
+      "//sandbox:sandbox_export",
+    ]
+    deps = [
+      ":sandbox_services",
+      "//base",
+      "//base/third_party/dynamic_annotations",
+    ]
+
+    if (is_nacl_nonsfi) {
+      sources -= [
+        "suid/client/setuid_sandbox_host.cc",
+        "suid/client/setuid_sandbox_host.h",
+        "suid/common/sandbox.h",
+        "suid/common/suid_unsafe_environment_variables.h",
+      ]
+    }
+  }
+}
diff -Naur chromium-65.0.3325.181-orig/services/preferences/tracked/pref_hash_filter.h chromium-65.0.3325.181.patched/services/preferences/tracked/pref_hash_filter.h
--- chromium-65.0.3325.181-orig/services/preferences/tracked/pref_hash_filter.h	2018-03-21 01:05:30.000000000 +0300
+++ chromium-65.0.3325.181.patched/services/preferences/tracked/pref_hash_filter.h	2018-04-27 11:31:20.615828015 +0300
@@ -21,9 +21,9 @@
 #include "services/preferences/public/interfaces/preferences.mojom.h"
 #include "services/preferences/tracked/hash_store_contents.h"
 #include "services/preferences/tracked/interceptable_pref_filter.h"
+#include "services/preferences/tracked/pref_hash_store.h"
 #include "services/preferences/tracked/tracked_preference.h"
 
-class PrefHashStore;
 class PrefService;
 
 namespace base {
diff -Naur chromium-65.0.3325.181-orig/services/preferences/tracked/pref_hash_filter.h.fulldecl chromium-65.0.3325.181.patched/services/preferences/tracked/pref_hash_filter.h.fulldecl
--- chromium-65.0.3325.181-orig/services/preferences/tracked/pref_hash_filter.h.fulldecl	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/services/preferences/tracked/pref_hash_filter.h.fulldecl	2018-03-21 01:05:30.000000000 +0300
@@ -0,0 +1,159 @@
+// Copyright 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef SERVICES_PREFERENCES_TRACKED_PREF_HASH_FILTER_H_
+#define SERVICES_PREFERENCES_TRACKED_PREF_HASH_FILTER_H_
+
+#include <stddef.h>
+
+#include <map>
+#include <memory>
+#include <set>
+#include <unordered_map>
+#include <vector>
+
+#include "base/callback.h"
+#include "base/compiler_specific.h"
+#include "base/files/file_path.h"
+#include "base/macros.h"
+#include "base/optional.h"
+#include "services/preferences/public/interfaces/preferences.mojom.h"
+#include "services/preferences/tracked/hash_store_contents.h"
+#include "services/preferences/tracked/interceptable_pref_filter.h"
+#include "services/preferences/tracked/tracked_preference.h"
+
+class PrefHashStore;
+class PrefService;
+
+namespace base {
+class DictionaryValue;
+class Time;
+}  // namespace base
+
+namespace prefs {
+namespace mojom {
+class TrackedPreferenceValidationDelegate;
+}
+}
+
+namespace user_prefs {
+class PrefRegistrySyncable;
+}  // namespace user_prefs
+
+// Intercepts preference values as they are loaded from disk and verifies them
+// using a PrefHashStore. Keeps the PrefHashStore contents up to date as values
+// are changed.
+class PrefHashFilter : public InterceptablePrefFilter {
+ public:
+  using StoreContentsPair = std::pair<std::unique_ptr<PrefHashStore>,
+                                      std::unique_ptr<HashStoreContents>>;
+
+  // Constructs a PrefHashFilter tracking the specified |tracked_preferences|
+  // using |pref_hash_store| to check/store hashes. An optional |delegate| is
+  // notified of the status of each preference as it is checked.
+  // If |reset_on_load_observer| is provided, it will be notified if a reset
+  // occurs in FilterOnLoad.
+  // |reporting_ids_count| is the count of all possible IDs (possibly greater
+  // than |tracked_preferences.size()|). If |report_super_mac_validity| is true,
+  // the state of the super MAC will be reported via UMA during
+  // FinalizeFilterOnLoad.
+  // |external_validation_hash_store_pair_| will be used (if non-null) to
+  // perform extra validations without triggering resets.
+  PrefHashFilter(std::unique_ptr<PrefHashStore> pref_hash_store,
+                 StoreContentsPair external_validation_hash_store_pair_,
+                 const std::vector<prefs::mojom::TrackedPreferenceMetadataPtr>&
+                     tracked_preferences,
+                 prefs::mojom::ResetOnLoadObserverPtr reset_on_load_observer,
+                 prefs::mojom::TrackedPreferenceValidationDelegate* delegate,
+                 size_t reporting_ids_count,
+                 bool report_super_mac_validity);
+
+  ~PrefHashFilter() override;
+
+  // Registers required user preferences.
+  static void RegisterProfilePrefs(user_prefs::PrefRegistrySyncable* registry);
+
+  // Retrieves the time of the last reset event, if any, for the provided user
+  // preferences. If no reset has occurred, Returns a null |Time|.
+  static base::Time GetResetTime(PrefService* user_prefs);
+
+  // Clears the time of the last reset event, if any, for the provided user
+  // preferences.
+  static void ClearResetTime(PrefService* user_prefs);
+
+  // Initializes the PrefHashStore with hashes of the tracked preferences in
+  // |pref_store_contents|. |pref_store_contents| will be the |storage| passed
+  // to PrefHashStore::BeginTransaction().
+  void Initialize(base::DictionaryValue* pref_store_contents);
+
+  // PrefFilter remaining implementation.
+  void FilterUpdate(const std::string& path) override;
+  OnWriteCallbackPair FilterSerializeData(
+      base::DictionaryValue* pref_store_contents) override;
+
+  void OnStoreDeletionFromDisk() override;
+
+ private:
+  // InterceptablePrefFilter implementation.
+  void FinalizeFilterOnLoad(
+      const PostFilterOnLoadCallback& post_filter_on_load_callback,
+      std::unique_ptr<base::DictionaryValue> pref_store_contents,
+      bool prefs_altered) override;
+
+  // Helper function to generate FilterSerializeData()'s pre-write and
+  // post-write callbacks. The returned callbacks are thread-safe.
+  OnWriteCallbackPair GetOnWriteSynchronousCallbacks(
+      base::DictionaryValue* pref_store_contents);
+
+  // Clears the MACs contained in |external_validation_hash_store_contents|
+  // which are present in |paths_to_clear|.
+  static void ClearFromExternalStore(
+      HashStoreContents* external_validation_hash_store_contents,
+      const base::DictionaryValue* changed_paths_and_macs);
+
+  // Flushes the MACs contained in |changed_paths_and_mac| to
+  // external_hash_store_contents if |write_success|, otherwise discards the
+  // changes.
+  static void FlushToExternalStore(
+      std::unique_ptr<HashStoreContents> external_hash_store_contents,
+      std::unique_ptr<base::DictionaryValue> changed_paths_and_macs,
+      bool write_success);
+
+  // Callback to be invoked only once (and subsequently reset) on the next
+  // FilterOnLoad event. It will be allowed to modify the |prefs| handed to
+  // FilterOnLoad before handing them back to this PrefHashFilter.
+  FilterOnLoadInterceptor filter_on_load_interceptor_;
+
+  // A map of paths to TrackedPreferences; this map owns this individual
+  // TrackedPreference objects.
+  using TrackedPreferencesMap =
+      std::unordered_map<std::string, std::unique_ptr<TrackedPreference>>;
+
+  // A map from changed paths to their corresponding TrackedPreferences (which
+  // aren't owned by this map).
+  using ChangedPathsMap = std::map<std::string, const TrackedPreference*>;
+
+  std::unique_ptr<PrefHashStore> pref_hash_store_;
+
+  // A store and contents on which to perform extra validations without
+  // triggering resets.
+  // Will be null if the platform does not support external validation.
+  base::Optional<StoreContentsPair> external_validation_hash_store_pair_;
+
+  // Notified if a reset occurs in a call to FilterOnLoad.
+  prefs::mojom::ResetOnLoadObserverPtr reset_on_load_observer_;
+
+  TrackedPreferencesMap tracked_paths_;
+
+  // The set of all paths whose value has changed since the last call to
+  // FilterSerializeData.
+  ChangedPathsMap changed_paths_;
+
+  // Whether to report the validity of the super MAC at load time (via UMA).
+  bool report_super_mac_validity_;
+
+  DISALLOW_COPY_AND_ASSIGN(PrefHashFilter);
+};
+
+#endif  // SERVICES_PREFERENCES_TRACKED_PREF_HASH_FILTER_H_
diff -Naur chromium-65.0.3325.181-orig/services/viz/public/cpp/compositing/filter_operation_struct_traits.h.gcc5-r3 chromium-65.0.3325.181.patched/services/viz/public/cpp/compositing/filter_operation_struct_traits.h.gcc5-r3
--- chromium-65.0.3325.181-orig/services/viz/public/cpp/compositing/filter_operation_struct_traits.h.gcc5-r3	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/services/viz/public/cpp/compositing/filter_operation_struct_traits.h.gcc5-r3	2018-03-21 01:05:30.000000000 +0300
@@ -0,0 +1,235 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef SERVICES_VIZ_PUBLIC_CPP_COMPOSITING_FILTER_OPERATION_STRUCT_TRAITS_H_
+#define SERVICES_VIZ_PUBLIC_CPP_COMPOSITING_FILTER_OPERATION_STRUCT_TRAITS_H_
+
+#include "base/containers/span.h"
+#include "base/memory/aligned_memory.h"
+#include "cc/paint/filter_operation.h"
+#include "cc/paint/paint_filter.h"
+#include "services/viz/public/cpp/compositing/paint_filter_struct_traits.h"
+#include "services/viz/public/interfaces/compositing/filter_operation.mojom-shared.h"
+#include "skia/public/interfaces/blur_image_filter_tile_mode_struct_traits.h"
+
+namespace mojo {
+
+namespace {
+viz::mojom::FilterType CCFilterTypeToMojo(
+    const cc::FilterOperation::FilterType& type) {
+  switch (type) {
+    case cc::FilterOperation::GRAYSCALE:
+      return viz::mojom::FilterType::GRAYSCALE;
+    case cc::FilterOperation::SEPIA:
+      return viz::mojom::FilterType::SEPIA;
+    case cc::FilterOperation::SATURATE:
+      return viz::mojom::FilterType::SATURATE;
+    case cc::FilterOperation::HUE_ROTATE:
+      return viz::mojom::FilterType::HUE_ROTATE;
+    case cc::FilterOperation::INVERT:
+      return viz::mojom::FilterType::INVERT;
+    case cc::FilterOperation::BRIGHTNESS:
+      return viz::mojom::FilterType::BRIGHTNESS;
+    case cc::FilterOperation::CONTRAST:
+      return viz::mojom::FilterType::CONTRAST;
+    case cc::FilterOperation::OPACITY:
+      return viz::mojom::FilterType::OPACITY;
+    case cc::FilterOperation::BLUR:
+      return viz::mojom::FilterType::BLUR;
+    case cc::FilterOperation::DROP_SHADOW:
+      return viz::mojom::FilterType::DROP_SHADOW;
+    case cc::FilterOperation::COLOR_MATRIX:
+      return viz::mojom::FilterType::COLOR_MATRIX;
+    case cc::FilterOperation::ZOOM:
+      return viz::mojom::FilterType::ZOOM;
+    case cc::FilterOperation::REFERENCE:
+      return viz::mojom::FilterType::REFERENCE;
+    case cc::FilterOperation::SATURATING_BRIGHTNESS:
+      return viz::mojom::FilterType::SATURATING_BRIGHTNESS;
+    case cc::FilterOperation::ALPHA_THRESHOLD:
+      return viz::mojom::FilterType::ALPHA_THRESHOLD;
+  }
+  NOTREACHED();
+  return viz::mojom::FilterType::FILTER_TYPE_LAST;
+}
+
+cc::FilterOperation::FilterType MojoFilterTypeToCC(
+    const viz::mojom::FilterType& type) {
+  switch (type) {
+    case viz::mojom::FilterType::GRAYSCALE:
+      return cc::FilterOperation::GRAYSCALE;
+    case viz::mojom::FilterType::SEPIA:
+      return cc::FilterOperation::SEPIA;
+    case viz::mojom::FilterType::SATURATE:
+      return cc::FilterOperation::SATURATE;
+    case viz::mojom::FilterType::HUE_ROTATE:
+      return cc::FilterOperation::HUE_ROTATE;
+    case viz::mojom::FilterType::INVERT:
+      return cc::FilterOperation::INVERT;
+    case viz::mojom::FilterType::BRIGHTNESS:
+      return cc::FilterOperation::BRIGHTNESS;
+    case viz::mojom::FilterType::CONTRAST:
+      return cc::FilterOperation::CONTRAST;
+    case viz::mojom::FilterType::OPACITY:
+      return cc::FilterOperation::OPACITY;
+    case viz::mojom::FilterType::BLUR:
+      return cc::FilterOperation::BLUR;
+    case viz::mojom::FilterType::DROP_SHADOW:
+      return cc::FilterOperation::DROP_SHADOW;
+    case viz::mojom::FilterType::COLOR_MATRIX:
+      return cc::FilterOperation::COLOR_MATRIX;
+    case viz::mojom::FilterType::ZOOM:
+      return cc::FilterOperation::ZOOM;
+    case viz::mojom::FilterType::REFERENCE:
+      return cc::FilterOperation::REFERENCE;
+    case viz::mojom::FilterType::SATURATING_BRIGHTNESS:
+      return cc::FilterOperation::SATURATING_BRIGHTNESS;
+    case viz::mojom::FilterType::ALPHA_THRESHOLD:
+      return cc::FilterOperation::ALPHA_THRESHOLD;
+  }
+  NOTREACHED();
+  return cc::FilterOperation::FILTER_TYPE_LAST;
+}
+
+}  // namespace
+
+template <>
+struct StructTraits<viz::mojom::FilterOperationDataView, cc::FilterOperation> {
+  static viz::mojom::FilterType type(const cc::FilterOperation& op) {
+    return CCFilterTypeToMojo(op.type());
+  }
+
+  static float amount(const cc::FilterOperation& operation) {
+    if (operation.type() == cc::FilterOperation::COLOR_MATRIX ||
+        operation.type() == cc::FilterOperation::REFERENCE) {
+      return 0.f;
+    }
+    return operation.amount();
+  }
+
+  static float outer_threshold(const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::ALPHA_THRESHOLD)
+      return 0.f;
+    return operation.outer_threshold();
+  }
+
+  static gfx::Point drop_shadow_offset(const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::DROP_SHADOW)
+      return gfx::Point();
+    return operation.drop_shadow_offset();
+  }
+
+  static uint32_t drop_shadow_color(const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::DROP_SHADOW)
+      return 0;
+    return operation.drop_shadow_color();
+  }
+
+  static sk_sp<cc::PaintFilter> image_filter(
+      const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::REFERENCE)
+      return nullptr;
+    if (!operation.image_filter())
+      return nullptr;
+    return operation.image_filter();
+  }
+
+  static base::span<const float> matrix(const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::COLOR_MATRIX)
+      return base::span<const float>();
+    return operation.matrix();
+  }
+
+  static base::span<const gfx::Rect> shape(
+      const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::ALPHA_THRESHOLD)
+      return base::span<gfx::Rect>();
+    return operation.shape();
+  }
+
+  static int32_t zoom_inset(const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::ZOOM)
+      return 0;
+    return operation.zoom_inset();
+  }
+
+  static skia::mojom::BlurTileMode blur_tile_mode(
+      const cc::FilterOperation& operation) {
+    if (operation.type() != cc::FilterOperation::BLUR)
+      return skia::mojom::BlurTileMode::CLAMP_TO_BLACK;
+    return EnumTraits<skia::mojom::BlurTileMode, SkBlurImageFilter::TileMode>::
+        ToMojom(operation.blur_tile_mode());
+  }
+
+  static bool Read(viz::mojom::FilterOperationDataView data,
+                   cc::FilterOperation* out) {
+    out->set_type(MojoFilterTypeToCC(data.type()));
+    switch (out->type()) {
+      case cc::FilterOperation::GRAYSCALE:
+      case cc::FilterOperation::SEPIA:
+      case cc::FilterOperation::SATURATE:
+      case cc::FilterOperation::HUE_ROTATE:
+      case cc::FilterOperation::INVERT:
+      case cc::FilterOperation::BRIGHTNESS:
+      case cc::FilterOperation::SATURATING_BRIGHTNESS:
+      case cc::FilterOperation::CONTRAST:
+      case cc::FilterOperation::OPACITY:
+        out->set_amount(data.amount());
+        return true;
+      case cc::FilterOperation::BLUR:
+        out->set_amount(data.amount());
+        SkBlurImageFilter::TileMode tile_mode;
+        if (!data.ReadBlurTileMode(&tile_mode))
+          return false;
+        out->set_blur_tile_mode(tile_mode);
+        return true;
+      case cc::FilterOperation::DROP_SHADOW: {
+        out->set_amount(data.amount());
+        gfx::Point offset;
+        if (!data.ReadDropShadowOffset(&offset))
+          return false;
+        out->set_drop_shadow_offset(offset);
+        out->set_drop_shadow_color(data.drop_shadow_color());
+        return true;
+      }
+      case cc::FilterOperation::COLOR_MATRIX: {
+        // TODO(fsamuel): It would be nice to modify cc::FilterOperation to
+        // avoid this extra copy.
+        cc::FilterOperation::Matrix matrix_buffer = {};
+        base::span<float> matrix(matrix_buffer);
+        if (!data.ReadMatrix(&matrix))
+          return false;
+        out->set_matrix(matrix_buffer);
+        return true;
+      }
+      case cc::FilterOperation::ZOOM: {
+        if (data.amount() < 0.f || data.zoom_inset() < 0)
+          return false;
+        out->set_amount(data.amount());
+        out->set_zoom_inset(data.zoom_inset());
+        return true;
+      }
+      case cc::FilterOperation::REFERENCE: {
+        sk_sp<cc::PaintFilter> filter;
+        if (!data.ReadImageFilter(&filter))
+          return false;
+        out->set_image_filter(std::move(filter));
+        return true;
+      }
+      case cc::FilterOperation::ALPHA_THRESHOLD:
+        out->set_amount(data.amount());
+        out->set_outer_threshold(data.outer_threshold());
+        cc::FilterOperation::ShapeRects shape;
+        if (!data.ReadShape(&shape))
+          return false;
+        out->set_shape(shape);
+        return true;
+    }
+    return false;
+  }
+};
+
+}  // namespace mojo
+
+#endif  // SERVICES_VIZ_PUBLIC_CPP_COMPOSITING_FILTER_OPERATION_STRUCT_TRAITS_H_
diff -Naur chromium-65.0.3325.181-orig/services/viz/public/cpp/compositing/quads_struct_traits.h chromium-65.0.3325.181.patched/services/viz/public/cpp/compositing/quads_struct_traits.h
--- chromium-65.0.3325.181-orig/services/viz/public/cpp/compositing/quads_struct_traits.h	2018-03-21 01:05:30.000000000 +0300
+++ chromium-65.0.3325.181.patched/services/viz/public/cpp/compositing/quads_struct_traits.h	2018-04-27 11:31:20.591828267 +0300
@@ -308,7 +308,7 @@
   static base::span<const float> vertex_opacity(const viz::DrawQuad& input) {
     const viz::TextureDrawQuad* quad =
         viz::TextureDrawQuad::MaterialCast(&input);
-    return quad->vertex_opacity;
+    return base::make_span(quad->vertex_opacity);
   }
 
   static bool y_flipped(const viz::DrawQuad& input) {
diff -Naur chromium-65.0.3325.181-orig/services/viz/public/cpp/compositing/quads_struct_traits.h.gcc5-r3 chromium-65.0.3325.181.patched/services/viz/public/cpp/compositing/quads_struct_traits.h.gcc5-r3
--- chromium-65.0.3325.181-orig/services/viz/public/cpp/compositing/quads_struct_traits.h.gcc5-r3	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/services/viz/public/cpp/compositing/quads_struct_traits.h.gcc5-r3	2018-03-21 01:05:30.000000000 +0300
@@ -0,0 +1,524 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef SERVICES_VIZ_PUBLIC_CPP_COMPOSITING_QUADS_STRUCT_TRAITS_H_
+#define SERVICES_VIZ_PUBLIC_CPP_COMPOSITING_QUADS_STRUCT_TRAITS_H_
+
+#include "base/containers/span.h"
+#include "base/logging.h"
+#include "components/viz/common/quads/debug_border_draw_quad.h"
+#include "components/viz/common/quads/picture_draw_quad.h"
+#include "components/viz/common/quads/render_pass_draw_quad.h"
+#include "components/viz/common/quads/solid_color_draw_quad.h"
+#include "components/viz/common/quads/stream_video_draw_quad.h"
+#include "components/viz/common/quads/surface_draw_quad.h"
+#include "components/viz/common/quads/texture_draw_quad.h"
+#include "components/viz/common/quads/tile_draw_quad.h"
+#include "components/viz/common/quads/yuv_video_draw_quad.h"
+#include "services/viz/public/cpp/compositing/filter_operation_struct_traits.h"
+#include "services/viz/public/cpp/compositing/filter_operations_struct_traits.h"
+#include "services/viz/public/cpp/compositing/shared_quad_state_struct_traits.h"
+#include "services/viz/public/cpp/compositing/surface_id_struct_traits.h"
+#include "services/viz/public/interfaces/compositing/quads.mojom-shared.h"
+#include "ui/gfx/geometry/mojo/geometry_struct_traits.h"
+#include "ui/gfx/ipc/color/gfx_param_traits.h"
+
+namespace mojo {
+
+viz::DrawQuad* AllocateAndConstruct(
+    viz::mojom::DrawQuadStateDataView::Tag material,
+    viz::QuadList* list);
+
+template <>
+struct UnionTraits<viz::mojom::DrawQuadStateDataView, viz::DrawQuad> {
+  static viz::mojom::DrawQuadStateDataView::Tag GetTag(
+      const viz::DrawQuad& quad) {
+    switch (quad.material) {
+      case viz::DrawQuad::INVALID:
+        break;
+      case viz::DrawQuad::DEBUG_BORDER:
+        return viz::mojom::DrawQuadStateDataView::Tag::DEBUG_BORDER_QUAD_STATE;
+      case viz::DrawQuad::PICTURE_CONTENT:
+        break;
+      case viz::DrawQuad::RENDER_PASS:
+        return viz::mojom::DrawQuadStateDataView::Tag::RENDER_PASS_QUAD_STATE;
+      case viz::DrawQuad::SOLID_COLOR:
+        return viz::mojom::DrawQuadStateDataView::Tag::SOLID_COLOR_QUAD_STATE;
+      case viz::DrawQuad::STREAM_VIDEO_CONTENT:
+        return viz::mojom::DrawQuadStateDataView::Tag::STREAM_VIDEO_QUAD_STATE;
+      case viz::DrawQuad::SURFACE_CONTENT:
+        return viz::mojom::DrawQuadStateDataView::Tag::SURFACE_QUAD_STATE;
+      case viz::DrawQuad::TEXTURE_CONTENT:
+        return viz::mojom::DrawQuadStateDataView::Tag::TEXTURE_QUAD_STATE;
+      case viz::DrawQuad::TILED_CONTENT:
+        return viz::mojom::DrawQuadStateDataView::Tag::TILE_QUAD_STATE;
+      case viz::DrawQuad::YUV_VIDEO_CONTENT:
+        return viz::mojom::DrawQuadStateDataView::Tag::YUV_VIDEO_QUAD_STATE;
+    }
+    NOTREACHED();
+    return viz::mojom::DrawQuadStateDataView::Tag::DEBUG_BORDER_QUAD_STATE;
+  }
+
+  static const viz::DrawQuad& debug_border_quad_state(
+      const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static const viz::DrawQuad& render_pass_quad_state(
+      const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static const viz::DrawQuad& solid_color_quad_state(
+      const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static const viz::DrawQuad& surface_quad_state(const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static const viz::DrawQuad& texture_quad_state(const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static const viz::DrawQuad& tile_quad_state(const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static const viz::DrawQuad& stream_video_quad_state(
+      const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static const viz::DrawQuad& yuv_video_quad_state(const viz::DrawQuad& quad) {
+    return quad;
+  }
+
+  static bool Read(viz::mojom::DrawQuadStateDataView data, viz::DrawQuad* out) {
+    switch (data.tag()) {
+      case viz::mojom::DrawQuadStateDataView::Tag::DEBUG_BORDER_QUAD_STATE:
+        return data.ReadDebugBorderQuadState(out);
+      case viz::mojom::DrawQuadStateDataView::Tag::RENDER_PASS_QUAD_STATE:
+        return data.ReadRenderPassQuadState(out);
+      case viz::mojom::DrawQuadStateDataView::Tag::SOLID_COLOR_QUAD_STATE:
+        return data.ReadSolidColorQuadState(out);
+      case viz::mojom::DrawQuadStateDataView::Tag::SURFACE_QUAD_STATE:
+        return data.ReadSurfaceQuadState(out);
+      case viz::mojom::DrawQuadStateDataView::Tag::TEXTURE_QUAD_STATE:
+        return data.ReadTextureQuadState(out);
+      case viz::mojom::DrawQuadStateDataView::Tag::TILE_QUAD_STATE:
+        return data.ReadTileQuadState(out);
+      case viz::mojom::DrawQuadStateDataView::Tag::STREAM_VIDEO_QUAD_STATE:
+        return data.ReadStreamVideoQuadState(out);
+      case viz::mojom::DrawQuadStateDataView::Tag::YUV_VIDEO_QUAD_STATE:
+        return data.ReadYuvVideoQuadState(out);
+    }
+    NOTREACHED();
+    return false;
+  }
+};
+
+template <>
+struct StructTraits<viz::mojom::DebugBorderQuadStateDataView, viz::DrawQuad> {
+  static uint32_t color(const viz::DrawQuad& input) {
+    const viz::DebugBorderDrawQuad* quad =
+        viz::DebugBorderDrawQuad::MaterialCast(&input);
+    return quad->color;
+  }
+
+  static int32_t width(const viz::DrawQuad& input) {
+    const viz::DebugBorderDrawQuad* quad =
+        viz::DebugBorderDrawQuad::MaterialCast(&input);
+    return quad->width;
+  }
+
+  static bool Read(viz::mojom::DebugBorderQuadStateDataView data,
+                   viz::DrawQuad* out);
+};
+
+template <>
+struct StructTraits<viz::mojom::RenderPassQuadStateDataView, viz::DrawQuad> {
+  static int32_t render_pass_id(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    DCHECK(quad->render_pass_id);
+    return quad->render_pass_id;
+  }
+
+  static uint32_t mask_resource_id(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    return quad->mask_resource_id();
+  }
+
+  static const gfx::RectF& mask_uv_rect(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    return quad->mask_uv_rect;
+  }
+
+  static const gfx::Size& mask_texture_size(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    return quad->mask_texture_size;
+  }
+
+  static const gfx::Vector2dF& filters_scale(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    return quad->filters_scale;
+  }
+
+  static const gfx::PointF& filters_origin(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    return quad->filters_origin;
+  }
+
+  static const gfx::RectF& tex_coord_rect(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    return quad->tex_coord_rect;
+  }
+
+  static bool force_anti_aliasing_off(const viz::DrawQuad& input) {
+    const viz::RenderPassDrawQuad* quad =
+        viz::RenderPassDrawQuad::MaterialCast(&input);
+    return quad->force_anti_aliasing_off;
+  }
+
+  static bool Read(viz::mojom::RenderPassQuadStateDataView data,
+                   viz::DrawQuad* out);
+};
+
+template <>
+struct StructTraits<viz::mojom::SolidColorQuadStateDataView, viz::DrawQuad> {
+  static uint32_t color(const viz::DrawQuad& input) {
+    const viz::SolidColorDrawQuad* quad =
+        viz::SolidColorDrawQuad::MaterialCast(&input);
+    return quad->color;
+  }
+
+  static bool force_anti_aliasing_off(const viz::DrawQuad& input) {
+    const viz::SolidColorDrawQuad* quad =
+        viz::SolidColorDrawQuad::MaterialCast(&input);
+    return quad->force_anti_aliasing_off;
+  }
+
+  static bool Read(viz::mojom::SolidColorQuadStateDataView data,
+                   viz::DrawQuad* out);
+};
+
+template <>
+struct StructTraits<viz::mojom::StreamVideoQuadStateDataView, viz::DrawQuad> {
+  static uint32_t resource_id(const viz::DrawQuad& input) {
+    const viz::StreamVideoDrawQuad* quad =
+        viz::StreamVideoDrawQuad::MaterialCast(&input);
+    return quad->resources.ids[viz::StreamVideoDrawQuad::kResourceIdIndex];
+  }
+
+  static const gfx::Size& resource_size_in_pixels(const viz::DrawQuad& input) {
+    const viz::StreamVideoDrawQuad* quad =
+        viz::StreamVideoDrawQuad::MaterialCast(&input);
+    return quad->overlay_resources
+        .size_in_pixels[viz::StreamVideoDrawQuad::kResourceIdIndex];
+  }
+
+  static const gfx::Transform& matrix(const viz::DrawQuad& input) {
+    const viz::StreamVideoDrawQuad* quad =
+        viz::StreamVideoDrawQuad::MaterialCast(&input);
+    return quad->matrix;
+  }
+
+  static bool Read(viz::mojom::StreamVideoQuadStateDataView data,
+                   viz::DrawQuad* out);
+};
+
+template <>
+struct StructTraits<viz::mojom::SurfaceQuadStateDataView, viz::DrawQuad> {
+  static const viz::SurfaceId& primary_surface_id(const viz::DrawQuad& input) {
+    const viz::SurfaceDrawQuad* quad =
+        viz::SurfaceDrawQuad::MaterialCast(&input);
+    return quad->primary_surface_id;
+  }
+
+  static const base::Optional<viz::SurfaceId>& fallback_surface_id(
+      const viz::DrawQuad& input) {
+    const viz::SurfaceDrawQuad* quad =
+        viz::SurfaceDrawQuad::MaterialCast(&input);
+    return quad->fallback_surface_id;
+  }
+
+  static uint32_t default_background_color(const viz::DrawQuad& input) {
+    const viz::SurfaceDrawQuad* quad =
+        viz::SurfaceDrawQuad::MaterialCast(&input);
+    return quad->default_background_color;
+  }
+
+  static bool stretch_content_to_fill_bounds(const viz::DrawQuad& input) {
+    const viz::SurfaceDrawQuad* quad =
+        viz::SurfaceDrawQuad::MaterialCast(&input);
+    return quad->stretch_content_to_fill_bounds;
+  }
+
+  static bool Read(viz::mojom::SurfaceQuadStateDataView data,
+                   viz::DrawQuad* out);
+};
+
+template <>
+struct StructTraits<viz::mojom::TextureQuadStateDataView, viz::DrawQuad> {
+  static uint32_t resource_id(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->resource_id();
+  }
+
+  static const gfx::Size& resource_size_in_pixels(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->resource_size_in_pixels();
+  }
+
+  static bool premultiplied_alpha(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->premultiplied_alpha;
+  }
+
+  static const gfx::PointF& uv_top_left(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->uv_top_left;
+  }
+
+  static const gfx::PointF& uv_bottom_right(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->uv_bottom_right;
+  }
+
+  static uint32_t background_color(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->background_color;
+  }
+
+  static base::span<const float> vertex_opacity(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->vertex_opacity;
+  }
+
+  static bool y_flipped(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->y_flipped;
+  }
+
+  static bool nearest_neighbor(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->nearest_neighbor;
+  }
+
+  static bool secure_output_only(const viz::DrawQuad& input) {
+    const viz::TextureDrawQuad* quad =
+        viz::TextureDrawQuad::MaterialCast(&input);
+    return quad->secure_output_only;
+  }
+
+  static bool Read(viz::mojom::TextureQuadStateDataView data,
+                   viz::DrawQuad* out);
+};
+
+template <>
+struct StructTraits<viz::mojom::TileQuadStateDataView, viz::DrawQuad> {
+  static const gfx::RectF& tex_coord_rect(const viz::DrawQuad& input) {
+    const viz::TileDrawQuad* quad = viz::TileDrawQuad::MaterialCast(&input);
+    return quad->tex_coord_rect;
+  }
+
+  static const gfx::Size& texture_size(const viz::DrawQuad& input) {
+    const viz::TileDrawQuad* quad = viz::TileDrawQuad::MaterialCast(&input);
+    return quad->texture_size;
+  }
+
+  static bool swizzle_contents(const viz::DrawQuad& input) {
+    const viz::TileDrawQuad* quad = viz::TileDrawQuad::MaterialCast(&input);
+    return quad->swizzle_contents;
+  }
+
+  static bool nearest_neighbor(const viz::DrawQuad& input) {
+    const viz::TileDrawQuad* quad = viz::TileDrawQuad::MaterialCast(&input);
+    return quad->nearest_neighbor;
+  }
+
+  static uint32_t resource_id(const viz::DrawQuad& input) {
+    const viz::TileDrawQuad* quad = viz::TileDrawQuad::MaterialCast(&input);
+    return quad->resource_id();
+  }
+
+  static bool force_anti_aliasing_off(const viz::DrawQuad& input) {
+    const viz::TileDrawQuad* quad = viz::TileDrawQuad::MaterialCast(&input);
+    return quad->force_anti_aliasing_off;
+  }
+
+  static bool Read(viz::mojom::TileQuadStateDataView data, viz::DrawQuad* out);
+};
+
+template <>
+struct StructTraits<viz::mojom::YUVVideoQuadStateDataView, viz::DrawQuad> {
+  static const gfx::RectF& ya_tex_coord_rect(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->ya_tex_coord_rect;
+  }
+
+  static const gfx::RectF& uv_tex_coord_rect(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->uv_tex_coord_rect;
+  }
+
+  static const gfx::Size& ya_tex_size(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->ya_tex_size;
+  }
+
+  static const gfx::Size& uv_tex_size(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->uv_tex_size;
+  }
+
+  static uint32_t y_plane_resource_id(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->y_plane_resource_id();
+  }
+
+  static uint32_t u_plane_resource_id(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->u_plane_resource_id();
+  }
+
+  static uint32_t v_plane_resource_id(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->v_plane_resource_id();
+  }
+
+  static uint32_t a_plane_resource_id(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->a_plane_resource_id();
+  }
+
+  static float resource_offset(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->resource_offset;
+  }
+
+  static float resource_multiplier(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->resource_multiplier;
+  }
+
+  static uint32_t bits_per_channel(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->bits_per_channel;
+  }
+  static gfx::ColorSpace video_color_space(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->video_color_space;
+  }
+  static bool require_overlay(const viz::DrawQuad& input) {
+    const viz::YUVVideoDrawQuad* quad =
+        viz::YUVVideoDrawQuad::MaterialCast(&input);
+    return quad->require_overlay;
+  }
+
+  static bool Read(viz::mojom::YUVVideoQuadStateDataView data,
+                   viz::DrawQuad* out);
+};
+
+struct DrawQuadWithSharedQuadState {
+  const viz::DrawQuad* quad;
+  const viz::SharedQuadState* shared_quad_state;
+};
+
+template <>
+struct StructTraits<viz::mojom::DrawQuadDataView, DrawQuadWithSharedQuadState> {
+  static const gfx::Rect& rect(const DrawQuadWithSharedQuadState& input) {
+    return input.quad->rect;
+  }
+
+  static const gfx::Rect& visible_rect(
+      const DrawQuadWithSharedQuadState& input) {
+    return input.quad->visible_rect;
+  }
+
+  static bool needs_blending(const DrawQuadWithSharedQuadState& input) {
+    return input.quad->needs_blending;
+  }
+
+  static OptSharedQuadState sqs(const DrawQuadWithSharedQuadState& input) {
+    return {input.shared_quad_state};
+  }
+
+  static const viz::DrawQuad& draw_quad_state(
+      const DrawQuadWithSharedQuadState& input) {
+    return *input.quad;
+  }
+};
+
+// This StructTraits is only used for deserialization within RenderPasses.
+template <>
+struct StructTraits<viz::mojom::DrawQuadDataView, viz::DrawQuad> {
+  static bool Read(viz::mojom::DrawQuadDataView data, viz::DrawQuad* out);
+};
+
+template <>
+struct ArrayTraits<viz::QuadList> {
+  using Element = DrawQuadWithSharedQuadState;
+  struct ConstIterator {
+    explicit ConstIterator(const viz::QuadList::ConstIterator& it)
+        : it(it), last_shared_quad_state(nullptr) {}
+
+    viz::QuadList::ConstIterator it;
+    const viz::SharedQuadState* last_shared_quad_state;
+  };
+
+  static ConstIterator GetBegin(const viz::QuadList& input) {
+    return ConstIterator(input.begin());
+  }
+
+  static void AdvanceIterator(ConstIterator& iterator) {  // NOLINT
+    iterator.last_shared_quad_state = (*iterator.it)->shared_quad_state;
+    ++iterator.it;
+  }
+
+  static Element GetValue(ConstIterator& iterator) {  // NOLINT
+    DrawQuadWithSharedQuadState dq = {*iterator.it, nullptr};
+    // Only serialize the SharedQuadState if we haven't seen it before and
+    // therefore have not already serialized it.
+    const viz::SharedQuadState* current_sqs = (*iterator.it)->shared_quad_state;
+    if (current_sqs != iterator.last_shared_quad_state)
+      dq.shared_quad_state = current_sqs;
+    return dq;
+  }
+
+  static size_t GetSize(const viz::QuadList& input) { return input.size(); }
+};
+
+}  // namespace mojo
+
+#endif  // SERVICES_VIZ_PUBLIC_CPP_COMPOSITING_QUADS_STRUCT_TRAITS_H_
diff -Naur chromium-65.0.3325.181-orig/third_party/BUILD.gn chromium-65.0.3325.181.patched/third_party/BUILD.gn
--- chromium-65.0.3325.181-orig/third_party/BUILD.gn	2018-03-21 01:05:30.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/BUILD.gn	2018-04-27 11:31:20.519829024 +0300
@@ -19,6 +19,7 @@
 config("system_libjpeg_config") {
   libs = [ "jpeg" ]
   defines = [ "USE_SYSTEM_LIBJPEG" ]
+  include_dirs = [ "/usr/include/" ]
 }
 
 config("libjpeg_turbo_config") {
diff -Naur chromium-65.0.3325.181-orig/third_party/BUILD.gn.jpegfix chromium-65.0.3325.181.patched/third_party/BUILD.gn.jpegfix
--- chromium-65.0.3325.181-orig/third_party/BUILD.gn.jpegfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/BUILD.gn.jpegfix	2018-03-21 01:05:30.000000000 +0300
@@ -0,0 +1,76 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/freetype/freetype.gni")
+import("//third_party/harfbuzz-ng/harfbuzz.gni")
+
+assert(!is_ios, "This is not used on iOS, don't drag it in unintentionally")
+
+declare_args() {
+  # Uses system libjpeg. If true, overrides use_libjpeg_turbo.
+  use_system_libjpeg = false
+
+  # Uses libjpeg_turbo as the jpeg implementation. Has no effect if
+  # use_system_libjpeg is set.
+  use_libjpeg_turbo = true
+}
+
+config("system_libjpeg_config") {
+  libs = [ "jpeg" ]
+  defines = [ "USE_SYSTEM_LIBJPEG" ]
+}
+
+config("libjpeg_turbo_config") {
+  defines = [ "USE_LIBJPEG_TURBO=1" ]
+}
+
+# This is a meta target that forwards to the system's libjpeg,
+# third_party/libjpeg, or third_party/libjpeg_turbo depending on the build args
+# declared in this file.
+group("jpeg") {
+  if (use_system_libjpeg) {
+    public_configs = [ ":system_libjpeg_config" ]
+  } else if (use_libjpeg_turbo) {
+    public_deps = [
+      "//third_party/libjpeg_turbo:libjpeg",
+    ]
+    public_configs = [ ":libjpeg_turbo_config" ]
+  } else {
+    public_deps = [
+      "//third_party/libjpeg:libjpeg",
+    ]
+  }
+}
+
+# This is a meta target that forwards include paths only to the system's
+# libjpeg, third_party/libjpeg, or third_party/libjpeg_turbo depending on the
+# build args declared in this file. This is needed, rarely, for targets that
+# need to reference libjpeg without explicitly building it.
+group("jpeg_includes") {
+  if (use_system_libjpeg) {
+    public_configs = [ ":system_libjpeg_config" ]
+  } else if (use_libjpeg_turbo) {
+    public_configs = [ "//third_party/libjpeg_turbo:libjpeg_config" ]
+  } else {
+    public_configs = [ "//third_party/libjpeg:libjpeg_config" ]
+  }
+}
+
+# FreeType and HarfBuzz libraries are dependent on each other. This component
+# will depend on the appropriate source sets or export the system packages
+# for both FreeType and HarfBuzz.
+component("freetype_harfbuzz") {
+  public_configs = []
+  public_deps = []
+  if (use_system_freetype) {
+    public_configs += [ "//build/linux:freetype_from_pkgconfig" ]
+  } else {
+    public_deps += [ "//third_party/freetype:freetype_source" ]
+  }
+  if (use_system_harfbuzz) {
+    public_configs += [ "//third_party/harfbuzz-ng:harfbuzz_from_pkgconfig" ]
+  } else {
+    public_deps += [ "//third_party/harfbuzz-ng:harfbuzz_source" ]
+  }
+}
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/BUILD.gn chromium-65.0.3325.181.patched/third_party/WebKit/Source/BUILD.gn
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/BUILD.gn	2018-03-21 01:05:48.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/BUILD.gn	2018-04-27 11:31:20.527828940 +0300
@@ -83,6 +83,9 @@
   cflags = []
   defines = []
 
+  # error: there are no arguments to 'swapAnchor' that depend on a template parameter, so a declaration of 'swapAnchor' must be available [-fpermissive]
+  cflags += [ "-fpermissive" ]
+
   if (is_win) {
     cflags += [
       "/wd4305",  # Truncation from 'type1' to 'type2'.
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/BUILD.gn.permissive chromium-65.0.3325.181.patched/third_party/WebKit/Source/BUILD.gn.permissive
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/BUILD.gn.permissive	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/BUILD.gn.permissive	2018-03-21 01:05:48.000000000 +0300
@@ -0,0 +1,154 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("config.gni")
+if (is_clang) {
+  import("//build/config/clang/clang.gni")
+}
+
+visibility = [ "//third_party/WebKit/*" ]
+
+# arguments --------------------------------------------------------------------
+
+declare_args() {
+  # Set to true to enable the clang plugin that checks the usage of the  Blink
+  # garbage-collection infrastructure during compilation.
+  blink_gc_plugin = true
+
+  # Set to true to have the clang Blink GC plugin emit class graph (in JSON)
+  # with typed pointer edges; for debugging or other (internal) uses.
+  blink_gc_plugin_option_do_dump_graph = false
+
+  # Set to true to have the clang Blink GC plugin additionally check if
+  # a class has an empty destructor which would be unnecessarily invoked
+  # when finalized.
+  blink_gc_plugin_option_warn_unneeded_finalizer = false
+}
+
+# features ---------------------------------------------------------------------
+
+config("features") {
+  defines = feature_defines_list
+}
+
+# inside_blink -----------------------------------------------------------------
+
+config("inside_blink") {
+  defines = [
+    "BLINK_IMPLEMENTATION=1",
+    "INSIDE_BLINK",
+  ]
+}
+
+# blink_pch --------------------------------------------------------------------
+
+# Precompiled headers can save a lot of time compiling since Blink has
+# a lot of source in header files.
+
+import("//build/config/pch.gni")
+
+config("blink_pch") {
+  if (enable_precompiled_headers) {
+    if (is_win) {
+      # This is a string rather than a file GN knows about. It has to match
+      # exactly what's in the /FI flag below, and what might appear in the
+      # source code in quotes for an #include directive.
+      precompiled_header = rebase_path("build/win/Precompile.h", root_build_dir)
+
+      # This is a file that GN will compile with the above header. It will be
+      # implicitly added to the sources (potentially multiple times, with one
+      # variant for each language used in the target).
+      precompiled_source =
+          "//third_party/WebKit/Source/build/win/Precompile.cpp"
+
+      # Force include the header.
+      cflags = [ "/FI$precompiled_header" ]
+    } else if (is_mac) {
+      precompiled_source = "//third_party/WebKit/Source/build/mac/Prefix.h"
+    }
+  }
+}
+
+# config -----------------------------------------------------------------------
+
+config("config") {
+  include_dirs = [
+    ".",
+    "..",
+    "$root_gen_dir/blink",
+    "$root_gen_dir/third_party/WebKit",
+  ]
+
+  cflags = []
+  defines = []
+
+  if (is_win) {
+    cflags += [
+      "/wd4305",  # Truncation from 'type1' to 'type2'.
+      "/wd4324",  # Struct padded due to declspec(align).
+      "/wd4714",  # Function marked forceinline not inlined.
+      "/wd4800",  # Value forced to bool.
+      "/wd4996",  # Deprecated function call.
+    ]
+  }
+
+  if (is_win) {
+    if (is_component_build) {
+      defines += [ "USING_V8_SHARED" ]
+    }
+  }
+
+  if (is_clang && blink_gc_plugin && clang_use_chrome_plugins) {
+    # On Windows, the plugin is built directly into clang, so there's
+    # no need to load it dynamically.
+    if (host_os != "win") {
+      _blink_gc_plugin_dll_extension = "so"
+      if (host_os == "mac") {
+        _blink_gc_plugin_dll_extension = "dylib"
+      }
+      cflags += [
+        "-Xclang",
+        "-load",
+        "-Xclang",
+        rebase_path(
+            "${clang_base_path}/lib/libBlinkGCPlugin.${_blink_gc_plugin_dll_extension}",
+            root_build_dir),
+      ]
+    }
+    cflags += [
+      "-Xclang",
+      "-add-plugin",
+      "-Xclang",
+      "blink-gc-plugin",
+    ]
+
+    # Add arguments for enabled GC plugin options:
+    if (blink_gc_plugin_option_do_dump_graph) {
+      cflags += [
+        "-Xclang",
+        "-plugin-arg-blink-gc-plugin",
+        "-Xclang",
+        "dump-graph",
+      ]
+    }
+    if (blink_gc_plugin_option_warn_unneeded_finalizer) {
+      cflags += [
+        "-Xclang",
+        "-plugin-arg-blink-gc-plugin",
+        "-Xclang",
+        "warn-unneeded-finalizer",
+      ]
+    }
+  }
+}
+
+# The follow configs apply to all targets except for unit tests, which rely on
+# static initializers.
+config("non_test_config") {
+  cflags = []
+
+  if (is_clang) {
+    cflags += [ "-Wglobal-constructors" ]
+  }
+}
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp chromium-65.0.3325.181.patched/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp	2018-03-21 01:05:48.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp	2018-04-27 11:31:20.655827593 +0300
@@ -68,7 +68,7 @@
     case IDBKeyPath::kNullType:
       return v8::Null(isolate);
     case IDBKeyPath::kStringType:
-      return V8String(isolate, value.String());
+      return V8String(isolate, value.GetString());
     case IDBKeyPath::kArrayType:
       return ToV8(value.Array(), creation_context, isolate);
   }
@@ -97,7 +97,7 @@
     case IDBKey::kNumberType:
       return v8::Number::New(isolate, key->Number());
     case IDBKey::kStringType:
-      return V8String(isolate, key->String());
+      return V8String(isolate, key->GetString());
     case IDBKey::kBinaryType:
       // https://w3c.github.io/IndexedDB/#convert-a-value-to-a-key
       return ToV8(DOMArrayBuffer::Create(key->Binary()), creation_context,
@@ -379,7 +379,7 @@
   }
 
   DCHECK_EQ(key_path.GetType(), IDBKeyPath::kStringType);
-  return CreateIDBKeyFromValueAndKeyPath(isolate, value, key_path.String(),
+  return CreateIDBKeyFromValueAndKeyPath(isolate, value, key_path.GetString(),
                                          exception_state);
 }
 
@@ -483,7 +483,7 @@
   DCHECK(isolate->InContext());
 
   DCHECK_EQ(key_path.GetType(), IDBKeyPath::kStringType);
-  Vector<String> key_path_elements = ParseKeyPath(key_path.String());
+  Vector<String> key_path_elements = ParseKeyPath(key_path.GetString());
 
   // The conbination of a key generator and an empty key path is forbidden by
   // spec.
@@ -569,7 +569,7 @@
                                     const IDBKeyPath& key_path) {
   IDB_TRACE("canInjectIDBKeyIntoScriptValue");
   DCHECK_EQ(key_path.GetType(), IDBKeyPath::kStringType);
-  Vector<String> key_path_elements = ParseKeyPath(key_path.String());
+  Vector<String> key_path_elements = ParseKeyPath(key_path.GetString());
 
   if (!key_path_elements.size())
     return false;
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp.GetString chromium-65.0.3325.181.patched/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp.GetString
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp.GetString	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/bindings/modules/v8/V8BindingForModules.cpp.GetString	2018-03-21 01:05:48.000000000 +0300
@@ -0,0 +1,686 @@
+/*
+ * Copyright (C) 2011 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1.  Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ * 2.  Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in the
+ *     documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS "AS IS" AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "bindings/modules/v8/V8BindingForModules.h"
+
+#include "bindings/core/v8/V8ArrayBuffer.h"
+#include "bindings/core/v8/V8ArrayBufferView.h"
+#include "bindings/core/v8/V8BindingForCore.h"
+#include "bindings/core/v8/V8Blob.h"
+#include "bindings/core/v8/V8DOMStringList.h"
+#include "bindings/core/v8/V8File.h"
+#include "bindings/core/v8/V8Uint8Array.h"
+#include "bindings/core/v8/serialization/SerializedScriptValue.h"
+#include "bindings/core/v8/serialization/SerializedScriptValueFactory.h"
+#include "bindings/modules/v8/ToV8ForModules.h"
+#include "bindings/modules/v8/V8IDBCursor.h"
+#include "bindings/modules/v8/V8IDBCursorWithValue.h"
+#include "bindings/modules/v8/V8IDBDatabase.h"
+#include "bindings/modules/v8/V8IDBIndex.h"
+#include "bindings/modules/v8/V8IDBKeyRange.h"
+#include "bindings/modules/v8/V8IDBObjectStore.h"
+#include "core/typed_arrays/DOMArrayBuffer.h"
+#include "core/typed_arrays/DOMArrayBufferView.h"
+#include "modules/indexeddb/IDBKey.h"
+#include "modules/indexeddb/IDBKeyPath.h"
+#include "modules/indexeddb/IDBKeyRange.h"
+#include "modules/indexeddb/IDBTracing.h"
+#include "modules/indexeddb/IDBValue.h"
+#include "platform/SharedBuffer.h"
+#include "platform/wtf/MathExtras.h"
+#include "platform/wtf/Vector.h"
+
+namespace blink {
+
+static v8::Local<v8::Value> DeserializeIDBValueData(v8::Isolate*,
+                                                    const IDBValue*);
+static v8::Local<v8::Value> DeserializeIDBValueArray(
+    v8::Isolate*,
+    v8::Local<v8::Object> creation_context,
+    const Vector<std::unique_ptr<IDBValue>>&);
+
+v8::Local<v8::Value> ToV8(const IDBKeyPath& value,
+                          v8::Local<v8::Object> creation_context,
+                          v8::Isolate* isolate) {
+  switch (value.GetType()) {
+    case IDBKeyPath::kNullType:
+      return v8::Null(isolate);
+    case IDBKeyPath::kStringType:
+      return V8String(isolate, value.String());
+    case IDBKeyPath::kArrayType:
+      return ToV8(value.Array(), creation_context, isolate);
+  }
+  NOTREACHED();
+  return v8::Undefined(isolate);
+}
+
+v8::Local<v8::Value> ToV8(const IDBKey* key,
+                          v8::Local<v8::Object> creation_context,
+                          v8::Isolate* isolate) {
+  if (!key) {
+    // The IndexedDB spec requires that absent keys appear as attribute
+    // values as undefined, rather than the more typical (for DOM) null.
+    // This appears on the |upper| and |lower| attributes of IDBKeyRange.
+    // Spec: http://www.w3.org/TR/IndexedDB/#idl-def-IDBKeyRange
+    return V8Undefined();
+  }
+
+  v8::Local<v8::Context> context = isolate->GetCurrentContext();
+
+  switch (key->GetType()) {
+    case IDBKey::kInvalidType:
+    case IDBKey::kTypeEnumMax:
+      NOTREACHED();
+      return V8Undefined();
+    case IDBKey::kNumberType:
+      return v8::Number::New(isolate, key->Number());
+    case IDBKey::kStringType:
+      return V8String(isolate, key->String());
+    case IDBKey::kBinaryType:
+      // https://w3c.github.io/IndexedDB/#convert-a-value-to-a-key
+      return ToV8(DOMArrayBuffer::Create(key->Binary()), creation_context,
+                  isolate);
+    case IDBKey::kDateType:
+      return v8::Date::New(context, key->Date()).ToLocalChecked();
+    case IDBKey::kArrayType: {
+      v8::Local<v8::Array> array = v8::Array::New(isolate, key->Array().size());
+      for (size_t i = 0; i < key->Array().size(); ++i) {
+        v8::Local<v8::Value> value =
+            ToV8(key->Array()[i].get(), creation_context, isolate);
+        if (value.IsEmpty())
+          value = v8::Undefined(isolate);
+        if (!V8CallBoolean(array->CreateDataProperty(context, i, value)))
+          return V8Undefined();
+      }
+      return array;
+    }
+  }
+
+  NOTREACHED();
+  return V8Undefined();
+}
+
+// IDBAny is a variant type used to hold the values produced by the |result|
+// attribute of IDBRequest and (as a convenience) the |source| attribute of
+// IDBRequest and IDBCursor.
+// TODO(jsbell): Replace the use of IDBAny for |source| attributes (which are
+// ScriptWrappable types) using unions per IDL.
+v8::Local<v8::Value> ToV8(const IDBAny* impl,
+                          v8::Local<v8::Object> creation_context,
+                          v8::Isolate* isolate) {
+  if (!impl)
+    return v8::Null(isolate);
+
+  switch (impl->GetType()) {
+    case IDBAny::kUndefinedType:
+      return v8::Undefined(isolate);
+    case IDBAny::kNullType:
+      return v8::Null(isolate);
+    case IDBAny::kDOMStringListType:
+      return ToV8(impl->DomStringList(), creation_context, isolate);
+    case IDBAny::kIDBCursorType:
+      return ToV8(impl->IdbCursor(), creation_context, isolate);
+    case IDBAny::kIDBCursorWithValueType:
+      return ToV8(impl->IdbCursorWithValue(), creation_context, isolate);
+    case IDBAny::kIDBDatabaseType:
+      return ToV8(impl->IdbDatabase(), creation_context, isolate);
+    case IDBAny::kIDBIndexType:
+      return ToV8(impl->IdbIndex(), creation_context, isolate);
+    case IDBAny::kIDBObjectStoreType:
+      return ToV8(impl->IdbObjectStore(), creation_context, isolate);
+    case IDBAny::kIDBValueType:
+      return DeserializeIDBValue(isolate, creation_context, impl->Value());
+    case IDBAny::kIDBValueArrayType:
+      return DeserializeIDBValueArray(isolate, creation_context,
+                                      impl->Values());
+    case IDBAny::kIntegerType:
+      return v8::Number::New(isolate, impl->Integer());
+    case IDBAny::kKeyType:
+      return ToV8(impl->Key(), creation_context, isolate);
+  }
+
+  NOTREACHED();
+  return v8::Undefined(isolate);
+}
+
+#if defined(NDEBUG)
+static const size_t kMaximumDepth = 2000;
+#else
+// Stack frames in debug builds are generally much larger than in release
+// builds. Use a lower recursion depth to avoid stack overflows (see e.g.
+// http://crbug.com/729334).
+static const size_t kMaximumDepth = 1000;
+#endif
+
+static std::unique_ptr<IDBKey> CreateIDBKeyFromValue(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> value,
+    Vector<v8::Local<v8::Array>>& stack,
+    ExceptionState& exception_state) {
+  if (value->IsNumber() && !std::isnan(value.As<v8::Number>()->Value()))
+    return IDBKey::CreateNumber(value.As<v8::Number>()->Value());
+  if (value->IsString())
+    return IDBKey::CreateString(ToCoreString(value.As<v8::String>()));
+  if (value->IsDate() && !std::isnan(value.As<v8::Date>()->ValueOf()))
+    return IDBKey::CreateDate(value.As<v8::Date>()->ValueOf());
+
+  // https://w3c.github.io/IndexedDB/#convert-a-key-to-a-value
+  if (value->IsArrayBuffer()) {
+    DOMArrayBuffer* buffer = V8ArrayBuffer::ToImpl(value.As<v8::Object>());
+    if (buffer->IsNeutered()) {
+      exception_state.ThrowTypeError("The ArrayBuffer is neutered.");
+      return nullptr;
+    }
+    const char* start = static_cast<const char*>(buffer->Data());
+    size_t length = buffer->ByteLength();
+    return IDBKey::CreateBinary(SharedBuffer::Create(start, length));
+  }
+  if (value->IsArrayBufferView()) {
+    DOMArrayBufferView* view =
+        V8ArrayBufferView::ToImpl(value.As<v8::Object>());
+    if (view->buffer()->IsNeutered()) {
+      exception_state.ThrowTypeError("The viewed ArrayBuffer is neutered.");
+      return nullptr;
+    }
+    const char* start = static_cast<const char*>(view->BaseAddress());
+    size_t length = view->byteLength();
+    return IDBKey::CreateBinary(SharedBuffer::Create(start, length));
+  }
+
+  if (value->IsArray()) {
+    v8::Local<v8::Array> array = value.As<v8::Array>();
+
+    if (stack.Contains(array))
+      return nullptr;
+    if (stack.size() >= kMaximumDepth)
+      return nullptr;
+    stack.push_back(array);
+
+    IDBKey::KeyArray subkeys;
+    uint32_t length = array->Length();
+    v8::TryCatch block(isolate);
+    v8::Local<v8::Context> context = isolate->GetCurrentContext();
+    for (uint32_t i = 0; i < length; ++i) {
+      if (!V8CallBoolean(array->HasOwnProperty(context, i)))
+        return nullptr;
+      v8::Local<v8::Value> item;
+      if (!array->Get(context, i).ToLocal(&item)) {
+        exception_state.RethrowV8Exception(block.Exception());
+        return nullptr;
+      }
+      std::unique_ptr<IDBKey> subkey =
+          CreateIDBKeyFromValue(isolate, item, stack, exception_state);
+      if (!subkey)
+        subkeys.push_back(IDBKey::CreateInvalid());
+      else
+        subkeys.push_back(std::move(subkey));
+    }
+
+    stack.pop_back();
+    return IDBKey::CreateArray(std::move(subkeys));
+  }
+  return nullptr;
+}
+
+static std::unique_ptr<IDBKey> CreateIDBKeyFromValue(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> value,
+    ExceptionState& exception_state) {
+  Vector<v8::Local<v8::Array>> stack;
+  std::unique_ptr<IDBKey> key =
+      CreateIDBKeyFromValue(isolate, value, stack, exception_state);
+  if (!key)
+    key = IDBKey::CreateInvalid();
+  return key;
+}
+
+// Indexed DB key paths should apply to explicitly copied properties (that
+// will be "own" properties when deserialized) as well as the following.
+// http://www.w3.org/TR/IndexedDB/#key-path-construct
+static bool IsImplicitProperty(v8::Isolate* isolate,
+                               v8::Local<v8::Value> value,
+                               const String& name) {
+  if (value->IsString() && name == "length")
+    return true;
+  if (value->IsArray() && name == "length")
+    return true;
+  if (V8Blob::hasInstance(value, isolate))
+    return name == "size" || name == "type";
+  if (V8File::hasInstance(value, isolate))
+    return name == "name" || name == "lastModified" ||
+           name == "lastModifiedDate";
+  return false;
+}
+
+// Assumes a valid key path.
+static Vector<String> ParseKeyPath(const String& key_path) {
+  Vector<String> elements;
+  IDBKeyPathParseError error;
+  IDBParseKeyPath(key_path, elements, error);
+  DCHECK_EQ(error, kIDBKeyPathParseErrorNone);
+  return elements;
+}
+
+static std::unique_ptr<IDBKey> CreateIDBKeyFromValueAndKeyPath(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> v8_value,
+    const String& key_path,
+    ExceptionState& exception_state) {
+  Vector<String> key_path_elements = ParseKeyPath(key_path);
+  DCHECK(isolate->InContext());
+
+  v8::HandleScope handle_scope(isolate);
+  v8::Local<v8::Context> context = isolate->GetCurrentContext();
+  v8::TryCatch block(isolate);
+  for (size_t i = 0; i < key_path_elements.size(); ++i) {
+    const String& element = key_path_elements[i];
+
+    // Special cases from https://w3c.github.io/IndexedDB/#key-path-construct
+    // These access special or non-own properties directly, to avoid side
+    // effects.
+
+    if (v8_value->IsString() && element == "length") {
+      int32_t length = v8_value.As<v8::String>()->Length();
+      v8_value = v8::Number::New(isolate, length);
+      continue;
+    }
+
+    if (v8_value->IsArray() && element == "length") {
+      int32_t length = v8_value.As<v8::Array>()->Length();
+      v8_value = v8::Number::New(isolate, length);
+      continue;
+    }
+
+    if (!v8_value->IsObject())
+      return nullptr;
+    v8::Local<v8::Object> object = v8_value.As<v8::Object>();
+
+    if (V8Blob::hasInstance(object, isolate)) {
+      if (element == "size") {
+        v8_value = v8::Number::New(isolate, V8Blob::ToImpl(object)->size());
+        continue;
+      }
+      if (element == "type") {
+        v8_value = V8String(isolate, V8Blob::ToImpl(object)->type());
+        continue;
+      }
+      // Fall through.
+    }
+
+    if (V8File::hasInstance(object, isolate)) {
+      if (element == "name") {
+        v8_value = V8String(isolate, V8File::ToImpl(object)->name());
+        continue;
+      }
+      if (element == "lastModified") {
+        v8_value =
+            v8::Number::New(isolate, V8File::ToImpl(object)->lastModified());
+        continue;
+      }
+      if (element == "lastModifiedDate") {
+        v8_value =
+            v8::Date::New(context, V8File::ToImpl(object)->lastModifiedDate())
+                .ToLocalChecked();
+        continue;
+      }
+      // Fall through.
+    }
+
+    v8::Local<v8::String> key = V8String(isolate, element);
+    if (!V8CallBoolean(object->HasOwnProperty(context, key)))
+      return nullptr;
+    if (!object->Get(context, key).ToLocal(&v8_value)) {
+      exception_state.RethrowV8Exception(block.Exception());
+      return nullptr;
+    }
+  }
+  return CreateIDBKeyFromValue(isolate, v8_value, exception_state);
+}
+
+static std::unique_ptr<IDBKey> CreateIDBKeyFromValueAndKeyPath(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> value,
+    const IDBKeyPath& key_path,
+    ExceptionState& exception_state) {
+  DCHECK(!key_path.IsNull());
+  v8::HandleScope handle_scope(isolate);
+  if (key_path.GetType() == IDBKeyPath::kArrayType) {
+    IDBKey::KeyArray result;
+    const Vector<String>& array = key_path.Array();
+    for (size_t i = 0; i < array.size(); ++i) {
+      result.emplace_back(CreateIDBKeyFromValueAndKeyPath(
+          isolate, value, array[i], exception_state));
+      if (!result.back())
+        return nullptr;
+    }
+    return IDBKey::CreateArray(std::move(result));
+  }
+
+  DCHECK_EQ(key_path.GetType(), IDBKeyPath::kStringType);
+  return CreateIDBKeyFromValueAndKeyPath(isolate, value, key_path.String(),
+                                         exception_state);
+}
+
+// Deserialize just the value data & blobInfo from the given IDBValue.
+//
+// Primary key injection is performed in deserializeIDBValue() below.
+static v8::Local<v8::Value> DeserializeIDBValueData(v8::Isolate* isolate,
+                                                    const IDBValue* value) {
+  DCHECK(isolate->InContext());
+  if (!value || value->IsNull())
+    return v8::Null(isolate);
+
+  scoped_refptr<SerializedScriptValue> serialized_value =
+      value->CreateSerializedValue();
+  SerializedScriptValue::DeserializeOptions options;
+  options.blob_info = &value->BlobInfo();
+  options.read_wasm_from_stream = true;
+
+  // deserialize() returns null when serialization fails.  This is sub-optimal
+  // because IndexedDB values can be null, so an application cannot distinguish
+  // between a de-serialization failure and a legitimately stored null value.
+  //
+  // TODO(crbug.com/703704): Ideally, SerializedScriptValue should return an
+  // empty handle on serialization errors, which should be handled by higher
+  // layers. For example, IndexedDB could throw an exception, abort the
+  // transaction, or close the database connection.
+  return serialized_value->Deserialize(isolate, options);
+}
+
+// Deserialize the entire IDBValue.
+//
+// On top of deserializeIDBValueData(), this handles the special case of having
+// to inject a key into the de-serialized value. See injectV8KeyIntoV8Value()
+// for details.
+v8::Local<v8::Value> DeserializeIDBValue(v8::Isolate* isolate,
+                                         v8::Local<v8::Object> creation_context,
+                                         const IDBValue* value) {
+  DCHECK(isolate->InContext());
+  if (!value || value->IsNull())
+    return v8::Null(isolate);
+
+  v8::Local<v8::Value> v8_value = DeserializeIDBValueData(isolate, value);
+  if (value->PrimaryKey()) {
+    v8::Local<v8::Value> key =
+        ToV8(value->PrimaryKey(), creation_context, isolate);
+    if (key.IsEmpty())
+      return v8::Local<v8::Value>();
+
+    InjectV8KeyIntoV8Value(isolate, key, v8_value, value->KeyPath());
+
+    // TODO(crbug.com/703704): Throw an error here or at a higher layer if
+    // injectV8KeyIntoV8Value() returns false, which means that the serialized
+    // value got corrupted while on disk.
+  }
+
+  return v8_value;
+}
+
+static v8::Local<v8::Value> DeserializeIDBValueArray(
+    v8::Isolate* isolate,
+    v8::Local<v8::Object> creation_context,
+    const Vector<std::unique_ptr<IDBValue>>& values) {
+  DCHECK(isolate->InContext());
+
+  v8::Local<v8::Context> context = isolate->GetCurrentContext();
+  v8::Local<v8::Array> array = v8::Array::New(isolate, values.size());
+  for (size_t i = 0; i < values.size(); ++i) {
+    v8::Local<v8::Value> v8_value =
+        DeserializeIDBValue(isolate, creation_context, values[i].get());
+    if (v8_value.IsEmpty())
+      v8_value = v8::Undefined(isolate);
+    if (!V8CallBoolean(array->CreateDataProperty(context, i, v8_value)))
+      return V8Undefined();
+  }
+
+  return array;
+}
+
+// Injects a primary key into a deserialized V8 value.
+//
+// In general, the value stored in IndexedDB is the serialized version of a
+// value passed to the API. However, the specification has a special case of
+// object stores that specify a key path and have a key generator. In this case,
+// the conceptual description in the spec states that the key produced by the
+// key generator is injected into the value before it is written to IndexedDB.
+//
+// We cannot implementing the spec's conceptual description. We need to assign
+// primary keys in the browser process, to ensure that multiple renderer
+// processes talking to the same database receive sequential keys. At the same
+// time, we want the value serialization code to live in the renderer process,
+// because this type of code is a likely victim to security exploits.
+//
+// We handle this special case by serializing and writing values without the
+// corresponding keys. At read time, we obtain the keys and the values
+// separately, and we inject the keys into values.
+bool InjectV8KeyIntoV8Value(v8::Isolate* isolate,
+                            v8::Local<v8::Value> key,
+                            v8::Local<v8::Value> value,
+                            const IDBKeyPath& key_path) {
+  IDB_TRACE("injectIDBV8KeyIntoV8Value");
+  DCHECK(isolate->InContext());
+
+  DCHECK_EQ(key_path.GetType(), IDBKeyPath::kStringType);
+  Vector<String> key_path_elements = ParseKeyPath(key_path.String());
+
+  // The conbination of a key generator and an empty key path is forbidden by
+  // spec.
+  if (!key_path_elements.size()) {
+    NOTREACHED();
+    return false;
+  }
+
+  v8::HandleScope handle_scope(isolate);
+  v8::Local<v8::Context> context = isolate->GetCurrentContext();
+
+  // For an object o = {} which should have keypath 'a.b.c' and key k, this
+  // populates o to be {a:{b:{}}}. This is only applied to deserialized
+  // values, so we can assume that there are no getters/setters on the
+  // object itself (though there might be on the prototype chain).
+  //
+  // Previous versions of this code assumed that the deserialized value meets
+  // the constraints checked by the serialization validation code. For example,
+  // given a keypath of a.b.c, the code assumed that the de-serialized value
+  // cannot possibly be {a:{b:42}}. This is not a safe assumption.
+  //
+  // IndexedDB's backing store (LevelDB) does use CRC32C to protect against disk
+  // errors. However, this does not prevent corruption caused by bugs in the
+  // higher level code writing invalid values. The following cases are
+  // interesting here.
+  //
+  // (1) Deserialization failures, which are currently handled by returning
+  // null. Disk errors aside, deserialization errors can also occur when a user
+  // switches channels and receives an older build which does not support the
+  // serialization format used by the previous (more recent) build that the user
+  // had.
+  //
+  // (2) Bugs that write a value which is incompatible with the primary key
+  // injection required by the object store. The simplest example is writing
+  // numbers or booleans to an object store with an auto-incrementing primary
+  // keys.
+  for (size_t i = 0; i < key_path_elements.size() - 1; ++i) {
+    if (!value->IsObject())
+      return false;
+
+    const String& key_path_element = key_path_elements[i];
+    DCHECK(!IsImplicitProperty(isolate, value, key_path_element));
+    v8::Local<v8::Object> object = value.As<v8::Object>();
+    v8::Local<v8::String> property = V8String(isolate, key_path_element);
+    bool has_own_property;
+    if (!object->HasOwnProperty(context, property).To(&has_own_property))
+      return false;
+    if (has_own_property) {
+      if (!object->Get(context, property).ToLocal(&value))
+        return false;
+    } else {
+      value = v8::Object::New(isolate);
+      if (!V8CallBoolean(object->CreateDataProperty(context, property, value)))
+        return false;
+    }
+  }
+
+  // Implicit properties don't need to be set. The caller is not required to
+  // be aware of this, so this is an expected no-op. The caller can verify
+  // that the value is correct via assertPrimaryKeyValidOrInjectable.
+  if (IsImplicitProperty(isolate, value, key_path_elements.back()))
+    return true;
+
+  // If the key path does not point to an implicit property, the value must be
+  // an object. Previous code versions DCHECKed this, which is unsafe in the
+  // event of database corruption or version skew in the serialization format.
+  if (!value->IsObject())
+    return false;
+
+  v8::Local<v8::Object> object = value.As<v8::Object>();
+  v8::Local<v8::String> property = V8String(isolate, key_path_elements.back());
+  if (!V8CallBoolean(object->CreateDataProperty(context, property, key)))
+    return false;
+
+  return true;
+}
+
+// Verify that an value can have an generated key inserted at the location
+// specified by the key path (by injectV8KeyIntoV8Value) when the object is
+// later deserialized.
+bool CanInjectIDBKeyIntoScriptValue(v8::Isolate* isolate,
+                                    const ScriptValue& script_value,
+                                    const IDBKeyPath& key_path) {
+  IDB_TRACE("canInjectIDBKeyIntoScriptValue");
+  DCHECK_EQ(key_path.GetType(), IDBKeyPath::kStringType);
+  Vector<String> key_path_elements = ParseKeyPath(key_path.String());
+
+  if (!key_path_elements.size())
+    return false;
+
+  v8::Local<v8::Value> current(script_value.V8Value());
+  if (!current->IsObject())
+    return false;
+
+  v8::Local<v8::Context> context = isolate->GetCurrentContext();
+  for (size_t i = 0; i < key_path_elements.size(); ++i) {
+    const String& key_path_element = key_path_elements[i];
+    // Can't overwrite properties like array or string length.
+    if (IsImplicitProperty(isolate, current, key_path_element))
+      return false;
+    // Can't set properties on non-objects.
+    if (!current->IsObject())
+      return false;
+    v8::Local<v8::Object> object = current.As<v8::Object>();
+    v8::Local<v8::String> property = V8String(isolate, key_path_element);
+    // If the value lacks an "own" property, it can be added - either as
+    // an intermediate object or as the final value.
+    bool has_own_property;
+    if (!object->HasOwnProperty(context, property).To(&has_own_property))
+      return false;
+    if (!has_own_property)
+      return true;
+    // Otherwise, get it and keep traversing.
+    if (!object->Get(context, property).ToLocal(&current))
+      return false;
+  }
+  return true;
+}
+
+ScriptValue DeserializeScriptValue(ScriptState* script_state,
+                                   SerializedScriptValue* serialized_value,
+                                   const Vector<WebBlobInfo>* blob_info,
+                                   bool read_wasm_from_stream) {
+  v8::Isolate* isolate = script_state->GetIsolate();
+  v8::HandleScope handle_scope(isolate);
+  if (!serialized_value)
+    return ScriptValue::CreateNull(script_state);
+
+  SerializedScriptValue::DeserializeOptions options;
+  options.blob_info = blob_info;
+  options.read_wasm_from_stream = read_wasm_from_stream;
+  return ScriptValue(script_state,
+                     serialized_value->Deserialize(isolate, options));
+}
+
+SQLValue NativeValueTraits<SQLValue>::NativeValue(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> value,
+    ExceptionState& exception_state) {
+  if (value.IsEmpty() || value->IsNull())
+    return SQLValue();
+  if (value->IsNumber())
+    return SQLValue(value.As<v8::Number>()->Value());
+  V8StringResource<> string_value(value);
+  if (!string_value.Prepare(exception_state))
+    return SQLValue();
+  return SQLValue(string_value);
+}
+
+std::unique_ptr<IDBKey> NativeValueTraits<std::unique_ptr<IDBKey>>::NativeValue(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> value,
+    ExceptionState& exception_state) {
+  return CreateIDBKeyFromValue(isolate, value, exception_state);
+}
+
+std::unique_ptr<IDBKey> NativeValueTraits<std::unique_ptr<IDBKey>>::NativeValue(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> value,
+    ExceptionState& exception_state,
+    const IDBKeyPath& key_path) {
+  IDB_TRACE("createIDBKeyFromValueAndKeyPath");
+  return CreateIDBKeyFromValueAndKeyPath(isolate, value, key_path,
+                                         exception_state);
+}
+
+IDBKeyRange* NativeValueTraits<IDBKeyRange*>::NativeValue(
+    v8::Isolate* isolate,
+    v8::Local<v8::Value> value,
+    ExceptionState& exception_state) {
+  return V8IDBKeyRange::ToImplWithTypeCheck(isolate, value);
+}
+
+#if DCHECK_IS_ON()
+// This assertion is used when a value has been retrieved from an object store
+// with implicit keys (i.e. a key path). It verifies that either the value
+// contains an implicit key matching the primary key (so it was correctly
+// extracted when stored) or that the key can be inserted as an own property.
+void AssertPrimaryKeyValidOrInjectable(ScriptState* script_state,
+                                       const IDBValue* value) {
+  ScriptState::Scope scope(script_state);
+  v8::Isolate* isolate = script_state->GetIsolate();
+  ScriptValue key_value = ScriptValue::From(script_state, value->PrimaryKey());
+  ScriptValue script_value(script_state,
+                           DeserializeIDBValueData(isolate, value));
+
+  DummyExceptionStateForTesting exception_state;
+  std::unique_ptr<IDBKey> expected_key = CreateIDBKeyFromValueAndKeyPath(
+      isolate, script_value.V8Value(), value->KeyPath(), exception_state);
+  DCHECK(!exception_state.HadException());
+  if (expected_key && expected_key->IsEqual(value->PrimaryKey()))
+    return;
+
+  bool injected = InjectV8KeyIntoV8Value(
+      isolate, key_value.V8Value(), script_value.V8Value(), value->KeyPath());
+  DCHECK(injected);
+}
+#endif  // DCHECK_IS_ON()
+
+}  // namespace blink
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.h chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.h
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.h	2018-03-21 01:05:48.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.h	2018-04-27 11:31:20.463829613 +0300
@@ -49,7 +49,7 @@
      * to the value of NodeType for the equivalent node type.
      */
   enum {
-    kShowAll = 0xFFFFFFFF,
+    kShowAll = 256 /* 0xFFFFFFFF */,
     kShowElement = 0x00000001,
     kShowAttribute = 0x00000002,
     kShowText = 0x00000004,
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.h.gcc5 chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.h.gcc5
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.h.gcc5	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.h.gcc5	2018-03-21 01:05:48.000000000 +0300
@@ -0,0 +1,70 @@
+/*
+ * Copyright (C) 1999 Lars Knoll (knoll@kde.org)
+ * Copyright (C) 2000 Frederik Holljen (frederik.holljen@hig.no)
+ * Copyright (C) 2001 Peter Kelly (pmk@post.com)
+ * Copyright (C) 2006 Samuel Weinig (sam.weinig@gmail.com)
+ * Copyright (C) 2004, 2008, 2009 Apple Inc. All rights reserved.
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public License
+ * along with this library; see the file COPYING.LIB.  If not, write to
+ * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ *
+ */
+
+#ifndef NodeFilter_h
+#define NodeFilter_h
+
+#include "platform/heap/Handle.h"
+
+namespace blink {
+
+// We never create NodeFilter instances.
+// The IDL interface 'NodeFilter' is represented by V8NodeFilterCondition and a
+// V8 value in Blink.
+class NodeFilter final {
+  STATIC_ONLY(NodeFilter);
+
+ public:
+  /**
+     * The following constants are returned by the acceptNode()
+     * method:
+     */
+  enum { kFilterAccept = 1, kFilterReject = 2, kFilterSkip = 3 };
+
+  /**
+     * These are the available values for the whatToShow parameter.
+     * They are the same as the set of possible types for Node, and
+     * their values are derived by using a bit position corresponding
+     * to the value of NodeType for the equivalent node type.
+     */
+  enum {
+    kShowAll = 0xFFFFFFFF,
+    kShowElement = 0x00000001,
+    kShowAttribute = 0x00000002,
+    kShowText = 0x00000004,
+    kShowCdataSection = 0x00000008,
+    kShowEntityReference = 0x00000010,
+    kShowEntity = 0x00000020,
+    kShowProcessingInstruction = 0x00000040,
+    kShowComment = 0x00000080,
+    kShowDocument = 0x00000100,
+    kShowDocumentType = 0x00000200,
+    kShowDocumentFragment = 0x00000400,
+    kShowNotation = 0x00000800
+  };
+};
+
+}  // namespace blink
+
+#endif  // NodeFilter_h
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.idl chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.idl
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.idl	2018-03-21 01:05:48.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.idl	2018-04-27 11:31:20.463829613 +0300
@@ -27,7 +27,7 @@
     const unsigned short FILTER_SKIP = 3;
 
     // Constants for whatToShow
-    const unsigned long SHOW_ALL = 0xFFFFFFFF;
+    const unsigned long SHOW_ALL = 256; // 0xFFFFFFFF
     const unsigned long SHOW_ELEMENT = 0x1;
     const unsigned long SHOW_ATTRIBUTE = 0x2; // historical
     const unsigned long SHOW_TEXT = 0x4;
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.idl.gcc5 chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.idl.gcc5
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/core/dom/NodeFilter.idl.gcc5	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/core/dom/NodeFilter.idl.gcc5	2018-03-21 01:05:48.000000000 +0300
@@ -0,0 +1,48 @@
+/*
+ * Copyright (C) 2006, 2007, 2008 Apple Inc. All rights reserved.
+ * Copyright (C) 2006 Samuel Weinig <sam.weinig@gmail.com>
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Library General Public
+ * License as published by the Free Software Foundation; either
+ * version 2 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Library General Public License for more details.
+ *
+ * You should have received a copy of the GNU Library General Public License
+ * along with this library; see the file COPYING.LIB.  If not, write to
+ * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
+ * Boston, MA 02110-1301, USA.
+ */
+
+// https://dom.spec.whatwg.org/#interface-nodefilter
+
+callback interface NodeFilter {
+    // Constants for acceptNode()
+    const unsigned short FILTER_ACCEPT = 1;
+    const unsigned short FILTER_REJECT = 2;
+    const unsigned short FILTER_SKIP = 3;
+
+    // Constants for whatToShow
+    const unsigned long SHOW_ALL = 0xFFFFFFFF;
+    const unsigned long SHOW_ELEMENT = 0x1;
+    const unsigned long SHOW_ATTRIBUTE = 0x2; // historical
+    const unsigned long SHOW_TEXT = 0x4;
+    const unsigned long SHOW_CDATA_SECTION = 0x8;
+    const unsigned long SHOW_ENTITY_REFERENCE = 0x10; // historical
+    const unsigned long SHOW_ENTITY = 0x20; // historical
+    const unsigned long SHOW_PROCESSING_INSTRUCTION = 0x40;
+    const unsigned long SHOW_COMMENT = 0x80;
+    const unsigned long SHOW_DOCUMENT = 0x100;
+    const unsigned long SHOW_DOCUMENT_TYPE = 0x200;
+    const unsigned long SHOW_DOCUMENT_FRAGMENT = 0x400;
+    const unsigned long SHOW_NOTATION = 0x800; // historical
+
+    // This function declaration doesn't generate any code because
+    // V8NodeFilterCondition represents this callback interface in Blink.
+    // TODO(bashi): Fix crbug.com/630986, and use generated code.
+    [RaisesException] unsigned short acceptNode(Node node);
+};
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp	2018-04-27 11:31:20.655827593 +0300
@@ -56,7 +56,7 @@
 }
 
 WebString WebIDBKeyView::String() const {
-  return private_->String();
+  return private_->GetString();
 }
 
 double WebIDBKeyView::Date() const {
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp.GetString chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp.GetString
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp.GetString	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/exported/WebIDBKey.cpp.GetString	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,114 @@
+/*
+ * Copyright (C) 2011 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "public/platform/modules/indexeddb/WebIDBKey.h"
+
+#include "modules/indexeddb/IDBKey.h"
+
+namespace blink {
+
+size_t WebIDBKeyArrayView::size() const {
+  return private_->Array().size();
+}
+
+WebIDBKeyView WebIDBKeyArrayView::operator[](size_t index) const {
+  return WebIDBKeyView(private_->Array()[index].get());
+}
+
+WebIDBKeyType WebIDBKeyView::KeyType() const {
+  if (!private_)
+    return kWebIDBKeyTypeNull;
+  return static_cast<WebIDBKeyType>(private_->GetType());
+}
+
+bool WebIDBKeyView::IsValid() const {
+  if (!private_)
+    return false;
+  return private_->IsValid();
+}
+
+WebData WebIDBKeyView::Binary() const {
+  return private_->Binary();
+}
+
+WebString WebIDBKeyView::String() const {
+  return private_->String();
+}
+
+double WebIDBKeyView::Date() const {
+  return private_->Date();
+}
+
+double WebIDBKeyView::Number() const {
+  return private_->Number();
+}
+
+WebIDBKey WebIDBKey::CreateArray(WebVector<WebIDBKey> array) {
+  IDBKey::KeyArray keys;
+  keys.ReserveCapacity(array.size());
+  for (WebIDBKey& key : array) {
+    DCHECK(key.View().KeyType() != kWebIDBKeyTypeNull);
+    keys.emplace_back(key.ReleaseIdbKey());
+  }
+  return WebIDBKey(IDBKey::CreateArray(std::move(keys)));
+}
+
+WebIDBKey WebIDBKey::CreateBinary(const WebData& binary) {
+  return WebIDBKey(IDBKey::CreateBinary(binary));
+}
+
+WebIDBKey WebIDBKey::CreateString(const WebString& string) {
+  return WebIDBKey(IDBKey::CreateString(string));
+}
+
+WebIDBKey WebIDBKey::CreateDate(double date) {
+  return WebIDBKey(IDBKey::CreateDate(date));
+}
+
+WebIDBKey WebIDBKey::CreateNumber(double number) {
+  return WebIDBKey(IDBKey::CreateNumber(number));
+}
+
+WebIDBKey WebIDBKey::CreateInvalid() {
+  return WebIDBKey(IDBKey::CreateInvalid());
+}
+
+WebIDBKey::WebIDBKey() noexcept = default;
+
+WebIDBKey::WebIDBKey(WebIDBKey&&) noexcept = default;
+WebIDBKey& WebIDBKey::operator=(WebIDBKey&&) noexcept = default;
+
+WebIDBKey::~WebIDBKey() noexcept = default;
+
+WebIDBKey::WebIDBKey(std::unique_ptr<IDBKey> idb_key) noexcept
+    : private_(std::move(idb_key)) {}
+WebIDBKey& WebIDBKey::operator=(std::unique_ptr<IDBKey> idb_key) noexcept {
+  private_ = std::move(idb_key);
+  return *this;
+}
+
+}  // namespace blink
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp	2018-04-27 11:31:20.655827593 +0300
@@ -297,7 +297,7 @@
   }
 
   if (auto_increment && ((key_path.GetType() == IDBKeyPath::kStringType &&
-                          key_path.String().IsEmpty()) ||
+                          key_path.GetString().IsEmpty()) ||
                          key_path.GetType() == IDBKeyPath::kArrayType)) {
     exception_state.ThrowDOMException(
         kInvalidAccessError,
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp.GetString chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp.GetString
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp.GetString	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBDatabase.cpp.GetString	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,625 @@
+/*
+ * Copyright (C) 2010 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1.  Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ * 2.  Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in the
+ *     documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS "AS IS" AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "modules/indexeddb/IDBDatabase.h"
+
+#include "bindings/core/v8/ExceptionState.h"
+#include "bindings/core/v8/Nullable.h"
+#include "bindings/core/v8/serialization/SerializedScriptValue.h"
+#include "bindings/modules/v8/V8BindingForModules.h"
+#include "bindings/modules/v8/v8_idb_observer_callback.h"
+#include "core/dom/ExceptionCode.h"
+#include "core/dom/ExecutionContext.h"
+#include "core/dom/events/EventQueue.h"
+#include "modules/indexeddb/IDBAny.h"
+#include "modules/indexeddb/IDBEventDispatcher.h"
+#include "modules/indexeddb/IDBIndex.h"
+#include "modules/indexeddb/IDBKeyPath.h"
+#include "modules/indexeddb/IDBObserver.h"
+#include "modules/indexeddb/IDBObserverChanges.h"
+#include "modules/indexeddb/IDBTracing.h"
+#include "modules/indexeddb/IDBVersionChangeEvent.h"
+#include "modules/indexeddb/WebIDBDatabaseCallbacksImpl.h"
+#include "platform/Histogram.h"
+#include "platform/wtf/Assertions.h"
+#include "platform/wtf/Atomics.h"
+#include "public/platform/modules/indexeddb/WebIDBDatabaseCallbacks.h"
+#include "public/platform/modules/indexeddb/WebIDBDatabaseException.h"
+#include "public/platform/modules/indexeddb/WebIDBKeyPath.h"
+#include "public/platform/modules/indexeddb/WebIDBObservation.h"
+#include "public/platform/modules/indexeddb/WebIDBTypes.h"
+
+#include <limits>
+#include <memory>
+
+using blink::WebIDBDatabase;
+
+namespace blink {
+
+const char IDBDatabase::kCannotObserveVersionChangeTransaction[] =
+    "An observer cannot target a version change transaction.";
+const char IDBDatabase::kIndexDeletedErrorMessage[] =
+    "The index or its object store has been deleted.";
+const char IDBDatabase::kIndexNameTakenErrorMessage[] =
+    "An index with the specified name already exists.";
+const char IDBDatabase::kIsKeyCursorErrorMessage[] =
+    "The cursor is a key cursor.";
+const char IDBDatabase::kNoKeyOrKeyRangeErrorMessage[] =
+    "No key or key range specified.";
+const char IDBDatabase::kNoSuchIndexErrorMessage[] =
+    "The specified index was not found.";
+const char IDBDatabase::kNoSuchObjectStoreErrorMessage[] =
+    "The specified object store was not found.";
+const char IDBDatabase::kNoValueErrorMessage[] =
+    "The cursor is being iterated or has iterated past its end.";
+const char IDBDatabase::kNotValidKeyErrorMessage[] =
+    "The parameter is not a valid key.";
+const char IDBDatabase::kNotVersionChangeTransactionErrorMessage[] =
+    "The database is not running a version change transaction.";
+const char IDBDatabase::kObjectStoreDeletedErrorMessage[] =
+    "The object store has been deleted.";
+const char IDBDatabase::kObjectStoreNameTakenErrorMessage[] =
+    "An object store with the specified name already exists.";
+const char IDBDatabase::kRequestNotFinishedErrorMessage[] =
+    "The request has not finished.";
+const char IDBDatabase::kSourceDeletedErrorMessage[] =
+    "The cursor's source or effective object store has been deleted.";
+const char IDBDatabase::kTransactionInactiveErrorMessage[] =
+    "The transaction is not active.";
+const char IDBDatabase::kTransactionFinishedErrorMessage[] =
+    "The transaction has finished.";
+const char IDBDatabase::kTransactionReadOnlyErrorMessage[] =
+    "The transaction is read-only.";
+const char IDBDatabase::kDatabaseClosedErrorMessage[] =
+    "The database connection is closed.";
+
+IDBDatabase* IDBDatabase::Create(ExecutionContext* context,
+                                 std::unique_ptr<WebIDBDatabase> database,
+                                 IDBDatabaseCallbacks* callbacks,
+                                 v8::Isolate* isolate) {
+  return new IDBDatabase(context, std::move(database), callbacks, isolate);
+}
+
+IDBDatabase::IDBDatabase(ExecutionContext* context,
+                         std::unique_ptr<WebIDBDatabase> backend,
+                         IDBDatabaseCallbacks* callbacks,
+                         v8::Isolate* isolate)
+    : ContextLifecycleObserver(context),
+      backend_(std::move(backend)),
+      database_callbacks_(callbacks),
+      isolate_(isolate) {
+  database_callbacks_->Connect(this);
+}
+
+IDBDatabase::~IDBDatabase() {
+  if (!close_pending_ && backend_)
+    backend_->Close();
+}
+
+void IDBDatabase::Trace(blink::Visitor* visitor) {
+  visitor->Trace(version_change_transaction_);
+  visitor->Trace(transactions_);
+  visitor->Trace(observers_);
+  visitor->Trace(enqueued_events_);
+  visitor->Trace(database_callbacks_);
+  EventTargetWithInlineData::Trace(visitor);
+  ContextLifecycleObserver::Trace(visitor);
+}
+
+void IDBDatabase::TraceWrappers(const ScriptWrappableVisitor* visitor) const {
+  for (const auto& observer : observers_.Values()) {
+    visitor->TraceWrappers(observer);
+  }
+  EventTargetWithInlineData::TraceWrappers(visitor);
+}
+
+int64_t IDBDatabase::NextTransactionId() {
+  // Only keep a 32-bit counter to allow ports to use the other 32
+  // bits of the id.
+  static int current_transaction_id = 0;
+  return AtomicIncrement(&current_transaction_id);
+}
+
+int32_t IDBDatabase::NextObserverId() {
+  static int current_observer_id = 0;
+  return AtomicIncrement(&current_observer_id);
+}
+
+void IDBDatabase::SetMetadata(const IDBDatabaseMetadata& metadata) {
+  metadata_ = metadata;
+}
+
+void IDBDatabase::SetDatabaseMetadata(const IDBDatabaseMetadata& metadata) {
+  metadata_.CopyFrom(metadata);
+}
+
+void IDBDatabase::TransactionCreated(IDBTransaction* transaction) {
+  DCHECK(transaction);
+  DCHECK(!transactions_.Contains(transaction->Id()));
+  transactions_.insert(transaction->Id(), transaction);
+
+  if (transaction->IsVersionChange()) {
+    DCHECK(!version_change_transaction_);
+    version_change_transaction_ = transaction;
+  }
+}
+
+void IDBDatabase::TransactionFinished(const IDBTransaction* transaction) {
+  DCHECK(transaction);
+  DCHECK(transactions_.Contains(transaction->Id()));
+  DCHECK_EQ(transactions_.at(transaction->Id()), transaction);
+  transactions_.erase(transaction->Id());
+
+  if (transaction->IsVersionChange()) {
+    DCHECK_EQ(version_change_transaction_, transaction);
+    version_change_transaction_ = nullptr;
+  }
+
+  if (close_pending_ && transactions_.IsEmpty())
+    CloseConnection();
+}
+
+void IDBDatabase::OnAbort(int64_t transaction_id, DOMException* error) {
+  DCHECK(transactions_.Contains(transaction_id));
+  transactions_.at(transaction_id)->OnAbort(error);
+}
+
+void IDBDatabase::OnComplete(int64_t transaction_id) {
+  DCHECK(transactions_.Contains(transaction_id));
+  transactions_.at(transaction_id)->OnComplete();
+}
+
+void IDBDatabase::OnChanges(
+    const WebIDBDatabaseCallbacks::ObservationIndexMap& observation_index_map,
+    WebVector<WebIDBObservation> web_observations,
+    const WebIDBDatabaseCallbacks::TransactionMap& transactions) {
+  HeapVector<Member<IDBObservation>> observations;
+  observations.ReserveInitialCapacity(web_observations.size());
+  for (WebIDBObservation& web_observation : web_observations) {
+    observations.emplace_back(
+        IDBObservation::Create(std::move(web_observation), isolate_));
+  }
+
+  for (const auto& map_entry : observation_index_map) {
+    auto it = observers_.find(map_entry.first);
+    if (it != observers_.end()) {
+      IDBObserver* observer = it->value;
+
+      IDBTransaction* transaction = nullptr;
+      auto it = transactions.find(map_entry.first);
+      if (it != transactions.end()) {
+        const std::pair<int64_t, std::vector<int64_t>>& obs_txn = it->second;
+        HashSet<String> stores;
+        for (int64_t store_id : obs_txn.second) {
+          stores.insert(metadata_.object_stores.at(store_id)->name);
+        }
+
+        transaction = IDBTransaction::CreateObserver(
+            GetExecutionContext(), obs_txn.first, stores, this);
+      }
+
+      observer->Callback()->InvokeAndReportException(
+          observer,
+          IDBObserverChanges::Create(this, transaction, web_observations,
+                                     observations, map_entry.second));
+      if (transaction)
+        transaction->SetActive(false);
+    }
+  }
+}
+
+DOMStringList* IDBDatabase::objectStoreNames() const {
+  DOMStringList* object_store_names = DOMStringList::Create();
+  for (const auto& it : metadata_.object_stores)
+    object_store_names->Append(it.value->name);
+  object_store_names->Sort();
+  return object_store_names;
+}
+
+const String& IDBDatabase::GetObjectStoreName(int64_t object_store_id) const {
+  const auto& it = metadata_.object_stores.find(object_store_id);
+  DCHECK(it != metadata_.object_stores.end());
+  return it->value->name;
+}
+
+int32_t IDBDatabase::AddObserver(
+    IDBObserver* observer,
+    int64_t transaction_id,
+    bool include_transaction,
+    bool no_records,
+    bool values,
+    const std::bitset<kWebIDBOperationTypeCount>& operation_types) {
+  int32_t observer_id = NextObserverId();
+  observers_.Set(observer_id, observer);
+  Backend()->AddObserver(transaction_id, observer_id, include_transaction,
+                         no_records, values, operation_types);
+  return observer_id;
+}
+
+void IDBDatabase::RemoveObservers(const Vector<int32_t>& observer_ids) {
+  observers_.RemoveAll(observer_ids);
+  Backend()->RemoveObservers(observer_ids);
+}
+
+IDBObjectStore* IDBDatabase::createObjectStore(
+    const String& name,
+    const IDBKeyPath& key_path,
+    bool auto_increment,
+    ExceptionState& exception_state) {
+  IDB_TRACE("IDBDatabase::createObjectStore");
+  RecordApiCallsHistogram(kIDBCreateObjectStoreCall);
+
+  if (!version_change_transaction_) {
+    exception_state.ThrowDOMException(
+        kInvalidStateError,
+        IDBDatabase::kNotVersionChangeTransactionErrorMessage);
+    return nullptr;
+  }
+  if (!version_change_transaction_->IsActive()) {
+    exception_state.ThrowDOMException(
+        kTransactionInactiveError,
+        version_change_transaction_->InactiveErrorMessage());
+    return nullptr;
+  }
+
+  if (!key_path.IsNull() && !key_path.IsValid()) {
+    exception_state.ThrowDOMException(
+        kSyntaxError, "The keyPath option is not a valid key path.");
+    return nullptr;
+  }
+
+  if (ContainsObjectStore(name)) {
+    exception_state.ThrowDOMException(
+        kConstraintError, IDBDatabase::kObjectStoreNameTakenErrorMessage);
+    return nullptr;
+  }
+
+  if (auto_increment && ((key_path.GetType() == IDBKeyPath::kStringType &&
+                          key_path.String().IsEmpty()) ||
+                         key_path.GetType() == IDBKeyPath::kArrayType)) {
+    exception_state.ThrowDOMException(
+        kInvalidAccessError,
+        "The autoIncrement option was set but the "
+        "keyPath option was empty or an array.");
+    return nullptr;
+  }
+
+  if (!backend_) {
+    exception_state.ThrowDOMException(kInvalidStateError,
+                                      IDBDatabase::kDatabaseClosedErrorMessage);
+    return nullptr;
+  }
+
+  int64_t object_store_id = metadata_.max_object_store_id + 1;
+  DCHECK_NE(object_store_id, IDBObjectStoreMetadata::kInvalidId);
+  backend_->CreateObjectStore(version_change_transaction_->Id(),
+                              object_store_id, name, key_path, auto_increment);
+
+  scoped_refptr<IDBObjectStoreMetadata> store_metadata =
+      base::AdoptRef(new IDBObjectStoreMetadata(
+          name, object_store_id, key_path, auto_increment,
+          WebIDBDatabase::kMinimumIndexId));
+  IDBObjectStore* object_store =
+      IDBObjectStore::Create(store_metadata, version_change_transaction_.Get());
+  version_change_transaction_->ObjectStoreCreated(name, object_store);
+  metadata_.object_stores.Set(object_store_id, std::move(store_metadata));
+  ++metadata_.max_object_store_id;
+
+  return object_store;
+}
+
+void IDBDatabase::deleteObjectStore(const String& name,
+                                    ExceptionState& exception_state) {
+  IDB_TRACE("IDBDatabase::deleteObjectStore");
+  RecordApiCallsHistogram(kIDBDeleteObjectStoreCall);
+  if (!version_change_transaction_) {
+    exception_state.ThrowDOMException(
+        kInvalidStateError,
+        IDBDatabase::kNotVersionChangeTransactionErrorMessage);
+    return;
+  }
+  if (!version_change_transaction_->IsActive()) {
+    exception_state.ThrowDOMException(
+        kTransactionInactiveError,
+        version_change_transaction_->InactiveErrorMessage());
+    return;
+  }
+
+  int64_t object_store_id = FindObjectStoreId(name);
+  if (object_store_id == IDBObjectStoreMetadata::kInvalidId) {
+    exception_state.ThrowDOMException(
+        kNotFoundError, "The specified object store was not found.");
+    return;
+  }
+
+  if (!backend_) {
+    exception_state.ThrowDOMException(kInvalidStateError,
+                                      IDBDatabase::kDatabaseClosedErrorMessage);
+    return;
+  }
+
+  backend_->DeleteObjectStore(version_change_transaction_->Id(),
+                              object_store_id);
+  version_change_transaction_->ObjectStoreDeleted(object_store_id, name);
+  metadata_.object_stores.erase(object_store_id);
+}
+
+IDBTransaction* IDBDatabase::transaction(
+    ScriptState* script_state,
+    const StringOrStringSequence& store_names,
+    const String& mode_string,
+    ExceptionState& exception_state) {
+  IDB_TRACE("IDBDatabase::transaction");
+  RecordApiCallsHistogram(kIDBTransactionCall);
+
+  HashSet<String> scope;
+  if (store_names.IsString()) {
+    scope.insert(store_names.GetAsString());
+  } else if (store_names.IsStringSequence()) {
+    for (const String& name : store_names.GetAsStringSequence())
+      scope.insert(name);
+  } else {
+    NOTREACHED();
+  }
+
+  if (version_change_transaction_) {
+    exception_state.ThrowDOMException(
+        kInvalidStateError, "A version change transaction is running.");
+    return nullptr;
+  }
+
+  if (close_pending_) {
+    exception_state.ThrowDOMException(kInvalidStateError,
+                                      "The database connection is closing.");
+    return nullptr;
+  }
+
+  if (!backend_) {
+    exception_state.ThrowDOMException(kInvalidStateError,
+                                      IDBDatabase::kDatabaseClosedErrorMessage);
+    return nullptr;
+  }
+
+  if (scope.IsEmpty()) {
+    exception_state.ThrowDOMException(kInvalidAccessError,
+                                      "The storeNames parameter was empty.");
+    return nullptr;
+  }
+
+  Vector<int64_t> object_store_ids;
+  for (const String& name : scope) {
+    int64_t object_store_id = FindObjectStoreId(name);
+    if (object_store_id == IDBObjectStoreMetadata::kInvalidId) {
+      exception_state.ThrowDOMException(
+          kNotFoundError, "One of the specified object stores was not found.");
+      return nullptr;
+    }
+    object_store_ids.push_back(object_store_id);
+  }
+
+  WebIDBTransactionMode mode = IDBTransaction::StringToMode(mode_string);
+  if (mode != kWebIDBTransactionModeReadOnly &&
+      mode != kWebIDBTransactionModeReadWrite) {
+    exception_state.ThrowTypeError(
+        "The mode provided ('" + mode_string +
+        "') is not one of 'readonly' or 'readwrite'.");
+    return nullptr;
+  }
+
+  int64_t transaction_id = NextTransactionId();
+  backend_->CreateTransaction(transaction_id, object_store_ids, mode);
+
+  return IDBTransaction::CreateNonVersionChange(script_state, transaction_id,
+                                                scope, mode, this);
+}
+
+void IDBDatabase::ForceClose() {
+  for (const auto& it : transactions_)
+    it.value->abort(IGNORE_EXCEPTION_FOR_TESTING);
+  this->close();
+  EnqueueEvent(Event::Create(EventTypeNames::close));
+}
+
+void IDBDatabase::close() {
+  IDB_TRACE("IDBDatabase::close");
+  if (close_pending_)
+    return;
+
+  close_pending_ = true;
+
+  if (transactions_.IsEmpty())
+    CloseConnection();
+}
+
+void IDBDatabase::CloseConnection() {
+  DCHECK(close_pending_);
+  DCHECK(transactions_.IsEmpty());
+
+  if (backend_) {
+    backend_->Close();
+    backend_.reset();
+  }
+
+  if (database_callbacks_)
+    database_callbacks_->DetachWebCallbacks();
+
+  if (!GetExecutionContext())
+    return;
+
+  EventQueue* event_queue = GetExecutionContext()->GetEventQueue();
+  // Remove any pending versionchange events scheduled to fire on this
+  // connection. They would have been scheduled by the backend when another
+  // connection attempted an upgrade, but the frontend connection is being
+  // closed before they could fire.
+  for (size_t i = 0; i < enqueued_events_.size(); ++i) {
+    bool removed = event_queue->CancelEvent(enqueued_events_[i].Get());
+    DCHECK(removed);
+  }
+}
+
+void IDBDatabase::OnVersionChange(int64_t old_version, int64_t new_version) {
+  IDB_TRACE("IDBDatabase::onVersionChange");
+  if (!GetExecutionContext())
+    return;
+
+  if (close_pending_) {
+    // If we're pending, that means there's a busy transaction. We won't
+    // fire 'versionchange' but since we're not closing immediately the
+    // back-end should still send out 'blocked'.
+    backend_->VersionChangeIgnored();
+    return;
+  }
+
+  Nullable<unsigned long long> new_version_nullable =
+      (new_version == IDBDatabaseMetadata::kNoVersion)
+          ? Nullable<unsigned long long>()
+          : Nullable<unsigned long long>(new_version);
+  EnqueueEvent(IDBVersionChangeEvent::Create(
+      EventTypeNames::versionchange, old_version, new_version_nullable));
+}
+
+void IDBDatabase::EnqueueEvent(Event* event) {
+  DCHECK(GetExecutionContext());
+  EventQueue* event_queue = GetExecutionContext()->GetEventQueue();
+  event->SetTarget(this);
+  event_queue->EnqueueEvent(FROM_HERE, event);
+  enqueued_events_.push_back(event);
+}
+
+DispatchEventResult IDBDatabase::DispatchEventInternal(Event* event) {
+  IDB_TRACE("IDBDatabase::dispatchEvent");
+  if (!GetExecutionContext())
+    return DispatchEventResult::kCanceledBeforeDispatch;
+  DCHECK(event->type() == EventTypeNames::versionchange ||
+         event->type() == EventTypeNames::close);
+  for (size_t i = 0; i < enqueued_events_.size(); ++i) {
+    if (enqueued_events_[i].Get() == event)
+      enqueued_events_.EraseAt(i);
+  }
+
+  DispatchEventResult dispatch_result =
+      EventTarget::DispatchEventInternal(event);
+  if (event->type() == EventTypeNames::versionchange && !close_pending_ &&
+      backend_)
+    backend_->VersionChangeIgnored();
+  return dispatch_result;
+}
+
+int64_t IDBDatabase::FindObjectStoreId(const String& name) const {
+  for (const auto& it : metadata_.object_stores) {
+    if (it.value->name == name) {
+      DCHECK_NE(it.key, IDBObjectStoreMetadata::kInvalidId);
+      return it.key;
+    }
+  }
+  return IDBObjectStoreMetadata::kInvalidId;
+}
+
+void IDBDatabase::RenameObjectStore(int64_t object_store_id,
+                                    const String& new_name) {
+  DCHECK(version_change_transaction_)
+      << "Object store renamed on database without a versionchange transaction";
+  DCHECK(version_change_transaction_->IsActive())
+      << "Object store renamed when versionchange transaction is not active";
+  DCHECK(backend_) << "Object store renamed after database connection closed";
+  DCHECK(metadata_.object_stores.Contains(object_store_id));
+
+  backend_->RenameObjectStore(version_change_transaction_->Id(),
+                              object_store_id, new_name);
+
+  IDBObjectStoreMetadata* object_store_metadata =
+      metadata_.object_stores.at(object_store_id);
+  version_change_transaction_->ObjectStoreRenamed(object_store_metadata->name,
+                                                  new_name);
+  object_store_metadata->name = new_name;
+}
+
+void IDBDatabase::RevertObjectStoreCreation(int64_t object_store_id) {
+  DCHECK(version_change_transaction_) << "Object store metadata reverted on "
+                                         "database without a versionchange "
+                                         "transaction";
+  DCHECK(!version_change_transaction_->IsActive())
+      << "Object store metadata reverted when versionchange transaction is "
+         "still active";
+  DCHECK(metadata_.object_stores.Contains(object_store_id));
+  metadata_.object_stores.erase(object_store_id);
+}
+
+void IDBDatabase::RevertObjectStoreMetadata(
+    scoped_refptr<IDBObjectStoreMetadata> old_metadata) {
+  DCHECK(version_change_transaction_) << "Object store metadata reverted on "
+                                         "database without a versionchange "
+                                         "transaction";
+  DCHECK(!version_change_transaction_->IsActive())
+      << "Object store metadata reverted when versionchange transaction is "
+         "still active";
+  DCHECK(old_metadata.get());
+  metadata_.object_stores.Set(old_metadata->id, std::move(old_metadata));
+}
+
+bool IDBDatabase::HasPendingActivity() const {
+  // The script wrapper must not be collected before the object is closed or
+  // we can't fire a "versionchange" event to let script manually close the
+  // connection.
+  return !close_pending_ && GetExecutionContext() && HasEventListeners();
+}
+
+void IDBDatabase::ContextDestroyed(ExecutionContext*) {
+  // Immediately close the connection to the back end. Don't attempt a
+  // normal close() since that may wait on transactions which require a
+  // round trip to the back-end to abort.
+  if (backend_) {
+    backend_->Close();
+    backend_.reset();
+  }
+
+  if (database_callbacks_)
+    database_callbacks_->DetachWebCallbacks();
+}
+
+const AtomicString& IDBDatabase::InterfaceName() const {
+  return EventTargetNames::IDBDatabase;
+}
+
+ExecutionContext* IDBDatabase::GetExecutionContext() const {
+  return ContextLifecycleObserver::GetExecutionContext();
+}
+
+void IDBDatabase::RecordApiCallsHistogram(IndexedDatabaseMethods method) {
+  DEFINE_THREAD_SAFE_STATIC_LOCAL(
+      EnumerationHistogram, api_calls_histogram,
+      ("WebCore.IndexedDB.FrontEndAPICalls", kIDBMethodsMax));
+  api_calls_histogram.Count(method);
+}
+
+STATIC_ASSERT_ENUM(kWebIDBDatabaseExceptionUnknownError, kUnknownError);
+STATIC_ASSERT_ENUM(kWebIDBDatabaseExceptionConstraintError, kConstraintError);
+STATIC_ASSERT_ENUM(kWebIDBDatabaseExceptionDataError, kDataError);
+STATIC_ASSERT_ENUM(kWebIDBDatabaseExceptionVersionError, kVersionError);
+STATIC_ASSERT_ENUM(kWebIDBDatabaseExceptionAbortError, kAbortError);
+STATIC_ASSERT_ENUM(kWebIDBDatabaseExceptionQuotaError, kQuotaExceededError);
+STATIC_ASSERT_ENUM(kWebIDBDatabaseExceptionTimeoutError, kTimeoutError);
+
+}  // namespace blink
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKey.h chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKey.h
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKey.h	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKey.h	2018-04-27 11:31:20.655827593 +0300
@@ -106,7 +106,7 @@
     return binary_;
   }
 
-  const String& String() const {
+  const String& GetString() const {
     DCHECK_EQ(type_, kStringType);
     return string_;
   }
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKey.h.GetString chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKey.h.GetString
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKey.h.GetString	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKey.h.GetString	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,161 @@
+/*
+ * Copyright (C) 2011 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1.  Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ * 2.  Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in the
+ *     documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS "AS IS" AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef IDBKey_h
+#define IDBKey_h
+
+#include <memory>
+#include <utility>
+
+#include "base/macros.h"
+#include "base/memory/scoped_refptr.h"
+#include "modules/ModulesExport.h"
+#include "platform/SharedBuffer.h"
+#include "platform/wtf/Forward.h"
+#include "platform/wtf/PtrUtil.h"
+#include "platform/wtf/Vector.h"
+#include "platform/wtf/text/WTFString.h"
+#include "public/platform/WebVector.h"
+#include "public/platform/modules/indexeddb/WebIDBKey.h"
+
+namespace blink {
+
+// An IndexedDB primary or index key.
+//
+// The IndexedDB backing store regards script values written as object store
+// record values as fairly opaque data (see IDBValue and IDBValueWrapping).
+// However, it needs a fair amount of visibility into script values used as
+// primary keys and index keys. For this reason, keys are represented using a
+// dedicated data type that fully exposes its contents to the backing store.
+class MODULES_EXPORT IDBKey {
+ public:
+  typedef Vector<std::unique_ptr<IDBKey>> KeyArray;
+
+  static std::unique_ptr<IDBKey> CreateInvalid() {
+    return WTF::WrapUnique(new IDBKey());
+  }
+
+  static std::unique_ptr<IDBKey> CreateNumber(double number) {
+    return WTF::WrapUnique(new IDBKey(kNumberType, number));
+  }
+
+  static std::unique_ptr<IDBKey> CreateBinary(
+      scoped_refptr<SharedBuffer> binary) {
+    return WTF::WrapUnique(new IDBKey(std::move(binary)));
+  }
+
+  static std::unique_ptr<IDBKey> CreateString(const String& string) {
+    return WTF::WrapUnique(new IDBKey(string));
+  }
+
+  static std::unique_ptr<IDBKey> CreateDate(double date) {
+    return WTF::WrapUnique(new IDBKey(kDateType, date));
+  }
+
+  static std::unique_ptr<IDBKey> CreateArray(KeyArray array) {
+    return WTF::WrapUnique(new IDBKey(std::move(array)));
+  }
+
+  ~IDBKey();
+
+  // In order of the least to the highest precedent in terms of sort order.
+  // These values are written to logs. New enum values can be added, but
+  // existing enums must never be renumbered or deleted and reused.
+  enum Type {
+    kInvalidType = 0,
+    kArrayType = 1,
+    kBinaryType = 2,
+    kStringType = 3,
+    kDateType = 4,
+    kNumberType = 5,
+    kTypeEnumMax,
+  };
+
+  Type GetType() const { return type_; }
+  bool IsValid() const;
+
+  const KeyArray& Array() const {
+    DCHECK_EQ(type_, kArrayType);
+    return array_;
+  }
+
+  scoped_refptr<SharedBuffer> Binary() const {
+    DCHECK_EQ(type_, kBinaryType);
+    return binary_;
+  }
+
+  const String& String() const {
+    DCHECK_EQ(type_, kStringType);
+    return string_;
+  }
+
+  double Date() const {
+    DCHECK_EQ(type_, kDateType);
+    return number_;
+  }
+
+  double Number() const {
+    DCHECK_EQ(type_, kNumberType);
+    return number_;
+  }
+
+  int Compare(const IDBKey* other) const;
+  bool IsLessThan(const IDBKey* other) const;
+  bool IsEqual(const IDBKey* other) const;
+
+  // Returns a new key array with invalid keys and duplicates removed.
+  //
+  // The items in the key array are moved out of the given IDBKey, which must be
+  // an array. For this reason, the method is a static method that receives its
+  // argument via an std::unique_ptr.
+  //
+  // The return value will be pasesd to the backing store, which requires
+  // Web types. Returning the correct types directly avoids copying later on
+  // (wasted CPU cycles and code size).
+  static WebVector<WebIDBKey> ToMultiEntryArray(
+      std::unique_ptr<IDBKey> array_key);
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(IDBKey);
+
+  IDBKey() : type_(kInvalidType) {}
+  IDBKey(Type type, double number) : type_(type), number_(number) {}
+  explicit IDBKey(const class String& value)
+      : type_(kStringType), string_(value) {}
+  explicit IDBKey(scoped_refptr<SharedBuffer> value)
+      : type_(kBinaryType), binary_(std::move(value)) {}
+  explicit IDBKey(KeyArray key_array)
+      : type_(kArrayType), array_(std::move(key_array)) {}
+
+  Type type_;
+  KeyArray array_;
+  scoped_refptr<SharedBuffer> binary_;
+  const class String string_;
+  const double number_ = 0;
+};
+
+}  // namespace blink
+
+#endif  // IDBKey_h
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h	2018-04-27 11:31:20.655827593 +0300
@@ -65,7 +65,7 @@
     return array_;
   }
 
-  const String& String() const {
+  const String& GetString() const {
     DCHECK_EQ(type_, kStringType);
     return string_;
   }
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h.GetString chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h.GetString
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h.GetString	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/IDBKeyPath.h.GetString	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,85 @@
+/*
+ * Copyright (C) 2010 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1.  Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ * 2.  Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in the
+ *     documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS "AS IS" AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef IDBKeyPath_h
+#define IDBKeyPath_h
+
+#include "bindings/core/v8/string_or_string_sequence.h"
+#include "modules/ModulesExport.h"
+#include "platform/wtf/Allocator.h"
+#include "platform/wtf/Vector.h"
+#include "platform/wtf/text/WTFString.h"
+#include "public/platform/modules/indexeddb/WebIDBKeyPath.h"
+
+namespace blink {
+
+enum IDBKeyPathParseError {
+  kIDBKeyPathParseErrorNone,
+  kIDBKeyPathParseErrorIdentifier,
+};
+
+MODULES_EXPORT void IDBParseKeyPath(const String&,
+                                    Vector<String>&,
+                                    IDBKeyPathParseError&);
+
+class MODULES_EXPORT IDBKeyPath {
+  DISALLOW_NEW();
+
+ public:
+  IDBKeyPath() : type_(kNullType) {}
+  explicit IDBKeyPath(const String&);
+  explicit IDBKeyPath(const Vector<String>& array);
+  explicit IDBKeyPath(const StringOrStringSequence& key_path);
+  IDBKeyPath(const WebIDBKeyPath&);
+
+  operator WebIDBKeyPath() const;
+
+  enum Type { kNullType = 0, kStringType, kArrayType };
+
+  Type GetType() const { return type_; }
+
+  const Vector<String>& Array() const {
+    DCHECK_EQ(type_, kArrayType);
+    return array_;
+  }
+
+  const String& String() const {
+    DCHECK_EQ(type_, kStringType);
+    return string_;
+  }
+
+  bool IsNull() const { return type_ == kNullType; }
+  bool IsValid() const;
+  bool operator==(const IDBKeyPath& other) const;
+
+ private:
+  Type type_;
+  class String string_;
+  Vector<class String> array_;
+};
+
+}  // namespace blink
+
+#endif  // IDBKeyPath_h
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp	2018-04-27 11:31:20.659827552 +0300
@@ -399,7 +399,7 @@
     case IDBKeyPath::kStringType:
       key_path = KeyPath::create()
                      .setType(KeyPath::TypeEnum::String)
-                     .setString(idb_key_path.String())
+                     .setString(idb_key_path.GetString())
                      .build();
       break;
     case IDBKeyPath::kArrayType: {
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp.GetString chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp.GetString
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp.GetString	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/indexeddb/InspectorIndexedDBAgent.cpp.GetString	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,1119 @@
+/*
+ * Copyright (C) 2012 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "modules/indexeddb/InspectorIndexedDBAgent.h"
+
+#include <memory>
+#include <utility>
+
+#include "bindings/core/v8/ExceptionState.h"
+#include "bindings/core/v8/ScriptController.h"
+#include "bindings/core/v8/V8BindingForCore.h"
+#include "core/dom/DOMStringList.h"
+#include "core/dom/Document.h"
+#include "core/dom/ExecutionContext.h"
+#include "core/dom/events/EventListener.h"
+#include "core/frame/LocalFrame.h"
+#include "core/inspector/InspectedFrames.h"
+#include "core/inspector/V8InspectorString.h"
+#include "modules/indexed_db_names.h"
+#include "modules/indexeddb/GlobalIndexedDB.h"
+#include "modules/indexeddb/IDBCursor.h"
+#include "modules/indexeddb/IDBCursorWithValue.h"
+#include "modules/indexeddb/IDBDatabase.h"
+#include "modules/indexeddb/IDBFactory.h"
+#include "modules/indexeddb/IDBIndex.h"
+#include "modules/indexeddb/IDBKey.h"
+#include "modules/indexeddb/IDBKeyPath.h"
+#include "modules/indexeddb/IDBKeyRange.h"
+#include "modules/indexeddb/IDBMetadata.h"
+#include "modules/indexeddb/IDBObjectStore.h"
+#include "modules/indexeddb/IDBOpenDBRequest.h"
+#include "modules/indexeddb/IDBRequest.h"
+#include "modules/indexeddb/IDBTransaction.h"
+#include "platform/bindings/ScriptState.h"
+#include "platform/bindings/V8PerIsolateData.h"
+#include "platform/weborigin/SecurityOrigin.h"
+#include "platform/wtf/Vector.h"
+#include "public/platform/modules/indexeddb/WebIDBCursor.h"
+#include "public/platform/modules/indexeddb/WebIDBTypes.h"
+
+using blink::protocol::Array;
+using blink::protocol::IndexedDB::DatabaseWithObjectStores;
+using blink::protocol::IndexedDB::DataEntry;
+using blink::protocol::IndexedDB::Key;
+using blink::protocol::IndexedDB::KeyPath;
+using blink::protocol::IndexedDB::KeyRange;
+using blink::protocol::IndexedDB::ObjectStore;
+using blink::protocol::IndexedDB::ObjectStoreIndex;
+using blink::protocol::Maybe;
+using blink::protocol::Response;
+
+typedef blink::protocol::IndexedDB::Backend::RequestDatabaseNamesCallback
+    RequestDatabaseNamesCallback;
+typedef blink::protocol::IndexedDB::Backend::RequestDatabaseCallback
+    RequestDatabaseCallback;
+typedef blink::protocol::IndexedDB::Backend::RequestDataCallback
+    RequestDataCallback;
+typedef blink::protocol::IndexedDB::Backend::DeleteObjectStoreEntriesCallback
+    DeleteObjectStoreEntriesCallback;
+typedef blink::protocol::IndexedDB::Backend::ClearObjectStoreCallback
+    ClearObjectStoreCallback;
+typedef blink::protocol::IndexedDB::Backend::DeleteDatabaseCallback
+    DeleteDatabaseCallback;
+
+namespace blink {
+
+namespace IndexedDBAgentState {
+static const char kIndexedDBAgentEnabled[] = "indexedDBAgentEnabled";
+};
+
+namespace {
+
+static const char kIndexedDBObjectGroup[] = "indexeddb";
+static const char kNoDocumentError[] = "No document for given frame found";
+
+static Response AssertIDBFactory(Document* document, IDBFactory*& result) {
+  LocalDOMWindow* dom_window = document->domWindow();
+  if (!dom_window)
+    return Response::Error("No IndexedDB factory for given frame found");
+  IDBFactory* idb_factory = GlobalIndexedDB::indexedDB(*dom_window);
+
+  if (!idb_factory)
+    return Response::Error("No IndexedDB factory for given frame found");
+  result = idb_factory;
+  return Response::OK();
+}
+
+class GetDatabaseNamesCallback final : public EventListener {
+  WTF_MAKE_NONCOPYABLE(GetDatabaseNamesCallback);
+
+ public:
+  static GetDatabaseNamesCallback* Create(
+      std::unique_ptr<RequestDatabaseNamesCallback> request_callback,
+      const String& security_origin) {
+    return new GetDatabaseNamesCallback(std::move(request_callback),
+                                        security_origin);
+  }
+
+  ~GetDatabaseNamesCallback() override = default;
+
+  bool operator==(const EventListener& other) const override {
+    return this == &other;
+  }
+
+  void handleEvent(ExecutionContext*, Event* event) override {
+    if (event->type() != EventTypeNames::success) {
+      request_callback_->sendFailure(Response::Error("Unexpected event type."));
+      return;
+    }
+
+    IDBRequest* idb_request = static_cast<IDBRequest*>(event->target());
+    IDBAny* request_result = idb_request->ResultAsAny();
+    if (request_result->GetType() != IDBAny::kDOMStringListType) {
+      request_callback_->sendFailure(
+          Response::Error("Unexpected result type."));
+      return;
+    }
+
+    DOMStringList* database_names_list = request_result->DomStringList();
+    std::unique_ptr<protocol::Array<String>> database_names =
+        protocol::Array<String>::create();
+    for (size_t i = 0; i < database_names_list->length(); ++i)
+      database_names->addItem(database_names_list->item(i));
+    request_callback_->sendSuccess(std::move(database_names));
+  }
+
+  virtual void Trace(blink::Visitor* visitor) { EventListener::Trace(visitor); }
+
+ private:
+  GetDatabaseNamesCallback(
+      std::unique_ptr<RequestDatabaseNamesCallback> request_callback,
+      const String& security_origin)
+      : EventListener(EventListener::kCPPEventListenerType),
+        request_callback_(std::move(request_callback)),
+        security_origin_(security_origin) {}
+  std::unique_ptr<RequestDatabaseNamesCallback> request_callback_;
+  String security_origin_;
+};
+
+class DeleteCallback final : public EventListener {
+  WTF_MAKE_NONCOPYABLE(DeleteCallback);
+
+ public:
+  static DeleteCallback* Create(
+      std::unique_ptr<DeleteDatabaseCallback> request_callback,
+      const String& security_origin) {
+    return new DeleteCallback(std::move(request_callback), security_origin);
+  }
+
+  ~DeleteCallback() override = default;
+
+  bool operator==(const EventListener& other) const override {
+    return this == &other;
+  }
+
+  void handleEvent(ExecutionContext*, Event* event) override {
+    if (event->type() != EventTypeNames::success) {
+      request_callback_->sendFailure(
+          Response::Error("Failed to delete database."));
+      return;
+    }
+    request_callback_->sendSuccess();
+  }
+
+  virtual void Trace(blink::Visitor* visitor) { EventListener::Trace(visitor); }
+
+ private:
+  DeleteCallback(std::unique_ptr<DeleteDatabaseCallback> request_callback,
+                 const String& security_origin)
+      : EventListener(EventListener::kCPPEventListenerType),
+        request_callback_(std::move(request_callback)),
+        security_origin_(security_origin) {}
+  std::unique_ptr<DeleteDatabaseCallback> request_callback_;
+  String security_origin_;
+};
+
+template <typename RequestCallback>
+class OpenDatabaseCallback;
+template <typename RequestCallback>
+class UpgradeDatabaseCallback;
+
+template <typename RequestCallback>
+class ExecutableWithDatabase
+    : public RefCounted<ExecutableWithDatabase<RequestCallback>> {
+ public:
+  virtual ~ExecutableWithDatabase() = default;
+  virtual void Execute(IDBDatabase*, ScriptState*) = 0;
+  virtual RequestCallback* GetRequestCallback() = 0;
+  void Start(LocalFrame* frame, const String& database_name) {
+    Document* document = frame ? frame->GetDocument() : nullptr;
+    if (!document) {
+      SendFailure(Response::Error(kNoDocumentError));
+      return;
+    }
+    IDBFactory* idb_factory = nullptr;
+    Response response = AssertIDBFactory(document, idb_factory);
+    if (!response.isSuccess()) {
+      SendFailure(response);
+      return;
+    }
+
+    ScriptState* script_state = ToScriptStateForMainWorld(frame);
+    if (!script_state) {
+      SendFailure(Response::InternalError());
+      return;
+    }
+
+    ScriptState::Scope scope(script_state);
+    DoStart(idb_factory, script_state, document->GetSecurityOrigin(),
+            database_name);
+  }
+
+ private:
+  void DoStart(IDBFactory* idb_factory,
+               ScriptState* script_state,
+               const SecurityOrigin*,
+               const String& database_name) {
+    OpenDatabaseCallback<RequestCallback>* open_callback =
+        OpenDatabaseCallback<RequestCallback>::Create(this, script_state);
+    UpgradeDatabaseCallback<RequestCallback>* upgrade_callback =
+        UpgradeDatabaseCallback<RequestCallback>::Create(this);
+    DummyExceptionStateForTesting exception_state;
+    IDBOpenDBRequest* idb_open_db_request =
+        idb_factory->open(script_state, database_name, exception_state);
+    if (exception_state.HadException()) {
+      SendFailure(Response::Error("Could not open database."));
+      return;
+    }
+    idb_open_db_request->addEventListener(EventTypeNames::upgradeneeded,
+                                          upgrade_callback, false);
+    idb_open_db_request->addEventListener(EventTypeNames::success,
+                                          open_callback, false);
+  }
+
+  void SendFailure(Response response) {
+    GetRequestCallback()->sendFailure(response);
+  }
+};
+
+template <typename RequestCallback>
+class OpenDatabaseCallback final : public EventListener {
+ public:
+  static OpenDatabaseCallback* Create(
+      ExecutableWithDatabase<RequestCallback>* executable_with_database,
+      scoped_refptr<ScriptState> script_state) {
+    return new OpenDatabaseCallback(executable_with_database, script_state);
+  }
+
+  ~OpenDatabaseCallback() override = default;
+
+  bool operator==(const EventListener& other) const override {
+    return this == &other;
+  }
+
+  void handleEvent(ExecutionContext* context, Event* event) override {
+    if (event->type() != EventTypeNames::success) {
+      executable_with_database_->GetRequestCallback()->sendFailure(
+          Response::Error("Unexpected event type."));
+      return;
+    }
+
+    IDBOpenDBRequest* idb_open_db_request =
+        static_cast<IDBOpenDBRequest*>(event->target());
+    IDBAny* request_result = idb_open_db_request->ResultAsAny();
+    if (request_result->GetType() != IDBAny::kIDBDatabaseType) {
+      executable_with_database_->GetRequestCallback()->sendFailure(
+          Response::Error("Unexpected result type."));
+      return;
+    }
+
+    IDBDatabase* idb_database = request_result->IdbDatabase();
+    executable_with_database_->Execute(idb_database, script_state_.get());
+    V8PerIsolateData::From(script_state_->GetIsolate())->RunEndOfScopeTasks();
+    idb_database->close();
+  }
+
+ private:
+  OpenDatabaseCallback(
+      ExecutableWithDatabase<RequestCallback>* executable_with_database,
+      scoped_refptr<ScriptState> script_state)
+      : EventListener(EventListener::kCPPEventListenerType),
+        executable_with_database_(executable_with_database),
+        script_state_(script_state) {}
+  scoped_refptr<ExecutableWithDatabase<RequestCallback>>
+      executable_with_database_;
+  scoped_refptr<ScriptState> script_state_;
+};
+
+template <typename RequestCallback>
+class UpgradeDatabaseCallback final : public EventListener {
+ public:
+  static UpgradeDatabaseCallback* Create(
+      ExecutableWithDatabase<RequestCallback>* executable_with_database) {
+    return new UpgradeDatabaseCallback(executable_with_database);
+  }
+
+  ~UpgradeDatabaseCallback() override = default;
+
+  bool operator==(const EventListener& other) const override {
+    return this == &other;
+  }
+
+  void handleEvent(ExecutionContext* context, Event* event) override {
+    if (event->type() != EventTypeNames::upgradeneeded) {
+      executable_with_database_->GetRequestCallback()->sendFailure(
+          Response::Error("Unexpected event type."));
+      return;
+    }
+
+    // If an "upgradeneeded" event comes through then the database that
+    // had previously been enumerated was deleted. We don't want to
+    // implicitly re-create it here, so abort the transaction.
+    IDBOpenDBRequest* idb_open_db_request =
+        static_cast<IDBOpenDBRequest*>(event->target());
+    NonThrowableExceptionState exception_state;
+    idb_open_db_request->transaction()->abort(exception_state);
+    executable_with_database_->GetRequestCallback()->sendFailure(
+        Response::Error("Aborted upgrade."));
+  }
+
+ private:
+  UpgradeDatabaseCallback(
+      ExecutableWithDatabase<RequestCallback>* executable_with_database)
+      : EventListener(EventListener::kCPPEventListenerType),
+        executable_with_database_(executable_with_database) {}
+  scoped_refptr<ExecutableWithDatabase<RequestCallback>>
+      executable_with_database_;
+};
+
+static IDBTransaction* TransactionForDatabase(
+    ScriptState* script_state,
+    IDBDatabase* idb_database,
+    const String& object_store_name,
+    const String& mode = IndexedDBNames::readonly) {
+  DummyExceptionStateForTesting exception_state;
+  StringOrStringSequence scope;
+  scope.SetString(object_store_name);
+  IDBTransaction* idb_transaction =
+      idb_database->transaction(script_state, scope, mode, exception_state);
+  if (exception_state.HadException())
+    return nullptr;
+  return idb_transaction;
+}
+
+static IDBObjectStore* ObjectStoreForTransaction(
+    IDBTransaction* idb_transaction,
+    const String& object_store_name) {
+  DummyExceptionStateForTesting exception_state;
+  IDBObjectStore* idb_object_store =
+      idb_transaction->objectStore(object_store_name, exception_state);
+  if (exception_state.HadException())
+    return nullptr;
+  return idb_object_store;
+}
+
+static IDBIndex* IndexForObjectStore(IDBObjectStore* idb_object_store,
+                                     const String& index_name) {
+  DummyExceptionStateForTesting exception_state;
+  IDBIndex* idb_index = idb_object_store->index(index_name, exception_state);
+  if (exception_state.HadException())
+    return nullptr;
+  return idb_index;
+}
+
+static std::unique_ptr<KeyPath> KeyPathFromIDBKeyPath(
+    const IDBKeyPath& idb_key_path) {
+  std::unique_ptr<KeyPath> key_path;
+  switch (idb_key_path.GetType()) {
+    case IDBKeyPath::kNullType:
+      key_path = KeyPath::create().setType(KeyPath::TypeEnum::Null).build();
+      break;
+    case IDBKeyPath::kStringType:
+      key_path = KeyPath::create()
+                     .setType(KeyPath::TypeEnum::String)
+                     .setString(idb_key_path.String())
+                     .build();
+      break;
+    case IDBKeyPath::kArrayType: {
+      key_path = KeyPath::create().setType(KeyPath::TypeEnum::Array).build();
+      std::unique_ptr<protocol::Array<String>> array =
+          protocol::Array<String>::create();
+      const Vector<String>& string_array = idb_key_path.Array();
+      for (size_t i = 0; i < string_array.size(); ++i)
+        array->addItem(string_array[i]);
+      key_path->setArray(std::move(array));
+      break;
+    }
+    default:
+      NOTREACHED();
+  }
+
+  return key_path;
+}
+
+class DatabaseLoader final
+    : public ExecutableWithDatabase<RequestDatabaseCallback> {
+ public:
+  static scoped_refptr<DatabaseLoader> Create(
+      std::unique_ptr<RequestDatabaseCallback> request_callback) {
+    return base::AdoptRef(new DatabaseLoader(std::move(request_callback)));
+  }
+
+  ~DatabaseLoader() override = default;
+
+  void Execute(IDBDatabase* idb_database, ScriptState*) override {
+    const IDBDatabaseMetadata database_metadata = idb_database->Metadata();
+
+    std::unique_ptr<protocol::Array<protocol::IndexedDB::ObjectStore>>
+        object_stores =
+            protocol::Array<protocol::IndexedDB::ObjectStore>::create();
+
+    for (const auto& store_map_entry : database_metadata.object_stores) {
+      const IDBObjectStoreMetadata& object_store_metadata =
+          *store_map_entry.value;
+
+      std::unique_ptr<protocol::Array<protocol::IndexedDB::ObjectStoreIndex>>
+          indexes =
+              protocol::Array<protocol::IndexedDB::ObjectStoreIndex>::create();
+
+      for (const auto& metadata_map_entry : object_store_metadata.indexes) {
+        const IDBIndexMetadata& index_metadata = *metadata_map_entry.value;
+
+        std::unique_ptr<ObjectStoreIndex> object_store_index =
+            ObjectStoreIndex::create()
+                .setName(index_metadata.name)
+                .setKeyPath(KeyPathFromIDBKeyPath(index_metadata.key_path))
+                .setUnique(index_metadata.unique)
+                .setMultiEntry(index_metadata.multi_entry)
+                .build();
+        indexes->addItem(std::move(object_store_index));
+      }
+
+      std::unique_ptr<ObjectStore> object_store =
+          ObjectStore::create()
+              .setName(object_store_metadata.name)
+              .setKeyPath(KeyPathFromIDBKeyPath(object_store_metadata.key_path))
+              .setAutoIncrement(object_store_metadata.auto_increment)
+              .setIndexes(std::move(indexes))
+              .build();
+      object_stores->addItem(std::move(object_store));
+    }
+    std::unique_ptr<DatabaseWithObjectStores> result =
+        DatabaseWithObjectStores::create()
+            .setName(idb_database->name())
+            .setVersion(idb_database->version())
+            .setObjectStores(std::move(object_stores))
+            .build();
+
+    request_callback_->sendSuccess(std::move(result));
+  }
+
+  RequestDatabaseCallback* GetRequestCallback() override {
+    return request_callback_.get();
+  }
+
+ private:
+  DatabaseLoader(std::unique_ptr<RequestDatabaseCallback> request_callback)
+      : request_callback_(std::move(request_callback)) {}
+  std::unique_ptr<RequestDatabaseCallback> request_callback_;
+};
+
+static std::unique_ptr<IDBKey> IdbKeyFromInspectorObject(
+    protocol::IndexedDB::Key* key) {
+  std::unique_ptr<IDBKey> idb_key;
+
+  if (!key)
+    return nullptr;
+  String type = key->getType();
+
+  DEFINE_STATIC_LOCAL(String, number, ("number"));
+  DEFINE_STATIC_LOCAL(String, string, ("string"));
+  DEFINE_STATIC_LOCAL(String, date, ("date"));
+  DEFINE_STATIC_LOCAL(String, array, ("array"));
+
+  if (type == number) {
+    if (!key->hasNumber())
+      return nullptr;
+    idb_key = IDBKey::CreateNumber(key->getNumber(0));
+  } else if (type == string) {
+    if (!key->hasString())
+      return nullptr;
+    idb_key = IDBKey::CreateString(key->getString(String()));
+  } else if (type == date) {
+    if (!key->hasDate())
+      return nullptr;
+    idb_key = IDBKey::CreateDate(key->getDate(0));
+  } else if (type == array) {
+    IDBKey::KeyArray key_array;
+    auto array = key->getArray(nullptr);
+    for (size_t i = 0; array && i < array->length(); ++i)
+      key_array.push_back(IdbKeyFromInspectorObject(array->get(i)));
+    idb_key = IDBKey::CreateArray(std::move(key_array));
+  } else {
+    return nullptr;
+  }
+
+  return idb_key;
+}
+
+static IDBKeyRange* IdbKeyRangeFromKeyRange(
+    protocol::IndexedDB::KeyRange* key_range) {
+  std::unique_ptr<IDBKey> idb_lower =
+      IdbKeyFromInspectorObject(key_range->getLower(nullptr));
+  if (key_range->hasLower() && !idb_lower)
+    return nullptr;
+
+  std::unique_ptr<IDBKey> idb_upper =
+      IdbKeyFromInspectorObject(key_range->getUpper(nullptr));
+  if (key_range->hasUpper() && !idb_upper)
+    return nullptr;
+
+  IDBKeyRange::LowerBoundType lower_bound_type =
+      key_range->getLowerOpen() ? IDBKeyRange::kLowerBoundOpen
+                                : IDBKeyRange::kLowerBoundClosed;
+  IDBKeyRange::UpperBoundType upper_bound_type =
+      key_range->getUpperOpen() ? IDBKeyRange::kUpperBoundOpen
+                                : IDBKeyRange::kUpperBoundClosed;
+  return IDBKeyRange::Create(std::move(idb_lower), std::move(idb_upper),
+                             lower_bound_type, upper_bound_type);
+}
+
+class DataLoader;
+
+class OpenCursorCallback final : public EventListener {
+ public:
+  static OpenCursorCallback* Create(
+      v8_inspector::V8InspectorSession* v8_session,
+      ScriptState* script_state,
+      std::unique_ptr<RequestDataCallback> request_callback,
+      int skip_count,
+      unsigned page_size) {
+    return new OpenCursorCallback(v8_session, script_state,
+                                  std::move(request_callback), skip_count,
+                                  page_size);
+  }
+
+  ~OpenCursorCallback() override = default;
+
+  bool operator==(const EventListener& other) const override {
+    return this == &other;
+  }
+
+  void handleEvent(ExecutionContext*, Event* event) override {
+    if (event->type() != EventTypeNames::success) {
+      request_callback_->sendFailure(Response::Error("Unexpected event type."));
+      return;
+    }
+
+    IDBRequest* idb_request = static_cast<IDBRequest*>(event->target());
+    IDBAny* request_result = idb_request->ResultAsAny();
+    if (request_result->GetType() == IDBAny::kIDBValueType) {
+      end(false);
+      return;
+    }
+    if (request_result->GetType() != IDBAny::kIDBCursorWithValueType) {
+      request_callback_->sendFailure(
+          Response::Error("Unexpected result type."));
+      return;
+    }
+
+    IDBCursorWithValue* idb_cursor = request_result->IdbCursorWithValue();
+
+    if (skip_count_) {
+      DummyExceptionStateForTesting exception_state;
+      idb_cursor->advance(skip_count_, exception_state);
+      if (exception_state.HadException()) {
+        request_callback_->sendFailure(
+            Response::Error("Could not advance cursor."));
+      }
+      skip_count_ = 0;
+      return;
+    }
+
+    if (result_->length() == page_size_) {
+      end(true);
+      return;
+    }
+
+    // Continue cursor before making injected script calls, otherwise
+    // transaction might be finished.
+    DummyExceptionStateForTesting exception_state;
+    idb_cursor->Continue(nullptr, nullptr, IDBRequest::AsyncTraceState(),
+                         exception_state);
+    if (exception_state.HadException()) {
+      request_callback_->sendFailure(
+          Response::Error("Could not continue cursor."));
+      return;
+    }
+
+    Document* document =
+        ToDocument(ExecutionContext::From(script_state_.get()));
+    if (!document)
+      return;
+    ScriptState* script_state = script_state_.get();
+    ScriptState::Scope scope(script_state);
+    v8::Local<v8::Context> context = script_state->GetContext();
+    v8_inspector::StringView object_group =
+        ToV8InspectorStringView(kIndexedDBObjectGroup);
+    std::unique_ptr<DataEntry> data_entry =
+        DataEntry::create()
+            .setKey(v8_session_->wrapObject(
+                context, idb_cursor->key(script_state).V8Value(), object_group,
+                true /* generatePreview */))
+            .setPrimaryKey(v8_session_->wrapObject(
+                context, idb_cursor->primaryKey(script_state).V8Value(),
+                object_group, true /* generatePreview */))
+            .setValue(v8_session_->wrapObject(
+                context, idb_cursor->value(script_state).V8Value(),
+                object_group, true /* generatePreview */))
+            .build();
+    result_->addItem(std::move(data_entry));
+  }
+
+  void end(bool has_more) {
+    request_callback_->sendSuccess(std::move(result_), has_more);
+  }
+
+  virtual void Trace(blink::Visitor* visitor) { EventListener::Trace(visitor); }
+
+ private:
+  OpenCursorCallback(v8_inspector::V8InspectorSession* v8_session,
+                     ScriptState* script_state,
+                     std::unique_ptr<RequestDataCallback> request_callback,
+                     int skip_count,
+                     unsigned page_size)
+      : EventListener(EventListener::kCPPEventListenerType),
+        v8_session_(v8_session),
+        script_state_(script_state),
+        request_callback_(std::move(request_callback)),
+        skip_count_(skip_count),
+        page_size_(page_size) {
+    result_ = Array<DataEntry>::create();
+  }
+
+  v8_inspector::V8InspectorSession* v8_session_;
+  scoped_refptr<ScriptState> script_state_;
+  std::unique_ptr<RequestDataCallback> request_callback_;
+  int skip_count_;
+  unsigned page_size_;
+  std::unique_ptr<Array<DataEntry>> result_;
+};
+
+class DataLoader final : public ExecutableWithDatabase<RequestDataCallback> {
+ public:
+  static scoped_refptr<DataLoader> Create(
+      v8_inspector::V8InspectorSession* v8_session,
+      std::unique_ptr<RequestDataCallback> request_callback,
+      const String& object_store_name,
+      const String& index_name,
+      IDBKeyRange* idb_key_range,
+      int skip_count,
+      unsigned page_size) {
+    return base::AdoptRef(new DataLoader(
+        v8_session, std::move(request_callback), object_store_name, index_name,
+        idb_key_range, skip_count, page_size));
+  }
+
+  ~DataLoader() override = default;
+
+  void Execute(IDBDatabase* idb_database, ScriptState* script_state) override {
+    IDBTransaction* idb_transaction =
+        TransactionForDatabase(script_state, idb_database, object_store_name_);
+    if (!idb_transaction) {
+      request_callback_->sendFailure(
+          Response::Error("Could not get transaction"));
+      return;
+    }
+    IDBObjectStore* idb_object_store =
+        ObjectStoreForTransaction(idb_transaction, object_store_name_);
+    if (!idb_object_store) {
+      request_callback_->sendFailure(
+          Response::Error("Could not get object store"));
+      return;
+    }
+
+    IDBRequest* idb_request;
+    if (!index_name_.IsEmpty()) {
+      IDBIndex* idb_index = IndexForObjectStore(idb_object_store, index_name_);
+      if (!idb_index) {
+        request_callback_->sendFailure(Response::Error("Could not get index"));
+        return;
+      }
+
+      idb_request = idb_index->openCursor(script_state, idb_key_range_.Get(),
+                                          kWebIDBCursorDirectionNext);
+    } else {
+      idb_request = idb_object_store->openCursor(
+          script_state, idb_key_range_.Get(), kWebIDBCursorDirectionNext);
+    }
+    OpenCursorCallback* open_cursor_callback = OpenCursorCallback::Create(
+        v8_session_, script_state, std::move(request_callback_), skip_count_,
+        page_size_);
+    idb_request->addEventListener(EventTypeNames::success, open_cursor_callback,
+                                  false);
+  }
+
+  RequestDataCallback* GetRequestCallback() override {
+    return request_callback_.get();
+  }
+  DataLoader(v8_inspector::V8InspectorSession* v8_session,
+             std::unique_ptr<RequestDataCallback> request_callback,
+             const String& object_store_name,
+             const String& index_name,
+             IDBKeyRange* idb_key_range,
+             int skip_count,
+             unsigned page_size)
+      : v8_session_(v8_session),
+        request_callback_(std::move(request_callback)),
+        object_store_name_(object_store_name),
+        index_name_(index_name),
+        idb_key_range_(idb_key_range),
+        skip_count_(skip_count),
+        page_size_(page_size) {}
+
+  v8_inspector::V8InspectorSession* v8_session_;
+  std::unique_ptr<RequestDataCallback> request_callback_;
+  String object_store_name_;
+  String index_name_;
+  Persistent<IDBKeyRange> idb_key_range_;
+  int skip_count_;
+  unsigned page_size_;
+};
+
+}  // namespace
+
+// static
+InspectorIndexedDBAgent::InspectorIndexedDBAgent(
+    InspectedFrames* inspected_frames,
+    v8_inspector::V8InspectorSession* v8_session)
+    : inspected_frames_(inspected_frames), v8_session_(v8_session) {}
+
+InspectorIndexedDBAgent::~InspectorIndexedDBAgent() = default;
+
+void InspectorIndexedDBAgent::Restore() {
+  if (state_->booleanProperty(IndexedDBAgentState::kIndexedDBAgentEnabled,
+                              false)) {
+    enable();
+  }
+}
+
+void InspectorIndexedDBAgent::DidCommitLoadForLocalFrame(LocalFrame* frame) {
+  if (frame == inspected_frames_->Root()) {
+    v8_session_->releaseObjectGroup(
+        ToV8InspectorStringView(kIndexedDBObjectGroup));
+  }
+}
+
+Response InspectorIndexedDBAgent::enable() {
+  state_->setBoolean(IndexedDBAgentState::kIndexedDBAgentEnabled, true);
+  return Response::OK();
+}
+
+Response InspectorIndexedDBAgent::disable() {
+  state_->setBoolean(IndexedDBAgentState::kIndexedDBAgentEnabled, false);
+  v8_session_->releaseObjectGroup(
+      ToV8InspectorStringView(kIndexedDBObjectGroup));
+  return Response::OK();
+}
+
+void InspectorIndexedDBAgent::requestDatabaseNames(
+    const String& security_origin,
+    std::unique_ptr<RequestDatabaseNamesCallback> request_callback) {
+  LocalFrame* frame =
+      inspected_frames_->FrameWithSecurityOrigin(security_origin);
+  Document* document = frame ? frame->GetDocument() : nullptr;
+  if (!document) {
+    request_callback->sendFailure(Response::Error(kNoDocumentError));
+    return;
+  }
+  IDBFactory* idb_factory = nullptr;
+  Response response = AssertIDBFactory(document, idb_factory);
+  if (!response.isSuccess()) {
+    request_callback->sendFailure(response);
+    return;
+  }
+
+  ScriptState* script_state = ToScriptStateForMainWorld(frame);
+  if (!script_state) {
+    request_callback->sendFailure(Response::InternalError());
+    return;
+  }
+  ScriptState::Scope scope(script_state);
+  DummyExceptionStateForTesting exception_state;
+  IDBRequest* idb_request =
+      idb_factory->GetDatabaseNames(script_state, exception_state);
+  if (exception_state.HadException()) {
+    request_callback->sendFailure(
+        Response::Error("Could not obtain database names."));
+    return;
+  }
+  idb_request->addEventListener(
+      EventTypeNames::success,
+      GetDatabaseNamesCallback::Create(
+          std::move(request_callback),
+          document->GetSecurityOrigin()->ToRawString()),
+      false);
+}
+
+void InspectorIndexedDBAgent::requestDatabase(
+    const String& security_origin,
+    const String& database_name,
+    std::unique_ptr<RequestDatabaseCallback> request_callback) {
+  scoped_refptr<DatabaseLoader> database_loader =
+      DatabaseLoader::Create(std::move(request_callback));
+  database_loader->Start(
+      inspected_frames_->FrameWithSecurityOrigin(security_origin),
+      database_name);
+}
+
+void InspectorIndexedDBAgent::requestData(
+    const String& security_origin,
+    const String& database_name,
+    const String& object_store_name,
+    const String& index_name,
+    int skip_count,
+    int page_size,
+    Maybe<protocol::IndexedDB::KeyRange> key_range,
+    std::unique_ptr<RequestDataCallback> request_callback) {
+  IDBKeyRange* idb_key_range =
+      key_range.isJust() ? IdbKeyRangeFromKeyRange(key_range.fromJust())
+                         : nullptr;
+  if (key_range.isJust() && !idb_key_range) {
+    request_callback->sendFailure(Response::Error("Can not parse key range."));
+    return;
+  }
+
+  scoped_refptr<DataLoader> data_loader = DataLoader::Create(
+      v8_session_, std::move(request_callback), object_store_name, index_name,
+      idb_key_range, skip_count, page_size);
+
+  data_loader->Start(
+      inspected_frames_->FrameWithSecurityOrigin(security_origin),
+      database_name);
+}
+
+class DeleteObjectStoreEntriesListener final : public EventListener {
+  WTF_MAKE_NONCOPYABLE(DeleteObjectStoreEntriesListener);
+
+ public:
+  static DeleteObjectStoreEntriesListener* Create(
+      std::unique_ptr<DeleteObjectStoreEntriesCallback> request_callback) {
+    return new DeleteObjectStoreEntriesListener(std::move(request_callback));
+  }
+
+  ~DeleteObjectStoreEntriesListener() override = default;
+
+  bool operator==(const EventListener& other) const override {
+    return this == &other;
+  }
+
+  void handleEvent(ExecutionContext*, Event* event) override {
+    if (event->type() != EventTypeNames::success) {
+      request_callback_->sendFailure(
+          Response::Error("Failed to delete specified entries"));
+      return;
+    }
+
+    request_callback_->sendSuccess();
+  }
+
+  virtual void Trace(blink::Visitor* visitor) { EventListener::Trace(visitor); }
+
+ private:
+  DeleteObjectStoreEntriesListener(
+      std::unique_ptr<DeleteObjectStoreEntriesCallback> request_callback)
+      : EventListener(EventListener::kCPPEventListenerType),
+        request_callback_(std::move(request_callback)) {}
+
+  std::unique_ptr<DeleteObjectStoreEntriesCallback> request_callback_;
+};
+
+class DeleteObjectStoreEntries final
+    : public ExecutableWithDatabase<DeleteObjectStoreEntriesCallback> {
+ public:
+  static scoped_refptr<DeleteObjectStoreEntries> Create(
+      const String& object_store_name,
+      IDBKeyRange* idb_key_range,
+      std::unique_ptr<DeleteObjectStoreEntriesCallback> request_callback) {
+    return AdoptRef(new DeleteObjectStoreEntries(
+        object_store_name, idb_key_range, std::move(request_callback)));
+  }
+
+  DeleteObjectStoreEntries(
+      const String& object_store_name,
+      IDBKeyRange* idb_key_range,
+      std::unique_ptr<DeleteObjectStoreEntriesCallback> request_callback)
+      : object_store_name_(object_store_name),
+        idb_key_range_(idb_key_range),
+        request_callback_(std::move(request_callback)) {}
+
+  void Execute(IDBDatabase* idb_database, ScriptState* script_state) override {
+    IDBTransaction* idb_transaction =
+        TransactionForDatabase(script_state, idb_database, object_store_name_,
+                               IndexedDBNames::readwrite);
+    if (!idb_transaction) {
+      request_callback_->sendFailure(
+          Response::Error("Could not get transaction"));
+      return;
+    }
+    IDBObjectStore* idb_object_store =
+        ObjectStoreForTransaction(idb_transaction, object_store_name_);
+    if (!idb_object_store) {
+      request_callback_->sendFailure(
+          Response::Error("Could not get object store"));
+      return;
+    }
+
+    IDBRequest* idb_request =
+        idb_object_store->deleteFunction(script_state, idb_key_range_.Get());
+    idb_request->addEventListener(
+        EventTypeNames::success,
+        DeleteObjectStoreEntriesListener::Create(std::move(request_callback_)),
+        false);
+  }
+
+  DeleteObjectStoreEntriesCallback* GetRequestCallback() override {
+    return request_callback_.get();
+  }
+
+ private:
+  const String object_store_name_;
+  Persistent<IDBKeyRange> idb_key_range_;
+  std::unique_ptr<DeleteObjectStoreEntriesCallback> request_callback_;
+};
+
+void InspectorIndexedDBAgent::deleteObjectStoreEntries(
+    const String& security_origin,
+    const String& database_name,
+    const String& object_store_name,
+    std::unique_ptr<protocol::IndexedDB::KeyRange> key_range,
+    std::unique_ptr<DeleteObjectStoreEntriesCallback> request_callback) {
+  IDBKeyRange* idb_key_range = IdbKeyRangeFromKeyRange(key_range.get());
+  if (!idb_key_range) {
+    request_callback->sendFailure(Response::Error("Can not parse key range"));
+    return;
+  }
+  scoped_refptr<DeleteObjectStoreEntries> delete_object_store_entries =
+      DeleteObjectStoreEntries::Create(object_store_name, idb_key_range,
+                                       std::move(request_callback));
+  delete_object_store_entries->Start(
+      inspected_frames_->FrameWithSecurityOrigin(security_origin),
+      database_name);
+}
+
+class ClearObjectStoreListener final : public EventListener {
+  WTF_MAKE_NONCOPYABLE(ClearObjectStoreListener);
+
+ public:
+  static ClearObjectStoreListener* Create(
+      std::unique_ptr<ClearObjectStoreCallback> request_callback) {
+    return new ClearObjectStoreListener(std::move(request_callback));
+  }
+
+  ~ClearObjectStoreListener() override = default;
+
+  bool operator==(const EventListener& other) const override {
+    return this == &other;
+  }
+
+  void handleEvent(ExecutionContext*, Event* event) override {
+    if (event->type() != EventTypeNames::complete) {
+      request_callback_->sendFailure(Response::Error("Unexpected event type."));
+      return;
+    }
+
+    request_callback_->sendSuccess();
+  }
+
+  virtual void Trace(blink::Visitor* visitor) { EventListener::Trace(visitor); }
+
+ private:
+  ClearObjectStoreListener(
+      std::unique_ptr<ClearObjectStoreCallback> request_callback)
+      : EventListener(EventListener::kCPPEventListenerType),
+        request_callback_(std::move(request_callback)) {}
+
+  std::unique_ptr<ClearObjectStoreCallback> request_callback_;
+};
+
+class ClearObjectStore final
+    : public ExecutableWithDatabase<ClearObjectStoreCallback> {
+ public:
+  static scoped_refptr<ClearObjectStore> Create(
+      const String& object_store_name,
+      std::unique_ptr<ClearObjectStoreCallback> request_callback) {
+    return base::AdoptRef(
+        new ClearObjectStore(object_store_name, std::move(request_callback)));
+  }
+
+  ClearObjectStore(const String& object_store_name,
+                   std::unique_ptr<ClearObjectStoreCallback> request_callback)
+      : object_store_name_(object_store_name),
+        request_callback_(std::move(request_callback)) {}
+
+  void Execute(IDBDatabase* idb_database, ScriptState* script_state) override {
+    IDBTransaction* idb_transaction =
+        TransactionForDatabase(script_state, idb_database, object_store_name_,
+                               IndexedDBNames::readwrite);
+    if (!idb_transaction) {
+      request_callback_->sendFailure(
+          Response::Error("Could not get transaction"));
+      return;
+    }
+    IDBObjectStore* idb_object_store =
+        ObjectStoreForTransaction(idb_transaction, object_store_name_);
+    if (!idb_object_store) {
+      request_callback_->sendFailure(
+          Response::Error("Could not get object store"));
+      return;
+    }
+
+    DummyExceptionStateForTesting exception_state;
+    idb_object_store->clear(script_state, exception_state);
+    DCHECK(!exception_state.HadException());
+    if (exception_state.HadException()) {
+      ExceptionCode ec = exception_state.Code();
+      request_callback_->sendFailure(Response::Error(
+          String::Format("Could not clear object store '%s': %d",
+                         object_store_name_.Utf8().data(), ec)));
+      return;
+    }
+    idb_transaction->addEventListener(
+        EventTypeNames::complete,
+        ClearObjectStoreListener::Create(std::move(request_callback_)), false);
+  }
+
+  ClearObjectStoreCallback* GetRequestCallback() override {
+    return request_callback_.get();
+  }
+
+ private:
+  const String object_store_name_;
+  std::unique_ptr<ClearObjectStoreCallback> request_callback_;
+};
+
+void InspectorIndexedDBAgent::clearObjectStore(
+    const String& security_origin,
+    const String& database_name,
+    const String& object_store_name,
+    std::unique_ptr<ClearObjectStoreCallback> request_callback) {
+  scoped_refptr<ClearObjectStore> clear_object_store =
+      ClearObjectStore::Create(object_store_name, std::move(request_callback));
+  clear_object_store->Start(
+      inspected_frames_->FrameWithSecurityOrigin(security_origin),
+      database_name);
+}
+
+void InspectorIndexedDBAgent::deleteDatabase(
+    const String& security_origin,
+    const String& database_name,
+    std::unique_ptr<DeleteDatabaseCallback> request_callback) {
+  LocalFrame* frame =
+      inspected_frames_->FrameWithSecurityOrigin(security_origin);
+  Document* document = frame ? frame->GetDocument() : nullptr;
+  if (!document) {
+    request_callback->sendFailure(Response::Error(kNoDocumentError));
+    return;
+  }
+  IDBFactory* idb_factory = nullptr;
+  Response response = AssertIDBFactory(document, idb_factory);
+  if (!response.isSuccess()) {
+    request_callback->sendFailure(response);
+    return;
+  }
+
+  ScriptState* script_state = ToScriptStateForMainWorld(frame);
+  if (!script_state) {
+    request_callback->sendFailure(Response::InternalError());
+    return;
+  }
+  ScriptState::Scope scope(script_state);
+  DummyExceptionStateForTesting exception_state;
+  IDBRequest* idb_request = idb_factory->CloseConnectionsAndDeleteDatabase(
+      script_state, database_name, exception_state);
+  if (exception_state.HadException()) {
+    request_callback->sendFailure(
+        Response::Error("Could not delete database."));
+    return;
+  }
+  idb_request->addEventListener(
+      EventTypeNames::success,
+      DeleteCallback::Create(std::move(request_callback),
+                             document->GetSecurityOrigin()->ToRawString()),
+      false);
+}
+
+void InspectorIndexedDBAgent::Trace(blink::Visitor* visitor) {
+  visitor->Trace(inspected_frames_);
+  InspectorBaseAgent::Trace(visitor);
+}
+
+}  // namespace blink
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h	2018-04-27 11:31:20.615828015 +0300
@@ -30,6 +30,7 @@
 
 #include <memory>
 #include "modules/webdatabase/DatabaseBasicTypes.h"
+#include "modules/webdatabase/SQLError.h"
 #include "modules/webdatabase/SQLStatement.h"
 #include "modules/webdatabase/SQLStatementBackend.h"
 #include "modules/webdatabase/SQLTransactionStateMachine.h"
@@ -41,7 +42,6 @@
 namespace blink {
 
 class Database;
-class SQLErrorData;
 class SQLiteTransaction;
 class SQLTransaction;
 class SQLTransactionBackend;
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h.fulldecl chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h.fulldecl
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h.fulldecl	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webdatabase/SQLTransactionBackend.h.fulldecl	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,145 @@
+/*
+ * Copyright (C) 2007, 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1.  Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ * 2.  Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in the
+ *     documentation and/or other materials provided with the distribution.
+ * 3.  Neither the name of Apple Computer, Inc. ("Apple") nor the names of
+ *     its contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS "AS IS" AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef SQLTransactionBackend_h
+#define SQLTransactionBackend_h
+
+#include <memory>
+#include "modules/webdatabase/DatabaseBasicTypes.h"
+#include "modules/webdatabase/SQLStatement.h"
+#include "modules/webdatabase/SQLStatementBackend.h"
+#include "modules/webdatabase/SQLTransactionStateMachine.h"
+#include "platform/heap/Handle.h"
+#include "platform/wtf/Deque.h"
+#include "platform/wtf/Forward.h"
+#include "platform/wtf/ThreadingPrimitives.h"
+
+namespace blink {
+
+class Database;
+class SQLErrorData;
+class SQLiteTransaction;
+class SQLTransaction;
+class SQLTransactionBackend;
+class SQLValue;
+
+class SQLTransactionWrapper
+    : public GarbageCollectedFinalized<SQLTransactionWrapper> {
+ public:
+  virtual ~SQLTransactionWrapper() = default;
+  virtual void Trace(blink::Visitor* visitor) {}
+  virtual bool PerformPreflight(SQLTransactionBackend*) = 0;
+  virtual bool PerformPostflight(SQLTransactionBackend*) = 0;
+  virtual SQLErrorData* SqlError() const = 0;
+  virtual void HandleCommitFailedAfterPostflight(SQLTransactionBackend*) = 0;
+};
+
+class SQLTransactionBackend final
+    : public GarbageCollectedFinalized<SQLTransactionBackend>,
+      public SQLTransactionStateMachine<SQLTransactionBackend> {
+ public:
+  static SQLTransactionBackend* Create(Database*,
+                                       SQLTransaction*,
+                                       SQLTransactionWrapper*,
+                                       bool read_only);
+
+  ~SQLTransactionBackend() override;
+  void Trace(blink::Visitor*);
+
+  void LockAcquired();
+  void PerformNextStep();
+
+  Database* GetDatabase() { return database_.Get(); }
+  bool IsReadOnly() { return read_only_; }
+  void NotifyDatabaseThreadIsShuttingDown();
+
+  // APIs called from the frontend published:
+  void RequestTransitToState(SQLTransactionState);
+  SQLErrorData* TransactionError();
+  SQLStatement* CurrentStatement();
+  void SetShouldRetryCurrentStatement(bool);
+  void ExecuteSQL(SQLStatement*,
+                  const String& statement,
+                  const Vector<SQLValue>& arguments,
+                  int permissions);
+
+ private:
+  SQLTransactionBackend(Database*,
+                        SQLTransaction*,
+                        SQLTransactionWrapper*,
+                        bool read_only);
+
+  void DoCleanup();
+
+  void EnqueueStatementBackend(SQLStatementBackend*);
+
+  // State Machine functions:
+  StateFunction StateFunctionFor(SQLTransactionState) override;
+  void ComputeNextStateAndCleanupIfNeeded();
+
+  // State functions:
+  SQLTransactionState AcquireLock();
+  SQLTransactionState OpenTransactionAndPreflight();
+  SQLTransactionState RunStatements();
+  SQLTransactionState PostflightAndCommit();
+  SQLTransactionState CleanupAndTerminate();
+  SQLTransactionState CleanupAfterTransactionErrorCallback();
+
+  SQLTransactionState UnreachableState();
+  SQLTransactionState SendToFrontendState();
+
+  SQLTransactionState NextStateForCurrentStatementError();
+  SQLTransactionState NextStateForTransactionError();
+  SQLTransactionState RunCurrentStatementAndGetNextState();
+
+  void GetNextStatement();
+
+  CrossThreadPersistent<SQLTransaction> frontend_;
+  CrossThreadPersistent<SQLStatementBackend> current_statement_backend_;
+
+  Member<Database> database_;
+  Member<SQLTransactionWrapper> wrapper_;
+  std::unique_ptr<SQLErrorData> transaction_error_;
+
+  bool has_callback_;
+  bool has_success_callback_;
+  bool has_error_callback_;
+  bool should_retry_current_statement_;
+  bool modified_database_;
+  bool lock_acquired_;
+  bool read_only_;
+  bool has_version_mismatch_;
+
+  Mutex statement_mutex_;
+  Deque<CrossThreadPersistent<SQLStatementBackend>> statement_queue_;
+
+  std::unique_ptr<SQLiteTransaction> sqlite_transaction_;
+};
+
+}  // namespace blink
+
+#endif  // SQLTransactionBackend_h
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl	2018-04-27 11:31:20.463829613 +0300
@@ -241,7 +241,7 @@
     const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES          = 0x8A43;
     const GLenum UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER     = 0x8A44;
     const GLenum UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER   = 0x8A46;
-    const GLenum INVALID_INDEX                                 = 0xFFFFFFFF;
+    const GLenum INVALID_INDEX                                 = 256;
     const GLenum MAX_VERTEX_OUTPUT_COMPONENTS                  = 0x9122;
     const GLenum MAX_FRAGMENT_INPUT_COMPONENTS                 = 0x9125;
     const GLenum MAX_SERVER_WAIT_TIMEOUT                       = 0x9111;
@@ -271,7 +271,7 @@
     const GLenum TEXTURE_IMMUTABLE_FORMAT                      = 0x912F;
     const GLenum MAX_ELEMENT_INDEX                             = 0x8D6B;
     const GLenum TEXTURE_IMMUTABLE_LEVELS                      = 0x82DF;
-    const GLint TIMEOUT_IGNORED                                = -1;
+    const GLint TIMEOUT_IGNORED                                = 256;
 
     /* WebGL-specific enums */
     const GLenum MAX_CLIENT_WAIT_TIMEOUT_WEBGL                 = 0x9247;
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl.gcc5 chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl.gcc5
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl.gcc5	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/modules/webgl/WebGL2RenderingContextBase.idl.gcc5	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,536 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+// https://www.khronos.org/registry/webgl/specs/latest/2.0/#3.7
+
+typedef long long GLint64;
+typedef unsigned long long GLuint64;
+
+[
+    NoInterfaceObject
+] interface WebGL2RenderingContextBase {
+    const GLenum READ_BUFFER                                   = 0x0C02;
+    const GLenum UNPACK_ROW_LENGTH                             = 0x0CF2;
+    const GLenum UNPACK_SKIP_ROWS                              = 0x0CF3;
+    const GLenum UNPACK_SKIP_PIXELS                            = 0x0CF4;
+    const GLenum PACK_ROW_LENGTH                               = 0x0D02;
+    const GLenum PACK_SKIP_ROWS                                = 0x0D03;
+    const GLenum PACK_SKIP_PIXELS                              = 0x0D04;
+    const GLenum COLOR                                         = 0x1800;
+    const GLenum DEPTH                                         = 0x1801;
+    const GLenum STENCIL                                       = 0x1802;
+    const GLenum RED                                           = 0x1903;
+    const GLenum RGB8                                          = 0x8051;
+    const GLenum RGBA8                                         = 0x8058;
+    const GLenum RGB10_A2                                      = 0x8059;
+    const GLenum TEXTURE_BINDING_3D                            = 0x806A;
+    const GLenum UNPACK_SKIP_IMAGES                            = 0x806D;
+    const GLenum UNPACK_IMAGE_HEIGHT                           = 0x806E;
+    const GLenum TEXTURE_3D                                    = 0x806F;
+    const GLenum TEXTURE_WRAP_R                                = 0x8072;
+    const GLenum MAX_3D_TEXTURE_SIZE                           = 0x8073;
+    const GLenum UNSIGNED_INT_2_10_10_10_REV                   = 0x8368;
+    const GLenum MAX_ELEMENTS_VERTICES                         = 0x80E8;
+    const GLenum MAX_ELEMENTS_INDICES                          = 0x80E9;
+    const GLenum TEXTURE_MIN_LOD                               = 0x813A;
+    const GLenum TEXTURE_MAX_LOD                               = 0x813B;
+    const GLenum TEXTURE_BASE_LEVEL                            = 0x813C;
+    const GLenum TEXTURE_MAX_LEVEL                             = 0x813D;
+    const GLenum MIN                                           = 0x8007;
+    const GLenum MAX                                           = 0x8008;
+    const GLenum DEPTH_COMPONENT24                             = 0x81A6;
+    const GLenum MAX_TEXTURE_LOD_BIAS                          = 0x84FD;
+    const GLenum TEXTURE_COMPARE_MODE                          = 0x884C;
+    const GLenum TEXTURE_COMPARE_FUNC                          = 0x884D;
+    const GLenum CURRENT_QUERY                                 = 0x8865;
+    const GLenum QUERY_RESULT                                  = 0x8866;
+    const GLenum QUERY_RESULT_AVAILABLE                        = 0x8867;
+    const GLenum STREAM_READ                                   = 0x88E1;
+    const GLenum STREAM_COPY                                   = 0x88E2;
+    const GLenum STATIC_READ                                   = 0x88E5;
+    const GLenum STATIC_COPY                                   = 0x88E6;
+    const GLenum DYNAMIC_READ                                  = 0x88E9;
+    const GLenum DYNAMIC_COPY                                  = 0x88EA;
+    const GLenum MAX_DRAW_BUFFERS                              = 0x8824;
+    const GLenum DRAW_BUFFER0                                  = 0x8825;
+    const GLenum DRAW_BUFFER1                                  = 0x8826;
+    const GLenum DRAW_BUFFER2                                  = 0x8827;
+    const GLenum DRAW_BUFFER3                                  = 0x8828;
+    const GLenum DRAW_BUFFER4                                  = 0x8829;
+    const GLenum DRAW_BUFFER5                                  = 0x882A;
+    const GLenum DRAW_BUFFER6                                  = 0x882B;
+    const GLenum DRAW_BUFFER7                                  = 0x882C;
+    const GLenum DRAW_BUFFER8                                  = 0x882D;
+    const GLenum DRAW_BUFFER9                                  = 0x882E;
+    const GLenum DRAW_BUFFER10                                 = 0x882F;
+    const GLenum DRAW_BUFFER11                                 = 0x8830;
+    const GLenum DRAW_BUFFER12                                 = 0x8831;
+    const GLenum DRAW_BUFFER13                                 = 0x8832;
+    const GLenum DRAW_BUFFER14                                 = 0x8833;
+    const GLenum DRAW_BUFFER15                                 = 0x8834;
+    const GLenum MAX_FRAGMENT_UNIFORM_COMPONENTS               = 0x8B49;
+    const GLenum MAX_VERTEX_UNIFORM_COMPONENTS                 = 0x8B4A;
+    const GLenum SAMPLER_3D                                    = 0x8B5F;
+    const GLenum SAMPLER_2D_SHADOW                             = 0x8B62;
+    const GLenum FRAGMENT_SHADER_DERIVATIVE_HINT               = 0x8B8B;
+    const GLenum PIXEL_PACK_BUFFER                             = 0x88EB;
+    const GLenum PIXEL_UNPACK_BUFFER                           = 0x88EC;
+    const GLenum PIXEL_PACK_BUFFER_BINDING                     = 0x88ED;
+    const GLenum PIXEL_UNPACK_BUFFER_BINDING                   = 0x88EF;
+    const GLenum FLOAT_MAT2x3                                  = 0x8B65;
+    const GLenum FLOAT_MAT2x4                                  = 0x8B66;
+    const GLenum FLOAT_MAT3x2                                  = 0x8B67;
+    const GLenum FLOAT_MAT3x4                                  = 0x8B68;
+    const GLenum FLOAT_MAT4x2                                  = 0x8B69;
+    const GLenum FLOAT_MAT4x3                                  = 0x8B6A;
+    const GLenum SRGB                                          = 0x8C40;
+    const GLenum SRGB8                                         = 0x8C41;
+    const GLenum SRGB8_ALPHA8                                  = 0x8C43;
+    const GLenum COMPARE_REF_TO_TEXTURE                        = 0x884E;
+    const GLenum RGBA32F                                       = 0x8814;
+    const GLenum RGB32F                                        = 0x8815;
+    const GLenum RGBA16F                                       = 0x881A;
+    const GLenum RGB16F                                        = 0x881B;
+    const GLenum VERTEX_ATTRIB_ARRAY_INTEGER                   = 0x88FD;
+    const GLenum MAX_ARRAY_TEXTURE_LAYERS                      = 0x88FF;
+    const GLenum MIN_PROGRAM_TEXEL_OFFSET                      = 0x8904;
+    const GLenum MAX_PROGRAM_TEXEL_OFFSET                      = 0x8905;
+    const GLenum MAX_VARYING_COMPONENTS                        = 0x8B4B;
+    const GLenum TEXTURE_2D_ARRAY                              = 0x8C1A;
+    const GLenum TEXTURE_BINDING_2D_ARRAY                      = 0x8C1D;
+    const GLenum R11F_G11F_B10F                                = 0x8C3A;
+    const GLenum UNSIGNED_INT_10F_11F_11F_REV                  = 0x8C3B;
+    const GLenum RGB9_E5                                       = 0x8C3D;
+    const GLenum UNSIGNED_INT_5_9_9_9_REV                      = 0x8C3E;
+    const GLenum TRANSFORM_FEEDBACK_BUFFER_MODE                = 0x8C7F;
+    const GLenum MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS    = 0x8C80;
+    const GLenum TRANSFORM_FEEDBACK_VARYINGS                   = 0x8C83;
+    const GLenum TRANSFORM_FEEDBACK_BUFFER_START               = 0x8C84;
+    const GLenum TRANSFORM_FEEDBACK_BUFFER_SIZE                = 0x8C85;
+    const GLenum TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN         = 0x8C88;
+    const GLenum RASTERIZER_DISCARD                            = 0x8C89;
+    const GLenum MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS = 0x8C8A;
+    const GLenum MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS       = 0x8C8B;
+    const GLenum INTERLEAVED_ATTRIBS                           = 0x8C8C;
+    const GLenum SEPARATE_ATTRIBS                              = 0x8C8D;
+    const GLenum TRANSFORM_FEEDBACK_BUFFER                     = 0x8C8E;
+    const GLenum TRANSFORM_FEEDBACK_BUFFER_BINDING             = 0x8C8F;
+    const GLenum RGBA32UI                                      = 0x8D70;
+    const GLenum RGB32UI                                       = 0x8D71;
+    const GLenum RGBA16UI                                      = 0x8D76;
+    const GLenum RGB16UI                                       = 0x8D77;
+    const GLenum RGBA8UI                                       = 0x8D7C;
+    const GLenum RGB8UI                                        = 0x8D7D;
+    const GLenum RGBA32I                                       = 0x8D82;
+    const GLenum RGB32I                                        = 0x8D83;
+    const GLenum RGBA16I                                       = 0x8D88;
+    const GLenum RGB16I                                        = 0x8D89;
+    const GLenum RGBA8I                                        = 0x8D8E;
+    const GLenum RGB8I                                         = 0x8D8F;
+    const GLenum RED_INTEGER                                   = 0x8D94;
+    const GLenum RGB_INTEGER                                   = 0x8D98;
+    const GLenum RGBA_INTEGER                                  = 0x8D99;
+    const GLenum SAMPLER_2D_ARRAY                              = 0x8DC1;
+    const GLenum SAMPLER_2D_ARRAY_SHADOW                       = 0x8DC4;
+    const GLenum SAMPLER_CUBE_SHADOW                           = 0x8DC5;
+    const GLenum UNSIGNED_INT_VEC2                             = 0x8DC6;
+    const GLenum UNSIGNED_INT_VEC3                             = 0x8DC7;
+    const GLenum UNSIGNED_INT_VEC4                             = 0x8DC8;
+    const GLenum INT_SAMPLER_2D                                = 0x8DCA;
+    const GLenum INT_SAMPLER_3D                                = 0x8DCB;
+    const GLenum INT_SAMPLER_CUBE                              = 0x8DCC;
+    const GLenum INT_SAMPLER_2D_ARRAY                          = 0x8DCF;
+    const GLenum UNSIGNED_INT_SAMPLER_2D                       = 0x8DD2;
+    const GLenum UNSIGNED_INT_SAMPLER_3D                       = 0x8DD3;
+    const GLenum UNSIGNED_INT_SAMPLER_CUBE                     = 0x8DD4;
+    const GLenum UNSIGNED_INT_SAMPLER_2D_ARRAY                 = 0x8DD7;
+    const GLenum DEPTH_COMPONENT32F                            = 0x8CAC;
+    const GLenum DEPTH32F_STENCIL8                             = 0x8CAD;
+    const GLenum FLOAT_32_UNSIGNED_INT_24_8_REV                = 0x8DAD;
+    const GLenum FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING         = 0x8210;
+    const GLenum FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE         = 0x8211;
+    const GLenum FRAMEBUFFER_ATTACHMENT_RED_SIZE               = 0x8212;
+    const GLenum FRAMEBUFFER_ATTACHMENT_GREEN_SIZE             = 0x8213;
+    const GLenum FRAMEBUFFER_ATTACHMENT_BLUE_SIZE              = 0x8214;
+    const GLenum FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE             = 0x8215;
+    const GLenum FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE             = 0x8216;
+    const GLenum FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE           = 0x8217;
+    const GLenum FRAMEBUFFER_DEFAULT                           = 0x8218;
+    const GLenum UNSIGNED_INT_24_8                             = 0x84FA;
+    const GLenum DEPTH24_STENCIL8                              = 0x88F0;
+    const GLenum UNSIGNED_NORMALIZED                           = 0x8C17;
+    const GLenum DRAW_FRAMEBUFFER_BINDING                      = 0x8CA6; /* Same as FRAMEBUFFER_BINDING */
+    const GLenum READ_FRAMEBUFFER                              = 0x8CA8;
+    const GLenum DRAW_FRAMEBUFFER                              = 0x8CA9;
+    const GLenum READ_FRAMEBUFFER_BINDING                      = 0x8CAA;
+    const GLenum RENDERBUFFER_SAMPLES                          = 0x8CAB;
+    const GLenum FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER          = 0x8CD4;
+    const GLenum MAX_COLOR_ATTACHMENTS                         = 0x8CDF;
+    const GLenum COLOR_ATTACHMENT1                             = 0x8CE1;
+    const GLenum COLOR_ATTACHMENT2                             = 0x8CE2;
+    const GLenum COLOR_ATTACHMENT3                             = 0x8CE3;
+    const GLenum COLOR_ATTACHMENT4                             = 0x8CE4;
+    const GLenum COLOR_ATTACHMENT5                             = 0x8CE5;
+    const GLenum COLOR_ATTACHMENT6                             = 0x8CE6;
+    const GLenum COLOR_ATTACHMENT7                             = 0x8CE7;
+    const GLenum COLOR_ATTACHMENT8                             = 0x8CE8;
+    const GLenum COLOR_ATTACHMENT9                             = 0x8CE9;
+    const GLenum COLOR_ATTACHMENT10                            = 0x8CEA;
+    const GLenum COLOR_ATTACHMENT11                            = 0x8CEB;
+    const GLenum COLOR_ATTACHMENT12                            = 0x8CEC;
+    const GLenum COLOR_ATTACHMENT13                            = 0x8CED;
+    const GLenum COLOR_ATTACHMENT14                            = 0x8CEE;
+    const GLenum COLOR_ATTACHMENT15                            = 0x8CEF;
+    const GLenum FRAMEBUFFER_INCOMPLETE_MULTISAMPLE            = 0x8D56;
+    const GLenum MAX_SAMPLES                                   = 0x8D57;
+    const GLenum HALF_FLOAT                                    = 0x140B;
+    const GLenum RG                                            = 0x8227;
+    const GLenum RG_INTEGER                                    = 0x8228;
+    const GLenum R8                                            = 0x8229;
+    const GLenum RG8                                           = 0x822B;
+    const GLenum R16F                                          = 0x822D;
+    const GLenum R32F                                          = 0x822E;
+    const GLenum RG16F                                         = 0x822F;
+    const GLenum RG32F                                         = 0x8230;
+    const GLenum R8I                                           = 0x8231;
+    const GLenum R8UI                                          = 0x8232;
+    const GLenum R16I                                          = 0x8233;
+    const GLenum R16UI                                         = 0x8234;
+    const GLenum R32I                                          = 0x8235;
+    const GLenum R32UI                                         = 0x8236;
+    const GLenum RG8I                                          = 0x8237;
+    const GLenum RG8UI                                         = 0x8238;
+    const GLenum RG16I                                         = 0x8239;
+    const GLenum RG16UI                                        = 0x823A;
+    const GLenum RG32I                                         = 0x823B;
+    const GLenum RG32UI                                        = 0x823C;
+    const GLenum VERTEX_ARRAY_BINDING                          = 0x85B5;
+    const GLenum R8_SNORM                                      = 0x8F94;
+    const GLenum RG8_SNORM                                     = 0x8F95;
+    const GLenum RGB8_SNORM                                    = 0x8F96;
+    const GLenum RGBA8_SNORM                                   = 0x8F97;
+    const GLenum SIGNED_NORMALIZED                             = 0x8F9C;
+    const GLenum COPY_READ_BUFFER                              = 0x8F36;
+    const GLenum COPY_WRITE_BUFFER                             = 0x8F37;
+    const GLenum COPY_READ_BUFFER_BINDING                      = 0x8F36; /* Same as COPY_READ_BUFFER */
+    const GLenum COPY_WRITE_BUFFER_BINDING                     = 0x8F37; /* Same as COPY_WRITE_BUFFER */
+    const GLenum UNIFORM_BUFFER                                = 0x8A11;
+    const GLenum UNIFORM_BUFFER_BINDING                        = 0x8A28;
+    const GLenum UNIFORM_BUFFER_START                          = 0x8A29;
+    const GLenum UNIFORM_BUFFER_SIZE                           = 0x8A2A;
+    const GLenum MAX_VERTEX_UNIFORM_BLOCKS                     = 0x8A2B;
+    const GLenum MAX_FRAGMENT_UNIFORM_BLOCKS                   = 0x8A2D;
+    const GLenum MAX_COMBINED_UNIFORM_BLOCKS                   = 0x8A2E;
+    const GLenum MAX_UNIFORM_BUFFER_BINDINGS                   = 0x8A2F;
+    const GLenum MAX_UNIFORM_BLOCK_SIZE                        = 0x8A30;
+    const GLenum MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS        = 0x8A31;
+    const GLenum MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS      = 0x8A33;
+    const GLenum UNIFORM_BUFFER_OFFSET_ALIGNMENT               = 0x8A34;
+    const GLenum ACTIVE_UNIFORM_BLOCKS                         = 0x8A36;
+    const GLenum UNIFORM_TYPE                                  = 0x8A37;
+    const GLenum UNIFORM_SIZE                                  = 0x8A38;
+    const GLenum UNIFORM_BLOCK_INDEX                           = 0x8A3A;
+    const GLenum UNIFORM_OFFSET                                = 0x8A3B;
+    const GLenum UNIFORM_ARRAY_STRIDE                          = 0x8A3C;
+    const GLenum UNIFORM_MATRIX_STRIDE                         = 0x8A3D;
+    const GLenum UNIFORM_IS_ROW_MAJOR                          = 0x8A3E;
+    const GLenum UNIFORM_BLOCK_BINDING                         = 0x8A3F;
+    const GLenum UNIFORM_BLOCK_DATA_SIZE                       = 0x8A40;
+    const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORMS                 = 0x8A42;
+    const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES          = 0x8A43;
+    const GLenum UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER     = 0x8A44;
+    const GLenum UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER   = 0x8A46;
+    const GLenum INVALID_INDEX                                 = 0xFFFFFFFF;
+    const GLenum MAX_VERTEX_OUTPUT_COMPONENTS                  = 0x9122;
+    const GLenum MAX_FRAGMENT_INPUT_COMPONENTS                 = 0x9125;
+    const GLenum MAX_SERVER_WAIT_TIMEOUT                       = 0x9111;
+    const GLenum OBJECT_TYPE                                   = 0x9112;
+    const GLenum SYNC_CONDITION                                = 0x9113;
+    const GLenum SYNC_STATUS                                   = 0x9114;
+    const GLenum SYNC_FLAGS                                    = 0x9115;
+    const GLenum SYNC_FENCE                                    = 0x9116;
+    const GLenum SYNC_GPU_COMMANDS_COMPLETE                    = 0x9117;
+    const GLenum UNSIGNALED                                    = 0x9118;
+    const GLenum SIGNALED                                      = 0x9119;
+    const GLenum ALREADY_SIGNALED                              = 0x911A;
+    const GLenum TIMEOUT_EXPIRED                               = 0x911B;
+    const GLenum CONDITION_SATISFIED                           = 0x911C;
+    const GLenum WAIT_FAILED                                   = 0x911D;
+    const GLenum SYNC_FLUSH_COMMANDS_BIT                       = 0x00000001;
+    const GLenum VERTEX_ATTRIB_ARRAY_DIVISOR                   = 0x88FE;
+    const GLenum ANY_SAMPLES_PASSED                            = 0x8C2F;
+    const GLenum ANY_SAMPLES_PASSED_CONSERVATIVE               = 0x8D6A;
+    const GLenum SAMPLER_BINDING                               = 0x8919;
+    const GLenum RGB10_A2UI                                    = 0x906F;
+    const GLenum INT_2_10_10_10_REV                            = 0x8D9F;
+    const GLenum TRANSFORM_FEEDBACK                            = 0x8E22;
+    const GLenum TRANSFORM_FEEDBACK_PAUSED                     = 0x8E23;
+    const GLenum TRANSFORM_FEEDBACK_ACTIVE                     = 0x8E24;
+    const GLenum TRANSFORM_FEEDBACK_BINDING                    = 0x8E25;
+    const GLenum TEXTURE_IMMUTABLE_FORMAT                      = 0x912F;
+    const GLenum MAX_ELEMENT_INDEX                             = 0x8D6B;
+    const GLenum TEXTURE_IMMUTABLE_LEVELS                      = 0x82DF;
+    const GLint TIMEOUT_IGNORED                                = -1;
+
+    /* WebGL-specific enums */
+    const GLenum MAX_CLIENT_WAIT_TIMEOUT_WEBGL                 = 0x9247;
+
+    /* Buffer objects */
+    void bufferData(GLenum target, [AllowShared] ArrayBufferView srcData, GLenum usage, GLuint srcOffset, optional GLuint length = 0);
+    void bufferSubData(GLenum target, GLintptr dstByteOffset, [AllowShared] ArrayBufferView srcData, GLuint srcOffset, optional GLuint length = 0);
+    void copyBufferSubData(GLenum readTarget, GLenum writeTarget, GLintptr readOffset, GLintptr writeOffset, GLsizeiptr size);
+    void getBufferSubData(GLenum target, GLintptr srcByteOffset, [AllowShared] ArrayBufferView dstData, optional GLuint dstOffset = 0, optional GLuint length = 0);
+
+    /* Framebuffer objects */
+    void blitFramebuffer(GLint srcX0, GLint srcY0, GLint srcX1, GLint srcY1, GLint dstX0, GLint dstY0, GLint dstX1, GLint dstY1, GLbitfield mask, GLenum filter);
+    void framebufferTextureLayer(GLenum target, GLenum attachment, WebGLTexture? texture, GLint level, GLint layer);
+    [CallWith=ScriptState] any getInternalformatParameter(GLenum target, GLenum internalformat, GLenum pname);
+    void invalidateFramebuffer(GLenum target, sequence<GLenum> attachments);
+    void invalidateSubFramebuffer(GLenum target, sequence<GLenum> attachments, GLint x, GLint y, GLsizei width, GLsizei height);
+    void readBuffer(GLenum mode);
+
+    /* Renderbuffer objects */
+    void renderbufferStorageMultisample(GLenum target, GLsizei samples, GLenum internalformat, GLsizei width, GLsizei height);
+
+    /* Texture objects */
+    void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, GLintptr offset);
+    void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, ImageData data);
+    [CallWith=ExecutionContext, RaisesException] void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, HTMLImageElement image);
+    [CallWith=ExecutionContext, RaisesException] void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, HTMLCanvasElement canvas);
+    [CallWith=ExecutionContext,RaisesException] void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, HTMLVideoElement video);
+    [RaisesException] void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, ImageBitmap bitmap);
+    void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData, GLuint srcOffset);
+    void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, GLintptr offset);
+    void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, ImageData data);
+    [CallWith=ExecutionContext, RaisesException] void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, HTMLImageElement image);
+    [CallWith=ExecutionContext, RaisesException] void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, HTMLCanvasElement canvas);
+    [CallWith=ExecutionContext, RaisesException] void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, HTMLVideoElement video);
+    [RaisesException] void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, ImageBitmap bitmap);
+    void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width, GLsizei height, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData, GLuint srcOffset);
+    void texStorage2D(GLenum target, GLsizei levels, GLenum internalformat, GLsizei width, GLsizei height);
+    void texStorage3D(GLenum target, GLsizei levels, GLenum internalformat, GLsizei width, GLsizei height, GLsizei depth);
+    void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, GLintptr offset);
+    void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, ImageData data);
+    [CallWith=ExecutionContext, RaisesException] void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, HTMLImageElement image);
+    [CallWith=ExecutionContext, RaisesException] void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, HTMLCanvasElement canvas);
+    [CallWith=ExecutionContext, RaisesException] void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, HTMLVideoElement video);
+    [RaisesException] void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, ImageBitmap bitmap);
+    void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView? pixels);
+    void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView pixels, GLuint srcOffset);
+    void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, GLintptr offset);
+    void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, ImageData data);
+    [CallWith=ExecutionContext, RaisesException] void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, HTMLImageElement image);
+    [CallWith=ExecutionContext, RaisesException] void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, HTMLCanvasElement canvas);
+    [CallWith=ExecutionContext, RaisesException] void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, HTMLVideoElement video);
+    [RaisesException] void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, ImageBitmap bitmap);
+    void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type, [AllowShared] ArrayBufferView pixels, optional GLuint srcOffset = 0);
+
+    void copyTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLint x, GLint y, GLsizei width, GLsizei height);
+
+    void compressedTexImage2D(GLenum target, GLint level, GLenum internalformat,
+                              GLsizei width, GLsizei height, GLint border,
+                              [AllowShared] ArrayBufferView data, GLuint srcOffset,
+                              optional GLuint srcLengthOverride = 0);
+    void compressedTexSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                                 GLsizei width, GLsizei height, GLenum format,
+                                 [AllowShared] ArrayBufferView data, GLuint srcOffset,
+                                 optional GLuint srcLengthOverride = 0);
+    void compressedTexImage3D(GLenum target, GLint level, GLenum internalformat, GLsizei width, GLsizei height, GLsizei depth, GLint border, [AllowShared] ArrayBufferView data, optional GLuint srcOffset = 0, optional GLuint srcLengthOverride = 0);
+    void compressedTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset, GLsizei width, GLsizei height, GLsizei depth, GLenum format, [AllowShared] ArrayBufferView data, optional GLuint srcOffset = 0, optional GLuint srcLengthOverride = 0);
+
+    void compressedTexImage2D(GLenum target, GLint level, GLenum internalformat,
+                              GLsizei width, GLsizei height, GLint border,
+                              GLsizei imageSize, GLintptr offset);
+    void compressedTexSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                                 GLsizei width, GLsizei height, GLenum format,
+                                 GLsizei imageSize, GLintptr offset);
+    void compressedTexImage3D(GLenum target, GLint level, GLenum internalformat,
+                              GLsizei width, GLsizei height, GLsizei depth, GLint border,
+                              GLsizei imageSize, GLintptr offset);
+    void compressedTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                                 GLsizei width, GLsizei height, GLsizei depth, GLenum format,
+                                 GLsizei imageSize, GLintptr offset);
+
+    /* Programs and shaders */
+    GLint getFragDataLocation(WebGLProgram program, DOMString name);
+
+    /* Uniforms and attributes */
+    void uniform1ui(WebGLUniformLocation? location, GLuint v0);
+    void uniform2ui(WebGLUniformLocation? location, GLuint v0, GLuint v1);
+    void uniform3ui(WebGLUniformLocation? location, GLuint v0, GLuint v1, GLuint v2);
+    void uniform4ui(WebGLUniformLocation? location, GLuint v0, GLuint v1, GLuint v2, GLuint v3);
+    // The WebGL1 uniform*v signatures are visible here, so srcOffset has to be non-optional
+    // to avoid conflicts. The effect is the same: if uniform*v is called with only two arguments,
+    // it goes to the WebGL1 signatures; if it's called with three or four arguments, it goes to
+    // the WebGL2 specific signatures.
+    void uniform1fv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Float32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform1fv(WebGLUniformLocation? location, sequence<GLfloat> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform2fv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Float32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform2fv(WebGLUniformLocation? location, sequence<GLfloat> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform3fv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Float32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform3fv(WebGLUniformLocation? location, sequence<GLfloat> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform4fv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Float32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform4fv(WebGLUniformLocation? location, sequence<GLfloat> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform1iv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Int32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform1iv(WebGLUniformLocation? location, sequence<GLint> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform2iv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Int32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform2iv(WebGLUniformLocation? location, sequence<GLint> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform3iv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Int32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform3iv(WebGLUniformLocation? location, sequence<GLint> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform4iv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Int32Array v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform4iv(WebGLUniformLocation? location, sequence<GLint> v,
+                    GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniform1uiv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Uint32Array v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniform1uiv(WebGLUniformLocation? location, sequence<GLuint> v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniform2uiv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Uint32Array v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniform2uiv(WebGLUniformLocation? location, sequence<GLuint> v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniform3uiv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Uint32Array v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniform3uiv(WebGLUniformLocation? location, sequence<GLuint> v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniform4uiv(WebGLUniformLocation? location, [FlexibleArrayBufferView] Uint32Array v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniform4uiv(WebGLUniformLocation? location, sequence<GLuint> v,
+                     optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix2fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array array,
+                          GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniformMatrix2fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> array,
+                          GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniformMatrix3fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array array,
+                          GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniformMatrix3fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> array,
+                          GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniformMatrix4fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array array,
+                          GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniformMatrix4fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> array,
+                          GLuint srcOffset, optional GLuint srcLength = 0);
+    void uniformMatrix2x3fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix2x3fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix3x2fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix3x2fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix2x4fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix2x4fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix4x2fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix4x2fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix3x4fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix3x4fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix4x3fv(WebGLUniformLocation? location, GLboolean transpose, [AllowShared] Float32Array value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+    void uniformMatrix4x3fv(WebGLUniformLocation? location, GLboolean transpose, sequence<GLfloat> value,
+                            optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+
+    void vertexAttribI4i(GLuint index, GLint x, GLint y, GLint z, GLint w);
+    void vertexAttribI4iv(GLuint index, [AllowShared] Int32Array v);
+    void vertexAttribI4iv(GLuint index, sequence<GLint> v);
+    void vertexAttribI4ui(GLuint index, GLuint x, GLuint y, GLuint z, GLuint w);
+    void vertexAttribI4uiv(GLuint index, [AllowShared] Uint32Array v);
+    void vertexAttribI4uiv(GLuint index, sequence<GLuint> v);
+    void vertexAttribIPointer(GLuint index, GLint size, GLenum type, GLsizei stride, GLintptr offset);
+
+    /* Writing to the drawing buffer */
+    void vertexAttribDivisor(GLuint index, GLuint divisor);
+    void drawArraysInstanced(GLenum mode, GLint first, GLsizei count, GLsizei instanceCount);
+    void drawElementsInstanced(GLenum mode, GLsizei count, GLenum type, GLintptr offset, GLsizei instanceCount);
+    void drawRangeElements(GLenum mode, GLuint start, GLuint end, GLsizei count, GLenum type, GLintptr offset);
+
+    /* Multiple Render Targets */
+    void drawBuffers(sequence<GLenum> buffers);
+    void clearBufferiv(GLenum buffer, GLint drawbuffer, [AllowShared] Int32Array value, optional GLuint srcOffset = 0);
+    void clearBufferiv(GLenum buffer, GLint drawbuffer, sequence<GLint> value, optional GLuint srcOffset = 0);
+    void clearBufferuiv(GLenum buffer, GLint drawbuffer, [AllowShared] Uint32Array value, optional GLuint srcOffset = 0);
+    void clearBufferuiv(GLenum buffer, GLint drawbuffer, sequence<GLuint> value, optional GLuint srcOffset = 0);
+    void clearBufferfv(GLenum buffer, GLint drawbuffer, [AllowShared] Float32Array value, optional GLuint srcOffset = 0);
+    void clearBufferfv(GLenum buffer, GLint drawbuffer, sequence<GLfloat> value, optional GLuint srcOffset = 0);
+    void clearBufferfi(GLenum buffer, GLint drawbuffer, GLfloat depth, GLint stencil);
+
+    /* Query Objects */
+    WebGLQuery? createQuery();
+    void deleteQuery(WebGLQuery? query);
+    GLboolean isQuery(WebGLQuery? query);
+    void beginQuery(GLenum target, WebGLQuery query);
+    void endQuery(GLenum target);
+    [CallWith=ScriptState] any getQuery(GLenum target, GLenum pname);
+    [CallWith=ScriptState] any getQueryParameter(WebGLQuery query, GLenum pname);
+
+    /* Sampler Objects */
+    WebGLSampler? createSampler();
+    void deleteSampler(WebGLSampler? sampler);
+    GLboolean isSampler(WebGLSampler? sampler);
+    void bindSampler(GLuint unit, WebGLSampler? sampler);
+    void samplerParameteri(WebGLSampler sampler, GLenum pname, GLint param);
+    void samplerParameterf(WebGLSampler sampler, GLenum pname, GLfloat param);
+    [CallWith=ScriptState] any getSamplerParameter(WebGLSampler sampler, GLenum pname);
+
+    /* Sync objects */
+    WebGLSync? fenceSync(GLenum condition, GLbitfield flags);
+    GLboolean isSync(WebGLSync? sync);
+    void deleteSync(WebGLSync? sync);
+    GLenum clientWaitSync(WebGLSync sync, GLbitfield flags, GLuint64 timeout);
+    void waitSync(WebGLSync sync, GLbitfield flags, GLint64 timeout);
+
+    [CallWith=ScriptState] any getSyncParameter(WebGLSync sync, GLenum pname);
+
+    /* Transform Feedback */
+    WebGLTransformFeedback? createTransformFeedback();
+    void deleteTransformFeedback(WebGLTransformFeedback? feedback);
+    GLboolean isTransformFeedback(WebGLTransformFeedback? feedback);
+    void bindTransformFeedback(GLenum target, WebGLTransformFeedback? feedback);
+    void beginTransformFeedback(GLenum primitiveMode);
+    void endTransformFeedback();
+    void transformFeedbackVaryings(WebGLProgram program, sequence<DOMString> varyings, GLenum bufferMode);
+    WebGLActiveInfo? getTransformFeedbackVarying(WebGLProgram program, GLuint index);
+    void pauseTransformFeedback();
+    void resumeTransformFeedback();
+
+    /* Uniform Buffer Objects and Transform Feedback Buffers */
+    void bindBufferBase(GLenum target, GLuint index, WebGLBuffer? buffer);
+    void bindBufferRange(GLenum target, GLuint index, WebGLBuffer? buffer, GLintptr offset, GLsizeiptr size);
+    [CallWith=ScriptState] any getIndexedParameter(GLenum target, GLuint index);
+    sequence<GLuint>? getUniformIndices(WebGLProgram program, sequence<DOMString> uniformNames);
+    [CallWith=ScriptState] any getActiveUniforms(WebGLProgram program, sequence<GLuint> uniformIndices, GLenum pname);
+    GLuint getUniformBlockIndex(WebGLProgram program, DOMString uniformBlockName);
+    [CallWith=ScriptState] any getActiveUniformBlockParameter(WebGLProgram program, GLuint uniformBlockIndex, GLenum pname);
+    DOMString? getActiveUniformBlockName(WebGLProgram program, GLuint uniformBlockIndex);
+    void uniformBlockBinding(WebGLProgram program, GLuint uniformBlockIndex, GLuint uniformBlockBinding);
+
+    /* Vertex Array Objects */
+    WebGLVertexArrayObject? createVertexArray();
+    void deleteVertexArray(WebGLVertexArrayObject? vertexArray);
+    GLboolean isVertexArray(WebGLVertexArrayObject? vertexArray);
+    void bindVertexArray(WebGLVertexArrayObject? vertexArray);
+
+    /* Reading */
+    void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type, [AllowShared] ArrayBufferView dstData, GLintptr offset);
+    void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type, GLintptr offset);
+};
+WebGL2RenderingContextBase implements WebGLRenderingContextBase;
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h	2018-04-27 11:31:20.527828940 +0300
@@ -5,6 +5,7 @@
 #ifndef SharedGpuContext_h
 #define SharedGpuContext_h
 
+#include <functional>
 #include <memory>
 #include "base/callback.h"
 #include "base/memory/weak_ptr.h"
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h.gcc7 chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h.gcc7
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h.gcc7	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/graphics/gpu/SharedGpuContext.h.gcc7	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,66 @@
+// Copyright 2016 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef SharedGpuContext_h
+#define SharedGpuContext_h
+
+#include <memory>
+#include "base/callback.h"
+#include "base/memory/weak_ptr.h"
+#include "platform/PlatformExport.h"
+#include "platform/graphics/WebGraphicsContext3DProviderWrapper.h"
+#include "platform/wtf/ThreadSpecific.h"
+
+namespace blink {
+
+class WebGraphicsContext3DProvider;
+
+// SharedGpuContext provides access to a thread-specific GPU context
+// that is shared by many callsites throughout the thread.
+// When on the main thread, provides access to the same context as
+// Platform::CreateSharedOffscreenGraphicsContext3DProvider, and the
+// same query as Platform::IsGPUCompositingEnabled().
+class PLATFORM_EXPORT SharedGpuContext {
+ public:
+  // Thread-safe query if gpu compositing is enabled. This should be done before
+  // calling ContextProviderWrapper() if the context will be used to make
+  // resources meant for the compositor. When it is false, no context will be
+  // needed and software-based resources should be given to the compositor
+  // instead.
+  static bool IsGpuCompositingEnabled();
+  // May re-create context if context was lost
+  static base::WeakPtr<WebGraphicsContext3DProviderWrapper>
+  ContextProviderWrapper();
+  static bool AllowSoftwareToAcceleratedCanvasUpgrade();
+  static bool IsValidWithoutRestoring();
+
+  using ContextProviderFactory =
+      base::RepeatingCallback<std::unique_ptr<WebGraphicsContext3DProvider>(
+          bool* is_gpu_compositing_disabled)>;
+  static void SetContextProviderFactoryForTesting(ContextProviderFactory);
+  // Resets the global instance including the |context_provider_factory_| and
+  // dropping the context. Should be called at the end of a test that uses this
+  // to not interfere with the next test.
+  static void ResetForTesting();
+
+ private:
+  friend class WTF::ThreadSpecific<SharedGpuContext>;
+
+  static SharedGpuContext* GetInstanceForCurrentThread();
+
+  SharedGpuContext();
+  void CreateContextProviderIfNeeded(bool only_if_gpu_compositing);
+
+  // Can be overridden for tests.
+  ContextProviderFactory context_provider_factory_;
+
+  // This is sticky once true, we never need to ask again.
+  bool is_gpu_compositing_disabled_ = false;
+  std::unique_ptr<WebGraphicsContext3DProviderWrapper>
+      context_provider_wrapper_;
+};
+
+}  // blink
+
+#endif  // SharedGpuContext_h
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/heap/TraceTraits.h.oilpan chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/heap/TraceTraits.h.oilpan
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/heap/TraceTraits.h.oilpan	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/heap/TraceTraits.h.oilpan	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,818 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef TraceTraits_h
+#define TraceTraits_h
+
+#include "platform/bindings/ScriptWrappableVisitor.h"
+#include "platform/heap/GCInfo.h"
+#include "platform/heap/Heap.h"
+#include "platform/heap/StackFrameDepth.h"
+#include "platform/heap/Visitor.h"
+#include "platform/wtf/Allocator.h"
+#include "platform/wtf/Assertions.h"
+#include "platform/wtf/HashCountedSet.h"
+#include "platform/wtf/HashMap.h"
+#include "platform/wtf/HashSet.h"
+#include "platform/wtf/HashTable.h"
+#include "platform/wtf/LinkedHashSet.h"
+#include "platform/wtf/ListHashSet.h"
+#include "platform/wtf/TypeTraits.h"
+
+namespace blink {
+
+template <typename T>
+class CrossThreadPersistent;
+template <typename T>
+class CrossThreadWeakPersistent;
+template <typename T>
+class HeapDoublyLinkedList;
+template <typename T>
+class HeapTerminatedArray;
+template <typename T>
+class Member;
+template <typename T>
+class TraceEagerlyTrait;
+template <typename T>
+class TraceTrait;
+template <typename T>
+class WeakMember;
+template <typename T>
+class WeakPersistent;
+
+// "g++ -Os" reasonably considers the mark() eager-tracing specialization
+// as an inlinable method. Its optimization pipeline will however trigger
+// unconditional uses of that inlining inside trace() methods, i.e., without
+// consideration for resulting code size, so one for each use of
+// "visitor->trace(..)". This results in an unwanted amount of extra code
+// across all trace methods. Address the issue indirectly by turning off
+// inlining for the method. See crbug.com/681991 for further details.
+//
+// TODO(sof): revisit with later g++ versions, or when g++ is no
+// longer used for production builds.
+#if !defined(__clang__) && defined(__GNUC__)
+#define NOINLINE_GXX_ONLY NOINLINE
+#else
+#define NOINLINE_GXX_ONLY
+#endif
+
+template <typename T, bool = NeedsAdjustAndMark<T>::value>
+class AdjustAndMarkTrait;
+
+template <typename T>
+class AdjustAndMarkTrait<T, false> {
+  STATIC_ONLY(AdjustAndMarkTrait);
+
+ public:
+  template <typename VisitorDispatcher>
+  static NOINLINE_GXX_ONLY void Mark(VisitorDispatcher visitor, const T* t) {
+#if DCHECK_IS_ON()
+    AssertObjectHasGCInfo(const_cast<T*>(t), GCInfoTrait<T>::Index());
+#endif
+    // Default mark method of the trait just calls the two-argument mark
+    // method on the visitor. The second argument is the static trace method
+    // of the trait, which by default calls the instance method
+    // trace(Visitor*) on the object.
+    //
+    // If the trait allows it, invoke the trace callback right here on the
+    // not-yet-marked object.
+    if (TraceEagerlyTrait<T>::value) {
+      // Protect against too deep trace call chains, and the
+      // unbounded system stack usage they can bring about.
+      //
+      // Assert against deep stacks so as to flush them out,
+      // but test and appropriately handle them should they occur
+      // in release builds.
+      //
+      // If you hit this assert, it means that you're creating an object
+      // graph that causes too many recursions, which might cause a stack
+      // overflow. To break the recursions, you need to add
+      // WILL_NOT_BE_EAGERLY_TRACED_CLASS() to classes that hold pointers
+      // that lead to many recursions.
+      DCHECK(visitor->Heap().GetStackFrameDepth().IsAcceptableStackUse());
+      if (LIKELY(visitor->Heap().GetStackFrameDepth().IsSafeToRecurse())) {
+        if (visitor->EnsureMarked(t)) {
+          TraceTrait<T>::Trace(visitor, const_cast<T*>(t));
+        }
+        return;
+      }
+    }
+    visitor->Mark(const_cast<T*>(t), &TraceTrait<T>::Trace);
+  }
+
+  static HeapObjectHeader* GetHeapObjectHeader(const T* self) {
+#if DCHECK_IS_ON()
+    HeapObjectHeader::CheckFromPayload(self);
+#endif
+    return HeapObjectHeader::FromPayload(self);
+  }
+
+  static void TraceMarkedWrapper(const ScriptWrappableVisitor* visitor,
+                                 const T* self) {
+    // The term *mark* is misleading here as we effectively trace through the
+    // API boundary, i.e., tell V8 that an object is alive. Actual marking
+    // will be done in V8.
+    visitor->DispatchTraceWrappers(self);
+    visitor->MarkWrappersInAllWorlds(self);
+  }
+};
+
+template <typename T>
+class AdjustAndMarkTrait<T, true> {
+  STATIC_ONLY(AdjustAndMarkTrait);
+
+ public:
+  template <typename VisitorDispatcher>
+  static void Mark(VisitorDispatcher visitor, const T* self) {
+    if (!self)
+      return;
+    self->AdjustAndMark(visitor);
+  }
+
+  static HeapObjectHeader* GetHeapObjectHeader(const T* self) {
+    return self->GetHeapObjectHeader();
+  }
+
+  static void TraceMarkedWrapper(const ScriptWrappableVisitor* visitor,
+                                 const T* self) {
+    self->AdjustAndTraceMarkedWrapper(visitor);
+  }
+};
+
+template <typename T, bool isTraceable>
+struct TraceIfEnabled;
+
+template <typename T>
+struct TraceIfEnabled<T, false> {
+  STATIC_ONLY(TraceIfEnabled);
+  template <typename VisitorDispatcher>
+  static void Trace(VisitorDispatcher, T&) {
+    static_assert(!WTF::IsTraceable<T>::value, "T should not be traced");
+  }
+};
+
+template <typename T>
+struct TraceIfEnabled<T, true> {
+  STATIC_ONLY(TraceIfEnabled);
+  template <typename VisitorDispatcher>
+  static void Trace(VisitorDispatcher visitor, T& t) {
+    static_assert(WTF::IsTraceable<T>::value, "T should not be traced");
+    visitor->Trace(t);
+  }
+};
+
+template <bool isTraceable,
+          WTF::WeakHandlingFlag weakHandlingFlag,
+          WTF::ShouldWeakPointersBeMarkedStrongly strongify,
+          typename T,
+          typename Traits>
+struct TraceCollectionIfEnabled;
+
+template <WTF::ShouldWeakPointersBeMarkedStrongly strongify,
+          typename T,
+          typename Traits>
+struct TraceCollectionIfEnabled<false,
+                                WTF::kNoWeakHandlingInCollections,
+                                strongify,
+                                T,
+                                Traits> {
+  STATIC_ONLY(TraceCollectionIfEnabled);
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher, T&) {
+    static_assert(!WTF::IsTraceableInCollectionTrait<Traits>::value,
+                  "T should not be traced");
+    return false;
+  }
+};
+
+template <bool isTraceable,
+          WTF::WeakHandlingFlag weakHandlingFlag,
+          WTF::ShouldWeakPointersBeMarkedStrongly strongify,
+          typename T,
+          typename Traits>
+struct TraceCollectionIfEnabled {
+  STATIC_ONLY(TraceCollectionIfEnabled);
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, T& t) {
+    static_assert(WTF::IsTraceableInCollectionTrait<Traits>::value ||
+                      weakHandlingFlag == WTF::kWeakHandlingInCollections,
+                  "Traits should be traced");
+    return WTF::TraceInCollectionTrait<weakHandlingFlag, strongify, T,
+                                       Traits>::Trace(visitor, t);
+  }
+};
+
+// The TraceTrait is used to specify how to mark an object pointer and
+// how to trace all of the pointers in the object.
+//
+// By default, the 'trace' method implemented on an object itself is
+// used to trace the pointers to other heap objects inside the object.
+//
+// However, the TraceTrait can be specialized to use a different
+// implementation. A common case where a TraceTrait specialization is
+// needed is when multiple inheritance leads to pointers that are not
+// to the start of the object in the Blink garbage-collected heap. In
+// that case the pointer has to be adjusted before marking.
+template <typename T>
+class TraceTrait {
+  STATIC_ONLY(TraceTrait);
+
+ public:
+  static void Trace(Visitor*, void* self);
+
+  static void TraceMarkedWrapper(const ScriptWrappableVisitor*, const void*);
+  static HeapObjectHeader* GetHeapObjectHeader(const void*);
+
+  template <typename VisitorDispatcher>
+  static void Mark(VisitorDispatcher visitor, const T* t) {
+    AdjustAndMarkTrait<T>::Mark(visitor, t);
+  }
+
+ private:
+  static const T* ToWrapperTracingType(const void* t) {
+    static_assert(sizeof(T), "type needs to be defined");
+    static_assert(IsGarbageCollectedType<T>::value,
+                  "only objects deriving from GarbageCollected can be used");
+    return reinterpret_cast<const T*>(t);
+  }
+};
+
+template <typename T>
+class TraceTrait<const T> : public TraceTrait<T> {};
+
+template <typename T>
+void TraceTrait<T>::Trace(Visitor* visitor, void* self) {
+  static_assert(WTF::IsTraceable<T>::value, "T should not be traced");
+  static_cast<T*>(self)->Trace(visitor);
+}
+
+template <typename T>
+void TraceTrait<T>::TraceMarkedWrapper(const ScriptWrappableVisitor* visitor,
+                                       const void* t) {
+  const T* traceable = ToWrapperTracingType(t);
+  DCHECK(GetHeapObjectHeader(traceable)->IsWrapperHeaderMarked());
+  AdjustAndMarkTrait<T>::TraceMarkedWrapper(visitor, traceable);
+}
+
+template <typename T>
+HeapObjectHeader* TraceTrait<T>::GetHeapObjectHeader(const void* t) {
+  return AdjustAndMarkTrait<T>::GetHeapObjectHeader(ToWrapperTracingType(t));
+}
+
+template <typename T, typename Traits>
+struct TraceTrait<HeapVectorBacking<T, Traits>> {
+  STATIC_ONLY(TraceTrait);
+  using Backing = HeapVectorBacking<T, Traits>;
+
+  template <typename VisitorDispatcher>
+  static void Trace(VisitorDispatcher visitor, void* self) {
+    static_assert(!WTF::IsWeak<T>::value,
+                  "weakness in HeapVectors and HeapDeques are not supported");
+    if (WTF::IsTraceableInCollectionTrait<Traits>::value)
+      WTF::TraceInCollectionTrait<
+          WTF::kNoWeakHandlingInCollections, WTF::kWeakPointersActWeak,
+          HeapVectorBacking<T, Traits>, void>::Trace(visitor, self);
+  }
+
+  template <typename VisitorDispatcher>
+  static void Mark(VisitorDispatcher visitor, const Backing* backing) {
+    AdjustAndMarkTrait<Backing>::Mark(visitor, backing);
+  }
+};
+
+// The trace trait for the heap hashtable backing is used when we find a
+// direct pointer to the backing from the conservative stack scanner.  This
+// normally indicates that there is an ongoing iteration over the table, and so
+// we disable weak processing of table entries.  When the backing is found
+// through the owning hash table we mark differently, in order to do weak
+// processing.
+template <typename Table>
+struct TraceTrait<HeapHashTableBacking<Table>> {
+  STATIC_ONLY(TraceTrait);
+  using Backing = HeapHashTableBacking<Table>;
+  using Traits = typename Table::ValueTraits;
+
+  template <typename VisitorDispatcher>
+  static void Trace(VisitorDispatcher visitor, void* self) {
+    if (WTF::IsTraceableInCollectionTrait<Traits>::value ||
+        Traits::kWeakHandlingFlag == WTF::kWeakHandlingInCollections)
+      WTF::TraceInCollectionTrait<WTF::kNoWeakHandlingInCollections,
+                                  WTF::kWeakPointersActStrong, Backing,
+                                  void>::Trace(visitor, self);
+  }
+
+  template <typename VisitorDispatcher>
+  static void Mark(VisitorDispatcher visitor, const Backing* backing) {
+    AdjustAndMarkTrait<Backing>::Mark(visitor, backing);
+  }
+};
+
+// This trace trait for std::pair will null weak members if their referent is
+// collected. If you have a collection that contain weakness it does not remove
+// entries from the collection that contain nulled weak members.
+template <typename T, typename U>
+class TraceTrait<std::pair<T, U>> {
+  STATIC_ONLY(TraceTrait);
+
+ public:
+  static const bool kFirstIsTraceable = WTF::IsTraceable<T>::value;
+  static const bool kSecondIsTraceable = WTF::IsTraceable<U>::value;
+  template <typename VisitorDispatcher>
+  static void Trace(VisitorDispatcher visitor, std::pair<T, U>* pair) {
+    TraceIfEnabled<T, kFirstIsTraceable>::Trace(visitor, pair->first);
+    TraceIfEnabled<U, kSecondIsTraceable>::Trace(visitor, pair->second);
+  }
+};
+
+// If eager tracing leads to excessively deep |trace()| call chains (and
+// the system stack usage that this brings), the marker implementation will
+// switch to using an explicit mark stack. Recursive and deep object graphs
+// are uncommon for Blink objects.
+//
+// A class type can opt out of eager tracing by declaring a TraceEagerlyTrait<>
+// specialization, mapping the trait's |value| to |false| (see the
+// WILL_NOT_BE_EAGERLY_TRACED_CLASS() macros below.) For Blink, this is done for
+// the small set of GCed classes that are directly recursive.
+//
+// The TraceEagerlyTrait<T> trait controls whether or not a class
+// (and its subclasses) should be eagerly traced or not.
+//
+// If |TraceEagerlyTrait<T>::value| is |true|, then the marker thread
+// should invoke |trace()| on not-yet-marked objects deriving from class T
+// right away, and not queue their trace callbacks on its marker stack,
+// which it will do if |value| is |false|.
+//
+// The trait can be declared to enable/disable eager tracing for a class T
+// and any of its subclasses, or just to the class T, but none of its
+// subclasses.
+//
+template <typename T>
+class TraceEagerlyTrait {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = true;
+};
+
+// Disable eager tracing for TYPE, but not any of its subclasses.
+#define WILL_NOT_BE_EAGERLY_TRACED_CLASS(TYPE) \
+  template <>                                  \
+  class TraceEagerlyTrait<TYPE> {              \
+    STATIC_ONLY(TraceEagerlyTrait);            \
+                                               \
+   public:                                     \
+    static const bool value = false;           \
+  }
+
+template <typename T>
+class TraceEagerlyTrait<Member<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<SameThreadCheckedMember<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<TraceWrapperMember<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<WeakMember<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<Persistent<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<WeakPersistent<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<CrossThreadPersistent<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<CrossThreadWeakPersistent<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<HeapTerminatedArray<T>> {
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename T>
+class TraceEagerlyTrait<HeapDoublyLinkedList<T>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = TraceEagerlyTrait<T>::value;
+};
+
+template <typename ValueArg, size_t inlineCapacity>
+class HeapListHashSetAllocator;
+template <typename T, size_t inlineCapacity>
+class TraceEagerlyTrait<
+    WTF::ListHashSetNode<T, HeapListHashSetAllocator<T, inlineCapacity>>> {
+  STATIC_ONLY(TraceEagerlyTrait);
+
+ public:
+  static const bool value = false;
+};
+
+template <typename T>
+struct TraceIfNeeded : public TraceIfEnabled<T, WTF::IsTraceable<T>::value> {
+  STATIC_ONLY(TraceIfNeeded);
+};
+
+}  // namespace blink
+
+namespace WTF {
+
+// Catch-all for types that have a way to trace that don't have special
+// handling for weakness in collections.  This means that if this type
+// contains WeakMember fields, they will simply be zeroed, but the entry
+// will not be removed from the collection.  This always happens for
+// things in vectors, which don't currently support special handling of
+// weak elements.
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename T,
+          typename Traits>
+struct TraceInCollectionTrait<kNoWeakHandlingInCollections,
+                              strongify,
+                              T,
+                              Traits> {
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, T& t) {
+    DCHECK(IsTraceableInCollectionTrait<Traits>::value);
+    visitor->Trace(t);
+    return false;
+  }
+};
+
+// Catch-all for things that have HashTrait support for tracing with weakness.
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename T,
+          typename Traits>
+struct TraceInCollectionTrait<kWeakHandlingInCollections,
+                              strongify,
+                              T,
+                              Traits> {
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, T& t) {
+    return Traits::TraceInCollection(visitor, t, strongify);
+  }
+};
+
+// This trace method is used only for on-stack HeapVectors found in
+// conservative scanning. On-heap HeapVectors are traced by Vector::trace.
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename T,
+          typename Traits>
+struct TraceInCollectionTrait<kNoWeakHandlingInCollections,
+                              strongify,
+                              blink::HeapVectorBacking<T, Traits>,
+                              void> {
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, void* self) {
+    // HeapVectorBacking does not know the exact size of the vector
+    // and just knows the capacity of the vector. Due to the constraint,
+    // HeapVectorBacking can support only the following objects:
+    //
+    // - An object that has a vtable. In this case, HeapVectorBacking
+    //   traces only slots that are not zeroed out. This is because if
+    //   the object has a vtable, the zeroed slot means that it is
+    //   an unused slot (Remember that the unused slots are guaranteed
+    //   to be zeroed out by VectorUnusedSlotClearer).
+    //
+    // - An object that can be initialized with memset. In this case,
+    //   HeapVectorBacking traces all slots including unused slots.
+    //   This is fine because the fact that the object can be initialized
+    //   with memset indicates that it is safe to treat the zerod slot
+    //   as a valid object.
+    static_assert(!IsTraceableInCollectionTrait<Traits>::value ||
+                      Traits::kCanClearUnusedSlotsWithMemset ||
+                      std::is_polymorphic<T>::value,
+                  "HeapVectorBacking doesn't support objects that cannot be "
+                  "cleared as unused with memset.");
+
+    // This trace method is instantiated for vectors where
+    // IsTraceableInCollectionTrait<Traits>::value is false, but the trace
+    // method should not be called. Thus we cannot static-assert
+    // IsTraceableInCollectionTrait<Traits>::value but should runtime-assert it.
+    DCHECK(IsTraceableInCollectionTrait<Traits>::value);
+
+    T* array = reinterpret_cast<T*>(self);
+    blink::HeapObjectHeader* header =
+        blink::HeapObjectHeader::FromPayload(self);
+    // Use the payload size as recorded by the heap to determine how many
+    // elements to trace.
+    size_t length = header->PayloadSize() / sizeof(T);
+#ifdef ANNOTATE_CONTIGUOUS_CONTAINER
+    // As commented above, HeapVectorBacking can trace unused slots
+    // (which are already zeroed out).
+    ANNOTATE_CHANGE_SIZE(array, length, 0, length);
+#endif
+    if (std::is_polymorphic<T>::value) {
+      char* pointer = reinterpret_cast<char*>(array);
+      for (unsigned i = 0; i < length; ++i) {
+        char* element = pointer + i * sizeof(T);
+        if (blink::VTableInitialized(element))
+          blink::TraceIfEnabled<
+              T, IsTraceableInCollectionTrait<Traits>::value>::Trace(visitor,
+                                                                     array[i]);
+      }
+    } else {
+      for (size_t i = 0; i < length; ++i)
+        blink::TraceIfEnabled<
+            T, IsTraceableInCollectionTrait<Traits>::value>::Trace(visitor,
+                                                                   array[i]);
+    }
+    return false;
+  }
+};
+
+// This trace method is used only for on-stack HeapHashTables found in
+// conservative scanning. On-heap HeapHashTables are traced by HashTable::trace.
+template <ShouldWeakPointersBeMarkedStrongly strongify, typename Table>
+struct TraceInCollectionTrait<kNoWeakHandlingInCollections,
+                              strongify,
+                              blink::HeapHashTableBacking<Table>,
+                              void> {
+  using Value = typename Table::ValueType;
+  using Traits = typename Table::ValueTraits;
+
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, void* self) {
+    static_assert(strongify == WTF::kWeakPointersActStrong,
+                  "An on-stack HeapHashTable needs to be visited strongly.");
+
+    DCHECK(IsTraceableInCollectionTrait<Traits>::value ||
+           Traits::kWeakHandlingFlag == kWeakHandlingInCollections);
+    Value* array = reinterpret_cast<Value*>(self);
+    blink::HeapObjectHeader* header =
+        blink::HeapObjectHeader::FromPayload(self);
+    // Use the payload size as recorded by the heap to determine how many
+    // elements to trace.
+    size_t length = header->PayloadSize() / sizeof(Value);
+    for (size_t i = 0; i < length; ++i) {
+      if (!HashTableHelper<
+              Value, typename Table::ExtractorType,
+              typename Table::KeyTraitsType>::IsEmptyOrDeletedBucket(array[i]))
+        blink::TraceCollectionIfEnabled<
+            IsTraceableInCollectionTrait<Traits>::value,
+            Traits::kWeakHandlingFlag, strongify, Value,
+            Traits>::Trace(visitor, array[i]);
+    }
+    return false;
+  }
+};
+
+// This specialization of TraceInCollectionTrait is for the backing of
+// HeapListHashSet.  This is for the case that we find a reference to the
+// backing from the stack.  That probably means we have a GC while we are in a
+// ListHashSet method since normal API use does not put pointers to the backing
+// on the stack.
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename NodeContents,
+          size_t inlineCapacity,
+          typename T,
+          typename U,
+          typename V,
+          typename W,
+          typename X,
+          typename Y>
+struct TraceInCollectionTrait<
+    kNoWeakHandlingInCollections,
+    strongify,
+    blink::HeapHashTableBacking<HashTable<
+        ListHashSetNode<NodeContents,
+                        blink::HeapListHashSetAllocator<T, inlineCapacity>>*,
+        U,
+        V,
+        W,
+        X,
+        Y,
+        blink::HeapAllocator>>,
+    void> {
+  using Node =
+      ListHashSetNode<NodeContents,
+                      blink::HeapListHashSetAllocator<T, inlineCapacity>>;
+  using Table = HashTable<Node*, U, V, W, X, Y, blink::HeapAllocator>;
+
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, void* self) {
+    Node** array = reinterpret_cast<Node**>(self);
+    blink::HeapObjectHeader* header =
+        blink::HeapObjectHeader::FromPayload(self);
+    size_t length = header->PayloadSize() / sizeof(Node*);
+    for (size_t i = 0; i < length; ++i) {
+      if (!HashTableHelper<Node*, typename Table::ExtractorType,
+                           typename Table::KeyTraitsType>::
+              IsEmptyOrDeletedBucket(array[i])) {
+        TraceListHashSetValue(visitor, array[i]->value_);
+        // Just mark the node without tracing because we already traced
+        // the contents, and there is no need to trace the next and
+        // prev fields since iterating over the hash table backing will
+        // find the whole chain.
+        visitor->MarkNoTracing(array[i]);
+      }
+    }
+    return false;
+  }
+};
+
+// Key value pairs, as used in HashMap.  To disambiguate template choice we have
+// to have two versions, first the one with no special weak handling, then the
+// one with weak handling.
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename Key,
+          typename Value,
+          typename Traits>
+struct TraceInCollectionTrait<kNoWeakHandlingInCollections,
+                              strongify,
+                              KeyValuePair<Key, Value>,
+                              Traits> {
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, KeyValuePair<Key, Value>& self) {
+    DCHECK(IsTraceableInCollectionTrait<Traits>::value);
+    blink::TraceCollectionIfEnabled<
+        IsTraceableInCollectionTrait<typename Traits::KeyTraits>::value,
+        kNoWeakHandlingInCollections, strongify, Key,
+        typename Traits::KeyTraits>::Trace(visitor, self.key);
+    blink::TraceCollectionIfEnabled<
+        IsTraceableInCollectionTrait<typename Traits::ValueTraits>::value,
+        kNoWeakHandlingInCollections, strongify, Value,
+        typename Traits::ValueTraits>::Trace(visitor, self.value);
+    return false;
+  }
+};
+
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename Key,
+          typename Value,
+          typename Traits>
+struct TraceInCollectionTrait<kWeakHandlingInCollections,
+                              strongify,
+                              KeyValuePair<Key, Value>,
+                              Traits> {
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, KeyValuePair<Key, Value>& self) {
+    // This is the core of the ephemeron-like functionality.  If there is
+    // weakness on the key side then we first check whether there are
+    // dead weak pointers on that side, and if there are we don't mark the
+    // value side (yet).  Conversely if there is weakness on the value side
+    // we check that first and don't mark the key side yet if we find dead
+    // weak pointers.
+    // Corner case: If there is weakness on both the key and value side,
+    // and there are also strong pointers on the both sides then we could
+    // unexpectedly leak.  The scenario is that the weak pointer on the key
+    // side is alive, which causes the strong pointer on the key side to be
+    // marked.  If that then results in the object pointed to by the weak
+    // pointer on the value side being marked live, then the whole
+    // key-value entry is leaked.  To avoid unexpected leaking, we disallow
+    // this case, but if you run into this assert, please reach out to Blink
+    // reviewers, and we may relax it.
+    constexpr bool kKeyIsWeak =
+        Traits::KeyTraits::kWeakHandlingFlag == kWeakHandlingInCollections;
+    constexpr bool kValueIsWeak =
+        Traits::ValueTraits::kWeakHandlingFlag == kWeakHandlingInCollections;
+    const bool kKeyHasStrongRefs =
+        IsTraceableInCollectionTrait<typename Traits::KeyTraits>::value;
+    const bool kValueHasStrongRefs =
+        IsTraceableInCollectionTrait<typename Traits::ValueTraits>::value;
+    static_assert(!kKeyIsWeak || !kValueIsWeak || !kKeyHasStrongRefs ||
+                      !kValueHasStrongRefs,
+                  "this configuration is disallowed to avoid unexpected leaks");
+    if ((kValueIsWeak && !kKeyIsWeak) ||
+        (kValueIsWeak && kKeyIsWeak && !kValueHasStrongRefs)) {
+      // Check value first.
+      bool dead_weak_objects_found_on_value_side =
+          blink::TraceCollectionIfEnabled<
+              IsTraceableInCollectionTrait<typename Traits::ValueTraits>::value,
+              Traits::ValueTraits::kWeakHandlingFlag, strongify, Value,
+              typename Traits::ValueTraits>::Trace(visitor, self.value);
+      if (dead_weak_objects_found_on_value_side)
+        return true;
+      return blink::TraceCollectionIfEnabled<
+          IsTraceableInCollectionTrait<typename Traits::KeyTraits>::value,
+          Traits::KeyTraits::kWeakHandlingFlag, strongify, Key,
+          typename Traits::KeyTraits>::Trace(visitor, self.key);
+    }
+    // Check key first.
+    bool dead_weak_objects_found_on_key_side = blink::TraceCollectionIfEnabled<
+        IsTraceableInCollectionTrait<typename Traits::KeyTraits>::value,
+        Traits::KeyTraits::kWeakHandlingFlag, strongify, Key,
+        typename Traits::KeyTraits>::Trace(visitor, self.key);
+    if (dead_weak_objects_found_on_key_side)
+      return true;
+    return blink::TraceCollectionIfEnabled<
+        IsTraceableInCollectionTrait<typename Traits::ValueTraits>::value,
+        Traits::ValueTraits::kWeakHandlingFlag, strongify, Value,
+        typename Traits::ValueTraits>::Trace(visitor, self.value);
+  }
+};
+
+// Nodes used by LinkedHashSet.  Again we need two versions to disambiguate the
+// template.
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename Value,
+          typename Allocator,
+          typename Traits>
+struct TraceInCollectionTrait<kNoWeakHandlingInCollections,
+                              strongify,
+                              LinkedHashSetNode<Value, Allocator>,
+                              Traits> {
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor,
+                    LinkedHashSetNode<Value, Allocator>& self) {
+    DCHECK(IsTraceableInCollectionTrait<Traits>::value);
+    return TraceInCollectionTrait<
+        kNoWeakHandlingInCollections, strongify, Value,
+        typename Traits::ValueTraits>::Trace(visitor, self.value_);
+  }
+};
+
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename Value,
+          typename Allocator,
+          typename Traits>
+struct TraceInCollectionTrait<kWeakHandlingInCollections,
+                              strongify,
+                              LinkedHashSetNode<Value, Allocator>,
+                              Traits> {
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor,
+                    LinkedHashSetNode<Value, Allocator>& self) {
+    return TraceInCollectionTrait<
+        kWeakHandlingInCollections, strongify, Value,
+        typename Traits::ValueTraits>::Trace(visitor, self.value_);
+  }
+};
+
+// ListHashSetNode pointers (a ListHashSet is implemented as a hash table of
+// these pointers).
+template <ShouldWeakPointersBeMarkedStrongly strongify,
+          typename Value,
+          size_t inlineCapacity,
+          typename Traits>
+struct TraceInCollectionTrait<
+    kNoWeakHandlingInCollections,
+    strongify,
+    ListHashSetNode<Value,
+                    blink::HeapListHashSetAllocator<Value, inlineCapacity>>*,
+    Traits> {
+  using Node =
+      ListHashSetNode<Value,
+                      blink::HeapListHashSetAllocator<Value, inlineCapacity>>;
+
+  template <typename VisitorDispatcher>
+  static bool Trace(VisitorDispatcher visitor, Node* node) {
+    DCHECK(IsTraceableInCollectionTrait<Traits>::value);
+    TraceListHashSetValue(visitor, node->value_);
+    // Just mark the node without tracing because we already traced the
+    // contents, and there is no need to trace the next and prev fields
+    // since iterating over the hash table backing will find the whole
+    // chain.
+    visitor->MarkNoTracing(node);
+    return false;
+  }
+};
+
+}  // namespace WTF
+
+#endif
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/DEPS chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/DEPS
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/DEPS	2018-03-21 01:05:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/DEPS	2018-04-27 11:31:20.611828057 +0300
@@ -16,6 +16,7 @@
     "+base/process/process_metrics.h",
     "+base/rand_util.h",
     "+base/strings",
+    "+base/template_util.h",
     "+base/threading/thread_checker.h",
     "+base/time/time.h",
     "+base/tuple.h",
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/DEPS.wtf-fix chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/DEPS.wtf-fix
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/DEPS.wtf-fix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/DEPS.wtf-fix	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,34 @@
+include_rules = [
+    # To whitelist base/ stuff Blink is allowed to include, we list up all
+    # directories and files instead of writing 'base/'.
+    "+base/allocator/partition_allocator",
+    "+base/atomic_ref_count.h",
+    "+base/auto_reset.h",
+    "+base/bind.h",
+    "+base/bits.h",
+    "+base/compiler_specific.h",
+    "+base/logging.h",
+    "+base/memory/ptr_util.h",
+    "+base/memory/ref_counted.h",
+    "+base/memory/weak_ptr.h",
+    "+base/numerics",
+    "+base/optional.h",
+    "+base/process/process_metrics.h",
+    "+base/rand_util.h",
+    "+base/strings",
+    "+base/threading/thread_checker.h",
+    "+base/time/time.h",
+    "+base/tuple.h",
+    # To avoid recursive dependency, we impose a blanket ban on using other
+    # platform files. Think carefully if you want to relax this restriction.
+    "-platform",
+    "+platform/wtf",
+    "+sandbox/linux/services/resource_limits.h",
+    "-v8",
+]
+
+specific_include_rules = {
+  ".*Test\.cpp": [
+    "+base/threading/thread.h"
+  ]
+}
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/Optional.h.oilpan chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/Optional.h.oilpan
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/Optional.h.oilpan	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/Optional.h.oilpan	2018-04-27 11:31:20.615828015 +0300
@@ -0,0 +1,37 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef Optional_h
+#define Optional_h
+
+#include "base/optional.h"
+#include "platform/wtf/TemplateUtil.h"
+#include "platform/wtf/TypeTraits.h"
+
+namespace WTF {
+
+// WTF::Optional is base::Optional. See base/optional.h for documentation.
+//
+// A clang plugin enforces that garbage collected types are not allocated
+// outside of the heap, similarly we enforce that one doesn't create garbage
+// collected types nested inside an Optional.
+template <typename T>
+using Optional =
+    typename std::enable_if<!IsGarbageCollectedType<T>::value ||
+                                IsPersistentReferenceType<T>::value,
+                            base::Optional<T>>::type;
+
+constexpr base::nullopt_t nullopt = base::nullopt;
+constexpr base::in_place_t in_place = base::in_place;
+
+template <typename T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return base::make_optional(std::forward<T>(value));
+}
+
+}  // namespace WTF
+
+using WTF::Optional;
+
+#endif  // Optional_h
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/Optional.h.wtf-fix chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/Optional.h.wtf-fix
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/Optional.h.wtf-fix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/Optional.h.wtf-fix	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,36 @@
+// Copyright 2015 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef Optional_h
+#define Optional_h
+
+#include "base/optional.h"
+#include "platform/wtf/TypeTraits.h"
+
+namespace WTF {
+
+// WTF::Optional is base::Optional. See base/optional.h for documentation.
+//
+// A clang plugin enforces that garbage collected types are not allocated
+// outside of the heap, similarly we enforce that one doesn't create garbage
+// collected types nested inside an Optional.
+template <typename T>
+using Optional =
+    typename std::enable_if<!IsGarbageCollectedType<T>::value ||
+                                IsPersistentReferenceType<T>::value,
+                            base::Optional<T>>::type;
+
+constexpr base::nullopt_t nullopt = base::nullopt;
+constexpr base::in_place_t in_place = base::in_place;
+
+template <typename T>
+constexpr Optional<typename std::decay<T>::type> make_optional(T&& value) {
+  return base::make_optional(std::forward<T>(value));
+}
+
+}  // namespace WTF
+
+using WTF::Optional;
+
+#endif  // Optional_h
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/TemplateUtil.h chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/TemplateUtil.h
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/TemplateUtil.h	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/TemplateUtil.h	2018-04-27 11:31:20.615828015 +0300
@@ -0,0 +1,28 @@
+// Copyright 2018 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef TemplateUtil_h
+#define TemplateUtil_h
+
+#include "base/template_util.h"
+#include "platform/wtf/Vector.h"
+
+namespace base {
+
+#if defined(__GNUC__) && !defined(__clang__) && __GNUC__ <= 7
+// Workaround for g++7 and earlier family.
+// Due to https://gcc.gnu.org/bugzilla/show_bug.cgi?id=80654, without this
+// Optional<WTF::Vector<T>> where T is non-copyable causes a compile error.
+// As we know it is not trivially copy constructible, explicitly declare so.
+//
+// It completes the declaration in base/template_util.h that was provided
+// for std::vector
+template <typename T>
+struct is_trivially_copy_constructible<WTF::Vector<T>> : std::false_type {};
+#endif
+
+}  // namespace base
+
+#endif  // TemplateUtil_h
+
diff -Naur chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/typed_arrays/ArrayBufferContents.h.gcc5-r3 chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/typed_arrays/ArrayBufferContents.h.gcc5-r3
--- chromium-65.0.3325.181-orig/third_party/WebKit/Source/platform/wtf/typed_arrays/ArrayBufferContents.h.gcc5-r3	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/WebKit/Source/platform/wtf/typed_arrays/ArrayBufferContents.h.gcc5-r3	2018-03-21 01:05:50.000000000 +0300
@@ -0,0 +1,275 @@
+/*
+ * Copyright (C) 2009 Apple Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE COMPUTER, INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE COMPUTER, INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef ArrayBufferContents_h
+#define ArrayBufferContents_h
+
+#include "base/macros.h"
+#include "base/memory/scoped_refptr.h"
+#include "platform/wtf/Allocator.h"
+#include "platform/wtf/Assertions.h"
+#include "platform/wtf/ThreadSafeRefCounted.h"
+#include "platform/wtf/WTF.h"
+#include "platform/wtf/WTFExport.h"
+
+namespace WTF {
+
+class WTF_EXPORT ArrayBufferContents {
+  DISALLOW_NEW_EXCEPT_PLACEMENT_NEW();
+
+ public:
+  using AdjustAmountOfExternalAllocatedMemoryFunction = void (*)(int64_t diff);
+  // Types that need to be used when injecting external memory.
+  // DataHandle allows specifying a deleter which will be invoked when
+  // DataHandle instance goes out of scope. If the data memory is allocated
+  // using ArrayBufferContents::AllocateMemoryOrNull, it is necessary to specify
+  // ArrayBufferContents::FreeMemory as the DataDeleter. Most clients would want
+  // to use ArrayBufferContents::CreateDataHandle, which allocates memory and
+  // specifies the correct deleter.
+  using DataDeleter = void (*)(void* data);
+
+  enum class AllocationKind { kNormal, kReservation };
+
+  class DataHandle {
+    DISALLOW_COPY_AND_ASSIGN(DataHandle);
+
+   public:
+    DataHandle(void* data, size_t length, DataDeleter deleter)
+        : allocation_base_(data),
+          allocation_length_(length),
+          data_(data),
+          data_length_(length),
+          kind_(AllocationKind::kNormal),
+          deleter_(deleter) {}
+    DataHandle(void* allocation_base,
+               size_t allocation_length,
+               void* data,
+               size_t data_length,
+               AllocationKind kind,
+               DataDeleter deleter)
+        : allocation_base_(allocation_base),
+          allocation_length_(allocation_length),
+          data_(data),
+          data_length_(data_length),
+          kind_(kind),
+          deleter_(deleter) {
+      DCHECK(reinterpret_cast<uintptr_t>(allocation_base_) <=
+             reinterpret_cast<uintptr_t>(data_));
+      DCHECK(reinterpret_cast<uintptr_t>(data_) + data_length_ <=
+             reinterpret_cast<uintptr_t>(allocation_base_) +
+                 allocation_length_);
+    }
+    // Move constructor
+    DataHandle(DataHandle&& other) { *this = std::move(other); }
+    ~DataHandle() {
+      if (!allocation_base_)
+        return;
+      DCHECK(reinterpret_cast<uintptr_t>(allocation_base_) <=
+             reinterpret_cast<uintptr_t>(data_));
+      DCHECK(reinterpret_cast<uintptr_t>(data_) + data_length_ <=
+             reinterpret_cast<uintptr_t>(allocation_base_) +
+                 allocation_length_);
+      switch (kind_) {
+        case AllocationKind::kNormal:
+          DCHECK(deleter_);
+          deleter_(data_);
+          return;
+        case AllocationKind::kReservation:
+          ReleaseReservedMemory(allocation_base_, allocation_length_);
+          return;
+      }
+    }
+
+    // Move operator
+    DataHandle& operator=(DataHandle&& other) {
+      allocation_base_ = other.allocation_base_;
+      allocation_length_ = other.allocation_length_;
+      data_ = other.data_;
+      data_length_ = other.data_length_;
+      kind_ = other.kind_;
+      deleter_ = other.deleter_;
+      other.allocation_base_ = nullptr;
+      return *this;
+    }
+
+    void* AllocationBase() const { return allocation_base_; }
+    size_t AllocationLength() const { return allocation_length_; }
+
+    void* Data() const { return data_; }
+    size_t DataLength() const { return data_length_; }
+
+    ArrayBufferContents::AllocationKind GetAllocationKind() const {
+      return kind_;
+    }
+
+    operator bool() const { return allocation_base_; }
+
+   private:
+    void* allocation_base_;
+    size_t allocation_length_;
+
+    void* data_;
+    size_t data_length_;
+
+    ArrayBufferContents::AllocationKind kind_;
+    DataDeleter deleter_;
+  };
+
+  enum InitializationPolicy { kZeroInitialize, kDontInitialize };
+
+  enum SharingType {
+    kNotShared,
+    kShared,
+  };
+
+  ArrayBufferContents();
+  ArrayBufferContents(unsigned num_elements,
+                      unsigned element_byte_size,
+                      SharingType is_shared,
+                      InitializationPolicy);
+  ArrayBufferContents(DataHandle,
+                      SharingType is_shared);
+  ArrayBufferContents(ArrayBufferContents&&) = default;
+
+  ~ArrayBufferContents();
+
+  ArrayBufferContents& operator=(ArrayBufferContents&&) = default;
+
+  void Neuter();
+
+  void* Data() const {
+    DCHECK(!IsShared());
+    return DataMaybeShared();
+  }
+  void* DataShared() const {
+    DCHECK(IsShared());
+    return DataMaybeShared();
+  }
+  void* DataMaybeShared() const { return holder_ ? holder_->Data() : nullptr; }
+  size_t DataLength() const { return holder_ ? holder_->DataLength() : 0; }
+  bool IsShared() const { return holder_ ? holder_->IsShared() : false; }
+
+  void Transfer(ArrayBufferContents& other);
+  void ShareWith(ArrayBufferContents& other);
+  void CopyTo(ArrayBufferContents& other);
+
+  static void* AllocateMemoryOrNull(size_t, InitializationPolicy);
+  static void* ReserveMemory(size_t);
+  static void FreeMemory(void*);
+  static void ReleaseReservedMemory(void*, size_t);
+  static DataHandle CreateDataHandle(size_t, InitializationPolicy);
+  static void Initialize(
+      AdjustAmountOfExternalAllocatedMemoryFunction function) {
+    DCHECK(IsMainThread());
+    DCHECK_EQ(adjust_amount_of_external_allocated_memory_function_,
+              DefaultAdjustAmountOfExternalAllocatedMemoryFunction);
+    adjust_amount_of_external_allocated_memory_function_ = function;
+  }
+
+  void RegisterExternalAllocationWithCurrentContext() {
+    if (holder_)
+      holder_->RegisterExternalAllocationWithCurrentContext();
+  }
+
+  void UnregisterExternalAllocationWithCurrentContext() {
+    if (holder_)
+      holder_->UnregisterExternalAllocationWithCurrentContext();
+  }
+
+ private:
+  static void* AllocateMemoryWithFlags(size_t, InitializationPolicy, int);
+
+  static void DefaultAdjustAmountOfExternalAllocatedMemoryFunction(
+      int64_t diff);
+
+  class DataHolder : public ThreadSafeRefCounted<DataHolder> {
+    DISALLOW_COPY_AND_ASSIGN(DataHolder);
+
+   public:
+    DataHolder();
+    ~DataHolder();
+
+    void AllocateNew(size_t length,
+                     SharingType is_shared,
+                     InitializationPolicy);
+    void Adopt(DataHandle, SharingType is_shared);
+    void CopyMemoryFrom(const DataHolder& source);
+
+    const void* Data() const { return data_.Data(); }
+    void* Data() { return data_.Data(); }
+    size_t DataLength() const { return data_.DataLength(); }
+    bool IsShared() const { return is_shared_ == kShared; }
+
+    void RegisterExternalAllocationWithCurrentContext();
+    void UnregisterExternalAllocationWithCurrentContext();
+
+   private:
+    void AdjustAmountOfExternalAllocatedMemory(int64_t diff) {
+      has_registered_external_allocation_ =
+          !has_registered_external_allocation_;
+      DCHECK(!diff || (has_registered_external_allocation_ == (diff > 0)));
+      CheckIfAdjustAmountOfExternalAllocatedMemoryIsConsistent();
+      adjust_amount_of_external_allocated_memory_function_(diff);
+    }
+
+    void AdjustAmountOfExternalAllocatedMemory(size_t diff) {
+      AdjustAmountOfExternalAllocatedMemory(static_cast<int64_t>(diff));
+    }
+
+    void CheckIfAdjustAmountOfExternalAllocatedMemoryIsConsistent() {
+      DCHECK(adjust_amount_of_external_allocated_memory_function_);
+
+#if DCHECK_IS_ON()
+      // Make sure that the function actually used is always the same.
+      // Shouldn't be updated during its use.
+      if (!last_used_adjust_amount_of_external_allocated_memory_function_) {
+        last_used_adjust_amount_of_external_allocated_memory_function_ =
+            adjust_amount_of_external_allocated_memory_function_;
+      }
+      DCHECK_EQ(adjust_amount_of_external_allocated_memory_function_,
+                last_used_adjust_amount_of_external_allocated_memory_function_);
+#endif
+    }
+
+    DataHandle data_;
+    SharingType is_shared_;
+    bool has_registered_external_allocation_;
+  };
+
+  scoped_refptr<DataHolder> holder_;
+  static AdjustAmountOfExternalAllocatedMemoryFunction
+      adjust_amount_of_external_allocated_memory_function_;
+#if DCHECK_IS_ON()
+  static AdjustAmountOfExternalAllocatedMemoryFunction
+      last_used_adjust_amount_of_external_allocated_memory_function_;
+#endif
+
+  DISALLOW_COPY_AND_ASSIGN(ArrayBufferContents);
+};
+
+}  // namespace WTF
+
+#endif  // ArrayBufferContents_h
diff -Naur chromium-65.0.3325.181-orig/third_party/boringssl/BUILD.gn chromium-65.0.3325.181.patched/third_party/boringssl/BUILD.gn
--- chromium-65.0.3325.181-orig/third_party/boringssl/BUILD.gn	2018-03-21 01:05:51.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/boringssl/BUILD.gn	2018-04-27 11:31:20.471829529 +0300
@@ -26,6 +26,7 @@
     "BORINGSSL_IMPLEMENTATION",
     "BORINGSSL_NO_STATIC_INITIALIZER",
     "OPENSSL_SMALL",
+    "_POSIX_C_SOURCE=200112L",
   ]
   configs = [
     # TODO(davidben): Fix size_t truncations in BoringSSL.
diff -Naur chromium-65.0.3325.181-orig/third_party/boringssl/BUILD.gn.addrfix chromium-65.0.3325.181.patched/third_party/boringssl/BUILD.gn.addrfix
--- chromium-65.0.3325.181-orig/third_party/boringssl/BUILD.gn.addrfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/boringssl/BUILD.gn.addrfix	2018-03-21 01:05:51.000000000 +0300
@@ -0,0 +1,310 @@
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/android/config.gni")
+import("//build/config/arm.gni")
+import("//build/config/sanitizers/sanitizers.gni")
+import("//build_overrides/build.gni")
+import("//testing/libfuzzer/fuzzer_test.gni")
+import("BUILD.generated.gni")
+import("BUILD.generated_tests.gni")
+
+# Config for us and everybody else depending on BoringSSL.
+config("external_config") {
+  include_dirs = [ "src/include" ]
+  if (is_component_build) {
+    defines = [ "BORINGSSL_SHARED_LIBRARY" ]
+  }
+}
+
+# Config internal to this build file, shared by boringssl and boringssl_fuzzer.
+config("internal_config") {
+  visibility = [ ":*" ]  # Only targets in this file can depend on this.
+  defines = [
+    "BORINGSSL_ALLOW_CXX_RUNTIME",
+    "BORINGSSL_IMPLEMENTATION",
+    "BORINGSSL_NO_STATIC_INITIALIZER",
+    "OPENSSL_SMALL",
+  ]
+  configs = [
+    # TODO(davidben): Fix size_t truncations in BoringSSL.
+    # https://crbug.com/boringssl/22
+    "//build/config/compiler:no_size_t_to_int_warning",
+    "//build/config/sanitizers:cfi_icall_generalize_pointers",
+  ]
+  if (is_posix) {
+    cflags_c = [ "-std=c99" ]
+    defines += [ "_XOPEN_SOURCE=700" ]
+  }
+}
+
+config("no_asm_config") {
+  visibility = [ ":*" ]  # Only targets in this file can depend on this.
+  defines = [ "OPENSSL_NO_ASM" ]
+}
+
+all_sources = crypto_sources + ssl_sources
+
+# Windows' assembly is built with Yasm. The other platforms use the platform
+# assembler.
+if (is_win && !is_msan) {
+  import("//third_party/yasm/yasm_assemble.gni")
+  yasm_assemble("boringssl_asm") {
+    if (current_cpu == "x64") {
+      sources = crypto_sources_win_x86_64
+    } else if (current_cpu == "x86") {
+      sources = crypto_sources_win_x86
+    }
+  }
+} else {
+  # This has no sources on some platforms so must be a source_set.
+  source_set("boringssl_asm") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+
+    defines = [ "BORINGSSL_CLANG_SUPPORTS_DOT_ARCH" ]
+    sources = []
+    asmflags = []
+    include_dirs = [ "src/include" ]
+
+    if ((current_cpu == "arm" || current_cpu == "arm64") && is_clang &&
+        !is_ios) {
+      if (current_cpu == "arm" && arm_version != 6) {
+        # TODO(hans) Enable integrated-as (crbug.com/124610).
+        asmflags += [ "-fno-integrated-as" ]
+      }
+      if (is_android) {
+        rebased_android_toolchain_root =
+            rebase_path(android_toolchain_root, root_build_dir)
+
+        # Else /usr/bin/as gets picked up.
+        asmflags += [ "-B${rebased_android_toolchain_root}/bin" ]
+      }
+    }
+
+    if (is_msan) {
+      public_configs = [ ":no_asm_config" ]
+    } else if (current_cpu == "x64") {
+      if (is_mac) {
+        sources += crypto_sources_mac_x86_64
+      } else if (is_linux || is_android) {
+        sources += crypto_sources_linux_x86_64
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else if (current_cpu == "x86") {
+      if (is_mac) {
+        sources += crypto_sources_mac_x86
+      } else if (is_linux || is_android) {
+        sources += crypto_sources_linux_x86
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else if (current_cpu == "arm") {
+      if (is_linux || is_android) {
+        sources += crypto_sources_linux_arm
+      } else if (is_ios) {
+        sources += crypto_sources_ios_arm
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else if (current_cpu == "arm64") {
+      if (is_linux || is_android) {
+        sources += crypto_sources_linux_aarch64
+      } else if (is_ios) {
+        sources += crypto_sources_ios_aarch64
+      } else {
+        public_configs = [ ":no_asm_config" ]
+      }
+    } else {
+      public_configs = [ ":no_asm_config" ]
+    }
+  }
+}
+
+component("boringssl") {
+  sources = all_sources
+  deps = [
+    ":boringssl_asm",
+    "//third_party/boringssl/src/third_party/fiat:fiat_license",
+  ]
+
+  public_configs = [ ":external_config" ]
+  configs += [ ":internal_config" ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [ "//build/config/compiler:no_chromium_code" ]
+
+  if (is_nacl) {
+    deps += [ "//native_client_sdk/src/libraries/nacl_io" ]
+  }
+}
+
+# These targets are named "_tests" rather than "_test" to avoid colliding with a
+# historical "boringssl_ssl_test" target. This works around a bug with the iOS
+# build rules.
+
+test("boringssl_crypto_tests") {
+  sources = crypto_test_sources + test_support_sources
+  deps = [
+    ":boringssl",
+    "//testing/gtest",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    ":internal_config",
+    "//build/config/compiler:no_chromium_code",
+  ]
+
+  # Chromium infrastructure does not support GTest, only the //base wrapper.
+  if (build_with_chromium) {
+    sources -= [
+      "src/crypto/test/gtest_main.cc",
+
+      # //base includes its own conflicting malloc shim.
+      "src/crypto/test/malloc.cc",
+    ]
+    sources += [ "gtest_main_chromium.cc" ]
+    deps += [ "//base/test:test_support" ]
+  }
+}
+
+test("boringssl_ssl_tests") {
+  sources = ssl_test_sources + test_support_sources
+  deps = [
+    ":boringssl",
+    "//testing/gtest",
+  ]
+
+  configs -= [ "//build/config/compiler:chromium_code" ]
+  configs += [
+    ":internal_config",
+    "//build/config/compiler:no_chromium_code",
+  ]
+
+  # Chromium infrastructure does not support GTest, only the //base wrapper.
+  if (build_with_chromium) {
+    sources -= [
+      "src/crypto/test/gtest_main.cc",
+
+      # //base includes its own conflicting malloc shim.
+      "src/crypto/test/malloc.cc",
+    ]
+    sources += [ "gtest_main_chromium.cc" ]
+    deps += [ "//base/test:test_support" ]
+  }
+}
+
+if (build_with_chromium) {
+  config("fuzzer_config") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+    defines = [
+      "BORINGSSL_UNSAFE_FUZZER_MODE",
+      "BORINGSSL_UNSAFE_DETERMINISTIC_MODE",
+    ]
+  }
+
+  # The same as boringssl, but builds with BORINGSSL_UNSAFE_FUZZER_MODE.
+  component("boringssl_fuzzer") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+
+    sources = all_sources
+    deps = [
+      ":boringssl_asm",
+    ]
+
+    public_configs = [
+      ":external_config",
+      ":fuzzer_config",
+    ]
+    configs += [ ":internal_config" ]
+
+    configs -= [ "//build/config/compiler:chromium_code" ]
+    configs += [ "//build/config/compiler:no_chromium_code" ]
+
+    if (is_nacl) {
+      deps += [ "//native_client_sdk/src/libraries/nacl_io" ]
+    }
+  }
+
+  foreach(fuzzer, fuzzers) {
+    fuzzer_test("boringssl_${fuzzer}_fuzzer") {
+      sources = [
+        "src/fuzz/${fuzzer}.cc",
+      ]
+      deps = [
+        ":boringssl_fuzzer",
+      ]
+      seed_corpus = "src/fuzz/${fuzzer}_corpus"
+
+      if ("cert" == fuzzer) {
+        libfuzzer_options = [ "max_len=3072" ]
+      } else if ("client" == fuzzer) {
+        libfuzzer_options = [ "max_len=20000" ]
+      } else if ("pkcs8" == fuzzer) {
+        libfuzzer_options = [ "max_len=2048" ]
+      } else if ("privkey" == fuzzer) {
+        libfuzzer_options = [ "max_len=2048" ]
+      } else if ("read_pem" == fuzzer) {
+        libfuzzer_options = [ "max_len=512" ]
+      } else if ("session" == fuzzer) {
+        libfuzzer_options = [ "max_len=8192" ]
+      } else if ("server" == fuzzer) {
+        libfuzzer_options = [ "max_len=4096" ]
+      } else if ("spki" == fuzzer) {
+        libfuzzer_options = [ "max_len=1024" ]
+      } else if ("ssl_ctx_api" == fuzzer) {
+        libfuzzer_options = [ "max_len=256" ]
+      }
+    }
+  }
+
+  config("fuzzer_no_fuzzer_mode_config") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+    defines = [ "BORINGSSL_UNSAFE_DETERMINISTIC_MODE" ]
+  }
+
+  # The same as boringssl, but builds with BORINGSSL_UNSAFE_DETERMINISTIC_MODE.
+  component("boringssl_fuzzer_no_fuzzer_mode") {
+    visibility = [ ":*" ]  # Only targets in this file can depend on this.
+
+    sources = all_sources
+    deps = [
+      ":boringssl_asm",
+    ]
+
+    public_configs = [
+      ":external_config",
+      ":fuzzer_no_fuzzer_mode_config",
+    ]
+    configs += [ ":internal_config" ]
+
+    configs -= [ "//build/config/compiler:chromium_code" ]
+    configs += [ "//build/config/compiler:no_chromium_code" ]
+
+    if (is_nacl) {
+      deps += [ "//native_client_sdk/src/libraries/nacl_io" ]
+    }
+  }
+
+  fuzzer_test("boringssl_client_no_fuzzer_mode_fuzzer") {
+    sources = [
+      "src/fuzz/client.cc",
+    ]
+    deps = [
+      ":boringssl_fuzzer_no_fuzzer_mode",
+    ]
+    seed_corpus = "src/fuzz/client_corpus_no_fuzzer_mode"
+  }
+
+  fuzzer_test("boringssl_server_no_fuzzer_mode_fuzzer") {
+    sources = [
+      "src/fuzz/server.cc",
+    ]
+    deps = [
+      ":boringssl_fuzzer_no_fuzzer_mode",
+    ]
+    seed_corpus = "src/fuzz/server_corpus_no_fuzzer_mode"
+  }
+}
diff -Naur chromium-65.0.3325.181-orig/third_party/boringssl/src/crypto/x509/by_dir.c chromium-65.0.3325.181.patched/third_party/boringssl/src/crypto/x509/by_dir.c
--- chromium-65.0.3325.181-orig/third_party/boringssl/src/crypto/x509/by_dir.c	2018-03-21 01:06:50.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/boringssl/src/crypto/x509/by_dir.c	2018-04-27 11:31:20.511829108 +0300
@@ -56,6 +56,7 @@
  * [including the GNU Public Licence.] */
 
 #include <string.h>
+#include <time.h>
 #include <sys/stat.h>
 #include <sys/types.h>
 
diff -Naur chromium-65.0.3325.181-orig/third_party/boringssl/src/crypto/x509/by_dir.c.timefix chromium-65.0.3325.181.patched/third_party/boringssl/src/crypto/x509/by_dir.c.timefix
--- chromium-65.0.3325.181-orig/third_party/boringssl/src/crypto/x509/by_dir.c.timefix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/boringssl/src/crypto/x509/by_dir.c.timefix	2018-03-21 01:06:50.000000000 +0300
@@ -0,0 +1,451 @@
+/* crypto/x509/by_dir.c */
+/* Copyright (C) 1995-1998 Eric Young (eay@cryptsoft.com)
+ * All rights reserved.
+ *
+ * This package is an SSL implementation written
+ * by Eric Young (eay@cryptsoft.com).
+ * The implementation was written so as to conform with Netscapes SSL.
+ *
+ * This library is free for commercial and non-commercial use as long as
+ * the following conditions are aheared to.  The following conditions
+ * apply to all code found in this distribution, be it the RC4, RSA,
+ * lhash, DES, etc., code; not just the SSL code.  The SSL documentation
+ * included with this distribution is covered by the same copyright terms
+ * except that the holder is Tim Hudson (tjh@cryptsoft.com).
+ *
+ * Copyright remains Eric Young's, and as such any Copyright notices in
+ * the code are not to be removed.
+ * If this package is used in a product, Eric Young should be given attribution
+ * as the author of the parts of the library used.
+ * This can be in the form of a textual message at program startup or
+ * in documentation (online or textual) provided with the package.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. All advertising materials mentioning features or use of this software
+ *    must display the following acknowledgement:
+ *    "This product includes cryptographic software written by
+ *     Eric Young (eay@cryptsoft.com)"
+ *    The word 'cryptographic' can be left out if the rouines from the library
+ *    being used are not cryptographic related :-).
+ * 4. If you include any Windows specific code (or a derivative thereof) from
+ *    the apps directory (application code) you must include an acknowledgement:
+ *    "This product includes software written by Tim Hudson (tjh@cryptsoft.com)"
+ *
+ * THIS SOFTWARE IS PROVIDED BY ERIC YOUNG ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
+ * SUCH DAMAGE.
+ *
+ * The licence and distribution terms for any publically available version or
+ * derivative of this code cannot be changed.  i.e. this code cannot simply be
+ * copied and put under another distribution licence
+ * [including the GNU Public Licence.] */
+
+#include <string.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+
+#include <openssl/buf.h>
+#include <openssl/err.h>
+#include <openssl/mem.h>
+#include <openssl/thread.h>
+#include <openssl/x509.h>
+
+#include "../internal.h"
+
+typedef struct lookup_dir_hashes_st {
+    unsigned long hash;
+    int suffix;
+} BY_DIR_HASH;
+
+typedef struct lookup_dir_entry_st {
+    char *dir;
+    int dir_type;
+    STACK_OF(BY_DIR_HASH) *hashes;
+} BY_DIR_ENTRY;
+
+typedef struct lookup_dir_st {
+    BUF_MEM *buffer;
+    STACK_OF(BY_DIR_ENTRY) *dirs;
+} BY_DIR;
+
+DEFINE_STACK_OF(BY_DIR_HASH)
+DEFINE_STACK_OF(BY_DIR_ENTRY)
+
+static int dir_ctrl(X509_LOOKUP *ctx, int cmd, const char *argp, long argl,
+                    char **ret);
+static int new_dir(X509_LOOKUP *lu);
+static void free_dir(X509_LOOKUP *lu);
+static int add_cert_dir(BY_DIR *ctx, const char *dir, int type);
+static int get_cert_by_subject(X509_LOOKUP *xl, int type, X509_NAME *name,
+                               X509_OBJECT *ret);
+static X509_LOOKUP_METHOD x509_dir_lookup = {
+    "Load certs from files in a directory",
+    new_dir,                    /* new */
+    free_dir,                   /* free */
+    NULL,                       /* init */
+    NULL,                       /* shutdown */
+    dir_ctrl,                   /* ctrl */
+    get_cert_by_subject,        /* get_by_subject */
+    NULL,                       /* get_by_issuer_serial */
+    NULL,                       /* get_by_fingerprint */
+    NULL,                       /* get_by_alias */
+};
+
+X509_LOOKUP_METHOD *X509_LOOKUP_hash_dir(void)
+{
+    return (&x509_dir_lookup);
+}
+
+static int dir_ctrl(X509_LOOKUP *ctx, int cmd, const char *argp, long argl,
+                    char **retp)
+{
+    int ret = 0;
+    BY_DIR *ld;
+    char *dir = NULL;
+
+    ld = (BY_DIR *)ctx->method_data;
+
+    switch (cmd) {
+    case X509_L_ADD_DIR:
+        if (argl == X509_FILETYPE_DEFAULT) {
+            dir = (char *)getenv(X509_get_default_cert_dir_env());
+            if (dir)
+                ret = add_cert_dir(ld, dir, X509_FILETYPE_PEM);
+            else
+                ret = add_cert_dir(ld, X509_get_default_cert_dir(),
+                                   X509_FILETYPE_PEM);
+            if (!ret) {
+                OPENSSL_PUT_ERROR(X509, X509_R_LOADING_CERT_DIR);
+            }
+        } else
+            ret = add_cert_dir(ld, argp, (int)argl);
+        break;
+    }
+    return (ret);
+}
+
+static int new_dir(X509_LOOKUP *lu)
+{
+    BY_DIR *a;
+
+    if ((a = (BY_DIR *)OPENSSL_malloc(sizeof(BY_DIR))) == NULL)
+        return (0);
+    if ((a->buffer = BUF_MEM_new()) == NULL) {
+        OPENSSL_free(a);
+        return (0);
+    }
+    a->dirs = NULL;
+    lu->method_data = (char *)a;
+    return (1);
+}
+
+static void by_dir_hash_free(BY_DIR_HASH *hash)
+{
+    OPENSSL_free(hash);
+}
+
+static int by_dir_hash_cmp(const BY_DIR_HASH **a, const BY_DIR_HASH **b)
+{
+    if ((*a)->hash > (*b)->hash)
+        return 1;
+    if ((*a)->hash < (*b)->hash)
+        return -1;
+    return 0;
+}
+
+static void by_dir_entry_free(BY_DIR_ENTRY *ent)
+{
+    if (ent->dir)
+        OPENSSL_free(ent->dir);
+    if (ent->hashes)
+        sk_BY_DIR_HASH_pop_free(ent->hashes, by_dir_hash_free);
+    OPENSSL_free(ent);
+}
+
+static void free_dir(X509_LOOKUP *lu)
+{
+    BY_DIR *a;
+
+    a = (BY_DIR *)lu->method_data;
+    if (a->dirs != NULL)
+        sk_BY_DIR_ENTRY_pop_free(a->dirs, by_dir_entry_free);
+    if (a->buffer != NULL)
+        BUF_MEM_free(a->buffer);
+    OPENSSL_free(a);
+}
+
+static int add_cert_dir(BY_DIR *ctx, const char *dir, int type)
+{
+    size_t j, len;
+    const char *s, *ss, *p;
+
+    if (dir == NULL || !*dir) {
+        OPENSSL_PUT_ERROR(X509, X509_R_INVALID_DIRECTORY);
+        return 0;
+    }
+
+    s = dir;
+    p = s;
+    do {
+        if ((*p == ':') || (*p == '\0')) {
+            BY_DIR_ENTRY *ent;
+            ss = s;
+            s = p + 1;
+            len = p - ss;
+            if (len == 0)
+                continue;
+            for (j = 0; j < sk_BY_DIR_ENTRY_num(ctx->dirs); j++) {
+                ent = sk_BY_DIR_ENTRY_value(ctx->dirs, j);
+                if (strlen(ent->dir) == len &&
+                    strncmp(ent->dir, ss, len) == 0)
+                    break;
+            }
+            if (j < sk_BY_DIR_ENTRY_num(ctx->dirs))
+                continue;
+            if (ctx->dirs == NULL) {
+                ctx->dirs = sk_BY_DIR_ENTRY_new_null();
+                if (!ctx->dirs) {
+                    OPENSSL_PUT_ERROR(X509, ERR_R_MALLOC_FAILURE);
+                    return 0;
+                }
+            }
+            ent = OPENSSL_malloc(sizeof(BY_DIR_ENTRY));
+            if (!ent)
+                return 0;
+            ent->dir_type = type;
+            ent->hashes = sk_BY_DIR_HASH_new(by_dir_hash_cmp);
+            ent->dir = OPENSSL_malloc(len + 1);
+            if (!ent->dir || !ent->hashes) {
+                by_dir_entry_free(ent);
+                return 0;
+            }
+            BUF_strlcpy(ent->dir, ss, len + 1);
+            if (!sk_BY_DIR_ENTRY_push(ctx->dirs, ent)) {
+                by_dir_entry_free(ent);
+                return 0;
+            }
+        }
+    } while (*p++ != '\0');
+    return 1;
+}
+
+/*
+ * g_ent_hashes_lock protects the |hashes| member of all |BY_DIR_ENTRY|
+ * objects.
+ */
+static struct CRYPTO_STATIC_MUTEX g_ent_hashes_lock =
+    CRYPTO_STATIC_MUTEX_INIT;
+
+static int get_cert_by_subject(X509_LOOKUP *xl, int type, X509_NAME *name,
+                               X509_OBJECT *ret)
+{
+    BY_DIR *ctx;
+    union {
+        struct {
+            X509 st_x509;
+            X509_CINF st_x509_cinf;
+        } x509;
+        struct {
+            X509_CRL st_crl;
+            X509_CRL_INFO st_crl_info;
+        } crl;
+    } data;
+    int ok = 0;
+    size_t i;
+    int j, k;
+    unsigned long h;
+    unsigned long hash_array[2];
+    int hash_index;
+    BUF_MEM *b = NULL;
+    X509_OBJECT stmp, *tmp;
+    const char *postfix = "";
+
+    if (name == NULL)
+        return (0);
+
+    stmp.type = type;
+    if (type == X509_LU_X509) {
+        data.x509.st_x509.cert_info = &data.x509.st_x509_cinf;
+        data.x509.st_x509_cinf.subject = name;
+        stmp.data.x509 = &data.x509.st_x509;
+        postfix = "";
+    } else if (type == X509_LU_CRL) {
+        data.crl.st_crl.crl = &data.crl.st_crl_info;
+        data.crl.st_crl_info.issuer = name;
+        stmp.data.crl = &data.crl.st_crl;
+        postfix = "r";
+    } else {
+        OPENSSL_PUT_ERROR(X509, X509_R_WRONG_LOOKUP_TYPE);
+        goto finish;
+    }
+
+    if ((b = BUF_MEM_new()) == NULL) {
+        OPENSSL_PUT_ERROR(X509, ERR_R_BUF_LIB);
+        goto finish;
+    }
+
+    ctx = (BY_DIR *)xl->method_data;
+
+    hash_array[0] = X509_NAME_hash(name);
+    hash_array[1] = X509_NAME_hash_old(name);
+    for (hash_index = 0; hash_index < 2; ++hash_index) {
+        h = hash_array[hash_index];
+        for (i = 0; i < sk_BY_DIR_ENTRY_num(ctx->dirs); i++) {
+            BY_DIR_ENTRY *ent;
+            size_t idx;
+            BY_DIR_HASH htmp, *hent;
+            ent = sk_BY_DIR_ENTRY_value(ctx->dirs, i);
+            j = strlen(ent->dir) + 1 + 8 + 6 + 1 + 1;
+            if (!BUF_MEM_grow(b, j)) {
+                OPENSSL_PUT_ERROR(X509, ERR_R_MALLOC_FAILURE);
+                goto finish;
+            }
+            if (type == X509_LU_CRL && ent->hashes) {
+                htmp.hash = h;
+                CRYPTO_STATIC_MUTEX_lock_read(&g_ent_hashes_lock);
+                if (sk_BY_DIR_HASH_find(ent->hashes, &idx, &htmp)) {
+                    hent = sk_BY_DIR_HASH_value(ent->hashes, idx);
+                    k = hent->suffix;
+                } else {
+                    hent = NULL;
+                    k = 0;
+                }
+                CRYPTO_STATIC_MUTEX_unlock_read(&g_ent_hashes_lock);
+            } else {
+                k = 0;
+                hent = NULL;
+            }
+            for (;;) {
+                char c = '/';
+#ifdef OPENSSL_SYS_VMS
+                c = ent->dir[strlen(ent->dir) - 1];
+                if (c != ':' && c != '>' && c != ']') {
+                    /*
+                     * If no separator is present, we assume the directory
+                     * specifier is a logical name, and add a colon.  We
+                     * really should use better VMS routines for merging
+                     * things like this, but this will do for now... --
+                     * Richard Levitte
+                     */
+                    c = ':';
+                } else {
+                    c = '\0';
+                }
+#endif
+                if (c == '\0') {
+                    /*
+                     * This is special.  When c == '\0', no directory
+                     * separator should be added.
+                     */
+                    BIO_snprintf(b->data, b->max,
+                                 "%s%08lx.%s%d", ent->dir, h, postfix, k);
+                } else {
+                    BIO_snprintf(b->data, b->max,
+                                 "%s%c%08lx.%s%d", ent->dir, c, h,
+                                 postfix, k);
+                }
+#ifndef OPENSSL_NO_POSIX_IO
+# if defined(_WIN32) && !defined(stat)
+#  define stat _stat
+# endif
+                {
+                    struct stat st;
+                    if (stat(b->data, &st) < 0)
+                        break;
+                }
+#endif
+                /* found one. */
+                if (type == X509_LU_X509) {
+                    if ((X509_load_cert_file(xl, b->data,
+                                             ent->dir_type)) == 0)
+                        break;
+                } else if (type == X509_LU_CRL) {
+                    if ((X509_load_crl_file(xl, b->data, ent->dir_type)) == 0)
+                        break;
+                }
+                /* else case will caught higher up */
+                k++;
+            }
+
+            /*
+             * we have added it to the cache so now pull it out again
+             */
+            CRYPTO_MUTEX_lock_write(&xl->store_ctx->objs_lock);
+            tmp = NULL;
+            if (sk_X509_OBJECT_find(xl->store_ctx->objs, &idx, &stmp)) {
+                tmp = sk_X509_OBJECT_value(xl->store_ctx->objs, idx);
+            }
+            CRYPTO_MUTEX_unlock_write(&xl->store_ctx->objs_lock);
+
+            /*
+             * If a CRL, update the last file suffix added for this
+             */
+
+            if (type == X509_LU_CRL) {
+                CRYPTO_STATIC_MUTEX_lock_write(&g_ent_hashes_lock);
+                /*
+                 * Look for entry again in case another thread added an entry
+                 * first.
+                 */
+                if (!hent) {
+                    htmp.hash = h;
+                    if (sk_BY_DIR_HASH_find(ent->hashes, &idx, &htmp))
+                        hent = sk_BY_DIR_HASH_value(ent->hashes, idx);
+                }
+                if (!hent) {
+                    hent = OPENSSL_malloc(sizeof(BY_DIR_HASH));
+                    if (hent == NULL) {
+                        CRYPTO_STATIC_MUTEX_unlock_write(&g_ent_hashes_lock);
+                        ok = 0;
+                        goto finish;
+                    }
+                    hent->hash = h;
+                    hent->suffix = k;
+                    if (!sk_BY_DIR_HASH_push(ent->hashes, hent)) {
+                        CRYPTO_STATIC_MUTEX_unlock_write(&g_ent_hashes_lock);
+                        OPENSSL_free(hent);
+                        ok = 0;
+                        goto finish;
+                    }
+                } else if (hent->suffix < k)
+                    hent->suffix = k;
+
+                CRYPTO_STATIC_MUTEX_unlock_write(&g_ent_hashes_lock);
+            }
+
+            if (tmp != NULL) {
+                ok = 1;
+                ret->type = tmp->type;
+                OPENSSL_memcpy(&ret->data, &tmp->data, sizeof(ret->data));
+                /*
+                 * If we were going to up the reference count, we would need
+                 * to do it on a perl 'type' basis
+                 */
+                /*
+                 * CRYPTO_add(&tmp->data.x509->references,1,
+                 * CRYPTO_LOCK_X509);
+                 */
+                goto finish;
+            }
+        }
+    }
+ finish:
+    if (b != NULL)
+        BUF_MEM_free(b);
+    return (ok);
+}
diff -Naur chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/cpu.c chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/cpu.c
--- chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/cpu.c	2018-03-21 01:06:51.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/cpu.c	2018-04-27 11:31:20.571828478 +0300
@@ -18,7 +18,13 @@
 
 #include <stddef.h>
 #include <stdint.h>
+// GCC 4.8 didn't have stdatomic, but was advertising it.
+// https://gcc.gnu.org/bugzilla/show_bug.cgi?id=58016
+#if !defined(__clang__) && defined(__GNUC__) && (__GNUC__ == 4 || (__GNUC__ == 4 && (__GNUC_MINOR__ == 8)))
+#include <compat/atomics/gcc/stdatomic.h>
+#else
 #include <stdatomic.h>
+#endif
 
 #include "attributes.h"
 #include "cpu.h"
diff -Naur chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic
--- chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/cpu.c.ffmpeg-stdatomic	2018-03-21 01:06:51.000000000 +0300
@@ -0,0 +1,321 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stddef.h>
+#include <stdint.h>
+#include <stdatomic.h>
+
+#include "attributes.h"
+#include "cpu.h"
+#include "cpu_internal.h"
+#include "config.h"
+#include "opt.h"
+#include "common.h"
+
+#if HAVE_SCHED_GETAFFINITY
+#ifndef _GNU_SOURCE
+# define _GNU_SOURCE
+#endif
+#include <sched.h>
+#endif
+#if HAVE_GETPROCESSAFFINITYMASK || HAVE_WINRT
+#include <windows.h>
+#endif
+#if HAVE_SYSCTL
+#if HAVE_SYS_PARAM_H
+#include <sys/param.h>
+#endif
+#include <sys/types.h>
+#include <sys/sysctl.h>
+#endif
+#if HAVE_UNISTD_H
+#include <unistd.h>
+#endif
+
+static atomic_int cpu_flags = ATOMIC_VAR_INIT(-1);
+
+static int get_cpu_flags(void)
+{
+    if (ARCH_AARCH64)
+        return ff_get_cpu_flags_aarch64();
+    if (ARCH_ARM)
+        return ff_get_cpu_flags_arm();
+    if (ARCH_PPC)
+        return ff_get_cpu_flags_ppc();
+    if (ARCH_X86)
+        return ff_get_cpu_flags_x86();
+    return 0;
+}
+
+void av_force_cpu_flags(int arg){
+    if (ARCH_X86 &&
+           (arg & ( AV_CPU_FLAG_3DNOW    |
+                    AV_CPU_FLAG_3DNOWEXT |
+                    AV_CPU_FLAG_MMXEXT   |
+                    AV_CPU_FLAG_SSE      |
+                    AV_CPU_FLAG_SSE2     |
+                    AV_CPU_FLAG_SSE2SLOW |
+                    AV_CPU_FLAG_SSE3     |
+                    AV_CPU_FLAG_SSE3SLOW |
+                    AV_CPU_FLAG_SSSE3    |
+                    AV_CPU_FLAG_SSE4     |
+                    AV_CPU_FLAG_SSE42    |
+                    AV_CPU_FLAG_AVX      |
+                    AV_CPU_FLAG_AVXSLOW  |
+                    AV_CPU_FLAG_XOP      |
+                    AV_CPU_FLAG_FMA3     |
+                    AV_CPU_FLAG_FMA4     |
+                    AV_CPU_FLAG_AVX2     |
+                    AV_CPU_FLAG_AVX512   ))
+        && !(arg & AV_CPU_FLAG_MMX)) {
+        av_log(NULL, AV_LOG_WARNING, "MMX implied by specified flags\n");
+        arg |= AV_CPU_FLAG_MMX;
+    }
+
+    atomic_store_explicit(&cpu_flags, arg, memory_order_relaxed);
+}
+
+int av_get_cpu_flags(void)
+{
+    int flags = atomic_load_explicit(&cpu_flags, memory_order_relaxed);
+    if (flags == -1) {
+        flags = get_cpu_flags();
+        atomic_store_explicit(&cpu_flags, flags, memory_order_relaxed);
+    }
+    return flags;
+}
+
+void av_set_cpu_flags_mask(int mask)
+{
+    atomic_store_explicit(&cpu_flags, get_cpu_flags() & mask,
+                          memory_order_relaxed);
+}
+
+int av_parse_cpu_flags(const char *s)
+{
+#define CPUFLAG_MMXEXT   (AV_CPU_FLAG_MMX      | AV_CPU_FLAG_MMXEXT | AV_CPU_FLAG_CMOV)
+#define CPUFLAG_3DNOW    (AV_CPU_FLAG_3DNOW    | AV_CPU_FLAG_MMX)
+#define CPUFLAG_3DNOWEXT (AV_CPU_FLAG_3DNOWEXT | CPUFLAG_3DNOW)
+#define CPUFLAG_SSE      (AV_CPU_FLAG_SSE      | CPUFLAG_MMXEXT)
+#define CPUFLAG_SSE2     (AV_CPU_FLAG_SSE2     | CPUFLAG_SSE)
+#define CPUFLAG_SSE2SLOW (AV_CPU_FLAG_SSE2SLOW | CPUFLAG_SSE2)
+#define CPUFLAG_SSE3     (AV_CPU_FLAG_SSE3     | CPUFLAG_SSE2)
+#define CPUFLAG_SSE3SLOW (AV_CPU_FLAG_SSE3SLOW | CPUFLAG_SSE3)
+#define CPUFLAG_SSSE3    (AV_CPU_FLAG_SSSE3    | CPUFLAG_SSE3)
+#define CPUFLAG_SSE4     (AV_CPU_FLAG_SSE4     | CPUFLAG_SSSE3)
+#define CPUFLAG_SSE42    (AV_CPU_FLAG_SSE42    | CPUFLAG_SSE4)
+#define CPUFLAG_AVX      (AV_CPU_FLAG_AVX      | CPUFLAG_SSE42)
+#define CPUFLAG_AVXSLOW  (AV_CPU_FLAG_AVXSLOW  | CPUFLAG_AVX)
+#define CPUFLAG_XOP      (AV_CPU_FLAG_XOP      | CPUFLAG_AVX)
+#define CPUFLAG_FMA3     (AV_CPU_FLAG_FMA3     | CPUFLAG_AVX)
+#define CPUFLAG_FMA4     (AV_CPU_FLAG_FMA4     | CPUFLAG_AVX)
+#define CPUFLAG_AVX2     (AV_CPU_FLAG_AVX2     | CPUFLAG_AVX)
+#define CPUFLAG_BMI2     (AV_CPU_FLAG_BMI2     | AV_CPU_FLAG_BMI1)
+#define CPUFLAG_AESNI    (AV_CPU_FLAG_AESNI    | CPUFLAG_SSE42)
+#define CPUFLAG_AVX512   (AV_CPU_FLAG_AVX512   | CPUFLAG_AVX2)
+    static const AVOption cpuflags_opts[] = {
+        { "flags"   , NULL, 0, AV_OPT_TYPE_FLAGS, { .i64 = 0 }, INT64_MIN, INT64_MAX, .unit = "flags" },
+#if   ARCH_PPC
+        { "altivec" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ALTIVEC  },    .unit = "flags" },
+#elif ARCH_X86
+        { "mmx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX      },    .unit = "flags" },
+        { "mmxext"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_MMXEXT       },    .unit = "flags" },
+        { "sse"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE          },    .unit = "flags" },
+        { "sse2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE2         },    .unit = "flags" },
+        { "sse2slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE2SLOW     },    .unit = "flags" },
+        { "sse3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE3         },    .unit = "flags" },
+        { "sse3slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE3SLOW     },    .unit = "flags" },
+        { "ssse3"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSSE3        },    .unit = "flags" },
+        { "atom"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ATOM     },    .unit = "flags" },
+        { "sse4.1"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE4         },    .unit = "flags" },
+        { "sse4.2"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_SSE42        },    .unit = "flags" },
+        { "avx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX          },    .unit = "flags" },
+        { "avxslow" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVXSLOW      },    .unit = "flags" },
+        { "xop"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_XOP          },    .unit = "flags" },
+        { "fma3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_FMA3         },    .unit = "flags" },
+        { "fma4"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_FMA4         },    .unit = "flags" },
+        { "avx2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX2         },    .unit = "flags" },
+        { "bmi1"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_BMI1     },    .unit = "flags" },
+        { "bmi2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_BMI2         },    .unit = "flags" },
+        { "3dnow"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_3DNOW        },    .unit = "flags" },
+        { "3dnowext", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_3DNOWEXT     },    .unit = "flags" },
+        { "cmov",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_CMOV     },    .unit = "flags" },
+        { "aesni"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AESNI        },    .unit = "flags" },
+        { "avx512"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPUFLAG_AVX512       },    .unit = "flags" },
+#elif ARCH_ARM
+        { "armv5te",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV5TE  },    .unit = "flags" },
+        { "armv6",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6    },    .unit = "flags" },
+        { "armv6t2",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6T2  },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+        { "vfp_vm",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP_VM   },    .unit = "flags" },
+        { "vfpv3",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFPV3    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+#elif ARCH_AARCH64
+        { "armv8",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV8    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+#endif
+        { NULL },
+    };
+    static const AVClass class = {
+        .class_name = "cpuflags",
+        .item_name  = av_default_item_name,
+        .option     = cpuflags_opts,
+        .version    = LIBAVUTIL_VERSION_INT,
+    };
+
+    int flags = 0, ret;
+    const AVClass *pclass = &class;
+
+    if ((ret = av_opt_eval_flags(&pclass, &cpuflags_opts[0], s, &flags)) < 0)
+        return ret;
+
+    return flags & INT_MAX;
+}
+
+int av_parse_cpu_caps(unsigned *flags, const char *s)
+{
+        static const AVOption cpuflags_opts[] = {
+        { "flags"   , NULL, 0, AV_OPT_TYPE_FLAGS, { .i64 = 0 }, INT64_MIN, INT64_MAX, .unit = "flags" },
+#if   ARCH_PPC
+        { "altivec" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ALTIVEC  },    .unit = "flags" },
+#elif ARCH_X86
+        { "mmx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX      },    .unit = "flags" },
+        { "mmx2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX2     },    .unit = "flags" },
+        { "mmxext"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX2     },    .unit = "flags" },
+        { "sse"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE      },    .unit = "flags" },
+        { "sse2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE2     },    .unit = "flags" },
+        { "sse2slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE2SLOW },    .unit = "flags" },
+        { "sse3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE3     },    .unit = "flags" },
+        { "sse3slow", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE3SLOW },    .unit = "flags" },
+        { "ssse3"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSSE3    },    .unit = "flags" },
+        { "atom"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ATOM     },    .unit = "flags" },
+        { "sse4.1"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE4     },    .unit = "flags" },
+        { "sse4.2"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SSE42    },    .unit = "flags" },
+        { "avx"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVX      },    .unit = "flags" },
+        { "avxslow" , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVXSLOW  },    .unit = "flags" },
+        { "xop"     , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_XOP      },    .unit = "flags" },
+        { "fma3"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_FMA3     },    .unit = "flags" },
+        { "fma4"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_FMA4     },    .unit = "flags" },
+        { "avx2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVX2     },    .unit = "flags" },
+        { "bmi1"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_BMI1     },    .unit = "flags" },
+        { "bmi2"    , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_BMI2     },    .unit = "flags" },
+        { "3dnow"   , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_3DNOW    },    .unit = "flags" },
+        { "3dnowext", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_3DNOWEXT },    .unit = "flags" },
+        { "cmov",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_CMOV     },    .unit = "flags" },
+        { "aesni",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AESNI    },    .unit = "flags" },
+        { "avx512"  , NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_AVX512   },    .unit = "flags" },
+
+#define CPU_FLAG_P2 AV_CPU_FLAG_CMOV | AV_CPU_FLAG_MMX
+#define CPU_FLAG_P3 CPU_FLAG_P2 | AV_CPU_FLAG_MMX2 | AV_CPU_FLAG_SSE
+#define CPU_FLAG_P4 CPU_FLAG_P3| AV_CPU_FLAG_SSE2
+        { "pentium2", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_P2          },    .unit = "flags" },
+        { "pentium3", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_P3          },    .unit = "flags" },
+        { "pentium4", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_P4          },    .unit = "flags" },
+
+#define CPU_FLAG_K62 AV_CPU_FLAG_MMX | AV_CPU_FLAG_3DNOW
+#define CPU_FLAG_ATHLON   CPU_FLAG_K62 | AV_CPU_FLAG_CMOV | AV_CPU_FLAG_3DNOWEXT | AV_CPU_FLAG_MMX2
+#define CPU_FLAG_ATHLONXP CPU_FLAG_ATHLON | AV_CPU_FLAG_SSE
+#define CPU_FLAG_K8  CPU_FLAG_ATHLONXP | AV_CPU_FLAG_SSE2
+        { "k6",       NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_MMX      },    .unit = "flags" },
+        { "k62",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_K62         },    .unit = "flags" },
+        { "athlon",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_ATHLON      },    .unit = "flags" },
+        { "athlonxp", NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_ATHLONXP    },    .unit = "flags" },
+        { "k8",       NULL, 0, AV_OPT_TYPE_CONST, { .i64 = CPU_FLAG_K8          },    .unit = "flags" },
+#elif ARCH_ARM
+        { "armv5te",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV5TE  },    .unit = "flags" },
+        { "armv6",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6    },    .unit = "flags" },
+        { "armv6t2",  NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV6T2  },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+        { "vfp_vm",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP_VM   },    .unit = "flags" },
+        { "vfpv3",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFPV3    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+        { "setend",   NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_SETEND   },    .unit = "flags" },
+#elif ARCH_AARCH64
+        { "armv8",    NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_ARMV8    },    .unit = "flags" },
+        { "neon",     NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_NEON     },    .unit = "flags" },
+        { "vfp",      NULL, 0, AV_OPT_TYPE_CONST, { .i64 = AV_CPU_FLAG_VFP      },    .unit = "flags" },
+#endif
+        { NULL },
+    };
+    static const AVClass class = {
+        .class_name = "cpuflags",
+        .item_name  = av_default_item_name,
+        .option     = cpuflags_opts,
+        .version    = LIBAVUTIL_VERSION_INT,
+    };
+    const AVClass *pclass = &class;
+
+    return av_opt_eval_flags(&pclass, &cpuflags_opts[0], s, flags);
+}
+
+int av_cpu_count(void)
+{
+    static volatile int printed;
+
+    int nb_cpus = 1;
+#if HAVE_WINRT
+    SYSTEM_INFO sysinfo;
+#endif
+#if HAVE_SCHED_GETAFFINITY && defined(CPU_COUNT)
+    cpu_set_t cpuset;
+
+    CPU_ZERO(&cpuset);
+
+    if (!sched_getaffinity(0, sizeof(cpuset), &cpuset))
+        nb_cpus = CPU_COUNT(&cpuset);
+#elif HAVE_GETPROCESSAFFINITYMASK
+    DWORD_PTR proc_aff, sys_aff;
+    if (GetProcessAffinityMask(GetCurrentProcess(), &proc_aff, &sys_aff))
+        nb_cpus = av_popcount64(proc_aff);
+#elif HAVE_SYSCTL && defined(HW_NCPU)
+    int mib[2] = { CTL_HW, HW_NCPU };
+    size_t len = sizeof(nb_cpus);
+
+    if (sysctl(mib, 2, &nb_cpus, &len, NULL, 0) == -1)
+        nb_cpus = 0;
+#elif HAVE_SYSCONF && defined(_SC_NPROC_ONLN)
+    nb_cpus = sysconf(_SC_NPROC_ONLN);
+#elif HAVE_SYSCONF && defined(_SC_NPROCESSORS_ONLN)
+    nb_cpus = sysconf(_SC_NPROCESSORS_ONLN);
+#elif HAVE_WINRT
+    GetNativeSystemInfo(&sysinfo);
+    nb_cpus = sysinfo.dwNumberOfProcessors;
+#endif
+
+    if (!printed) {
+        av_log(NULL, AV_LOG_DEBUG, "detected %d logical cores\n", nb_cpus);
+        printed = 1;
+    }
+
+    return nb_cpus;
+}
+
+size_t av_cpu_max_align(void)
+{
+    if (ARCH_AARCH64)
+        return ff_get_cpu_max_align_aarch64();
+    if (ARCH_ARM)
+        return ff_get_cpu_max_align_arm();
+    if (ARCH_PPC)
+        return ff_get_cpu_max_align_ppc();
+    if (ARCH_X86)
+        return ff_get_cpu_max_align_x86();
+
+    return 8;
+}
diff -Naur chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/timer.h chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/timer.h
--- chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/timer.h	2018-03-21 01:06:51.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/timer.h	2018-04-27 11:31:20.583828351 +0300
@@ -49,13 +49,13 @@
 #include "log.h"
 
 #if   ARCH_AARCH64
-#   include "aarch64/timer.h"
+#   include "libavutil/aarch64/timer.h"
 #elif ARCH_ARM
-#   include "arm/timer.h"
+#   include "libavutil/arm/timer.h"
 #elif ARCH_PPC
-#   include "ppc/timer.h"
+#   include "libavutil/ppc/timer.h"
 #elif ARCH_X86
-#   include "x86/timer.h"
+#   include "libavutil/x86/timer.h"
 #endif
 
 #if !defined(AV_READ_TIME)
diff -Naur chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/timer.h.pathfix chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/timer.h.pathfix
--- chromium-65.0.3325.181-orig/third_party/ffmpeg/libavutil/timer.h.pathfix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/ffmpeg/libavutil/timer.h.pathfix	2018-03-21 01:06:51.000000000 +0300
@@ -0,0 +1,141 @@
+/*
+ * copyright (c) 2006 Michael Niedermayer <michaelni@gmx.at>
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * high precision timer, useful to profile code
+ */
+
+#ifndef AVUTIL_TIMER_H
+#define AVUTIL_TIMER_H
+
+#include "config.h"
+
+#if CONFIG_LINUX_PERF
+# ifndef _GNU_SOURCE
+#  define _GNU_SOURCE
+# endif
+# include <unistd.h> // read(3)
+# include <sys/ioctl.h>
+# include <asm/unistd.h>
+# include <linux/perf_event.h>
+#endif
+
+#include <stdlib.h>
+#include <stdint.h>
+#include <inttypes.h>
+
+#if HAVE_MACH_ABSOLUTE_TIME
+#include <mach/mach_time.h>
+#endif
+
+#include "log.h"
+
+#if   ARCH_AARCH64
+#   include "aarch64/timer.h"
+#elif ARCH_ARM
+#   include "arm/timer.h"
+#elif ARCH_PPC
+#   include "ppc/timer.h"
+#elif ARCH_X86
+#   include "x86/timer.h"
+#endif
+
+#if !defined(AV_READ_TIME)
+#   if HAVE_GETHRTIME
+#       define AV_READ_TIME gethrtime
+#   elif HAVE_MACH_ABSOLUTE_TIME
+#       define AV_READ_TIME mach_absolute_time
+#   endif
+#endif
+
+#ifndef FF_TIMER_UNITS
+#   define FF_TIMER_UNITS "UNITS"
+#endif
+
+#define TIMER_REPORT(id, tdiff)                                           \
+    {                                                                     \
+        static uint64_t tsum   = 0;                                       \
+        static int tcount      = 0;                                       \
+        static int tskip_count = 0;                                       \
+        static int thistogram[32] = {0};                                  \
+        thistogram[av_log2(tdiff)]++;                                     \
+        if (tcount < 2                ||                                  \
+            (tdiff) < 8 * tsum / tcount ||                                \
+            (tdiff) < 2000) {                                             \
+            tsum += (tdiff);                                              \
+            tcount++;                                                     \
+        } else                                                            \
+            tskip_count++;                                                \
+        if (((tcount + tskip_count) & (tcount + tskip_count - 1)) == 0) { \
+            int i;                                                        \
+            av_log(NULL, AV_LOG_ERROR,                                    \
+                   "%7"PRIu64" " FF_TIMER_UNITS " in %s,%8d runs,%7d skips",          \
+                   tsum * 10 / tcount, id, tcount, tskip_count);          \
+            for (i = 0; i < 32; i++)                                      \
+                av_log(NULL, AV_LOG_VERBOSE, " %2d", av_log2(2*thistogram[i]));\
+            av_log(NULL, AV_LOG_ERROR, "\n");                             \
+        }                                                                 \
+    }
+
+#if CONFIG_LINUX_PERF
+
+#define START_TIMER                                                         \
+    static int linux_perf_fd;                                               \
+    uint64_t tperf;                                                         \
+    if (!linux_perf_fd) {                                                   \
+        struct perf_event_attr attr = {                                     \
+            .type           = PERF_TYPE_HARDWARE,                           \
+            .size           = sizeof(struct perf_event_attr),               \
+            .config         = PERF_COUNT_HW_CPU_CYCLES,                     \
+            .disabled       = 1,                                            \
+            .exclude_kernel = 1,                                            \
+            .exclude_hv     = 1,                                            \
+        };                                                                  \
+        linux_perf_fd = syscall(__NR_perf_event_open, &attr,                \
+                                0, -1, -1, 0);                              \
+    }                                                                       \
+    if (linux_perf_fd == -1) {                                              \
+        av_log(NULL, AV_LOG_ERROR, "perf_event_open failed: %s\n",          \
+               av_err2str(AVERROR(errno)));                                 \
+    } else {                                                                \
+        ioctl(linux_perf_fd, PERF_EVENT_IOC_RESET, 0);                      \
+        ioctl(linux_perf_fd, PERF_EVENT_IOC_ENABLE, 0);                     \
+    }
+
+#define STOP_TIMER(id)                                                      \
+    ioctl(linux_perf_fd, PERF_EVENT_IOC_DISABLE, 0);                        \
+    read(linux_perf_fd, &tperf, sizeof(tperf));                             \
+    TIMER_REPORT(id, tperf)
+
+#elif defined(AV_READ_TIME)
+#define START_TIMER                             \
+    uint64_t tend;                              \
+    uint64_t tstart = AV_READ_TIME();           \
+
+#define STOP_TIMER(id)                                                    \
+    tend = AV_READ_TIME();                                                \
+    TIMER_REPORT(id, tend - tstart)
+#else
+#define START_TIMER
+#define STOP_TIMER(id) { }
+#endif
+
+#endif /* AVUTIL_TIMER_H */
diff -Naur chromium-65.0.3325.181-orig/third_party/libjpeg_turbo/jpeglib.h chromium-65.0.3325.181.patched/third_party/libjpeg_turbo/jpeglib.h
--- chromium-65.0.3325.181-orig/third_party/libjpeg_turbo/jpeglib.h	2018-03-21 01:06:51.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/libjpeg_turbo/jpeglib.h	2018-04-27 11:31:20.579828393 +0300
@@ -18,10 +18,6 @@
 #ifndef JPEGLIB_H
 #define JPEGLIB_H
 
-/* Begin chromium edits */
-#include "jpeglibmangler.h"
-/* End chromium edits */
-
 /*
  * First we include the configuration files that record how this
  * installation of the JPEG library is set up.  jconfig.h can be
diff -Naur chromium-65.0.3325.181-orig/third_party/libjpeg_turbo/jpeglib.h.nomangle chromium-65.0.3325.181.patched/third_party/libjpeg_turbo/jpeglib.h.nomangle
--- chromium-65.0.3325.181-orig/third_party/libjpeg_turbo/jpeglib.h.nomangle	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/libjpeg_turbo/jpeglib.h.nomangle	2018-03-21 01:06:51.000000000 +0300
@@ -0,0 +1,1126 @@
+/*
+ * jpeglib.h
+ *
+ * This file was part of the Independent JPEG Group's software:
+ * Copyright (C) 1991-1998, Thomas G. Lane.
+ * Modified 2002-2009 by Guido Vollbeding.
+ * libjpeg-turbo Modifications:
+ * Copyright (C) 2009-2011, 2013-2014, 2016, D. R. Commander.
+ * Copyright (C) 2015, Google, Inc.
+ * For conditions of distribution and use, see the accompanying README.ijg
+ * file.
+ *
+ * This file defines the application interface for the JPEG library.
+ * Most applications using the library need only include this file,
+ * and perhaps jerror.h if they want to know the exact error codes.
+ */
+
+#ifndef JPEGLIB_H
+#define JPEGLIB_H
+
+/* Begin chromium edits */
+#include "jpeglibmangler.h"
+/* End chromium edits */
+
+/*
+ * First we include the configuration files that record how this
+ * installation of the JPEG library is set up.  jconfig.h can be
+ * generated automatically for many systems.  jmorecfg.h contains
+ * manual configuration options that most people need not worry about.
+ */
+
+#ifndef JCONFIG_INCLUDED        /* in case jinclude.h already did */
+#include "jconfig.h"            /* widely used configuration options */
+#endif
+#include "jmorecfg.h"           /* seldom changed options */
+
+
+#ifdef __cplusplus
+#ifndef DONT_USE_EXTERN_C
+extern "C" {
+#endif
+#endif
+
+
+/* Various constants determining the sizes of things.
+ * All of these are specified by the JPEG standard, so don't change them
+ * if you want to be compatible.
+ */
+
+#define DCTSIZE             8   /* The basic DCT block is 8x8 samples */
+#define DCTSIZE2            64  /* DCTSIZE squared; # of elements in a block */
+#define NUM_QUANT_TBLS      4   /* Quantization tables are numbered 0..3 */
+#define NUM_HUFF_TBLS       4   /* Huffman tables are numbered 0..3 */
+#define NUM_ARITH_TBLS      16  /* Arith-coding tables are numbered 0..15 */
+#define MAX_COMPS_IN_SCAN   4   /* JPEG limit on # of components in one scan */
+#define MAX_SAMP_FACTOR     4   /* JPEG limit on sampling factors */
+/* Unfortunately, some bozo at Adobe saw no reason to be bound by the standard;
+ * the PostScript DCT filter can emit files with many more than 10 blocks/MCU.
+ * If you happen to run across such a file, you can up D_MAX_BLOCKS_IN_MCU
+ * to handle it.  We even let you do this from the jconfig.h file.  However,
+ * we strongly discourage changing C_MAX_BLOCKS_IN_MCU; just because Adobe
+ * sometimes emits noncompliant files doesn't mean you should too.
+ */
+#define C_MAX_BLOCKS_IN_MCU   10 /* compressor's limit on blocks per MCU */
+#ifndef D_MAX_BLOCKS_IN_MCU
+#define D_MAX_BLOCKS_IN_MCU   10 /* decompressor's limit on blocks per MCU */
+#endif
+
+
+/* Data structures for images (arrays of samples and of DCT coefficients).
+ */
+
+typedef JSAMPLE *JSAMPROW;      /* ptr to one image row of pixel samples. */
+typedef JSAMPROW *JSAMPARRAY;   /* ptr to some rows (a 2-D sample array) */
+typedef JSAMPARRAY *JSAMPIMAGE; /* a 3-D sample array: top index is color */
+
+typedef JCOEF JBLOCK[DCTSIZE2]; /* one block of coefficients */
+typedef JBLOCK *JBLOCKROW;      /* pointer to one row of coefficient blocks */
+typedef JBLOCKROW *JBLOCKARRAY;         /* a 2-D array of coefficient blocks */
+typedef JBLOCKARRAY *JBLOCKIMAGE;       /* a 3-D array of coefficient blocks */
+
+typedef JCOEF *JCOEFPTR;        /* useful in a couple of places */
+
+
+/* Types for JPEG compression parameters and working tables. */
+
+
+/* DCT coefficient quantization tables. */
+
+typedef struct {
+  /* This array gives the coefficient quantizers in natural array order
+   * (not the zigzag order in which they are stored in a JPEG DQT marker).
+   * CAUTION: IJG versions prior to v6a kept this array in zigzag order.
+   */
+  UINT16 quantval[DCTSIZE2];    /* quantization step for each coefficient */
+  /* This field is used only during compression.  It's initialized FALSE when
+   * the table is created, and set TRUE when it's been output to the file.
+   * You could suppress output of a table by setting this to TRUE.
+   * (See jpeg_suppress_tables for an example.)
+   */
+  boolean sent_table;           /* TRUE when table has been output */
+} JQUANT_TBL;
+
+
+/* Huffman coding tables. */
+
+typedef struct {
+  /* These two fields directly represent the contents of a JPEG DHT marker */
+  UINT8 bits[17];               /* bits[k] = # of symbols with codes of */
+                                /* length k bits; bits[0] is unused */
+  UINT8 huffval[256];           /* The symbols, in order of incr code length */
+  /* This field is used only during compression.  It's initialized FALSE when
+   * the table is created, and set TRUE when it's been output to the file.
+   * You could suppress output of a table by setting this to TRUE.
+   * (See jpeg_suppress_tables for an example.)
+   */
+  boolean sent_table;           /* TRUE when table has been output */
+} JHUFF_TBL;
+
+
+/* Basic info about one component (color channel). */
+
+typedef struct {
+  /* These values are fixed over the whole image. */
+  /* For compression, they must be supplied by parameter setup; */
+  /* for decompression, they are read from the SOF marker. */
+  int component_id;             /* identifier for this component (0..255) */
+  int component_index;          /* its index in SOF or cinfo->comp_info[] */
+  int h_samp_factor;            /* horizontal sampling factor (1..4) */
+  int v_samp_factor;            /* vertical sampling factor (1..4) */
+  int quant_tbl_no;             /* quantization table selector (0..3) */
+  /* These values may vary between scans. */
+  /* For compression, they must be supplied by parameter setup; */
+  /* for decompression, they are read from the SOS marker. */
+  /* The decompressor output side may not use these variables. */
+  int dc_tbl_no;                /* DC entropy table selector (0..3) */
+  int ac_tbl_no;                /* AC entropy table selector (0..3) */
+
+  /* Remaining fields should be treated as private by applications. */
+
+  /* These values are computed during compression or decompression startup: */
+  /* Component's size in DCT blocks.
+   * Any dummy blocks added to complete an MCU are not counted; therefore
+   * these values do not depend on whether a scan is interleaved or not.
+   */
+  JDIMENSION width_in_blocks;
+  JDIMENSION height_in_blocks;
+  /* Size of a DCT block in samples.  Always DCTSIZE for compression.
+   * For decompression this is the size of the output from one DCT block,
+   * reflecting any scaling we choose to apply during the IDCT step.
+   * Values from 1 to 16 are supported.
+   * Note that different components may receive different IDCT scalings.
+   */
+#if JPEG_LIB_VERSION >= 70
+  int DCT_h_scaled_size;
+  int DCT_v_scaled_size;
+#else
+  int DCT_scaled_size;
+#endif
+  /* The downsampled dimensions are the component's actual, unpadded number
+   * of samples at the main buffer (preprocessing/compression interface), thus
+   * downsampled_width = ceil(image_width * Hi/Hmax)
+   * and similarly for height.  For decompression, IDCT scaling is included, so
+   * downsampled_width = ceil(image_width * Hi/Hmax * DCT_[h_]scaled_size/DCTSIZE)
+   */
+  JDIMENSION downsampled_width;  /* actual width in samples */
+  JDIMENSION downsampled_height; /* actual height in samples */
+  /* This flag is used only for decompression.  In cases where some of the
+   * components will be ignored (eg grayscale output from YCbCr image),
+   * we can skip most computations for the unused components.
+   */
+  boolean component_needed;     /* do we need the value of this component? */
+
+  /* These values are computed before starting a scan of the component. */
+  /* The decompressor output side may not use these variables. */
+  int MCU_width;                /* number of blocks per MCU, horizontally */
+  int MCU_height;               /* number of blocks per MCU, vertically */
+  int MCU_blocks;               /* MCU_width * MCU_height */
+  int MCU_sample_width;         /* MCU width in samples, MCU_width*DCT_[h_]scaled_size */
+  int last_col_width;           /* # of non-dummy blocks across in last MCU */
+  int last_row_height;          /* # of non-dummy blocks down in last MCU */
+
+  /* Saved quantization table for component; NULL if none yet saved.
+   * See jdinput.c comments about the need for this information.
+   * This field is currently used only for decompression.
+   */
+  JQUANT_TBL *quant_table;
+
+  /* Private per-component storage for DCT or IDCT subsystem. */
+  void *dct_table;
+} jpeg_component_info;
+
+
+/* The script for encoding a multiple-scan file is an array of these: */
+
+typedef struct {
+  int comps_in_scan;            /* number of components encoded in this scan */
+  int component_index[MAX_COMPS_IN_SCAN]; /* their SOF/comp_info[] indexes */
+  int Ss, Se;                   /* progressive JPEG spectral selection parms */
+  int Ah, Al;                   /* progressive JPEG successive approx. parms */
+} jpeg_scan_info;
+
+/* The decompressor can save APPn and COM markers in a list of these: */
+
+typedef struct jpeg_marker_struct *jpeg_saved_marker_ptr;
+
+struct jpeg_marker_struct {
+  jpeg_saved_marker_ptr next;   /* next in list, or NULL */
+  UINT8 marker;                 /* marker code: JPEG_COM, or JPEG_APP0+n */
+  unsigned int original_length; /* # bytes of data in the file */
+  unsigned int data_length;     /* # bytes of data saved at data[] */
+  JOCTET *data;                 /* the data contained in the marker */
+  /* the marker length word is not counted in data_length or original_length */
+};
+
+/* Known color spaces. */
+
+#define JCS_EXTENSIONS 1
+#define JCS_ALPHA_EXTENSIONS 1
+
+typedef enum {
+  JCS_UNKNOWN,            /* error/unspecified */
+  JCS_GRAYSCALE,          /* monochrome */
+  JCS_RGB,                /* red/green/blue as specified by the RGB_RED,
+                             RGB_GREEN, RGB_BLUE, and RGB_PIXELSIZE macros */
+  JCS_YCbCr,              /* Y/Cb/Cr (also known as YUV) */
+  JCS_CMYK,               /* C/M/Y/K */
+  JCS_YCCK,               /* Y/Cb/Cr/K */
+  JCS_EXT_RGB,            /* red/green/blue */
+  JCS_EXT_RGBX,           /* red/green/blue/x */
+  JCS_EXT_BGR,            /* blue/green/red */
+  JCS_EXT_BGRX,           /* blue/green/red/x */
+  JCS_EXT_XBGR,           /* x/blue/green/red */
+  JCS_EXT_XRGB,           /* x/red/green/blue */
+  /* When out_color_space it set to JCS_EXT_RGBX, JCS_EXT_BGRX, JCS_EXT_XBGR,
+     or JCS_EXT_XRGB during decompression, the X byte is undefined, and in
+     order to ensure the best performance, libjpeg-turbo can set that byte to
+     whatever value it wishes.  Use the following colorspace constants to
+     ensure that the X byte is set to 0xFF, so that it can be interpreted as an
+     opaque alpha channel. */
+  JCS_EXT_RGBA,           /* red/green/blue/alpha */
+  JCS_EXT_BGRA,           /* blue/green/red/alpha */
+  JCS_EXT_ABGR,           /* alpha/blue/green/red */
+  JCS_EXT_ARGB,           /* alpha/red/green/blue */
+  JCS_RGB565              /* 5-bit red/6-bit green/5-bit blue */
+} J_COLOR_SPACE;
+
+/* DCT/IDCT algorithm options. */
+
+typedef enum {
+  JDCT_ISLOW,             /* slow but accurate integer algorithm */
+  JDCT_IFAST,             /* faster, less accurate integer method */
+  JDCT_FLOAT              /* floating-point: accurate, fast on fast HW */
+} J_DCT_METHOD;
+
+#ifndef JDCT_DEFAULT            /* may be overridden in jconfig.h */
+#define JDCT_DEFAULT  JDCT_ISLOW
+#endif
+#ifndef JDCT_FASTEST            /* may be overridden in jconfig.h */
+#define JDCT_FASTEST  JDCT_IFAST
+#endif
+
+/* Dithering options for decompression. */
+
+typedef enum {
+  JDITHER_NONE,           /* no dithering */
+  JDITHER_ORDERED,        /* simple ordered dither */
+  JDITHER_FS              /* Floyd-Steinberg error diffusion dither */
+} J_DITHER_MODE;
+
+
+/* Common fields between JPEG compression and decompression master structs. */
+
+#define jpeg_common_fields \
+  struct jpeg_error_mgr *err;   /* Error handler module */\
+  struct jpeg_memory_mgr *mem;  /* Memory manager module */\
+  struct jpeg_progress_mgr *progress; /* Progress monitor, or NULL if none */\
+  void *client_data;            /* Available for use by application */\
+  boolean is_decompressor;      /* So common code can tell which is which */\
+  int global_state              /* For checking call sequence validity */
+
+/* Routines that are to be used by both halves of the library are declared
+ * to receive a pointer to this structure.  There are no actual instances of
+ * jpeg_common_struct, only of jpeg_compress_struct and jpeg_decompress_struct.
+ */
+struct jpeg_common_struct {
+  jpeg_common_fields;           /* Fields common to both master struct types */
+  /* Additional fields follow in an actual jpeg_compress_struct or
+   * jpeg_decompress_struct.  All three structs must agree on these
+   * initial fields!  (This would be a lot cleaner in C++.)
+   */
+};
+
+typedef struct jpeg_common_struct *j_common_ptr;
+typedef struct jpeg_compress_struct *j_compress_ptr;
+typedef struct jpeg_decompress_struct *j_decompress_ptr;
+
+
+/* Master record for a compression instance */
+
+struct jpeg_compress_struct {
+  jpeg_common_fields;           /* Fields shared with jpeg_decompress_struct */
+
+  /* Destination for compressed data */
+  struct jpeg_destination_mgr *dest;
+
+  /* Description of source image --- these fields must be filled in by
+   * outer application before starting compression.  in_color_space must
+   * be correct before you can even call jpeg_set_defaults().
+   */
+
+  JDIMENSION image_width;       /* input image width */
+  JDIMENSION image_height;      /* input image height */
+  int input_components;         /* # of color components in input image */
+  J_COLOR_SPACE in_color_space; /* colorspace of input image */
+
+  double input_gamma;           /* image gamma of input image */
+
+  /* Compression parameters --- these fields must be set before calling
+   * jpeg_start_compress().  We recommend calling jpeg_set_defaults() to
+   * initialize everything to reasonable defaults, then changing anything
+   * the application specifically wants to change.  That way you won't get
+   * burnt when new parameters are added.  Also note that there are several
+   * helper routines to simplify changing parameters.
+   */
+
+#if JPEG_LIB_VERSION >= 70
+  unsigned int scale_num, scale_denom; /* fraction by which to scale image */
+
+  JDIMENSION jpeg_width;        /* scaled JPEG image width */
+  JDIMENSION jpeg_height;       /* scaled JPEG image height */
+  /* Dimensions of actual JPEG image that will be written to file,
+   * derived from input dimensions by scaling factors above.
+   * These fields are computed by jpeg_start_compress().
+   * You can also use jpeg_calc_jpeg_dimensions() to determine these values
+   * in advance of calling jpeg_start_compress().
+   */
+#endif
+
+  int data_precision;           /* bits of precision in image data */
+
+  int num_components;           /* # of color components in JPEG image */
+  J_COLOR_SPACE jpeg_color_space; /* colorspace of JPEG image */
+
+  jpeg_component_info *comp_info;
+  /* comp_info[i] describes component that appears i'th in SOF */
+
+  JQUANT_TBL *quant_tbl_ptrs[NUM_QUANT_TBLS];
+#if JPEG_LIB_VERSION >= 70
+  int q_scale_factor[NUM_QUANT_TBLS];
+#endif
+  /* ptrs to coefficient quantization tables, or NULL if not defined,
+   * and corresponding scale factors (percentage, initialized 100).
+   */
+
+  JHUFF_TBL *dc_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  JHUFF_TBL *ac_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  /* ptrs to Huffman coding tables, or NULL if not defined */
+
+  UINT8 arith_dc_L[NUM_ARITH_TBLS]; /* L values for DC arith-coding tables */
+  UINT8 arith_dc_U[NUM_ARITH_TBLS]; /* U values for DC arith-coding tables */
+  UINT8 arith_ac_K[NUM_ARITH_TBLS]; /* Kx values for AC arith-coding tables */
+
+  int num_scans;                /* # of entries in scan_info array */
+  const jpeg_scan_info *scan_info; /* script for multi-scan file, or NULL */
+  /* The default value of scan_info is NULL, which causes a single-scan
+   * sequential JPEG file to be emitted.  To create a multi-scan file,
+   * set num_scans and scan_info to point to an array of scan definitions.
+   */
+
+  boolean raw_data_in;          /* TRUE=caller supplies downsampled data */
+  boolean arith_code;           /* TRUE=arithmetic coding, FALSE=Huffman */
+  boolean optimize_coding;      /* TRUE=optimize entropy encoding parms */
+  boolean CCIR601_sampling;     /* TRUE=first samples are cosited */
+#if JPEG_LIB_VERSION >= 70
+  boolean do_fancy_downsampling; /* TRUE=apply fancy downsampling */
+#endif
+  int smoothing_factor;         /* 1..100, or 0 for no input smoothing */
+  J_DCT_METHOD dct_method;      /* DCT algorithm selector */
+
+  /* The restart interval can be specified in absolute MCUs by setting
+   * restart_interval, or in MCU rows by setting restart_in_rows
+   * (in which case the correct restart_interval will be figured
+   * for each scan).
+   */
+  unsigned int restart_interval; /* MCUs per restart, or 0 for no restart */
+  int restart_in_rows;          /* if > 0, MCU rows per restart interval */
+
+  /* Parameters controlling emission of special markers. */
+
+  boolean write_JFIF_header;    /* should a JFIF marker be written? */
+  UINT8 JFIF_major_version;     /* What to write for the JFIF version number */
+  UINT8 JFIF_minor_version;
+  /* These three values are not used by the JPEG code, merely copied */
+  /* into the JFIF APP0 marker.  density_unit can be 0 for unknown, */
+  /* 1 for dots/inch, or 2 for dots/cm.  Note that the pixel aspect */
+  /* ratio is defined by X_density/Y_density even when density_unit=0. */
+  UINT8 density_unit;           /* JFIF code for pixel size units */
+  UINT16 X_density;             /* Horizontal pixel density */
+  UINT16 Y_density;             /* Vertical pixel density */
+  boolean write_Adobe_marker;   /* should an Adobe marker be written? */
+
+  /* State variable: index of next scanline to be written to
+   * jpeg_write_scanlines().  Application may use this to control its
+   * processing loop, e.g., "while (next_scanline < image_height)".
+   */
+
+  JDIMENSION next_scanline;     /* 0 .. image_height-1  */
+
+  /* Remaining fields are known throughout compressor, but generally
+   * should not be touched by a surrounding application.
+   */
+
+  /*
+   * These fields are computed during compression startup
+   */
+  boolean progressive_mode;     /* TRUE if scan script uses progressive mode */
+  int max_h_samp_factor;        /* largest h_samp_factor */
+  int max_v_samp_factor;        /* largest v_samp_factor */
+
+#if JPEG_LIB_VERSION >= 70
+  int min_DCT_h_scaled_size;    /* smallest DCT_h_scaled_size of any component */
+  int min_DCT_v_scaled_size;    /* smallest DCT_v_scaled_size of any component */
+#endif
+
+  JDIMENSION total_iMCU_rows;   /* # of iMCU rows to be input to coef ctlr */
+  /* The coefficient controller receives data in units of MCU rows as defined
+   * for fully interleaved scans (whether the JPEG file is interleaved or not).
+   * There are v_samp_factor * DCTSIZE sample rows of each component in an
+   * "iMCU" (interleaved MCU) row.
+   */
+
+  /*
+   * These fields are valid during any one scan.
+   * They describe the components and MCUs actually appearing in the scan.
+   */
+  int comps_in_scan;            /* # of JPEG components in this scan */
+  jpeg_component_info *cur_comp_info[MAX_COMPS_IN_SCAN];
+  /* *cur_comp_info[i] describes component that appears i'th in SOS */
+
+  JDIMENSION MCUs_per_row;      /* # of MCUs across the image */
+  JDIMENSION MCU_rows_in_scan;  /* # of MCU rows in the image */
+
+  int blocks_in_MCU;            /* # of DCT blocks per MCU */
+  int MCU_membership[C_MAX_BLOCKS_IN_MCU];
+  /* MCU_membership[i] is index in cur_comp_info of component owning */
+  /* i'th block in an MCU */
+
+  int Ss, Se, Ah, Al;           /* progressive JPEG parameters for scan */
+
+#if JPEG_LIB_VERSION >= 80
+  int block_size;               /* the basic DCT block size: 1..16 */
+  const int *natural_order;     /* natural-order position array */
+  int lim_Se;                   /* min( Se, DCTSIZE2-1 ) */
+#endif
+
+  /*
+   * Links to compression subobjects (methods and private variables of modules)
+   */
+  struct jpeg_comp_master *master;
+  struct jpeg_c_main_controller *main;
+  struct jpeg_c_prep_controller *prep;
+  struct jpeg_c_coef_controller *coef;
+  struct jpeg_marker_writer *marker;
+  struct jpeg_color_converter *cconvert;
+  struct jpeg_downsampler *downsample;
+  struct jpeg_forward_dct *fdct;
+  struct jpeg_entropy_encoder *entropy;
+  jpeg_scan_info *script_space; /* workspace for jpeg_simple_progression */
+  int script_space_size;
+};
+
+
+/* Master record for a decompression instance */
+
+struct jpeg_decompress_struct {
+  jpeg_common_fields;           /* Fields shared with jpeg_compress_struct */
+
+  /* Source of compressed data */
+  struct jpeg_source_mgr *src;
+
+  /* Basic description of image --- filled in by jpeg_read_header(). */
+  /* Application may inspect these values to decide how to process image. */
+
+  JDIMENSION image_width;       /* nominal image width (from SOF marker) */
+  JDIMENSION image_height;      /* nominal image height */
+  int num_components;           /* # of color components in JPEG image */
+  J_COLOR_SPACE jpeg_color_space; /* colorspace of JPEG image */
+
+  /* Decompression processing parameters --- these fields must be set before
+   * calling jpeg_start_decompress().  Note that jpeg_read_header() initializes
+   * them to default values.
+   */
+
+  J_COLOR_SPACE out_color_space; /* colorspace for output */
+
+  unsigned int scale_num, scale_denom; /* fraction by which to scale image */
+
+  double output_gamma;          /* image gamma wanted in output */
+
+  boolean buffered_image;       /* TRUE=multiple output passes */
+  boolean raw_data_out;         /* TRUE=downsampled data wanted */
+
+  J_DCT_METHOD dct_method;      /* IDCT algorithm selector */
+  boolean do_fancy_upsampling;  /* TRUE=apply fancy upsampling */
+  boolean do_block_smoothing;   /* TRUE=apply interblock smoothing */
+
+  boolean quantize_colors;      /* TRUE=colormapped output wanted */
+  /* the following are ignored if not quantize_colors: */
+  J_DITHER_MODE dither_mode;    /* type of color dithering to use */
+  boolean two_pass_quantize;    /* TRUE=use two-pass color quantization */
+  int desired_number_of_colors; /* max # colors to use in created colormap */
+  /* these are significant only in buffered-image mode: */
+  boolean enable_1pass_quant;   /* enable future use of 1-pass quantizer */
+  boolean enable_external_quant;/* enable future use of external colormap */
+  boolean enable_2pass_quant;   /* enable future use of 2-pass quantizer */
+
+  /* Description of actual output image that will be returned to application.
+   * These fields are computed by jpeg_start_decompress().
+   * You can also use jpeg_calc_output_dimensions() to determine these values
+   * in advance of calling jpeg_start_decompress().
+   */
+
+  JDIMENSION output_width;      /* scaled image width */
+  JDIMENSION output_height;     /* scaled image height */
+  int out_color_components;     /* # of color components in out_color_space */
+  int output_components;        /* # of color components returned */
+  /* output_components is 1 (a colormap index) when quantizing colors;
+   * otherwise it equals out_color_components.
+   */
+  int rec_outbuf_height;        /* min recommended height of scanline buffer */
+  /* If the buffer passed to jpeg_read_scanlines() is less than this many rows
+   * high, space and time will be wasted due to unnecessary data copying.
+   * Usually rec_outbuf_height will be 1 or 2, at most 4.
+   */
+
+  /* When quantizing colors, the output colormap is described by these fields.
+   * The application can supply a colormap by setting colormap non-NULL before
+   * calling jpeg_start_decompress; otherwise a colormap is created during
+   * jpeg_start_decompress or jpeg_start_output.
+   * The map has out_color_components rows and actual_number_of_colors columns.
+   */
+  int actual_number_of_colors;  /* number of entries in use */
+  JSAMPARRAY colormap;          /* The color map as a 2-D pixel array */
+
+  /* State variables: these variables indicate the progress of decompression.
+   * The application may examine these but must not modify them.
+   */
+
+  /* Row index of next scanline to be read from jpeg_read_scanlines().
+   * Application may use this to control its processing loop, e.g.,
+   * "while (output_scanline < output_height)".
+   */
+  JDIMENSION output_scanline;   /* 0 .. output_height-1  */
+
+  /* Current input scan number and number of iMCU rows completed in scan.
+   * These indicate the progress of the decompressor input side.
+   */
+  int input_scan_number;        /* Number of SOS markers seen so far */
+  JDIMENSION input_iMCU_row;    /* Number of iMCU rows completed */
+
+  /* The "output scan number" is the notional scan being displayed by the
+   * output side.  The decompressor will not allow output scan/row number
+   * to get ahead of input scan/row, but it can fall arbitrarily far behind.
+   */
+  int output_scan_number;       /* Nominal scan number being displayed */
+  JDIMENSION output_iMCU_row;   /* Number of iMCU rows read */
+
+  /* Current progression status.  coef_bits[c][i] indicates the precision
+   * with which component c's DCT coefficient i (in zigzag order) is known.
+   * It is -1 when no data has yet been received, otherwise it is the point
+   * transform (shift) value for the most recent scan of the coefficient
+   * (thus, 0 at completion of the progression).
+   * This pointer is NULL when reading a non-progressive file.
+   */
+  int (*coef_bits)[DCTSIZE2];   /* -1 or current Al value for each coef */
+
+  /* Internal JPEG parameters --- the application usually need not look at
+   * these fields.  Note that the decompressor output side may not use
+   * any parameters that can change between scans.
+   */
+
+  /* Quantization and Huffman tables are carried forward across input
+   * datastreams when processing abbreviated JPEG datastreams.
+   */
+
+  JQUANT_TBL *quant_tbl_ptrs[NUM_QUANT_TBLS];
+  /* ptrs to coefficient quantization tables, or NULL if not defined */
+
+  JHUFF_TBL *dc_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  JHUFF_TBL *ac_huff_tbl_ptrs[NUM_HUFF_TBLS];
+  /* ptrs to Huffman coding tables, or NULL if not defined */
+
+  /* These parameters are never carried across datastreams, since they
+   * are given in SOF/SOS markers or defined to be reset by SOI.
+   */
+
+  int data_precision;           /* bits of precision in image data */
+
+  jpeg_component_info *comp_info;
+  /* comp_info[i] describes component that appears i'th in SOF */
+
+#if JPEG_LIB_VERSION >= 80
+  boolean is_baseline;          /* TRUE if Baseline SOF0 encountered */
+#endif
+  boolean progressive_mode;     /* TRUE if SOFn specifies progressive mode */
+  boolean arith_code;           /* TRUE=arithmetic coding, FALSE=Huffman */
+
+  UINT8 arith_dc_L[NUM_ARITH_TBLS]; /* L values for DC arith-coding tables */
+  UINT8 arith_dc_U[NUM_ARITH_TBLS]; /* U values for DC arith-coding tables */
+  UINT8 arith_ac_K[NUM_ARITH_TBLS]; /* Kx values for AC arith-coding tables */
+
+  unsigned int restart_interval; /* MCUs per restart interval, or 0 for no restart */
+
+  /* These fields record data obtained from optional markers recognized by
+   * the JPEG library.
+   */
+  boolean saw_JFIF_marker;      /* TRUE iff a JFIF APP0 marker was found */
+  /* Data copied from JFIF marker; only valid if saw_JFIF_marker is TRUE: */
+  UINT8 JFIF_major_version;     /* JFIF version number */
+  UINT8 JFIF_minor_version;
+  UINT8 density_unit;           /* JFIF code for pixel size units */
+  UINT16 X_density;             /* Horizontal pixel density */
+  UINT16 Y_density;             /* Vertical pixel density */
+  boolean saw_Adobe_marker;     /* TRUE iff an Adobe APP14 marker was found */
+  UINT8 Adobe_transform;        /* Color transform code from Adobe marker */
+
+  boolean CCIR601_sampling;     /* TRUE=first samples are cosited */
+
+  /* Aside from the specific data retained from APPn markers known to the
+   * library, the uninterpreted contents of any or all APPn and COM markers
+   * can be saved in a list for examination by the application.
+   */
+  jpeg_saved_marker_ptr marker_list; /* Head of list of saved markers */
+
+  /* Remaining fields are known throughout decompressor, but generally
+   * should not be touched by a surrounding application.
+   */
+
+  /*
+   * These fields are computed during decompression startup
+   */
+  int max_h_samp_factor;        /* largest h_samp_factor */
+  int max_v_samp_factor;        /* largest v_samp_factor */
+
+#if JPEG_LIB_VERSION >= 70
+  int min_DCT_h_scaled_size;    /* smallest DCT_h_scaled_size of any component */
+  int min_DCT_v_scaled_size;    /* smallest DCT_v_scaled_size of any component */
+#else
+  int min_DCT_scaled_size;      /* smallest DCT_scaled_size of any component */
+#endif
+
+  JDIMENSION total_iMCU_rows;   /* # of iMCU rows in image */
+  /* The coefficient controller's input and output progress is measured in
+   * units of "iMCU" (interleaved MCU) rows.  These are the same as MCU rows
+   * in fully interleaved JPEG scans, but are used whether the scan is
+   * interleaved or not.  We define an iMCU row as v_samp_factor DCT block
+   * rows of each component.  Therefore, the IDCT output contains
+   * v_samp_factor*DCT_[v_]scaled_size sample rows of a component per iMCU row.
+   */
+
+  JSAMPLE *sample_range_limit;  /* table for fast range-limiting */
+
+  /*
+   * These fields are valid during any one scan.
+   * They describe the components and MCUs actually appearing in the scan.
+   * Note that the decompressor output side must not use these fields.
+   */
+  int comps_in_scan;            /* # of JPEG components in this scan */
+  jpeg_component_info *cur_comp_info[MAX_COMPS_IN_SCAN];
+  /* *cur_comp_info[i] describes component that appears i'th in SOS */
+
+  JDIMENSION MCUs_per_row;      /* # of MCUs across the image */
+  JDIMENSION MCU_rows_in_scan;  /* # of MCU rows in the image */
+
+  int blocks_in_MCU;            /* # of DCT blocks per MCU */
+  int MCU_membership[D_MAX_BLOCKS_IN_MCU];
+  /* MCU_membership[i] is index in cur_comp_info of component owning */
+  /* i'th block in an MCU */
+
+  int Ss, Se, Ah, Al;           /* progressive JPEG parameters for scan */
+
+#if JPEG_LIB_VERSION >= 80
+  /* These fields are derived from Se of first SOS marker.
+   */
+  int block_size;               /* the basic DCT block size: 1..16 */
+  const int *natural_order; /* natural-order position array for entropy decode */
+  int lim_Se;                   /* min( Se, DCTSIZE2-1 ) for entropy decode */
+#endif
+
+  /* This field is shared between entropy decoder and marker parser.
+   * It is either zero or the code of a JPEG marker that has been
+   * read from the data source, but has not yet been processed.
+   */
+  int unread_marker;
+
+  /*
+   * Links to decompression subobjects (methods, private variables of modules)
+   */
+  struct jpeg_decomp_master *master;
+  struct jpeg_d_main_controller *main;
+  struct jpeg_d_coef_controller *coef;
+  struct jpeg_d_post_controller *post;
+  struct jpeg_input_controller *inputctl;
+  struct jpeg_marker_reader *marker;
+  struct jpeg_entropy_decoder *entropy;
+  struct jpeg_inverse_dct *idct;
+  struct jpeg_upsampler *upsample;
+  struct jpeg_color_deconverter *cconvert;
+  struct jpeg_color_quantizer *cquantize;
+};
+
+
+/* "Object" declarations for JPEG modules that may be supplied or called
+ * directly by the surrounding application.
+ * As with all objects in the JPEG library, these structs only define the
+ * publicly visible methods and state variables of a module.  Additional
+ * private fields may exist after the public ones.
+ */
+
+
+/* Error handler object */
+
+struct jpeg_error_mgr {
+  /* Error exit handler: does not return to caller */
+  void (*error_exit) (j_common_ptr cinfo);
+  /* Conditionally emit a trace or warning message */
+  void (*emit_message) (j_common_ptr cinfo, int msg_level);
+  /* Routine that actually outputs a trace or error message */
+  void (*output_message) (j_common_ptr cinfo);
+  /* Format a message string for the most recent JPEG error or message */
+  void (*format_message) (j_common_ptr cinfo, char *buffer);
+#define JMSG_LENGTH_MAX  200    /* recommended size of format_message buffer */
+  /* Reset error state variables at start of a new image */
+  void (*reset_error_mgr) (j_common_ptr cinfo);
+
+  /* The message ID code and any parameters are saved here.
+   * A message can have one string parameter or up to 8 int parameters.
+   */
+  int msg_code;
+#define JMSG_STR_PARM_MAX  80
+  union {
+    int i[8];
+    char s[JMSG_STR_PARM_MAX];
+  } msg_parm;
+
+  /* Standard state variables for error facility */
+
+  int trace_level;              /* max msg_level that will be displayed */
+
+  /* For recoverable corrupt-data errors, we emit a warning message,
+   * but keep going unless emit_message chooses to abort.  emit_message
+   * should count warnings in num_warnings.  The surrounding application
+   * can check for bad data by seeing if num_warnings is nonzero at the
+   * end of processing.
+   */
+  long num_warnings;            /* number of corrupt-data warnings */
+
+  /* These fields point to the table(s) of error message strings.
+   * An application can change the table pointer to switch to a different
+   * message list (typically, to change the language in which errors are
+   * reported).  Some applications may wish to add additional error codes
+   * that will be handled by the JPEG library error mechanism; the second
+   * table pointer is used for this purpose.
+   *
+   * First table includes all errors generated by JPEG library itself.
+   * Error code 0 is reserved for a "no such error string" message.
+   */
+  const char * const *jpeg_message_table; /* Library errors */
+  int last_jpeg_message;    /* Table contains strings 0..last_jpeg_message */
+  /* Second table can be added by application (see cjpeg/djpeg for example).
+   * It contains strings numbered first_addon_message..last_addon_message.
+   */
+  const char * const *addon_message_table; /* Non-library errors */
+  int first_addon_message;      /* code for first string in addon table */
+  int last_addon_message;       /* code for last string in addon table */
+};
+
+
+/* Progress monitor object */
+
+struct jpeg_progress_mgr {
+  void (*progress_monitor) (j_common_ptr cinfo);
+
+  long pass_counter;            /* work units completed in this pass */
+  long pass_limit;              /* total number of work units in this pass */
+  int completed_passes;         /* passes completed so far */
+  int total_passes;             /* total number of passes expected */
+};
+
+
+/* Data destination object for compression */
+
+struct jpeg_destination_mgr {
+  JOCTET *next_output_byte;     /* => next byte to write in buffer */
+  size_t free_in_buffer;        /* # of byte spaces remaining in buffer */
+
+  void (*init_destination) (j_compress_ptr cinfo);
+  boolean (*empty_output_buffer) (j_compress_ptr cinfo);
+  void (*term_destination) (j_compress_ptr cinfo);
+};
+
+
+/* Data source object for decompression */
+
+struct jpeg_source_mgr {
+  const JOCTET *next_input_byte; /* => next byte to read from buffer */
+  size_t bytes_in_buffer;       /* # of bytes remaining in buffer */
+
+  void (*init_source) (j_decompress_ptr cinfo);
+  boolean (*fill_input_buffer) (j_decompress_ptr cinfo);
+  void (*skip_input_data) (j_decompress_ptr cinfo, long num_bytes);
+  boolean (*resync_to_restart) (j_decompress_ptr cinfo, int desired);
+  void (*term_source) (j_decompress_ptr cinfo);
+};
+
+
+/* Memory manager object.
+ * Allocates "small" objects (a few K total), "large" objects (tens of K),
+ * and "really big" objects (virtual arrays with backing store if needed).
+ * The memory manager does not allow individual objects to be freed; rather,
+ * each created object is assigned to a pool, and whole pools can be freed
+ * at once.  This is faster and more convenient than remembering exactly what
+ * to free, especially where malloc()/free() are not too speedy.
+ * NB: alloc routines never return NULL.  They exit to error_exit if not
+ * successful.
+ */
+
+#define JPOOL_PERMANENT 0       /* lasts until master record is destroyed */
+#define JPOOL_IMAGE     1       /* lasts until done with image/datastream */
+#define JPOOL_NUMPOOLS  2
+
+typedef struct jvirt_sarray_control *jvirt_sarray_ptr;
+typedef struct jvirt_barray_control *jvirt_barray_ptr;
+
+
+struct jpeg_memory_mgr {
+  /* Method pointers */
+  void *(*alloc_small) (j_common_ptr cinfo, int pool_id, size_t sizeofobject);
+  void *(*alloc_large) (j_common_ptr cinfo, int pool_id,
+                        size_t sizeofobject);
+  JSAMPARRAY (*alloc_sarray) (j_common_ptr cinfo, int pool_id,
+                              JDIMENSION samplesperrow, JDIMENSION numrows);
+  JBLOCKARRAY (*alloc_barray) (j_common_ptr cinfo, int pool_id,
+                               JDIMENSION blocksperrow, JDIMENSION numrows);
+  jvirt_sarray_ptr (*request_virt_sarray) (j_common_ptr cinfo, int pool_id,
+                                           boolean pre_zero,
+                                           JDIMENSION samplesperrow,
+                                           JDIMENSION numrows,
+                                           JDIMENSION maxaccess);
+  jvirt_barray_ptr (*request_virt_barray) (j_common_ptr cinfo, int pool_id,
+                                           boolean pre_zero,
+                                           JDIMENSION blocksperrow,
+                                           JDIMENSION numrows,
+                                           JDIMENSION maxaccess);
+  void (*realize_virt_arrays) (j_common_ptr cinfo);
+  JSAMPARRAY (*access_virt_sarray) (j_common_ptr cinfo, jvirt_sarray_ptr ptr,
+                                    JDIMENSION start_row, JDIMENSION num_rows,
+                                    boolean writable);
+  JBLOCKARRAY (*access_virt_barray) (j_common_ptr cinfo, jvirt_barray_ptr ptr,
+                                     JDIMENSION start_row, JDIMENSION num_rows,
+                                     boolean writable);
+  void (*free_pool) (j_common_ptr cinfo, int pool_id);
+  void (*self_destruct) (j_common_ptr cinfo);
+
+  /* Limit on memory allocation for this JPEG object.  (Note that this is
+   * merely advisory, not a guaranteed maximum; it only affects the space
+   * used for virtual-array buffers.)  May be changed by outer application
+   * after creating the JPEG object.
+   */
+  long max_memory_to_use;
+
+  /* Maximum allocation request accepted by alloc_large. */
+  long max_alloc_chunk;
+};
+
+
+/* Routine signature for application-supplied marker processing methods.
+ * Need not pass marker code since it is stored in cinfo->unread_marker.
+ */
+typedef boolean (*jpeg_marker_parser_method) (j_decompress_ptr cinfo);
+
+
+/* Originally, this macro was used as a way of defining function prototypes
+ * for both modern compilers as well as older compilers that did not support
+ * prototype parameters.  libjpeg-turbo has never supported these older,
+ * non-ANSI compilers, but the macro is still included because there is some
+ * software out there that uses it.
+ */
+
+#define JPP(arglist)    arglist
+
+
+/* Default error-management setup */
+EXTERN(struct jpeg_error_mgr *) jpeg_std_error (struct jpeg_error_mgr *err);
+
+/* Initialization of JPEG compression objects.
+ * jpeg_create_compress() and jpeg_create_decompress() are the exported
+ * names that applications should call.  These expand to calls on
+ * jpeg_CreateCompress and jpeg_CreateDecompress with additional information
+ * passed for version mismatch checking.
+ * NB: you must set up the error-manager BEFORE calling jpeg_create_xxx.
+ */
+#define jpeg_create_compress(cinfo) \
+    jpeg_CreateCompress((cinfo), JPEG_LIB_VERSION, \
+                        (size_t) sizeof(struct jpeg_compress_struct))
+#define jpeg_create_decompress(cinfo) \
+    jpeg_CreateDecompress((cinfo), JPEG_LIB_VERSION, \
+                          (size_t) sizeof(struct jpeg_decompress_struct))
+EXTERN(void) jpeg_CreateCompress (j_compress_ptr cinfo, int version,
+                                  size_t structsize);
+EXTERN(void) jpeg_CreateDecompress (j_decompress_ptr cinfo, int version,
+                                    size_t structsize);
+/* Destruction of JPEG compression objects */
+EXTERN(void) jpeg_destroy_compress (j_compress_ptr cinfo);
+EXTERN(void) jpeg_destroy_decompress (j_decompress_ptr cinfo);
+
+/* Standard data source and destination managers: stdio streams. */
+/* Caller is responsible for opening the file before and closing after. */
+EXTERN(void) jpeg_stdio_dest (j_compress_ptr cinfo, FILE *outfile);
+EXTERN(void) jpeg_stdio_src (j_decompress_ptr cinfo, FILE *infile);
+
+#if JPEG_LIB_VERSION >= 80 || defined(MEM_SRCDST_SUPPORTED)
+/* Data source and destination managers: memory buffers. */
+EXTERN(void) jpeg_mem_dest (j_compress_ptr cinfo, unsigned char **outbuffer,
+                            unsigned long *outsize);
+EXTERN(void) jpeg_mem_src (j_decompress_ptr cinfo,
+                           const unsigned char *inbuffer,
+                           unsigned long insize);
+#endif
+
+/* Default parameter setup for compression */
+EXTERN(void) jpeg_set_defaults (j_compress_ptr cinfo);
+/* Compression parameter setup aids */
+EXTERN(void) jpeg_set_colorspace (j_compress_ptr cinfo,
+                                  J_COLOR_SPACE colorspace);
+EXTERN(void) jpeg_default_colorspace (j_compress_ptr cinfo);
+EXTERN(void) jpeg_set_quality (j_compress_ptr cinfo, int quality,
+                               boolean force_baseline);
+EXTERN(void) jpeg_set_linear_quality (j_compress_ptr cinfo, int scale_factor,
+                                      boolean force_baseline);
+#if JPEG_LIB_VERSION >= 70
+EXTERN(void) jpeg_default_qtables (j_compress_ptr cinfo,
+                                   boolean force_baseline);
+#endif
+EXTERN(void) jpeg_add_quant_table (j_compress_ptr cinfo, int which_tbl,
+                                   const unsigned int *basic_table,
+                                   int scale_factor, boolean force_baseline);
+EXTERN(int) jpeg_quality_scaling (int quality);
+EXTERN(void) jpeg_simple_progression (j_compress_ptr cinfo);
+EXTERN(void) jpeg_suppress_tables (j_compress_ptr cinfo, boolean suppress);
+EXTERN(JQUANT_TBL *) jpeg_alloc_quant_table (j_common_ptr cinfo);
+EXTERN(JHUFF_TBL *) jpeg_alloc_huff_table (j_common_ptr cinfo);
+
+/* Main entry points for compression */
+EXTERN(void) jpeg_start_compress (j_compress_ptr cinfo,
+                                  boolean write_all_tables);
+EXTERN(JDIMENSION) jpeg_write_scanlines (j_compress_ptr cinfo,
+                                         JSAMPARRAY scanlines,
+                                         JDIMENSION num_lines);
+EXTERN(void) jpeg_finish_compress (j_compress_ptr cinfo);
+
+#if JPEG_LIB_VERSION >= 70
+/* Precalculate JPEG dimensions for current compression parameters. */
+EXTERN(void) jpeg_calc_jpeg_dimensions (j_compress_ptr cinfo);
+#endif
+
+/* Replaces jpeg_write_scanlines when writing raw downsampled data. */
+EXTERN(JDIMENSION) jpeg_write_raw_data (j_compress_ptr cinfo, JSAMPIMAGE data,
+                                        JDIMENSION num_lines);
+
+/* Write a special marker.  See libjpeg.txt concerning safe usage. */
+EXTERN(void) jpeg_write_marker (j_compress_ptr cinfo, int marker,
+                                const JOCTET *dataptr, unsigned int datalen);
+/* Same, but piecemeal. */
+EXTERN(void) jpeg_write_m_header (j_compress_ptr cinfo, int marker,
+                                  unsigned int datalen);
+EXTERN(void) jpeg_write_m_byte (j_compress_ptr cinfo, int val);
+
+/* Alternate compression function: just write an abbreviated table file */
+EXTERN(void) jpeg_write_tables (j_compress_ptr cinfo);
+
+/* Decompression startup: read start of JPEG datastream to see what's there */
+EXTERN(int) jpeg_read_header (j_decompress_ptr cinfo, boolean require_image);
+/* Return value is one of: */
+#define JPEG_SUSPENDED          0 /* Suspended due to lack of input data */
+#define JPEG_HEADER_OK          1 /* Found valid image datastream */
+#define JPEG_HEADER_TABLES_ONLY 2 /* Found valid table-specs-only datastream */
+/* If you pass require_image = TRUE (normal case), you need not check for
+ * a TABLES_ONLY return code; an abbreviated file will cause an error exit.
+ * JPEG_SUSPENDED is only possible if you use a data source module that can
+ * give a suspension return (the stdio source module doesn't).
+ */
+
+/* Main entry points for decompression */
+EXTERN(boolean) jpeg_start_decompress (j_decompress_ptr cinfo);
+EXTERN(JDIMENSION) jpeg_read_scanlines (j_decompress_ptr cinfo,
+                                        JSAMPARRAY scanlines,
+                                        JDIMENSION max_lines);
+EXTERN(JDIMENSION) jpeg_skip_scanlines (j_decompress_ptr cinfo,
+                                        JDIMENSION num_lines);
+EXTERN(void) jpeg_crop_scanline (j_decompress_ptr cinfo, JDIMENSION *xoffset,
+                                 JDIMENSION *width);
+EXTERN(boolean) jpeg_finish_decompress (j_decompress_ptr cinfo);
+
+/* Replaces jpeg_read_scanlines when reading raw downsampled data. */
+EXTERN(JDIMENSION) jpeg_read_raw_data (j_decompress_ptr cinfo, JSAMPIMAGE data,
+                                       JDIMENSION max_lines);
+
+/* Additional entry points for buffered-image mode. */
+EXTERN(boolean) jpeg_has_multiple_scans (j_decompress_ptr cinfo);
+EXTERN(boolean) jpeg_start_output (j_decompress_ptr cinfo, int scan_number);
+EXTERN(boolean) jpeg_finish_output (j_decompress_ptr cinfo);
+EXTERN(boolean) jpeg_input_complete (j_decompress_ptr cinfo);
+EXTERN(void) jpeg_new_colormap (j_decompress_ptr cinfo);
+EXTERN(int) jpeg_consume_input (j_decompress_ptr cinfo);
+/* Return value is one of: */
+/* #define JPEG_SUSPENDED       0    Suspended due to lack of input data */
+#define JPEG_REACHED_SOS        1 /* Reached start of new scan */
+#define JPEG_REACHED_EOI        2 /* Reached end of image */
+#define JPEG_ROW_COMPLETED      3 /* Completed one iMCU row */
+#define JPEG_SCAN_COMPLETED     4 /* Completed last iMCU row of a scan */
+
+/* Precalculate output dimensions for current decompression parameters. */
+#if JPEG_LIB_VERSION >= 80
+EXTERN(void) jpeg_core_output_dimensions (j_decompress_ptr cinfo);
+#endif
+EXTERN(void) jpeg_calc_output_dimensions (j_decompress_ptr cinfo);
+
+/* Control saving of COM and APPn markers into marker_list. */
+EXTERN(void) jpeg_save_markers (j_decompress_ptr cinfo, int marker_code,
+                                unsigned int length_limit);
+
+/* Install a special processing method for COM or APPn markers. */
+EXTERN(void) jpeg_set_marker_processor (j_decompress_ptr cinfo,
+                                        int marker_code,
+                                        jpeg_marker_parser_method routine);
+
+/* Read or write raw DCT coefficients --- useful for lossless transcoding. */
+EXTERN(jvirt_barray_ptr *) jpeg_read_coefficients (j_decompress_ptr cinfo);
+EXTERN(void) jpeg_write_coefficients (j_compress_ptr cinfo,
+                                      jvirt_barray_ptr *coef_arrays);
+EXTERN(void) jpeg_copy_critical_parameters (j_decompress_ptr srcinfo,
+                                            j_compress_ptr dstinfo);
+
+/* If you choose to abort compression or decompression before completing
+ * jpeg_finish_(de)compress, then you need to clean up to release memory,
+ * temporary files, etc.  You can just call jpeg_destroy_(de)compress
+ * if you're done with the JPEG object, but if you want to clean it up and
+ * reuse it, call this:
+ */
+EXTERN(void) jpeg_abort_compress (j_compress_ptr cinfo);
+EXTERN(void) jpeg_abort_decompress (j_decompress_ptr cinfo);
+
+/* Generic versions of jpeg_abort and jpeg_destroy that work on either
+ * flavor of JPEG object.  These may be more convenient in some places.
+ */
+EXTERN(void) jpeg_abort (j_common_ptr cinfo);
+EXTERN(void) jpeg_destroy (j_common_ptr cinfo);
+
+/* Default restart-marker-resync procedure for use by data source modules */
+EXTERN(boolean) jpeg_resync_to_restart (j_decompress_ptr cinfo, int desired);
+
+
+/* These marker codes are exported since applications and data source modules
+ * are likely to want to use them.
+ */
+
+#define JPEG_RST0       0xD0    /* RST0 marker code */
+#define JPEG_EOI        0xD9    /* EOI marker code */
+#define JPEG_APP0       0xE0    /* APP0 marker code */
+#define JPEG_COM        0xFE    /* COM marker code */
+
+
+/* If we have a brain-damaged compiler that emits warnings (or worse, errors)
+ * for structure definitions that are never filled in, keep it quiet by
+ * supplying dummy definitions for the various substructures.
+ */
+
+#ifdef INCOMPLETE_TYPES_BROKEN
+#ifndef JPEG_INTERNALS          /* will be defined in jpegint.h */
+struct jvirt_sarray_control { long dummy; };
+struct jvirt_barray_control { long dummy; };
+struct jpeg_comp_master { long dummy; };
+struct jpeg_c_main_controller { long dummy; };
+struct jpeg_c_prep_controller { long dummy; };
+struct jpeg_c_coef_controller { long dummy; };
+struct jpeg_marker_writer { long dummy; };
+struct jpeg_color_converter { long dummy; };
+struct jpeg_downsampler { long dummy; };
+struct jpeg_forward_dct { long dummy; };
+struct jpeg_entropy_encoder { long dummy; };
+struct jpeg_decomp_master { long dummy; };
+struct jpeg_d_main_controller { long dummy; };
+struct jpeg_d_coef_controller { long dummy; };
+struct jpeg_d_post_controller { long dummy; };
+struct jpeg_input_controller { long dummy; };
+struct jpeg_marker_reader { long dummy; };
+struct jpeg_entropy_decoder { long dummy; };
+struct jpeg_inverse_dct { long dummy; };
+struct jpeg_upsampler { long dummy; };
+struct jpeg_color_deconverter { long dummy; };
+struct jpeg_color_quantizer { long dummy; };
+#endif /* JPEG_INTERNALS */
+#endif /* INCOMPLETE_TYPES_BROKEN */
+
+
+/*
+ * The JPEG library modules define JPEG_INTERNALS before including this file.
+ * The internal structure declarations are read only when that is true.
+ * Applications using the library should not include jpegint.h, but may wish
+ * to include jerror.h.
+ */
+
+#ifdef JPEG_INTERNALS
+#include "jpegint.h"            /* fetch private declarations */
+#include "jerror.h"             /* fetch error codes too */
+#endif
+
+#ifdef __cplusplus
+#ifndef DONT_USE_EXTERN_C
+}
+#endif
+#endif
+
+#endif /* JPEGLIB_H */
diff -Naur chromium-65.0.3325.181-orig/third_party/libpng/pnglibconf.h chromium-65.0.3325.181.patched/third_party/libpng/pnglibconf.h
--- chromium-65.0.3325.181-orig/third_party/libpng/pnglibconf.h	2018-03-21 01:05:52.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/libpng/pnglibconf.h	2018-04-27 11:31:20.579828393 +0300
@@ -225,13 +225,4 @@
 #define PNG_USER_CHUNK_MALLOC_MAX 4000000L
 /* end of chromium settings */
 
-/* chromium prefixing */
-/*
- * This is necessary to build multiple copies of libpng.  We need this while pdfium builds
- * its own copy of libpng.
- */
-#define PNG_PREFIX
-#include "pngprefix.h"
-/* end of chromium prefixing */
-
 #endif /* PNGLCONF_H */
diff -Naur chromium-65.0.3325.181-orig/third_party/libpng/pnglibconf.h.noprefix chromium-65.0.3325.181.patched/third_party/libpng/pnglibconf.h.noprefix
--- chromium-65.0.3325.181-orig/third_party/libpng/pnglibconf.h.noprefix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/libpng/pnglibconf.h.noprefix	2018-03-21 01:05:52.000000000 +0300
@@ -0,0 +1,237 @@
+/* libpng 1.6.22 CUSTOM API DEFINITION */
+
+/* pnglibconf.h - library build configuration */
+
+/* Libpng version 1.6.22 - May 29, 2016 */
+
+/* Copyright (c) 1998-2015 Glenn Randers-Pehrson */
+
+/* This code is released under the libpng license. */
+/* For conditions of distribution and use, see the disclaimer */
+/* and license in png.h */
+
+/* pnglibconf.h */
+/* Derived from: scripts/pnglibconf.dfa */
+#ifndef PNGLCONF_H
+#define PNGLCONF_H
+
+/* default options */
+/* These are PNG options that match the default in scripts/pnglibconf.dfa */
+#define PNG_16BIT_SUPPORTED
+#define PNG_ALIGNED_MEMORY_SUPPORTED
+/*#undef PNG_ARM_NEON_API_SUPPORTED*/
+/*#undef PNG_ARM_NEON_CHECK_SUPPORTED*/
+#define PNG_BENIGN_ERRORS_SUPPORTED
+#define PNG_BENIGN_READ_ERRORS_SUPPORTED
+/*#undef PNG_BENIGN_WRITE_ERRORS_SUPPORTED*/
+#define PNG_COLORSPACE_SUPPORTED
+#define PNG_EASY_ACCESS_SUPPORTED
+/*#undef PNG_ERROR_NUMBERS_SUPPORTED*/
+#define PNG_ERROR_TEXT_SUPPORTED
+#define PNG_FIXED_POINT_SUPPORTED
+#define PNG_FLOATING_ARITHMETIC_SUPPORTED
+#define PNG_FLOATING_POINT_SUPPORTED
+#define PNG_FORMAT_AFIRST_SUPPORTED
+#define PNG_FORMAT_BGR_SUPPORTED
+#define PNG_GAMMA_SUPPORTED
+#define PNG_HANDLE_AS_UNKNOWN_SUPPORTED
+#define PNG_INFO_IMAGE_SUPPORTED
+#define PNG_POINTER_INDEXING_SUPPORTED
+#define PNG_PROGRESSIVE_READ_SUPPORTED
+#define PNG_READ_16BIT_SUPPORTED
+#define PNG_READ_ALPHA_MODE_SUPPORTED
+#define PNG_READ_ANCILLARY_CHUNKS_SUPPORTED
+#define PNG_READ_BACKGROUND_SUPPORTED
+#define PNG_READ_BGR_SUPPORTED
+#define PNG_READ_COMPOSITE_NODIV_SUPPORTED
+#define PNG_READ_COMPRESSED_TEXT_SUPPORTED
+#define PNG_READ_EXPAND_16_SUPPORTED
+#define PNG_READ_EXPAND_SUPPORTED
+#define PNG_READ_FILLER_SUPPORTED
+#define PNG_READ_GAMMA_SUPPORTED
+#define PNG_READ_GRAY_TO_RGB_SUPPORTED
+#define PNG_READ_INTERLACING_SUPPORTED
+#define PNG_READ_INT_FUNCTIONS_SUPPORTED
+#define PNG_READ_PACKSWAP_SUPPORTED
+#define PNG_READ_PACK_SUPPORTED
+#define PNG_READ_RGB_TO_GRAY_SUPPORTED
+#define PNG_READ_SCALE_16_TO_8_SUPPORTED
+#define PNG_READ_SHIFT_SUPPORTED
+#define PNG_READ_STRIP_16_TO_8_SUPPORTED
+#define PNG_READ_STRIP_ALPHA_SUPPORTED
+#define PNG_READ_SUPPORTED
+#define PNG_READ_SWAP_ALPHA_SUPPORTED
+#define PNG_READ_SWAP_SUPPORTED
+#define PNG_READ_TEXT_SUPPORTED
+#define PNG_READ_TRANSFORMS_SUPPORTED
+#define PNG_READ_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_READ_USER_CHUNKS_SUPPORTED
+#define PNG_READ_USER_TRANSFORM_SUPPORTED
+#define PNG_READ_cHRM_SUPPORTED
+#define PNG_READ_gAMA_SUPPORTED
+#define PNG_READ_iCCP_SUPPORTED
+#define PNG_READ_sRGB_SUPPORTED
+#define PNG_READ_tEXt_SUPPORTED
+#define PNG_READ_tRNS_SUPPORTED
+#define PNG_READ_zTXt_SUPPORTED
+#define PNG_SAVE_INT_32_SUPPORTED
+#define PNG_SAVE_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_SEQUENTIAL_READ_SUPPORTED
+#define PNG_SETJMP_SUPPORTED
+#define PNG_SET_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_SET_USER_LIMITS_SUPPORTED
+#define PNG_SIMPLIFIED_READ_AFIRST_SUPPORTED
+#define PNG_SIMPLIFIED_READ_BGR_SUPPORTED
+#define PNG_SIMPLIFIED_READ_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_AFIRST_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_BGR_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_STDIO_SUPPORTED
+#define PNG_SIMPLIFIED_WRITE_SUPPORTED
+#define PNG_STDIO_SUPPORTED
+#define PNG_STORE_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_TEXT_SUPPORTED
+#define PNG_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_USER_CHUNKS_SUPPORTED
+#define PNG_USER_LIMITS_SUPPORTED
+#define PNG_USER_MEM_SUPPORTED
+#define PNG_USER_TRANSFORM_INFO_SUPPORTED
+#define PNG_USER_TRANSFORM_PTR_SUPPORTED
+#define PNG_WARNINGS_SUPPORTED
+#define PNG_WRITE_16BIT_SUPPORTED
+#define PNG_WRITE_ANCILLARY_CHUNKS_SUPPORTED
+#define PNG_WRITE_BGR_SUPPORTED
+#define PNG_WRITE_COMPRESSED_TEXT_SUPPORTED
+#define PNG_WRITE_CUSTOMIZE_COMPRESSION_SUPPORTED
+#define PNG_WRITE_CUSTOMIZE_ZTXT_COMPRESSION_SUPPORTED
+#define PNG_WRITE_FILLER_SUPPORTED
+#define PNG_WRITE_FILTER_SUPPORTED
+#define PNG_WRITE_FLUSH_SUPPORTED
+#define PNG_WRITE_INTERLACING_SUPPORTED
+#define PNG_WRITE_INT_FUNCTIONS_SUPPORTED
+#define PNG_WRITE_PACKSWAP_SUPPORTED
+#define PNG_WRITE_PACK_SUPPORTED
+#define PNG_WRITE_SHIFT_SUPPORTED
+#define PNG_WRITE_SUPPORTED
+#define PNG_WRITE_SWAP_ALPHA_SUPPORTED
+#define PNG_WRITE_SWAP_SUPPORTED
+#define PNG_WRITE_TEXT_SUPPORTED
+#define PNG_WRITE_TRANSFORMS_SUPPORTED
+#define PNG_WRITE_UNKNOWN_CHUNKS_SUPPORTED
+#define PNG_WRITE_USER_TRANSFORM_SUPPORTED
+#define PNG_WRITE_WEIGHTED_FILTER_SUPPORTED
+#define PNG_WRITE_cHRM_SUPPORTED
+#define PNG_WRITE_gAMA_SUPPORTED
+#define PNG_WRITE_iCCP_SUPPORTED
+#define PNG_WRITE_sRGB_SUPPORTED
+#define PNG_WRITE_tEXt_SUPPORTED
+#define PNG_WRITE_tRNS_SUPPORTED
+#define PNG_WRITE_zTXt_SUPPORTED
+#define PNG_cHRM_SUPPORTED
+#define PNG_gAMA_SUPPORTED
+#define PNG_iCCP_SUPPORTED
+#define PNG_sBIT_SUPPORTED
+#define PNG_sRGB_SUPPORTED
+#define PNG_tEXt_SUPPORTED
+#define PNG_tRNS_SUPPORTED
+#define PNG_zTXt_SUPPORTED
+/* end of options */
+
+/* chromium options */
+/* These are PNG options that chromium chooses to explicitly disable */
+/*#undef PNG_BUILD_GRAYSCALE_PALETTE_SUPPORTED*/
+/*#undef PNG_CHECK_FOR_INVALID_INDEX_SUPPORTED*/
+/*#undef PNG_CONSOLE_IO_SUPPORTED*/
+/*#undef PNG_CONVERT_tIME_SUPPORTED*/
+/*#undef PNG_GET_PALETTE_MAX_SUPPORTED*/
+/*#undef PNG_INCH_CONVERSIONS_SUPPORTED*/
+/*#undef PNG_IO_STATE_SUPPORTED*/
+/*#undef PNG_MNG_FEATURES_SUPPORTED*/
+/*#undef PNG_READ_CHECK_FOR_INVALID_INDEX_SUPPORTED*/
+/*#undef PNG_READ_GET_PALETTE_MAX_SUPPORTED*/
+/*#undef PNG_READ_INVERT_ALPHA_SUPPORTED*/
+/*#undef PNG_READ_INVERT_SUPPORTED*/
+/*#undef PNG_READ_OPT_PLTE_SUPPORTED*/
+/*#undef PNG_READ_QUANTIZE_SUPPORTED*/
+/*#undef PNG_READ_bKGD_SUPPORTED*/
+/*#undef PNG_READ_hIST_SUPPORTED*/
+/*#undef PNG_READ_iTXt_SUPPORTED*/
+/*#undef PNG_READ_oFFs_SUPPORTED*/
+/*#undef PNG_READ_pCAL_SUPPORTED*/
+/*#undef PNG_READ_pHYs_SUPPORTED*/
+/*#undef PNG_READ_sBIT_SUPPORTED*/
+/*#undef PNG_READ_sCAL_SUPPORTED*/
+/*#undef PNG_READ_sPLT_SUPPORTED*/
+/*#undef PNG_READ_tIME_SUPPORTED*/
+/*#undef PNG_SET_OPTION_SUPPORTED*/
+/*#undef PNG_TIME_RFC1123_SUPPORTED*/
+/*#undef PNG_WRITE_CHECK_FOR_INVALID_INDEX_SUPPORTED*/
+/*#undef PNG_WRITE_GET_PALETTE_MAX_SUPPORTED*/
+/*#undef PNG_WRITE_INVERT_ALPHA_SUPPORTED*/
+/*#undef PNG_WRITE_INVERT_SUPPORTED*/
+/*#undef PNG_WRITE_OPTIMIZE_CMF_SUPPORTED*/
+/*#undef PNG_WRITE_bKGD_SUPPORTED*/
+/*#undef PNG_WRITE_hIST_SUPPORTED*/
+/*#undef PNG_WRITE_iTXt_SUPPORTED*/
+/*#undef PNG_WRITE_oFFs_SUPPORTED*/
+/*#undef PNG_WRITE_pCAL_SUPPORTED*/
+/*#undef PNG_WRITE_pHYs_SUPPORTED*/
+/*#undef PNG_WRITE_sBIT_SUPPORTED*/
+/*#undef PNG_WRITE_sCAL_SUPPORTED*/
+/*#undef PNG_WRITE_sPLT_SUPPORTED*/
+/*#undef PNG_WRITE_tIME_SUPPORTED*/
+/*#undef PNG_bKGD_SUPPORTED*/
+/*#undef PNG_hIST_SUPPORTED*/
+/*#undef PNG_iTXt_SUPPORTED*/
+/*#undef PNG_oFFs_SUPPORTED*/
+/*#undef PNG_pCAL_SUPPORTED*/
+/*#undef PNG_pHYs_SUPPORTED*/
+/*#undef PNG_sCAL_SUPPORTED*/
+/*#undef PNG_sPLT_SUPPORTED*/
+/*#undef PNG_tIME_SUPPORTED*/
+/* end of chromium options */
+
+/* default settings */
+/* These are PNG settings that match the default in scripts/pnglibconf.dfa */
+#define PNG_API_RULE 0
+#define PNG_DEFAULT_READ_MACROS 1
+#define PNG_GAMMA_THRESHOLD_FIXED 5000
+#define PNG_IDAT_READ_SIZE PNG_ZBUF_SIZE
+#define PNG_INFLATE_BUF_SIZE 1024
+#define PNG_LINKAGE_API extern
+#define PNG_LINKAGE_CALLBACK extern
+#define PNG_LINKAGE_DATA extern
+#define PNG_LINKAGE_FUNCTION extern
+#define PNG_MAX_GAMMA_8 11
+#define PNG_QUANTIZE_BLUE_BITS 5
+#define PNG_QUANTIZE_GREEN_BITS 5
+#define PNG_QUANTIZE_RED_BITS 5
+#define PNG_TEXT_Z_DEFAULT_COMPRESSION (-1)
+#define PNG_TEXT_Z_DEFAULT_STRATEGY 0
+#define PNG_USER_HEIGHT_MAX 1000000
+#define PNG_USER_WIDTH_MAX 1000000
+#define PNG_ZBUF_SIZE 8192
+#define PNG_ZLIB_VERNUM 0 /* unknown */
+#define PNG_Z_DEFAULT_COMPRESSION (-1)
+#define PNG_Z_DEFAULT_NOFILTER_STRATEGY 0
+#define PNG_Z_DEFAULT_STRATEGY 1
+#define PNG_sCAL_PRECISION 5
+#define PNG_sRGB_PROFILE_CHECKS 2
+/* end of default settings */
+
+/* chromium settings */
+/* These are PNG setting that chromium has modified */
+/* crbug.com/117369 */
+#define PNG_USER_CHUNK_CACHE_MAX 128
+#define PNG_USER_CHUNK_MALLOC_MAX 4000000L
+/* end of chromium settings */
+
+/* chromium prefixing */
+/*
+ * This is necessary to build multiple copies of libpng.  We need this while pdfium builds
+ * its own copy of libpng.
+ */
+#define PNG_PREFIX
+#include "pngprefix.h"
+/* end of chromium prefixing */
+
+#endif /* PNGLCONF_H */
diff -Naur chromium-65.0.3325.181-orig/third_party/skia/src/jumper/SkJumper_stages.cpp chromium-65.0.3325.181.patched/third_party/skia/src/jumper/SkJumper_stages.cpp
--- chromium-65.0.3325.181-orig/third_party/skia/src/jumper/SkJumper_stages.cpp	2018-03-21 01:06:53.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/skia/src/jumper/SkJumper_stages.cpp	2018-04-27 11:31:20.695827172 +0300
@@ -666,7 +666,7 @@
 }
 
 SI F from_half(U16 h) {
-#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+#if defined(JUMPER_IS_NEON) && defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
     return vcvt_f32_f16(h);
 
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
@@ -686,7 +686,7 @@
 }
 
 SI U16 to_half(F f) {
-#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+#if defined(JUMPER_IS_NEON) && defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
     return vcvt_f16_f32(f);
 
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
diff -Naur chromium-65.0.3325.181-orig/third_party/skia/src/jumper/SkJumper_stages.cpp.aarch64fix chromium-65.0.3325.181.patched/third_party/skia/src/jumper/SkJumper_stages.cpp.aarch64fix
--- chromium-65.0.3325.181-orig/third_party/skia/src/jumper/SkJumper_stages.cpp.aarch64fix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/skia/src/jumper/SkJumper_stages.cpp.aarch64fix	2018-03-21 01:06:53.000000000 +0300
@@ -0,0 +1,2234 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "SkJumper.h"
+#include "SkJumper_misc.h"
+
+// A little wrapper macro to name Stages differently depending on the instruction set.
+// That lets us link together several options.
+#if !defined(JUMPER_IS_OFFLINE)
+    #define WRAP(name) sk_##name
+#elif defined(__AVX512F__)
+    #define WRAP(name) sk_##name##_skx
+#elif defined(__AVX2__)
+    #define WRAP(name) sk_##name##_hsw
+#elif defined(__AVX__)
+    #define WRAP(name) sk_##name##_avx
+#elif defined(__SSE4_1__)
+    #define WRAP(name) sk_##name##_sse41
+#elif defined(__SSE2__)
+    #define WRAP(name) sk_##name##_sse2
+#endif
+
+// Every function in this file should be marked static and inline using SI (see SkJumper_misc.h).
+
+#if !defined(__clang__)
+    #define JUMPER_IS_SCALAR
+#elif defined(__ARM_NEON)
+    #define JUMPER_IS_NEON
+#elif defined(__AVX512F__)
+    #define JUMPER_IS_AVX512
+#elif defined(__AVX2__) && defined(__F16C__) && defined(__FMA__)
+    #define JUMPER_IS_HSW
+#elif defined(__AVX__)
+    #define JUMPER_IS_AVX
+#elif defined(__SSE4_1__)
+    #define JUMPER_IS_SSE41
+#elif defined(__SSE2__)
+    #define JUMPER_IS_SSE2
+#else
+    #define JUMPER_IS_SCALAR
+#endif
+
+// Older Clangs seem to crash when generating non-optimized NEON code for ARMv7.
+#if defined(__clang__) && !defined(__OPTIMIZE__) && defined(__arm__)
+    // Apple Clang 9 and vanilla Clang 5 are fine, and may even be conservative.
+    #if defined(__apple_build_version__) && __clang_major__ < 9
+        #define JUMPER_IS_SCALAR
+    #elif __clang_major__ < 5
+        #define JUMPER_IS_SCALAR
+    #endif
+#endif
+
+#if defined(JUMPER_IS_SCALAR)
+    // This path should lead to portable scalar code.
+    #include <math.h>
+
+    using F   = float   ;
+    using I32 =  int32_t;
+    using U64 = uint64_t;
+    using U32 = uint32_t;
+    using U16 = uint16_t;
+    using U8  = uint8_t ;
+
+    SI F   mad(F f, F m, F a)   { return f*m+a; }
+    SI F   min(F a, F b)        { return fminf(a,b); }
+    SI F   max(F a, F b)        { return fmaxf(a,b); }
+    SI F   abs_  (F v)          { return fabsf(v); }
+    SI F   floor_(F v)          { return floorf(v); }
+    SI F   rcp   (F v)          { return 1.0f / v; }
+    SI F   rsqrt (F v)          { return 1.0f / sqrtf(v); }
+    SI F    sqrt_(F v)          { return sqrtf(v); }
+    SI U32 round (F v, F scale) { return (uint32_t)(v*scale + 0.5f); }
+    SI U16 pack(U32 v)          { return (U16)v; }
+    SI U8  pack(U16 v)          { return  (U8)v; }
+
+    SI F if_then_else(I32 c, F t, F e) { return c ? t : e; }
+
+    template <typename T>
+    SI T gather(const T* p, U32 ix) { return p[ix]; }
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        *r = ptr[0];
+        *g = ptr[1];
+        *b = ptr[2];
+    }
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        *r = ptr[0];
+        *g = ptr[1];
+        *b = ptr[2];
+        *a = ptr[3];
+    }
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        ptr[0] = r;
+        ptr[1] = g;
+        ptr[2] = b;
+        ptr[3] = a;
+    }
+
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        *r = ptr[0];
+        *g = ptr[1];
+        *b = ptr[2];
+        *a = ptr[3];
+    }
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        ptr[0] = r;
+        ptr[1] = g;
+        ptr[2] = b;
+        ptr[3] = a;
+    }
+
+#elif defined(JUMPER_IS_NEON)
+    #include <arm_neon.h>
+
+    // Since we know we're using Clang, we can use its vector extensions.
+    template <typename T> using V = T __attribute__((ext_vector_type(4)));
+    using F   = V<float   >;
+    using I32 = V< int32_t>;
+    using U64 = V<uint64_t>;
+    using U32 = V<uint32_t>;
+    using U16 = V<uint16_t>;
+    using U8  = V<uint8_t >;
+
+    // We polyfill a few routines that Clang doesn't build into ext_vector_types.
+    SI F   min(F a, F b)                         { return vminq_f32(a,b);          }
+    SI F   max(F a, F b)                         { return vmaxq_f32(a,b);          }
+    SI F   abs_  (F v)                           { return vabsq_f32(v);            }
+    SI F   rcp   (F v) { auto e = vrecpeq_f32 (v); return vrecpsq_f32 (v,e  ) * e; }
+    SI F   rsqrt (F v) { auto e = vrsqrteq_f32(v); return vrsqrtsq_f32(v,e*e) * e; }
+    SI U16 pack(U32 v)                           { return __builtin_convertvector(v, U16); }
+    SI U8  pack(U16 v)                           { return __builtin_convertvector(v,  U8); }
+
+    SI F if_then_else(I32 c, F t, F e) { return vbslq_f32((U32)c,t,e); }
+
+    #if defined(__aarch64__)
+        SI F     mad(F f, F m, F a) { return vfmaq_f32(a,f,m); }
+        SI F  floor_(F v) { return vrndmq_f32(v); }
+        SI F   sqrt_(F v) { return vsqrtq_f32(v); }
+        SI U32 round(F v, F scale) { return vcvtnq_u32_f32(v*scale); }
+    #else
+        SI F mad(F f, F m, F a) { return vmlaq_f32(a,f,m); }
+        SI F floor_(F v) {
+            F roundtrip = vcvtq_f32_s32(vcvtq_s32_f32(v));
+            return roundtrip - if_then_else(roundtrip > v, 1, 0);
+        }
+
+        SI F sqrt_(F v) {
+            auto e = vrsqrteq_f32(v);  // Estimate and two refinement steps for e = rsqrt(v).
+            e *= vrsqrtsq_f32(v,e*e);
+            e *= vrsqrtsq_f32(v,e*e);
+            return v*e;                // sqrt(v) == v*rsqrt(v).
+        }
+
+        SI U32 round(F v, F scale) {
+            return vcvtq_u32_f32(mad(v,scale,0.5f));
+        }
+    #endif
+
+
+    template <typename T>
+    SI V<T> gather(const T* p, U32 ix) {
+        return {p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]]};
+    }
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        uint16x4x3_t rgb;
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { rgb = vld3_lane_u16(ptr + 0, rgb, 0); }
+            if (tail > 1) { rgb = vld3_lane_u16(ptr + 3, rgb, 1); }
+            if (tail > 2) { rgb = vld3_lane_u16(ptr + 6, rgb, 2); }
+        } else {
+            rgb = vld3_u16(ptr);
+        }
+        *r = rgb.val[0];
+        *g = rgb.val[1];
+        *b = rgb.val[2];
+    }
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        uint16x4x4_t rgba;
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { rgba = vld4_lane_u16(ptr + 0, rgba, 0); }
+            if (tail > 1) { rgba = vld4_lane_u16(ptr + 4, rgba, 1); }
+            if (tail > 2) { rgba = vld4_lane_u16(ptr + 8, rgba, 2); }
+        } else {
+            rgba = vld4_u16(ptr);
+        }
+        *r = rgba.val[0];
+        *g = rgba.val[1];
+        *b = rgba.val[2];
+        *a = rgba.val[3];
+    }
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { vst4_lane_u16(ptr + 0, (uint16x4x4_t{{r,g,b,a}}), 0); }
+            if (tail > 1) { vst4_lane_u16(ptr + 4, (uint16x4x4_t{{r,g,b,a}}), 1); }
+            if (tail > 2) { vst4_lane_u16(ptr + 8, (uint16x4x4_t{{r,g,b,a}}), 2); }
+        } else {
+            vst4_u16(ptr, (uint16x4x4_t{{r,g,b,a}}));
+        }
+    }
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        float32x4x4_t rgba;
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { rgba = vld4q_lane_f32(ptr + 0, rgba, 0); }
+            if (tail > 1) { rgba = vld4q_lane_f32(ptr + 4, rgba, 1); }
+            if (tail > 2) { rgba = vld4q_lane_f32(ptr + 8, rgba, 2); }
+        } else {
+            rgba = vld4q_f32(ptr);
+        }
+        *r = rgba.val[0];
+        *g = rgba.val[1];
+        *b = rgba.val[2];
+        *a = rgba.val[3];
+    }
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        if (__builtin_expect(tail,0)) {
+            if (  true  ) { vst4q_lane_f32(ptr + 0, (float32x4x4_t{{r,g,b,a}}), 0); }
+            if (tail > 1) { vst4q_lane_f32(ptr + 4, (float32x4x4_t{{r,g,b,a}}), 1); }
+            if (tail > 2) { vst4q_lane_f32(ptr + 8, (float32x4x4_t{{r,g,b,a}}), 2); }
+        } else {
+            vst4q_f32(ptr, (float32x4x4_t{{r,g,b,a}}));
+        }
+    }
+
+#elif defined(JUMPER_IS_AVX) || defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    #include <immintrin.h>
+
+    // These are __m256 and __m256i, but friendlier and strongly-typed.
+    template <typename T> using V = T __attribute__((ext_vector_type(8)));
+    using F   = V<float   >;
+    using I32 = V< int32_t>;
+    using U64 = V<uint64_t>;
+    using U32 = V<uint32_t>;
+    using U16 = V<uint16_t>;
+    using U8  = V<uint8_t >;
+
+    SI F mad(F f, F m, F a)  {
+    #if defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+        return _mm256_fmadd_ps(f,m,a);
+    #else
+        return f*m+a;
+    #endif
+    }
+
+    SI F   min(F a, F b)        { return _mm256_min_ps(a,b);    }
+    SI F   max(F a, F b)        { return _mm256_max_ps(a,b);    }
+    SI F   abs_  (F v)          { return _mm256_and_ps(v, 0-v); }
+    SI F   floor_(F v)          { return _mm256_floor_ps(v);    }
+    SI F   rcp   (F v)          { return _mm256_rcp_ps  (v);    }
+    SI F   rsqrt (F v)          { return _mm256_rsqrt_ps(v);    }
+    SI F    sqrt_(F v)          { return _mm256_sqrt_ps (v);    }
+    SI U32 round (F v, F scale) { return _mm256_cvtps_epi32(v*scale); }
+
+    SI U16 pack(U32 v) {
+        return _mm_packus_epi32(_mm256_extractf128_si256(v, 0),
+                                _mm256_extractf128_si256(v, 1));
+    }
+    SI U8 pack(U16 v) {
+        auto r = _mm_packus_epi16(v,v);
+        return unaligned_load<U8>(&r);
+    }
+
+    SI F if_then_else(I32 c, F t, F e) { return _mm256_blendv_ps(e,t,c); }
+
+    template <typename T>
+    SI V<T> gather(const T* p, U32 ix) {
+        return { p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]],
+                 p[ix[4]], p[ix[5]], p[ix[6]], p[ix[7]], };
+    }
+    #if defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+        SI F   gather(const float*    p, U32 ix) { return _mm256_i32gather_ps   (p, ix, 4); }
+        SI U32 gather(const uint32_t* p, U32 ix) { return _mm256_i32gather_epi32(p, ix, 4); }
+        SI U64 gather(const uint64_t* p, U32 ix) {
+            __m256i parts[] = {
+                _mm256_i32gather_epi64(p, _mm256_extracti128_si256(ix,0), 8),
+                _mm256_i32gather_epi64(p, _mm256_extracti128_si256(ix,1), 8),
+            };
+            return bit_cast<U64>(parts);
+        }
+    #endif
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        __m128i _0,_1,_2,_3,_4,_5,_6,_7;
+        if (__builtin_expect(tail,0)) {
+            auto load_rgb = [](const uint16_t* src) {
+                auto v = _mm_cvtsi32_si128(*(const uint32_t*)src);
+                return _mm_insert_epi16(v, src[2], 2);
+            };
+            _1 = _2 = _3 = _4 = _5 = _6 = _7 = _mm_setzero_si128();
+            if (  true  ) { _0 = load_rgb(ptr +  0); }
+            if (tail > 1) { _1 = load_rgb(ptr +  3); }
+            if (tail > 2) { _2 = load_rgb(ptr +  6); }
+            if (tail > 3) { _3 = load_rgb(ptr +  9); }
+            if (tail > 4) { _4 = load_rgb(ptr + 12); }
+            if (tail > 5) { _5 = load_rgb(ptr + 15); }
+            if (tail > 6) { _6 = load_rgb(ptr + 18); }
+        } else {
+            // Load 0+1, 2+3, 4+5 normally, and 6+7 backed up 4 bytes so we don't run over.
+            auto _01 =                _mm_loadu_si128((const __m128i*)(ptr +  0))    ;
+            auto _23 =                _mm_loadu_si128((const __m128i*)(ptr +  6))    ;
+            auto _45 =                _mm_loadu_si128((const __m128i*)(ptr + 12))    ;
+            auto _67 = _mm_srli_si128(_mm_loadu_si128((const __m128i*)(ptr + 16)), 4);
+            _0 = _01; _1 = _mm_srli_si128(_01, 6);
+            _2 = _23; _3 = _mm_srli_si128(_23, 6);
+            _4 = _45; _5 = _mm_srli_si128(_45, 6);
+            _6 = _67; _7 = _mm_srli_si128(_67, 6);
+        }
+
+        auto _02 = _mm_unpacklo_epi16(_0, _2),  // r0 r2 g0 g2 b0 b2 xx xx
+             _13 = _mm_unpacklo_epi16(_1, _3),
+             _46 = _mm_unpacklo_epi16(_4, _6),
+             _57 = _mm_unpacklo_epi16(_5, _7);
+
+        auto rg0123 = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             bx0123 = _mm_unpackhi_epi16(_02, _13),  // b0 b1 b2 b3 xx xx xx xx
+             rg4567 = _mm_unpacklo_epi16(_46, _57),
+             bx4567 = _mm_unpackhi_epi16(_46, _57);
+
+        *r = _mm_unpacklo_epi64(rg0123, rg4567);
+        *g = _mm_unpackhi_epi64(rg0123, rg4567);
+        *b = _mm_unpacklo_epi64(bx0123, bx4567);
+    }
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        __m128i _01, _23, _45, _67;
+        if (__builtin_expect(tail,0)) {
+            auto src = (const double*)ptr;
+            _01 = _23 = _45 = _67 = _mm_setzero_si128();
+            if (tail > 0) { _01 = _mm_loadl_pd(_01, src+0); }
+            if (tail > 1) { _01 = _mm_loadh_pd(_01, src+1); }
+            if (tail > 2) { _23 = _mm_loadl_pd(_23, src+2); }
+            if (tail > 3) { _23 = _mm_loadh_pd(_23, src+3); }
+            if (tail > 4) { _45 = _mm_loadl_pd(_45, src+4); }
+            if (tail > 5) { _45 = _mm_loadh_pd(_45, src+5); }
+            if (tail > 6) { _67 = _mm_loadl_pd(_67, src+6); }
+        } else {
+            _01 = _mm_loadu_si128(((__m128i*)ptr) + 0);
+            _23 = _mm_loadu_si128(((__m128i*)ptr) + 1);
+            _45 = _mm_loadu_si128(((__m128i*)ptr) + 2);
+            _67 = _mm_loadu_si128(((__m128i*)ptr) + 3);
+        }
+
+        auto _02 = _mm_unpacklo_epi16(_01, _23),  // r0 r2 g0 g2 b0 b2 a0 a2
+             _13 = _mm_unpackhi_epi16(_01, _23),  // r1 r3 g1 g3 b1 b3 a1 a3
+             _46 = _mm_unpacklo_epi16(_45, _67),
+             _57 = _mm_unpackhi_epi16(_45, _67);
+
+        auto rg0123 = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             ba0123 = _mm_unpackhi_epi16(_02, _13),  // b0 b1 b2 b3 a0 a1 a2 a3
+             rg4567 = _mm_unpacklo_epi16(_46, _57),
+             ba4567 = _mm_unpackhi_epi16(_46, _57);
+
+        *r = _mm_unpacklo_epi64(rg0123, rg4567);
+        *g = _mm_unpackhi_epi64(rg0123, rg4567);
+        *b = _mm_unpacklo_epi64(ba0123, ba4567);
+        *a = _mm_unpackhi_epi64(ba0123, ba4567);
+    }
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        auto rg0123 = _mm_unpacklo_epi16(r, g),  // r0 g0 r1 g1 r2 g2 r3 g3
+             rg4567 = _mm_unpackhi_epi16(r, g),  // r4 g4 r5 g5 r6 g6 r7 g7
+             ba0123 = _mm_unpacklo_epi16(b, a),
+             ba4567 = _mm_unpackhi_epi16(b, a);
+
+        auto _01 = _mm_unpacklo_epi32(rg0123, ba0123),
+             _23 = _mm_unpackhi_epi32(rg0123, ba0123),
+             _45 = _mm_unpacklo_epi32(rg4567, ba4567),
+             _67 = _mm_unpackhi_epi32(rg4567, ba4567);
+
+        if (__builtin_expect(tail,0)) {
+            auto dst = (double*)ptr;
+            if (tail > 0) { _mm_storel_pd(dst+0, _01); }
+            if (tail > 1) { _mm_storeh_pd(dst+1, _01); }
+            if (tail > 2) { _mm_storel_pd(dst+2, _23); }
+            if (tail > 3) { _mm_storeh_pd(dst+3, _23); }
+            if (tail > 4) { _mm_storel_pd(dst+4, _45); }
+            if (tail > 5) { _mm_storeh_pd(dst+5, _45); }
+            if (tail > 6) { _mm_storel_pd(dst+6, _67); }
+        } else {
+            _mm_storeu_si128((__m128i*)ptr + 0, _01);
+            _mm_storeu_si128((__m128i*)ptr + 1, _23);
+            _mm_storeu_si128((__m128i*)ptr + 2, _45);
+            _mm_storeu_si128((__m128i*)ptr + 3, _67);
+        }
+    }
+
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        F _04, _15, _26, _37;
+        _04 = _15 = _26 = _37 = 0;
+        switch (tail) {
+            case 0: _37 = _mm256_insertf128_ps(_37, _mm_loadu_ps(ptr+28), 1);
+            case 7: _26 = _mm256_insertf128_ps(_26, _mm_loadu_ps(ptr+24), 1);
+            case 6: _15 = _mm256_insertf128_ps(_15, _mm_loadu_ps(ptr+20), 1);
+            case 5: _04 = _mm256_insertf128_ps(_04, _mm_loadu_ps(ptr+16), 1);
+            case 4: _37 = _mm256_insertf128_ps(_37, _mm_loadu_ps(ptr+12), 0);
+            case 3: _26 = _mm256_insertf128_ps(_26, _mm_loadu_ps(ptr+ 8), 0);
+            case 2: _15 = _mm256_insertf128_ps(_15, _mm_loadu_ps(ptr+ 4), 0);
+            case 1: _04 = _mm256_insertf128_ps(_04, _mm_loadu_ps(ptr+ 0), 0);
+        }
+
+        F rg0145 = _mm256_unpacklo_ps(_04,_15),  // r0 r1 g0 g1 | r4 r5 g4 g5
+          ba0145 = _mm256_unpackhi_ps(_04,_15),
+          rg2367 = _mm256_unpacklo_ps(_26,_37),
+          ba2367 = _mm256_unpackhi_ps(_26,_37);
+
+        *r = _mm256_unpacklo_pd(rg0145, rg2367);
+        *g = _mm256_unpackhi_pd(rg0145, rg2367);
+        *b = _mm256_unpacklo_pd(ba0145, ba2367);
+        *a = _mm256_unpackhi_pd(ba0145, ba2367);
+    }
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        F rg0145 = _mm256_unpacklo_ps(r, g),  // r0 g0 r1 g1 | r4 g4 r5 g5
+          rg2367 = _mm256_unpackhi_ps(r, g),  // r2 ...      | r6 ...
+          ba0145 = _mm256_unpacklo_ps(b, a),  // b0 a0 b1 a1 | b4 a4 b5 a5
+          ba2367 = _mm256_unpackhi_ps(b, a);  // b2 ...      | b6 ...
+
+        F _04 = _mm256_unpacklo_pd(rg0145, ba0145),  // r0 g0 b0 a0 | r4 g4 b4 a4
+          _15 = _mm256_unpackhi_pd(rg0145, ba0145),  // r1 ...      | r5 ...
+          _26 = _mm256_unpacklo_pd(rg2367, ba2367),  // r2 ...      | r6 ...
+          _37 = _mm256_unpackhi_pd(rg2367, ba2367);  // r3 ...      | r7 ...
+
+        if (__builtin_expect(tail, 0)) {
+            if (tail > 0) { _mm_storeu_ps(ptr+ 0, _mm256_extractf128_ps(_04, 0)); }
+            if (tail > 1) { _mm_storeu_ps(ptr+ 4, _mm256_extractf128_ps(_15, 0)); }
+            if (tail > 2) { _mm_storeu_ps(ptr+ 8, _mm256_extractf128_ps(_26, 0)); }
+            if (tail > 3) { _mm_storeu_ps(ptr+12, _mm256_extractf128_ps(_37, 0)); }
+            if (tail > 4) { _mm_storeu_ps(ptr+16, _mm256_extractf128_ps(_04, 1)); }
+            if (tail > 5) { _mm_storeu_ps(ptr+20, _mm256_extractf128_ps(_15, 1)); }
+            if (tail > 6) { _mm_storeu_ps(ptr+24, _mm256_extractf128_ps(_26, 1)); }
+        } else {
+            F _01 = _mm256_permute2f128_ps(_04, _15, 32),  // 32 == 0010 0000 == lo, lo
+              _23 = _mm256_permute2f128_ps(_26, _37, 32),
+              _45 = _mm256_permute2f128_ps(_04, _15, 49),  // 49 == 0011 0001 == hi, hi
+              _67 = _mm256_permute2f128_ps(_26, _37, 49);
+            _mm256_storeu_ps(ptr+ 0, _01);
+            _mm256_storeu_ps(ptr+ 8, _23);
+            _mm256_storeu_ps(ptr+16, _45);
+            _mm256_storeu_ps(ptr+24, _67);
+        }
+    }
+
+#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41)
+    #include <immintrin.h>
+
+    template <typename T> using V = T __attribute__((ext_vector_type(4)));
+    using F   = V<float   >;
+    using I32 = V< int32_t>;
+    using U64 = V<uint64_t>;
+    using U32 = V<uint32_t>;
+    using U16 = V<uint16_t>;
+    using U8  = V<uint8_t >;
+
+    SI F   mad(F f, F m, F a)  { return f*m+a;              }
+    SI F   min(F a, F b)       { return _mm_min_ps(a,b);    }
+    SI F   max(F a, F b)       { return _mm_max_ps(a,b);    }
+    SI F   abs_(F v)           { return _mm_and_ps(v, 0-v); }
+    SI F   rcp   (F v)         { return _mm_rcp_ps  (v);    }
+    SI F   rsqrt (F v)         { return _mm_rsqrt_ps(v);    }
+    SI F    sqrt_(F v)         { return _mm_sqrt_ps (v);    }
+    SI U32 round(F v, F scale) { return _mm_cvtps_epi32(v*scale); }
+
+    SI U16 pack(U32 v) {
+    #if defined(JUMPER_IS_SSE41)
+        auto p = _mm_packus_epi32(v,v);
+    #else
+        // Sign extend so that _mm_packs_epi32() does the pack we want.
+        auto p = _mm_srai_epi32(_mm_slli_epi32(v, 16), 16);
+        p = _mm_packs_epi32(p,p);
+    #endif
+        return unaligned_load<U16>(&p);  // We have two copies.  Return (the lower) one.
+    }
+    SI U8 pack(U16 v) {
+        auto r = widen_cast<__m128i>(v);
+        r = _mm_packus_epi16(r,r);
+        return unaligned_load<U8>(&r);
+    }
+
+    SI F if_then_else(I32 c, F t, F e) {
+        return _mm_or_ps(_mm_and_ps(c, t), _mm_andnot_ps(c, e));
+    }
+
+    SI F floor_(F v) {
+    #if defined(JUMPER_IS_SSE41)
+        return _mm_floor_ps(v);
+    #else
+        F roundtrip = _mm_cvtepi32_ps(_mm_cvttps_epi32(v));
+        return roundtrip - if_then_else(roundtrip > v, 1, 0);
+    #endif
+    }
+
+    template <typename T>
+    SI V<T> gather(const T* p, U32 ix) {
+        return {p[ix[0]], p[ix[1]], p[ix[2]], p[ix[3]]};
+    }
+
+    SI void load3(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b) {
+        __m128i _0, _1, _2, _3;
+        if (__builtin_expect(tail,0)) {
+            _1 = _2 = _3 = _mm_setzero_si128();
+            auto load_rgb = [](const uint16_t* src) {
+                auto v = _mm_cvtsi32_si128(*(const uint32_t*)src);
+                return _mm_insert_epi16(v, src[2], 2);
+            };
+            if (  true  ) { _0 = load_rgb(ptr + 0); }
+            if (tail > 1) { _1 = load_rgb(ptr + 3); }
+            if (tail > 2) { _2 = load_rgb(ptr + 6); }
+        } else {
+            // Load slightly weirdly to make sure we don't load past the end of 4x48 bits.
+            auto _01 =                _mm_loadu_si128((const __m128i*)(ptr + 0))    ,
+                 _23 = _mm_srli_si128(_mm_loadu_si128((const __m128i*)(ptr + 4)), 4);
+
+            // Each _N holds R,G,B for pixel N in its lower 3 lanes (upper 5 are ignored).
+            _0 = _01;
+            _1 = _mm_srli_si128(_01, 6);
+            _2 = _23;
+            _3 = _mm_srli_si128(_23, 6);
+        }
+
+        // De-interlace to R,G,B.
+        auto _02 = _mm_unpacklo_epi16(_0, _2),  // r0 r2 g0 g2 b0 b2 xx xx
+             _13 = _mm_unpacklo_epi16(_1, _3);  // r1 r3 g1 g3 b1 b3 xx xx
+
+        auto R = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             G = _mm_srli_si128(R, 8),
+             B = _mm_unpackhi_epi16(_02, _13);  // b0 b1 b2 b3 xx xx xx xx
+
+        *r = unaligned_load<U16>(&R);
+        *g = unaligned_load<U16>(&G);
+        *b = unaligned_load<U16>(&B);
+    }
+
+    SI void load4(const uint16_t* ptr, size_t tail, U16* r, U16* g, U16* b, U16* a) {
+        __m128i _01, _23;
+        if (__builtin_expect(tail,0)) {
+            _01 = _23 = _mm_setzero_si128();
+            auto src = (const double*)ptr;
+            if (  true  ) { _01 = _mm_loadl_pd(_01, src + 0); } // r0 g0 b0 a0 00 00 00 00
+            if (tail > 1) { _01 = _mm_loadh_pd(_01, src + 1); } // r0 g0 b0 a0 r1 g1 b1 a1
+            if (tail > 2) { _23 = _mm_loadl_pd(_23, src + 2); } // r2 g2 b2 a2 00 00 00 00
+        } else {
+            _01 = _mm_loadu_si128(((__m128i*)ptr) + 0); // r0 g0 b0 a0 r1 g1 b1 a1
+            _23 = _mm_loadu_si128(((__m128i*)ptr) + 1); // r2 g2 b2 a2 r3 g3 b3 a3
+        }
+
+        auto _02 = _mm_unpacklo_epi16(_01, _23),  // r0 r2 g0 g2 b0 b2 a0 a2
+             _13 = _mm_unpackhi_epi16(_01, _23);  // r1 r3 g1 g3 b1 b3 a1 a3
+
+        auto rg = _mm_unpacklo_epi16(_02, _13),  // r0 r1 r2 r3 g0 g1 g2 g3
+             ba = _mm_unpackhi_epi16(_02, _13);  // b0 b1 b2 b3 a0 a1 a2 a3
+
+        *r = unaligned_load<U16>((uint16_t*)&rg + 0);
+        *g = unaligned_load<U16>((uint16_t*)&rg + 4);
+        *b = unaligned_load<U16>((uint16_t*)&ba + 0);
+        *a = unaligned_load<U16>((uint16_t*)&ba + 4);
+    }
+
+    SI void store4(uint16_t* ptr, size_t tail, U16 r, U16 g, U16 b, U16 a) {
+        auto rg = _mm_unpacklo_epi16(widen_cast<__m128i>(r), widen_cast<__m128i>(g)),
+             ba = _mm_unpacklo_epi16(widen_cast<__m128i>(b), widen_cast<__m128i>(a));
+
+        if (__builtin_expect(tail, 0)) {
+            auto dst = (double*)ptr;
+            if (  true  ) { _mm_storel_pd(dst + 0, _mm_unpacklo_epi32(rg, ba)); }
+            if (tail > 1) { _mm_storeh_pd(dst + 1, _mm_unpacklo_epi32(rg, ba)); }
+            if (tail > 2) { _mm_storel_pd(dst + 2, _mm_unpackhi_epi32(rg, ba)); }
+        } else {
+            _mm_storeu_si128((__m128i*)ptr + 0, _mm_unpacklo_epi32(rg, ba));
+            _mm_storeu_si128((__m128i*)ptr + 1, _mm_unpackhi_epi32(rg, ba));
+        }
+    }
+
+    SI void load4(const float* ptr, size_t tail, F* r, F* g, F* b, F* a) {
+        F _0, _1, _2, _3;
+        if (__builtin_expect(tail, 0)) {
+            _1 = _2 = _3 = _mm_setzero_si128();
+            if (  true  ) { _0 = _mm_loadu_ps(ptr + 0); }
+            if (tail > 1) { _1 = _mm_loadu_ps(ptr + 4); }
+            if (tail > 2) { _2 = _mm_loadu_ps(ptr + 8); }
+        } else {
+            _0 = _mm_loadu_ps(ptr + 0);
+            _1 = _mm_loadu_ps(ptr + 4);
+            _2 = _mm_loadu_ps(ptr + 8);
+            _3 = _mm_loadu_ps(ptr +12);
+        }
+        _MM_TRANSPOSE4_PS(_0,_1,_2,_3);
+        *r = _0;
+        *g = _1;
+        *b = _2;
+        *a = _3;
+    }
+
+    SI void store4(float* ptr, size_t tail, F r, F g, F b, F a) {
+        _MM_TRANSPOSE4_PS(r,g,b,a);
+        if (__builtin_expect(tail, 0)) {
+            if (  true  ) { _mm_storeu_ps(ptr + 0, r); }
+            if (tail > 1) { _mm_storeu_ps(ptr + 4, g); }
+            if (tail > 2) { _mm_storeu_ps(ptr + 8, b); }
+        } else {
+            _mm_storeu_ps(ptr + 0, r);
+            _mm_storeu_ps(ptr + 4, g);
+            _mm_storeu_ps(ptr + 8, b);
+            _mm_storeu_ps(ptr +12, a);
+        }
+    }
+#endif
+
+// We need to be a careful with casts.
+// (F)x means cast x to float in the portable path, but bit_cast x to float in the others.
+// These named casts and bit_cast() are always what they seem to be.
+#if defined(JUMPER_IS_SCALAR)
+    SI F   cast  (U32 v) { return   (F)v; }
+    SI U32 trunc_(F   v) { return (U32)v; }
+    SI U32 expand(U16 v) { return (U32)v; }
+    SI U32 expand(U8  v) { return (U32)v; }
+#else
+    SI F   cast  (U32 v) { return      __builtin_convertvector((I32)v,   F); }
+    SI U32 trunc_(F   v) { return (U32)__builtin_convertvector(     v, I32); }
+    SI U32 expand(U16 v) { return      __builtin_convertvector(     v, U32); }
+    SI U32 expand(U8  v) { return      __builtin_convertvector(     v, U32); }
+#endif
+
+template <typename V>
+SI V if_then_else(I32 c, V t, V e) {
+    return bit_cast<V>(if_then_else(c, bit_cast<F>(t), bit_cast<F>(e)));
+}
+
+SI U16 bswap(U16 x) {
+#if defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41)
+    // Somewhat inexplicably Clang decides to do (x<<8) | (x>>8) in 32-bit lanes
+    // when generating code for SSE2 and SSE4.1.  We'll do it manually...
+    auto v = widen_cast<__m128i>(x);
+    v = _mm_slli_epi16(v,8) | _mm_srli_epi16(v,8);
+    return unaligned_load<U16>(&v);
+#else
+    return (x<<8) | (x>>8);
+#endif
+}
+
+SI F fract(F v) { return v - floor_(v); }
+
+// See http://www.machinedlearnings.com/2011/06/fast-approximate-logarithm-exponential.html.
+SI F approx_log2(F x) {
+    // e - 127 is a fair approximation of log2(x) in its own right...
+    F e = cast(bit_cast<U32>(x)) * (1.0f / (1<<23));
+
+    // ... but using the mantissa to refine its error is _much_ better.
+    F m = bit_cast<F>((bit_cast<U32>(x) & 0x007fffff) | 0x3f000000);
+    return e
+         - 124.225514990f
+         -   1.498030302f * m
+         -   1.725879990f / (0.3520887068f + m);
+}
+SI F approx_pow2(F x) {
+    F f = fract(x);
+    return bit_cast<F>(round(1.0f * (1<<23),
+                             x + 121.274057500f
+                               -   1.490129070f * f
+                               +  27.728023300f / (4.84252568f - f)));
+}
+
+SI F approx_powf(F x, F y) {
+    return if_then_else(x == 0, 0
+                              , approx_pow2(approx_log2(x) * y));
+}
+
+SI F from_half(U16 h) {
+#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+    return vcvt_f32_f16(h);
+
+#elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    return _mm256_cvtph_ps(h);
+
+#else
+    // Remember, a half is 1-5-10 (sign-exponent-mantissa) with 15 exponent bias.
+    U32 sem = expand(h),
+        s   = sem & 0x8000,
+         em = sem ^ s;
+
+    // Convert to 1-8-23 float with 127 bias, flushing denorm halfs (including zero) to zero.
+    auto denorm = (I32)em < 0x0400;      // I32 comparison is often quicker, and always safe here.
+    return if_then_else(denorm, F(0)
+                              , bit_cast<F>( (s<<16) + (em<<13) + ((127-15)<<23) ));
+#endif
+}
+
+SI U16 to_half(F f) {
+#if defined(__aarch64__) && !defined(SK_BUILD_FOR_GOOGLE3)  // Temporary workaround for some Google3 builds.
+    return vcvt_f16_f32(f);
+
+#elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    return _mm256_cvtps_ph(f, _MM_FROUND_CUR_DIRECTION);
+
+#else
+    // Remember, a float is 1-8-23 (sign-exponent-mantissa) with 127 exponent bias.
+    U32 sem = bit_cast<U32>(f),
+        s   = sem & 0x80000000,
+         em = sem ^ s;
+
+    // Convert to 1-5-10 half with 15 bias, flushing denorm halfs (including zero) to zero.
+    auto denorm = (I32)em < 0x38800000;  // I32 comparison is often quicker, and always safe here.
+    return pack(if_then_else(denorm, U32(0)
+                                   , (s>>16) + (em>>13) - ((127-15)<<10)));
+#endif
+}
+
+// Our fundamental vector depth is our pixel stride.
+static const size_t N = sizeof(F) / sizeof(float);
+
+// We're finally going to get to what a Stage function looks like!
+//    tail == 0 ~~> work on a full N pixels
+//    tail != 0 ~~> work on only the first tail pixels
+// tail is always < N.
+
+#if defined(__i386__) || defined(_M_IX86) || defined(__arm__)
+    // On 32-bit x86 we've only got 8 xmm registers, so we keep the 4 hottest (r,g,b,a)
+    // in registers and the d-registers on the stack (giving us 4 temporary registers).
+    // General-purpose registers are also tight, so we put most of those on the stack too.
+    // On ARMv7, we do the same so that we can make the r,g,b,a vectors wider.
+    struct Params {
+        size_t dx, dy, tail;
+        F dr,dg,db,da;
+    };
+    using Stage = void(ABI*)(Params*, void** program, F r, F g, F b, F a);
+
+#else
+    // We keep program the second argument, so that it's passed in rsi for load_and_inc().
+    using Stage = void(ABI*)(size_t tail, void** program, size_t dx, size_t dy, F,F,F,F, F,F,F,F);
+#endif
+
+
+extern "C" MAYBE_MSABI void WRAP(start_pipeline)(size_t dx, size_t dy, size_t xlimit, size_t ylimit,
+                                                 void** program) {
+    auto start = (Stage)load_and_inc(program);
+    const size_t x0 = dx;
+    for (; dy < ylimit; dy++) {
+    #if defined(__i386__) || defined(_M_IX86) || defined(__arm__)
+        Params params = { x0,dy,0, 0,0,0,0 };
+        while (params.dx + N <= xlimit) {
+            start(&params,program, 0,0,0,0);
+            params.dx += N;
+        }
+        if (size_t tail = xlimit - params.dx) {
+            params.tail = tail;
+            start(&params,program, 0,0,0,0);
+        }
+    #else
+        dx = x0;
+        while (dx + N <= xlimit) {
+            start(0,program,dx,dy,    0,0,0,0, 0,0,0,0);
+            dx += N;
+        }
+        if (size_t tail = xlimit - dx) {
+            start(tail,program,dx,dy, 0,0,0,0, 0,0,0,0);
+        }
+    #endif
+    }
+}
+
+#if defined(__i386__) || defined(_M_IX86) || defined(__arm__)
+    #define STAGE(name, ...)                                                          \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,              \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da);         \
+        extern "C" ABI void WRAP(name)(Params* params, void** program,                \
+                                       F r, F g, F b, F a) {                          \
+            name##_k(Ctx{program},params->dx,params->dy,params->tail, r,g,b,a,        \
+                     params->dr, params->dg, params->db, params->da);                 \
+            auto next = (Stage)load_and_inc(program);                                 \
+            next(params,program, r,g,b,a);                                            \
+        }                                                                             \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,              \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da)
+#else
+    #define STAGE(name, ...)                                                              \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,                  \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da);             \
+        extern "C" ABI void WRAP(name)(size_t tail, void** program, size_t dx, size_t dy, \
+                                       F r, F g, F b, F a, F dr, F dg, F db, F da) {      \
+            name##_k(Ctx{program},dx,dy,tail, r,g,b,a, dr,dg,db,da);                      \
+            auto next = (Stage)load_and_inc(program);                                     \
+            next(tail,program,dx,dy, r,g,b,a, dr,dg,db,da);                               \
+        }                                                                                 \
+        SI void name##_k(__VA_ARGS__, size_t dx, size_t dy, size_t tail,                  \
+                         F& r, F& g, F& b, F& a, F& dr, F& dg, F& db, F& da)
+#endif
+
+
+// just_return() is a simple no-op stage that only exists to end the chain,
+// returning back up to start_pipeline(), and from there to the caller.
+#if defined(__i386__) || defined(_M_IX86) || defined(__arm__)
+    extern "C" ABI void WRAP(just_return)(Params*, void**, F,F,F,F) {}
+#else
+    extern "C" ABI void WRAP(just_return)(size_t, void**, size_t,size_t, F,F,F,F, F,F,F,F) {}
+#endif
+
+
+// We could start defining normal Stages now.  But first, some helper functions.
+
+// These load() and store() methods are tail-aware,
+// but focus mainly on keeping the at-stride tail==0 case fast.
+
+template <typename V, typename T>
+SI V load(const T* src, size_t tail) {
+#if !defined(JUMPER_IS_SCALAR)
+    __builtin_assume(tail < N);
+    if (__builtin_expect(tail, 0)) {
+        V v{};  // Any inactive lanes are zeroed.
+        switch (tail) {
+            case 7: v[6] = src[6];
+            case 6: v[5] = src[5];
+            case 5: v[4] = src[4];
+            case 4: memcpy(&v, src, 4*sizeof(T)); break;
+            case 3: v[2] = src[2];
+            case 2: memcpy(&v, src, 2*sizeof(T)); break;
+            case 1: memcpy(&v, src, 1*sizeof(T)); break;
+        }
+        return v;
+    }
+#endif
+    return unaligned_load<V>(src);
+}
+
+template <typename V, typename T>
+SI void store(T* dst, V v, size_t tail) {
+#if !defined(JUMPER_IS_SCALAR)
+    __builtin_assume(tail < N);
+    if (__builtin_expect(tail, 0)) {
+        switch (tail) {
+            case 7: dst[6] = v[6];
+            case 6: dst[5] = v[5];
+            case 5: dst[4] = v[4];
+            case 4: memcpy(dst, &v, 4*sizeof(T)); break;
+            case 3: dst[2] = v[2];
+            case 2: memcpy(dst, &v, 2*sizeof(T)); break;
+            case 1: memcpy(dst, &v, 1*sizeof(T)); break;
+        }
+        return;
+    }
+#endif
+    unaligned_store(dst, v);
+}
+
+SI F from_byte(U8 b) {
+    return cast(expand(b)) * (1/255.0f);
+}
+SI void from_565(U16 _565, F* r, F* g, F* b) {
+    U32 wide = expand(_565);
+    *r = cast(wide & (31<<11)) * (1.0f / (31<<11));
+    *g = cast(wide & (63<< 5)) * (1.0f / (63<< 5));
+    *b = cast(wide & (31<< 0)) * (1.0f / (31<< 0));
+}
+SI void from_4444(U16 _4444, F* r, F* g, F* b, F* a) {
+    U32 wide = expand(_4444);
+    *r = cast(wide & (15<<12)) * (1.0f / (15<<12));
+    *g = cast(wide & (15<< 8)) * (1.0f / (15<< 8));
+    *b = cast(wide & (15<< 4)) * (1.0f / (15<< 4));
+    *a = cast(wide & (15<< 0)) * (1.0f / (15<< 0));
+}
+SI void from_8888(U32 _8888, F* r, F* g, F* b, F* a) {
+    *r = cast((_8888      ) & 0xff) * (1/255.0f);
+    *g = cast((_8888 >>  8) & 0xff) * (1/255.0f);
+    *b = cast((_8888 >> 16) & 0xff) * (1/255.0f);
+    *a = cast((_8888 >> 24)       ) * (1/255.0f);
+}
+
+// Used by load_ and store_ stages to get to the right (dx,dy) starting point of contiguous memory.
+template <typename T>
+SI T* ptr_at_xy(const SkJumper_MemoryCtx* ctx, int dx, int dy) {
+    return (T*)ctx->pixels + dy*ctx->stride + dx;
+}
+
+// clamp v to [0,limit).
+SI F clamp(F v, F limit) {
+    F inclusive = bit_cast<F>( bit_cast<U32>(limit) - 1 );  // Exclusive -> inclusive.
+    return min(max(0, v), inclusive);
+}
+
+// Used by gather_ stages to calculate the base pointer and a vector of indices to load.
+template <typename T>
+SI U32 ix_and_ptr(T** ptr, const SkJumper_GatherCtx* ctx, F x, F y) {
+    x = clamp(x, ctx->width);
+    y = clamp(y, ctx->height);
+
+    *ptr = (const T*)ctx->pixels;
+    return trunc_(y)*ctx->stride + trunc_(x);
+}
+
+// We often have a nominally [0,1] float value we need to scale and convert to an integer,
+// whether for a table lookup or to pack back down into bytes for storage.
+//
+// In practice, especially when dealing with interesting color spaces, that notionally
+// [0,1] float may be out of [0,1] range.  Unorms cannot represent that, so we must clamp.
+//
+// You can adjust the expected input to [0,bias] by tweaking that parameter.
+SI U32 to_unorm(F v, F scale, F bias = 1.0f) {
+    // TODO: platform-specific implementations to to_unorm(), removing round() entirely?
+    // Any time we use round() we probably want to use to_unorm().
+    return round(min(max(0, v), bias), scale);
+}
+
+// Now finally, normal Stages!
+
+STAGE(seed_shader, const float* iota) {
+    // It's important for speed to explicitly cast(dx) and cast(dy),
+    // which has the effect of splatting them to vectors before converting to floats.
+    // On Intel this breaks a data dependency on previous loop iterations' registers.
+    r = cast(dx) + unaligned_load<F>(iota);
+    g = cast(dy) + 0.5f;
+    b = 1.0f;
+    a = 0;
+    dr = dg = db = da = 0;
+}
+
+STAGE(dither, const float* rate) {
+    // Get [(dx,dy), (dx+1,dy), (dx+2,dy), ...] loaded up in integer vectors.
+    uint32_t iota[] = {0,1,2,3,4,5,6,7};
+    U32 X = dx + unaligned_load<U32>(iota),
+        Y = dy;
+
+    // We're doing 8x8 ordered dithering, see https://en.wikipedia.org/wiki/Ordered_dithering.
+    // In this case n=8 and we're using the matrix that looks like 1/64 x [ 0 48 12 60 ... ].
+
+    // We only need X and X^Y from here on, so it's easier to just think of that as "Y".
+    Y ^= X;
+
+    // We'll mix the bottom 3 bits of each of X and Y to make 6 bits,
+    // for 2^6 == 64 == 8x8 matrix values.  If X=abc and Y=def, we make fcebda.
+    U32 M = (Y & 1) << 5 | (X & 1) << 4
+          | (Y & 2) << 2 | (X & 2) << 1
+          | (Y & 4) >> 1 | (X & 4) >> 2;
+
+    // Scale that dither to [0,1), then (-0.5,+0.5), here using 63/128 = 0.4921875 as 0.5-epsilon.
+    // We want to make sure our dither is less than 0.5 in either direction to keep exact values
+    // like 0 and 1 unchanged after rounding.
+    F dither = cast(M) * (2/128.0f) - (63/128.0f);
+
+    r += *rate*dither;
+    g += *rate*dither;
+    b += *rate*dither;
+
+    r = max(0, min(r, a));
+    g = max(0, min(g, a));
+    b = max(0, min(b, a));
+}
+
+// load 4 floats from memory, and splat them into r,g,b,a
+STAGE(uniform_color, const SkJumper_UniformColorCtx* c) {
+    r = c->r;
+    g = c->g;
+    b = c->b;
+    a = c->a;
+}
+
+// splats opaque-black into r,g,b,a
+STAGE(black_color, Ctx::None) {
+    r = g = b = 0.0f;
+    a = 1.0f;
+}
+
+STAGE(white_color, Ctx::None) {
+    r = g = b = a = 1.0f;
+}
+
+// load registers r,g,b,a from context (mirrors store_rgba)
+STAGE(load_rgba, const float* ptr) {
+    r = unaligned_load<F>(ptr + 0*N);
+    g = unaligned_load<F>(ptr + 1*N);
+    b = unaligned_load<F>(ptr + 2*N);
+    a = unaligned_load<F>(ptr + 3*N);
+}
+
+// store registers r,g,b,a into context (mirrors load_rgba)
+STAGE(store_rgba, float* ptr) {
+    unaligned_store(ptr + 0*N, r);
+    unaligned_store(ptr + 1*N, g);
+    unaligned_store(ptr + 2*N, b);
+    unaligned_store(ptr + 3*N, a);
+}
+
+// Most blend modes apply the same logic to each channel.
+#define BLEND_MODE(name)                       \
+    SI F name##_channel(F s, F d, F sa, F da); \
+    STAGE(name, Ctx::None) {                   \
+        r = name##_channel(r,dr,a,da);         \
+        g = name##_channel(g,dg,a,da);         \
+        b = name##_channel(b,db,a,da);         \
+        a = name##_channel(a,da,a,da);         \
+    }                                          \
+    SI F name##_channel(F s, F d, F sa, F da)
+
+SI F inv(F x) { return 1.0f - x; }
+SI F two(F x) { return x + x; }
+
+
+BLEND_MODE(clear)    { return 0; }
+BLEND_MODE(srcatop)  { return s*da + d*inv(sa); }
+BLEND_MODE(dstatop)  { return d*sa + s*inv(da); }
+BLEND_MODE(srcin)    { return s * da; }
+BLEND_MODE(dstin)    { return d * sa; }
+BLEND_MODE(srcout)   { return s * inv(da); }
+BLEND_MODE(dstout)   { return d * inv(sa); }
+BLEND_MODE(srcover)  { return mad(d, inv(sa), s); }
+BLEND_MODE(dstover)  { return mad(s, inv(da), d); }
+
+BLEND_MODE(modulate) { return s*d; }
+BLEND_MODE(multiply) { return s*inv(da) + d*inv(sa) + s*d; }
+BLEND_MODE(plus_)    { return min(s + d, 1.0f); }  // We can clamp to either 1 or sa.
+BLEND_MODE(screen)   { return s + d - s*d; }
+BLEND_MODE(xor_)     { return s*inv(da) + d*inv(sa); }
+#undef BLEND_MODE
+
+// Most other blend modes apply the same logic to colors, and srcover to alpha.
+#define BLEND_MODE(name)                       \
+    SI F name##_channel(F s, F d, F sa, F da); \
+    STAGE(name, Ctx::None) {                   \
+        r = name##_channel(r,dr,a,da);         \
+        g = name##_channel(g,dg,a,da);         \
+        b = name##_channel(b,db,a,da);         \
+        a = mad(da, inv(a), a);                \
+    }                                          \
+    SI F name##_channel(F s, F d, F sa, F da)
+
+BLEND_MODE(darken)     { return s + d -     max(s*da, d*sa) ; }
+BLEND_MODE(lighten)    { return s + d -     min(s*da, d*sa) ; }
+BLEND_MODE(difference) { return s + d - two(min(s*da, d*sa)); }
+BLEND_MODE(exclusion)  { return s + d - two(s*d); }
+
+BLEND_MODE(colorburn) {
+    return if_then_else(d == da,    d +    s*inv(da),
+           if_then_else(s ==  0, /* s + */ d*inv(sa),
+                                 sa*(da - min(da, (da-d)*sa*rcp(s))) + s*inv(da) + d*inv(sa)));
+}
+BLEND_MODE(colordodge) {
+    return if_then_else(d ==  0, /* d + */ s*inv(da),
+           if_then_else(s == sa,    s +    d*inv(sa),
+                                 sa*min(da, (d*sa)*rcp(sa - s)) + s*inv(da) + d*inv(sa)));
+}
+BLEND_MODE(hardlight) {
+    return s*inv(da) + d*inv(sa)
+         + if_then_else(two(s) <= sa, two(s*d), sa*da - two((da-d)*(sa-s)));
+}
+BLEND_MODE(overlay) {
+    return s*inv(da) + d*inv(sa)
+         + if_then_else(two(d) <= da, two(s*d), sa*da - two((da-d)*(sa-s)));
+}
+
+BLEND_MODE(softlight) {
+    F m  = if_then_else(da > 0, d / da, 0),
+      s2 = two(s),
+      m4 = two(two(m));
+
+    // The logic forks three ways:
+    //    1. dark src?
+    //    2. light src, dark dst?
+    //    3. light src, light dst?
+    F darkSrc = d*(sa + (s2 - sa)*(1.0f - m)),     // Used in case 1.
+      darkDst = (m4*m4 + m4)*(m - 1.0f) + 7.0f*m,  // Used in case 2.
+      liteDst = rcp(rsqrt(m)) - m,                 // Used in case 3.
+      liteSrc = d*sa + da*(s2 - sa) * if_then_else(two(two(d)) <= da, darkDst, liteDst); // 2 or 3?
+    return s*inv(da) + d*inv(sa) + if_then_else(s2 <= sa, darkSrc, liteSrc);      // 1 or (2 or 3)?
+}
+#undef BLEND_MODE
+
+// We're basing our implemenation of non-separable blend modes on
+//   https://www.w3.org/TR/compositing-1/#blendingnonseparable.
+// and
+//   https://www.khronos.org/registry/OpenGL/specs/es/3.2/es_spec_3.2.pdf
+// They're equivalent, but ES' math has been better simplified.
+//
+// Anything extra we add beyond that is to make the math work with premul inputs.
+
+SI F max(F r, F g, F b) { return max(r, max(g, b)); }
+SI F min(F r, F g, F b) { return min(r, min(g, b)); }
+
+SI F sat(F r, F g, F b) { return max(r,g,b) - min(r,g,b); }
+SI F lum(F r, F g, F b) { return r*0.30f + g*0.59f + b*0.11f; }
+
+SI void set_sat(F* r, F* g, F* b, F s) {
+    F mn  = min(*r,*g,*b),
+      mx  = max(*r,*g,*b),
+      sat = mx - mn;
+
+    // Map min channel to 0, max channel to s, and scale the middle proportionally.
+    auto scale = [=](F c) {
+        return if_then_else(sat == 0, 0, (c - mn) * s / sat);
+    };
+    *r = scale(*r);
+    *g = scale(*g);
+    *b = scale(*b);
+}
+SI void set_lum(F* r, F* g, F* b, F l) {
+    F diff = l - lum(*r, *g, *b);
+    *r += diff;
+    *g += diff;
+    *b += diff;
+}
+SI void clip_color(F* r, F* g, F* b, F a) {
+    F mn = min(*r, *g, *b),
+      mx = max(*r, *g, *b),
+      l  = lum(*r, *g, *b);
+
+    auto clip = [=](F c) {
+        c = if_then_else(mn >= 0, c, l + (c - l) * (    l) / (l - mn)   );
+        c = if_then_else(mx >  a,    l + (c - l) * (a - l) / (mx - l), c);
+        c = max(c, 0);  // Sometimes without this we may dip just a little negative.
+        return c;
+    };
+    *r = clip(*r);
+    *g = clip(*g);
+    *b = clip(*b);
+}
+
+STAGE(hue, Ctx::None) {
+    F R = r*a,
+      G = g*a,
+      B = b*a;
+
+    set_sat(&R, &G, &B, sat(dr,dg,db)*a);
+    set_lum(&R, &G, &B, lum(dr,dg,db)*a);
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+STAGE(saturation, Ctx::None) {
+    F R = dr*a,
+      G = dg*a,
+      B = db*a;
+
+    set_sat(&R, &G, &B, sat( r, g, b)*da);
+    set_lum(&R, &G, &B, lum(dr,dg,db)* a);  // (This is not redundant.)
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+STAGE(color, Ctx::None) {
+    F R = r*da,
+      G = g*da,
+      B = b*da;
+
+    set_lum(&R, &G, &B, lum(dr,dg,db)*a);
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+STAGE(luminosity, Ctx::None) {
+    F R = dr*a,
+      G = dg*a,
+      B = db*a;
+
+    set_lum(&R, &G, &B, lum(r,g,b)*da);
+    clip_color(&R,&G,&B, a*da);
+
+    r = r*inv(da) + dr*inv(a) + R;
+    g = g*inv(da) + dg*inv(a) + G;
+    b = b*inv(da) + db*inv(a) + B;
+    a = a + da - a*da;
+}
+
+STAGE(srcover_rgba_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 dst = load<U32>(ptr, tail);
+    dr = cast((dst      ) & 0xff);
+    dg = cast((dst >>  8) & 0xff);
+    db = cast((dst >> 16) & 0xff);
+    da = cast((dst >> 24)       );
+    // {dr,dg,db,da} are in [0,255]
+    // { r, g, b, a} are in [0,  1] (but may be out of gamut)
+
+    r = mad(dr, inv(a), r*255.0f);
+    g = mad(dg, inv(a), g*255.0f);
+    b = mad(db, inv(a), b*255.0f);
+    a = mad(da, inv(a), a*255.0f);
+    // { r, g, b, a} are now in [0,255]  (but may be out of gamut)
+
+    // to_unorm() clamps back to gamut.  Scaling by 1 since we're already 255-biased.
+    dst = to_unorm(r, 1, 255)
+        | to_unorm(g, 1, 255) <<  8
+        | to_unorm(b, 1, 255) << 16
+        | to_unorm(a, 1, 255) << 24;
+    store(ptr, dst, tail);
+}
+
+STAGE(srcover_bgra_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 dst = load<U32>(ptr, tail);
+    db = cast((dst      ) & 0xff);
+    dg = cast((dst >>  8) & 0xff);
+    dr = cast((dst >> 16) & 0xff);
+    da = cast((dst >> 24)       );
+    // {dr,dg,db,da} are in [0,255]
+    // { r, g, b, a} are in [0,  1] (but may be out of gamut)
+
+    r = mad(dr, inv(a), r*255.0f);
+    g = mad(dg, inv(a), g*255.0f);
+    b = mad(db, inv(a), b*255.0f);
+    a = mad(da, inv(a), a*255.0f);
+    // { r, g, b, a} are now in [0,255]  (but may be out of gamut)
+
+    // to_unorm() clamps back to gamut.  Scaling by 1 since we're already 255-biased.
+    dst = to_unorm(b, 1, 255)
+        | to_unorm(g, 1, 255) <<  8
+        | to_unorm(r, 1, 255) << 16
+        | to_unorm(a, 1, 255) << 24;
+    store(ptr, dst, tail);
+}
+
+STAGE(clamp_0, Ctx::None) {
+    r = max(r, 0);
+    g = max(g, 0);
+    b = max(b, 0);
+    a = max(a, 0);
+}
+
+STAGE(clamp_1, Ctx::None) {
+    r = min(r, 1.0f);
+    g = min(g, 1.0f);
+    b = min(b, 1.0f);
+    a = min(a, 1.0f);
+}
+
+STAGE(clamp_a, Ctx::None) {
+    a = min(a, 1.0f);
+    r = min(r, a);
+    g = min(g, a);
+    b = min(b, a);
+}
+
+STAGE(clamp_a_dst, Ctx::None) {
+    da = min(da, 1.0f);
+    dr = min(dr, da);
+    dg = min(dg, da);
+    db = min(db, da);
+}
+
+STAGE(set_rgb, const float* rgb) {
+    r = rgb[0];
+    g = rgb[1];
+    b = rgb[2];
+}
+STAGE(swap_rb, Ctx::None) {
+    auto tmp = r;
+    r = b;
+    b = tmp;
+}
+STAGE(invert, Ctx::None) {
+    r = inv(r);
+    g = inv(g);
+    b = inv(b);
+    a = inv(a);
+}
+
+STAGE(move_src_dst, Ctx::None) {
+    dr = r;
+    dg = g;
+    db = b;
+    da = a;
+}
+STAGE(move_dst_src, Ctx::None) {
+    r = dr;
+    g = dg;
+    b = db;
+    a = da;
+}
+
+STAGE(premul, Ctx::None) {
+    r = r * a;
+    g = g * a;
+    b = b * a;
+}
+STAGE(premul_dst, Ctx::None) {
+    dr = dr * da;
+    dg = dg * da;
+    db = db * da;
+}
+STAGE(unpremul, Ctx::None) {
+    float inf = bit_cast<float>(0x7f800000);
+    auto scale = if_then_else(1.0f/a < inf, 1.0f/a, 0);
+    r *= scale;
+    g *= scale;
+    b *= scale;
+}
+
+SI F from_srgb(F s) {
+    auto lo = s * (1/12.92f);
+    auto hi = mad(s*s, mad(s, 0.3000f, 0.6975f), 0.0025f);
+    return if_then_else(s < 0.055f, lo, hi);
+}
+
+STAGE(from_srgb, Ctx::None) {
+    r = from_srgb(r);
+    g = from_srgb(g);
+    b = from_srgb(b);
+}
+STAGE(from_srgb_dst, Ctx::None) {
+    dr = from_srgb(dr);
+    dg = from_srgb(dg);
+    db = from_srgb(db);
+}
+STAGE(to_srgb, Ctx::None) {
+    auto fn = [&](F l) {
+        // We tweak c and d for each instruction set to make sure fn(1) is exactly 1.
+    #if defined(JUMPER_IS_AVX512)
+        const float c = 1.130026340485f,
+                    d = 0.141387879848f;
+    #elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41) || \
+          defined(JUMPER_IS_AVX ) || defined(JUMPER_IS_HSW )
+        const float c = 1.130048394203f,
+                    d = 0.141357362270f;
+    #elif defined(JUMPER_IS_NEON)
+        const float c = 1.129999995232f,
+                    d = 0.141381442547f;
+    #else
+        const float c = 1.129999995232f,
+                    d = 0.141377761960f;
+    #endif
+        F t = rsqrt(l);
+        auto lo = l * 12.92f;
+        auto hi = mad(t, mad(t, -0.0024542345f, 0.013832027f), c)
+                * rcp(d + t);
+        return if_then_else(l < 0.00465985f, lo, hi);
+    };
+    r = fn(r);
+    g = fn(g);
+    b = fn(b);
+}
+
+STAGE(rgb_to_hsl, Ctx::None) {
+    F mx = max(r,g,b),
+      mn = min(r,g,b),
+      d = mx - mn,
+      d_rcp = 1.0f / d;
+
+    F h = (1/6.0f) *
+          if_then_else(mx == mn, 0,
+          if_then_else(mx ==  r, (g-b)*d_rcp + if_then_else(g < b, 6.0f, 0),
+          if_then_else(mx ==  g, (b-r)*d_rcp + 2.0f,
+                                 (r-g)*d_rcp + 4.0f)));
+
+    F l = (mx + mn) * 0.5f;
+    F s = if_then_else(mx == mn, 0,
+                       d / if_then_else(l > 0.5f, 2.0f-mx-mn, mx+mn));
+
+    r = h;
+    g = s;
+    b = l;
+}
+STAGE(hsl_to_rgb, Ctx::None) {
+    F h = r,
+      s = g,
+      l = b;
+
+    F q = l + if_then_else(l >= 0.5f, s - l*s, l*s),
+      p = 2.0f*l - q;
+
+    auto hue_to_rgb = [&](F t) {
+        t = fract(t);
+
+        F r = p;
+        r = if_then_else(t >= 4/6.0f, r, p + (q-p)*(4.0f - 6.0f*t));
+        r = if_then_else(t >= 3/6.0f, r, q);
+        r = if_then_else(t >= 1/6.0f, r, p + (q-p)*(       6.0f*t));
+        return r;
+    };
+
+    r = if_then_else(s == 0, l, hue_to_rgb(h + (1/3.0f)));
+    g = if_then_else(s == 0, l, hue_to_rgb(h           ));
+    b = if_then_else(s == 0, l, hue_to_rgb(h - (1/3.0f)));
+}
+
+// Derive alpha's coverage from rgb coverage and the values of src and dst alpha.
+SI F alpha_coverage_from_rgb_coverage(F a, F da, F cr, F cg, F cb) {
+    return if_then_else(a < da, min(cr,cg,cb)
+                              , max(cr,cg,cb));
+}
+
+STAGE(scale_1_float, const float* c) {
+    r = r * *c;
+    g = g * *c;
+    b = b * *c;
+    a = a * *c;
+}
+STAGE(scale_u8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    auto scales = load<U8>(ptr, tail);
+    auto c = from_byte(scales);
+
+    r = r * c;
+    g = g * c;
+    b = b * c;
+    a = a * c;
+}
+STAGE(scale_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    F cr,cg,cb;
+    from_565(load<U16>(ptr, tail), &cr, &cg, &cb);
+
+    F ca = alpha_coverage_from_rgb_coverage(a,da, cr,cg,cb);
+
+    r = r * cr;
+    g = g * cg;
+    b = b * cb;
+    a = a * ca;
+}
+
+SI F lerp(F from, F to, F t) {
+    return mad(to-from, t, from);
+}
+
+STAGE(lerp_1_float, const float* c) {
+    r = lerp(dr, r, *c);
+    g = lerp(dg, g, *c);
+    b = lerp(db, b, *c);
+    a = lerp(da, a, *c);
+}
+STAGE(lerp_u8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    auto scales = load<U8>(ptr, tail);
+    auto c = from_byte(scales);
+
+    r = lerp(dr, r, c);
+    g = lerp(dg, g, c);
+    b = lerp(db, b, c);
+    a = lerp(da, a, c);
+}
+STAGE(lerp_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    F cr,cg,cb;
+    from_565(load<U16>(ptr, tail), &cr, &cg, &cb);
+
+    F ca = alpha_coverage_from_rgb_coverage(a,da, cr,cg,cb);
+
+    r = lerp(dr, r, cr);
+    g = lerp(dg, g, cg);
+    b = lerp(db, b, cb);
+    a = lerp(da, a, ca);
+}
+
+STAGE(load_tables, const SkJumper_LoadTablesCtx* c) {
+    auto px = load<U32>((const uint32_t*)c->src + dx, tail);
+    r = gather(c->r, (px      ) & 0xff);
+    g = gather(c->g, (px >>  8) & 0xff);
+    b = gather(c->b, (px >> 16) & 0xff);
+    a = cast(        (px >> 24)) * (1/255.0f);
+}
+STAGE(load_tables_u16_be, const SkJumper_LoadTablesCtx* c) {
+    auto ptr = (const uint16_t*)c->src + 4*dx;
+
+    U16 R,G,B,A;
+    load4(ptr, tail, &R,&G,&B,&A);
+
+    // c->src is big-endian, so & 0xff grabs the 8 most signficant bits.
+    r = gather(c->r, expand(R) & 0xff);
+    g = gather(c->g, expand(G) & 0xff);
+    b = gather(c->b, expand(B) & 0xff);
+    a = (1/65535.0f) * cast(expand(bswap(A)));
+}
+STAGE(load_tables_rgb_u16_be, const SkJumper_LoadTablesCtx* c) {
+    auto ptr = (const uint16_t*)c->src + 3*dx;
+
+    U16 R,G,B;
+    load3(ptr, tail, &R,&G,&B);
+
+    // c->src is big-endian, so & 0xff grabs the 8 most signficant bits.
+    r = gather(c->r, expand(R) & 0xff);
+    g = gather(c->g, expand(G) & 0xff);
+    b = gather(c->b, expand(B) & 0xff);
+    a = 1.0f;
+}
+
+STAGE(byte_tables, const void* ctx) {  // TODO: rename Tables SkJumper_ByteTablesCtx
+    struct Tables { const uint8_t *r, *g, *b, *a; };
+    auto tables = (const Tables*)ctx;
+
+    r = from_byte(gather(tables->r, to_unorm(r, 255)));
+    g = from_byte(gather(tables->g, to_unorm(g, 255)));
+    b = from_byte(gather(tables->b, to_unorm(b, 255)));
+    a = from_byte(gather(tables->a, to_unorm(a, 255)));
+}
+
+STAGE(byte_tables_rgb, const void* ctx) {  // TODO: rename Tables SkJumper_ByteTablesRGBCtx
+    struct Tables { const uint8_t *r, *g, *b; int n; };
+    auto tables = (const Tables*)ctx;
+
+    int scale = tables->n - 1;
+    r = from_byte(gather(tables->r, to_unorm(r, scale)));
+    g = from_byte(gather(tables->g, to_unorm(g, scale)));
+    b = from_byte(gather(tables->b, to_unorm(b, scale)));
+}
+
+SI F table(F v, const SkJumper_TableCtx* ctx) {
+    return gather(ctx->table, to_unorm(v, ctx->size - 1));
+}
+STAGE(table_r, const SkJumper_TableCtx* ctx) { r = table(r, ctx); }
+STAGE(table_g, const SkJumper_TableCtx* ctx) { g = table(g, ctx); }
+STAGE(table_b, const SkJumper_TableCtx* ctx) { b = table(b, ctx); }
+STAGE(table_a, const SkJumper_TableCtx* ctx) { a = table(a, ctx); }
+
+SI F parametric(F v, const SkJumper_ParametricTransferFunction* ctx) {
+    F r = if_then_else(v <= ctx->D, mad(ctx->C, v, ctx->F)
+                                  , approx_powf(mad(ctx->A, v, ctx->B), ctx->G) + ctx->E);
+    return min(max(r, 0), 1.0f);  // Clamp to [0,1], with argument order mattering to handle NaN.
+}
+STAGE(parametric_r, const SkJumper_ParametricTransferFunction* ctx) { r = parametric(r, ctx); }
+STAGE(parametric_g, const SkJumper_ParametricTransferFunction* ctx) { g = parametric(g, ctx); }
+STAGE(parametric_b, const SkJumper_ParametricTransferFunction* ctx) { b = parametric(b, ctx); }
+STAGE(parametric_a, const SkJumper_ParametricTransferFunction* ctx) { a = parametric(a, ctx); }
+
+STAGE(gamma, const float* G) {
+    r = approx_powf(r, *G);
+    g = approx_powf(g, *G);
+    b = approx_powf(b, *G);
+}
+STAGE(gamma_dst, const float* G) {
+    dr = approx_powf(dr, *G);
+    dg = approx_powf(dg, *G);
+    db = approx_powf(db, *G);
+}
+
+STAGE(lab_to_xyz, Ctx::None) {
+    F L = r * 100.0f,
+      A = g * 255.0f - 128.0f,
+      B = b * 255.0f - 128.0f;
+
+    F Y = (L + 16.0f) * (1/116.0f),
+      X = Y + A*(1/500.0f),
+      Z = Y - B*(1/200.0f);
+
+    X = if_then_else(X*X*X > 0.008856f, X*X*X, (X - (16/116.0f)) * (1/7.787f));
+    Y = if_then_else(Y*Y*Y > 0.008856f, Y*Y*Y, (Y - (16/116.0f)) * (1/7.787f));
+    Z = if_then_else(Z*Z*Z > 0.008856f, Z*Z*Z, (Z - (16/116.0f)) * (1/7.787f));
+
+    // Adjust to D50 illuminant.
+    r = X * 0.96422f;
+    g = Y           ;
+    b = Z * 0.82521f;
+}
+
+STAGE(load_a8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    r = g = b = 0.0f;
+    a = from_byte(load<U8>(ptr, tail));
+}
+STAGE(load_a8_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    dr = dg = db = 0.0f;
+    da = from_byte(load<U8>(ptr, tail));
+}
+STAGE(gather_a8, const SkJumper_GatherCtx* ctx) {
+    const uint8_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    r = g = b = 0.0f;
+    a = from_byte(gather(ptr, ix));
+}
+STAGE(store_a8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint8_t>(ctx, dx,dy);
+
+    U8 packed = pack(pack(to_unorm(a, 255)));
+    store(ptr, packed, tail);
+}
+
+STAGE(load_g8, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    r = g = b = from_byte(load<U8>(ptr, tail));
+    a = 1.0f;
+}
+STAGE(load_g8_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint8_t>(ctx, dx,dy);
+
+    dr = dg = db = from_byte(load<U8>(ptr, tail));
+    da = 1.0f;
+}
+STAGE(gather_g8, const SkJumper_GatherCtx* ctx) {
+    const uint8_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    r = g = b = from_byte(gather(ptr, ix));
+    a = 1.0f;
+}
+
+STAGE(load_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    from_565(load<U16>(ptr, tail), &r,&g,&b);
+    a = 1.0f;
+}
+STAGE(load_565_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+
+    from_565(load<U16>(ptr, tail), &dr,&dg,&db);
+    da = 1.0f;
+}
+STAGE(gather_565, const SkJumper_GatherCtx* ctx) {
+    const uint16_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_565(gather(ptr, ix), &r,&g,&b);
+    a = 1.0f;
+}
+STAGE(store_565, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint16_t>(ctx, dx,dy);
+
+    U16 px = pack( to_unorm(r, 31) << 11
+                 | to_unorm(g, 63) <<  5
+                 | to_unorm(b, 31)      );
+    store(ptr, px, tail);
+}
+
+STAGE(load_4444, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+    from_4444(load<U16>(ptr, tail), &r,&g,&b,&a);
+}
+STAGE(load_4444_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, dx,dy);
+    from_4444(load<U16>(ptr, tail), &dr,&dg,&db,&da);
+}
+STAGE(gather_4444, const SkJumper_GatherCtx* ctx) {
+    const uint16_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_4444(gather(ptr, ix), &r,&g,&b,&a);
+}
+STAGE(store_4444, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint16_t>(ctx, dx,dy);
+    U16 px = pack( to_unorm(r, 15) << 12
+                 | to_unorm(g, 15) <<  8
+                 | to_unorm(b, 15) <<  4
+                 | to_unorm(a, 15)      );
+    store(ptr, px, tail);
+}
+
+STAGE(load_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &r,&g,&b,&a);
+}
+STAGE(load_8888_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &dr,&dg,&db,&da);
+}
+STAGE(gather_8888, const SkJumper_GatherCtx* ctx) {
+    const uint32_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_8888(gather(ptr, ix), &r,&g,&b,&a);
+}
+STAGE(store_8888, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 px = to_unorm(r, 255)
+           | to_unorm(g, 255) <<  8
+           | to_unorm(b, 255) << 16
+           | to_unorm(a, 255) << 24;
+    store(ptr, px, tail);
+}
+
+STAGE(load_bgra, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &b,&g,&r,&a);
+}
+STAGE(load_bgra_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint32_t>(ctx, dx,dy);
+    from_8888(load<U32>(ptr, tail), &db,&dg,&dr,&da);
+}
+STAGE(gather_bgra, const SkJumper_GatherCtx* ctx) {
+    const uint32_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    from_8888(gather(ptr, ix), &b,&g,&r,&a);
+}
+STAGE(store_bgra, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint32_t>(ctx, dx,dy);
+
+    U32 px = to_unorm(b, 255)
+           | to_unorm(g, 255) <<  8
+           | to_unorm(r, 255) << 16
+           | to_unorm(a, 255) << 24;
+    store(ptr, px, tail);
+}
+
+STAGE(load_f16, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint64_t>(ctx, dx,dy);
+
+    U16 R,G,B,A;
+    load4((const uint16_t*)ptr,tail, &R,&G,&B,&A);
+    r = from_half(R);
+    g = from_half(G);
+    b = from_half(B);
+    a = from_half(A);
+}
+STAGE(load_f16_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint64_t>(ctx, dx,dy);
+
+    U16 R,G,B,A;
+    load4((const uint16_t*)ptr,tail, &R,&G,&B,&A);
+    dr = from_half(R);
+    dg = from_half(G);
+    db = from_half(B);
+    da = from_half(A);
+}
+STAGE(gather_f16, const SkJumper_GatherCtx* ctx) {
+    const uint64_t* ptr;
+    U32 ix = ix_and_ptr(&ptr, ctx, r,g);
+    auto px = gather(ptr, ix);
+
+    U16 R,G,B,A;
+    load4((const uint16_t*)&px,0, &R,&G,&B,&A);
+    r = from_half(R);
+    g = from_half(G);
+    b = from_half(B);
+    a = from_half(A);
+}
+STAGE(store_f16, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint64_t>(ctx, dx,dy);
+    store4((uint16_t*)ptr,tail, to_half(r)
+                              , to_half(g)
+                              , to_half(b)
+                              , to_half(a));
+}
+
+STAGE(load_u16_be, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, 4*dx,dy);
+
+    U16 R,G,B,A;
+    load4(ptr,tail, &R,&G,&B,&A);
+
+    r = (1/65535.0f) * cast(expand(bswap(R)));
+    g = (1/65535.0f) * cast(expand(bswap(G)));
+    b = (1/65535.0f) * cast(expand(bswap(B)));
+    a = (1/65535.0f) * cast(expand(bswap(A)));
+}
+STAGE(load_rgb_u16_be, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const uint16_t>(ctx, 3*dx,dy);
+
+    U16 R,G,B;
+    load3(ptr,tail, &R,&G,&B);
+
+    r = (1/65535.0f) * cast(expand(bswap(R)));
+    g = (1/65535.0f) * cast(expand(bswap(G)));
+    b = (1/65535.0f) * cast(expand(bswap(B)));
+    a = 1.0f;
+}
+STAGE(store_u16_be, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<uint16_t>(ctx, 4*dx,dy);
+
+    U16 R = bswap(pack(to_unorm(r, 65535))),
+        G = bswap(pack(to_unorm(g, 65535))),
+        B = bswap(pack(to_unorm(b, 65535))),
+        A = bswap(pack(to_unorm(a, 65535)));
+
+    store4(ptr,tail, R,G,B,A);
+}
+
+STAGE(load_f32, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const float>(ctx, 4*dx,dy);
+    load4(ptr,tail, &r,&g,&b,&a);
+}
+STAGE(load_f32_dst, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<const float>(ctx, 4*dx,dy);
+    load4(ptr,tail, &dr,&dg,&db,&da);
+}
+STAGE(store_f32, const SkJumper_MemoryCtx* ctx) {
+    auto ptr = ptr_at_xy<float>(ctx, 4*dx,dy);
+    store4(ptr,tail, r,g,b,a);
+}
+
+SI F exclusive_repeat(F v, const SkJumper_TileCtx* ctx) {
+    return v - floor_(v*ctx->invScale)*ctx->scale;
+}
+SI F exclusive_mirror(F v, const SkJumper_TileCtx* ctx) {
+    auto limit = ctx->scale;
+    auto invLimit = ctx->invScale;
+    return abs_( (v-limit) - (limit+limit)*floor_((v-limit)*(invLimit*0.5f)) - limit );
+}
+// Tile x or y to [0,limit) == [0,limit - 1 ulp] (think, sampling from images).
+// The gather stages will hard clamp the output of these stages to [0,limit)...
+// we just need to do the basic repeat or mirroring.
+STAGE(repeat_x, const SkJumper_TileCtx* ctx) { r = exclusive_repeat(r, ctx); }
+STAGE(repeat_y, const SkJumper_TileCtx* ctx) { g = exclusive_repeat(g, ctx); }
+STAGE(mirror_x, const SkJumper_TileCtx* ctx) { r = exclusive_mirror(r, ctx); }
+STAGE(mirror_y, const SkJumper_TileCtx* ctx) { g = exclusive_mirror(g, ctx); }
+
+// Clamp x to [0,1], both sides inclusive (think, gradients).
+// Even repeat and mirror funnel through a clamp to handle bad inputs like +Inf, NaN.
+SI F clamp_01(F v) { return min(max(0, v), 1); }
+
+STAGE( clamp_x_1, Ctx::None) { r = clamp_01(r); }
+STAGE(repeat_x_1, Ctx::None) { r = clamp_01(r - floor_(r)); }
+STAGE(mirror_x_1, Ctx::None) { r = clamp_01(abs_( (r-1.0f) - two(floor_((r-1.0f)*0.5f)) - 1.0f )); }
+
+STAGE(luminance_to_alpha, Ctx::None) {
+    a = r*0.2126f + g*0.7152f + b*0.0722f;
+    r = g = b = 0;
+}
+
+STAGE(matrix_translate, const float* m) {
+    r += m[0];
+    g += m[1];
+}
+STAGE(matrix_scale_translate, const float* m) {
+    r = mad(r,m[0], m[2]);
+    g = mad(g,m[1], m[3]);
+}
+STAGE(matrix_2x3, const float* m) {
+    auto R = mad(r,m[0], mad(g,m[2], m[4])),
+         G = mad(r,m[1], mad(g,m[3], m[5]));
+    r = R;
+    g = G;
+}
+STAGE(matrix_3x4, const float* m) {
+    auto R = mad(r,m[0], mad(g,m[3], mad(b,m[6], m[ 9]))),
+         G = mad(r,m[1], mad(g,m[4], mad(b,m[7], m[10]))),
+         B = mad(r,m[2], mad(g,m[5], mad(b,m[8], m[11])));
+    r = R;
+    g = G;
+    b = B;
+}
+STAGE(matrix_4x5, const float* m) {
+    auto R = mad(r,m[0], mad(g,m[4], mad(b,m[ 8], mad(a,m[12], m[16])))),
+         G = mad(r,m[1], mad(g,m[5], mad(b,m[ 9], mad(a,m[13], m[17])))),
+         B = mad(r,m[2], mad(g,m[6], mad(b,m[10], mad(a,m[14], m[18])))),
+         A = mad(r,m[3], mad(g,m[7], mad(b,m[11], mad(a,m[15], m[19]))));
+    r = R;
+    g = G;
+    b = B;
+    a = A;
+}
+STAGE(matrix_4x3, const float* m) {
+    auto X = r,
+         Y = g;
+
+    r = mad(X, m[0], mad(Y, m[4], m[ 8]));
+    g = mad(X, m[1], mad(Y, m[5], m[ 9]));
+    b = mad(X, m[2], mad(Y, m[6], m[10]));
+    a = mad(X, m[3], mad(Y, m[7], m[11]));
+}
+STAGE(matrix_perspective, const float* m) {
+    // N.B. Unlike the other matrix_ stages, this matrix is row-major.
+    auto R = mad(r,m[0], mad(g,m[1], m[2])),
+         G = mad(r,m[3], mad(g,m[4], m[5])),
+         Z = mad(r,m[6], mad(g,m[7], m[8]));
+    r = R * rcp(Z);
+    g = G * rcp(Z);
+}
+
+SI void gradient_lookup(const SkJumper_GradientCtx* c, U32 idx, F t,
+                        F* r, F* g, F* b, F* a) {
+    F fr, br, fg, bg, fb, bb, fa, ba;
+#if defined(JUMPER_IS_HSW) || defined(JUMPER_IS_AVX512)
+    if (c->stopCount <=8) {
+        fr = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[0]), idx);
+        br = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[0]), idx);
+        fg = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[1]), idx);
+        bg = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[1]), idx);
+        fb = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[2]), idx);
+        bb = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[2]), idx);
+        fa = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->fs[3]), idx);
+        ba = _mm256_permutevar8x32_ps(_mm256_loadu_ps(c->bs[3]), idx);
+    } else
+#endif
+    {
+        fr = gather(c->fs[0], idx);
+        br = gather(c->bs[0], idx);
+        fg = gather(c->fs[1], idx);
+        bg = gather(c->bs[1], idx);
+        fb = gather(c->fs[2], idx);
+        bb = gather(c->bs[2], idx);
+        fa = gather(c->fs[3], idx);
+        ba = gather(c->bs[3], idx);
+    }
+
+    *r = mad(t, fr, br);
+    *g = mad(t, fg, bg);
+    *b = mad(t, fb, bb);
+    *a = mad(t, fa, ba);
+}
+
+STAGE(evenly_spaced_gradient, const SkJumper_GradientCtx* c) {
+    auto t = r;
+    auto idx = trunc_(t * (c->stopCount-1));
+    gradient_lookup(c, idx, t, &r, &g, &b, &a);
+}
+
+STAGE(gradient, const SkJumper_GradientCtx* c) {
+    auto t = r;
+    U32 idx = 0;
+
+    // N.B. The loop starts at 1 because idx 0 is the color to use before the first stop.
+    for (size_t i = 1; i < c->stopCount; i++) {
+        idx += if_then_else(t >= c->ts[i], U32(1), U32(0));
+    }
+
+    gradient_lookup(c, idx, t, &r, &g, &b, &a);
+}
+
+STAGE(evenly_spaced_2_stop_gradient, const void* ctx) {
+    // TODO: Rename Ctx SkJumper_EvenlySpaced2StopGradientCtx.
+    struct Ctx { float f[4], b[4]; };
+    auto c = (const Ctx*)ctx;
+
+    auto t = r;
+    r = mad(t, c->f[0], c->b[0]);
+    g = mad(t, c->f[1], c->b[1]);
+    b = mad(t, c->f[2], c->b[2]);
+    a = mad(t, c->f[3], c->b[3]);
+}
+
+STAGE(xy_to_unit_angle, Ctx::None) {
+    F X = r,
+      Y = g;
+    F xabs = abs_(X),
+      yabs = abs_(Y);
+
+    F slope = min(xabs, yabs)/max(xabs, yabs);
+    F s = slope * slope;
+
+    // Use a 7th degree polynomial to approximate atan.
+    // This was generated using sollya.gforge.inria.fr.
+    // A float optimized polynomial was generated using the following command.
+    // P1 = fpminimax((1/(2*Pi))*atan(x),[|1,3,5,7|],[|24...|],[2^(-40),1],relative);
+    F phi = slope
+             * (0.15912117063999176025390625f     + s
+             * (-5.185396969318389892578125e-2f   + s
+             * (2.476101927459239959716796875e-2f + s
+             * (-7.0547382347285747528076171875e-3f))));
+
+    phi = if_then_else(xabs < yabs, 1.0f/4.0f - phi, phi);
+    phi = if_then_else(X < 0.0f   , 1.0f/2.0f - phi, phi);
+    phi = if_then_else(Y < 0.0f   , 1.0f - phi     , phi);
+    phi = if_then_else(phi != phi , 0              , phi);  // Check for NaN.
+    r = phi;
+}
+
+STAGE(xy_to_radius, Ctx::None) {
+    F X2 = r * r,
+      Y2 = g * g;
+    r = sqrt_(X2 + Y2);
+}
+
+// Please see https://skia.org/dev/design/conical for how our 2pt conical shader works.
+
+STAGE(negate_x, Ctx::None) { r = -r; }
+
+STAGE(xy_to_2pt_conical_strip, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = x + sqrt_(ctx->fP0 - y*y); // ctx->fP0 = r0 * r0
+}
+
+STAGE(xy_to_2pt_conical_focal_on_circle, Ctx::None) {
+    F x = r, y = g, &t = r;
+    t = x + y*y / x; // (x^2 + y^2) / x
+}
+
+STAGE(xy_to_2pt_conical_well_behaved, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = sqrt_(x*x + y*y) - x * ctx->fP0; // ctx->fP0 = 1/r1
+}
+
+STAGE(xy_to_2pt_conical_greater, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = sqrt_(x*x - y*y) - x * ctx->fP0; // ctx->fP0 = 1/r1
+}
+
+STAGE(xy_to_2pt_conical_smaller, const SkJumper_2PtConicalCtx* ctx) {
+    F x = r, y = g, &t = r;
+    t = -sqrt_(x*x - y*y) - x * ctx->fP0; // ctx->fP0 = 1/r1
+}
+
+STAGE(alter_2pt_conical_compensate_focal, const SkJumper_2PtConicalCtx* ctx) {
+    F& t = r;
+    t = t + ctx->fP1; // ctx->fP1 = f
+}
+
+STAGE(alter_2pt_conical_unswap, Ctx::None) {
+    F& t = r;
+    t = 1 - t;
+}
+
+STAGE(mask_2pt_conical_nan, SkJumper_2PtConicalCtx* c) {
+    F& t = r;
+    auto is_degenerate = (t != t); // NaN
+    t = if_then_else(is_degenerate, F(0), t);
+    unaligned_store(&c->fMask, if_then_else(is_degenerate, U32(0), U32(0xffffffff)));
+}
+
+STAGE(mask_2pt_conical_degenerates, SkJumper_2PtConicalCtx* c) {
+    F& t = r;
+    auto is_degenerate = (t <= 0) | (t != t);
+    t = if_then_else(is_degenerate, F(0), t);
+    unaligned_store(&c->fMask, if_then_else(is_degenerate, U32(0), U32(0xffffffff)));
+}
+
+STAGE(apply_vector_mask, const uint32_t* ctx) {
+    const U32 mask = unaligned_load<U32>(ctx);
+    r = bit_cast<F>(bit_cast<U32>(r) & mask);
+    g = bit_cast<F>(bit_cast<U32>(g) & mask);
+    b = bit_cast<F>(bit_cast<U32>(b) & mask);
+    a = bit_cast<F>(bit_cast<U32>(a) & mask);
+}
+
+STAGE(save_xy, SkJumper_SamplerCtx* c) {
+    // Whether bilinear or bicubic, all sample points are at the same fractional offset (fx,fy).
+    // They're either the 4 corners of a logical 1x1 pixel or the 16 corners of a 3x3 grid
+    // surrounding (x,y) at (0.5,0.5) off-center.
+    F fx = fract(r + 0.5f),
+      fy = fract(g + 0.5f);
+
+    // Samplers will need to load x and fx, or y and fy.
+    unaligned_store(c->x,  r);
+    unaligned_store(c->y,  g);
+    unaligned_store(c->fx, fx);
+    unaligned_store(c->fy, fy);
+}
+
+STAGE(accumulate, const SkJumper_SamplerCtx* c) {
+    // Bilinear and bicubic filters are both separable, so we produce independent contributions
+    // from x and y, multiplying them together here to get each pixel's total scale factor.
+    auto scale = unaligned_load<F>(c->scalex)
+               * unaligned_load<F>(c->scaley);
+    dr = mad(scale, r, dr);
+    dg = mad(scale, g, dg);
+    db = mad(scale, b, db);
+    da = mad(scale, a, da);
+}
+
+// In bilinear interpolation, the 4 pixels at +/- 0.5 offsets from the sample pixel center
+// are combined in direct proportion to their area overlapping that logical query pixel.
+// At positive offsets, the x-axis contribution to that rectangle is fx, or (1-fx) at negative x.
+// The y-axis is symmetric.
+
+template <int kScale>
+SI void bilinear_x(SkJumper_SamplerCtx* ctx, F* x) {
+    *x = unaligned_load<F>(ctx->x) + (kScale * 0.5f);
+    F fx = unaligned_load<F>(ctx->fx);
+
+    F scalex;
+    if (kScale == -1) { scalex = 1.0f - fx; }
+    if (kScale == +1) { scalex =        fx; }
+    unaligned_store(ctx->scalex, scalex);
+}
+template <int kScale>
+SI void bilinear_y(SkJumper_SamplerCtx* ctx, F* y) {
+    *y = unaligned_load<F>(ctx->y) + (kScale * 0.5f);
+    F fy = unaligned_load<F>(ctx->fy);
+
+    F scaley;
+    if (kScale == -1) { scaley = 1.0f - fy; }
+    if (kScale == +1) { scaley =        fy; }
+    unaligned_store(ctx->scaley, scaley);
+}
+
+STAGE(bilinear_nx, SkJumper_SamplerCtx* ctx) { bilinear_x<-1>(ctx, &r); }
+STAGE(bilinear_px, SkJumper_SamplerCtx* ctx) { bilinear_x<+1>(ctx, &r); }
+STAGE(bilinear_ny, SkJumper_SamplerCtx* ctx) { bilinear_y<-1>(ctx, &g); }
+STAGE(bilinear_py, SkJumper_SamplerCtx* ctx) { bilinear_y<+1>(ctx, &g); }
+
+
+// In bicubic interpolation, the 16 pixels and +/- 0.5 and +/- 1.5 offsets from the sample
+// pixel center are combined with a non-uniform cubic filter, with higher values near the center.
+//
+// We break this function into two parts, one for near 0.5 offsets and one for far 1.5 offsets.
+// See GrCubicEffect for details of this particular filter.
+
+SI F bicubic_near(F t) {
+    // 1/18 + 9/18t + 27/18t^2 - 21/18t^3 == t ( t ( -21/18t + 27/18) + 9/18) + 1/18
+    return mad(t, mad(t, mad((-21/18.0f), t, (27/18.0f)), (9/18.0f)), (1/18.0f));
+}
+SI F bicubic_far(F t) {
+    // 0/18 + 0/18*t - 6/18t^2 + 7/18t^3 == t^2 (7/18t - 6/18)
+    return (t*t)*mad((7/18.0f), t, (-6/18.0f));
+}
+
+template <int kScale>
+SI void bicubic_x(SkJumper_SamplerCtx* ctx, F* x) {
+    *x = unaligned_load<F>(ctx->x) + (kScale * 0.5f);
+    F fx = unaligned_load<F>(ctx->fx);
+
+    F scalex;
+    if (kScale == -3) { scalex = bicubic_far (1.0f - fx); }
+    if (kScale == -1) { scalex = bicubic_near(1.0f - fx); }
+    if (kScale == +1) { scalex = bicubic_near(       fx); }
+    if (kScale == +3) { scalex = bicubic_far (       fx); }
+    unaligned_store(ctx->scalex, scalex);
+}
+template <int kScale>
+SI void bicubic_y(SkJumper_SamplerCtx* ctx, F* y) {
+    *y = unaligned_load<F>(ctx->y) + (kScale * 0.5f);
+    F fy = unaligned_load<F>(ctx->fy);
+
+    F scaley;
+    if (kScale == -3) { scaley = bicubic_far (1.0f - fy); }
+    if (kScale == -1) { scaley = bicubic_near(1.0f - fy); }
+    if (kScale == +1) { scaley = bicubic_near(       fy); }
+    if (kScale == +3) { scaley = bicubic_far (       fy); }
+    unaligned_store(ctx->scaley, scaley);
+}
+
+STAGE(bicubic_n3x, SkJumper_SamplerCtx* ctx) { bicubic_x<-3>(ctx, &r); }
+STAGE(bicubic_n1x, SkJumper_SamplerCtx* ctx) { bicubic_x<-1>(ctx, &r); }
+STAGE(bicubic_p1x, SkJumper_SamplerCtx* ctx) { bicubic_x<+1>(ctx, &r); }
+STAGE(bicubic_p3x, SkJumper_SamplerCtx* ctx) { bicubic_x<+3>(ctx, &r); }
+
+STAGE(bicubic_n3y, SkJumper_SamplerCtx* ctx) { bicubic_y<-3>(ctx, &g); }
+STAGE(bicubic_n1y, SkJumper_SamplerCtx* ctx) { bicubic_y<-1>(ctx, &g); }
+STAGE(bicubic_p1y, SkJumper_SamplerCtx* ctx) { bicubic_y<+1>(ctx, &g); }
+STAGE(bicubic_p3y, SkJumper_SamplerCtx* ctx) { bicubic_y<+3>(ctx, &g); }
+
+STAGE(callback, SkJumper_CallbackCtx* c) {
+    store4(c->rgba,0, r,g,b,a);
+    c->fn(c, tail ? tail : N);
+    load4(c->read_from,0, &r,&g,&b,&a);
+}
+
+// Our general strategy is to recursively interpolate each dimension,
+// accumulating the index to sample at, and our current pixel stride to help accumulate the index.
+template <int dim>
+SI void color_lookup_table(const SkJumper_ColorLookupTableCtx* ctx,
+                           F& r, F& g, F& b, F a, U32 index, U32 stride) {
+    // We'd logically like to sample this dimension at x.
+    int limit = ctx->limits[dim-1];
+    F src;
+    switch(dim) {
+        case 1: src = r; break;
+        case 2: src = g; break;
+        case 3: src = b; break;
+        case 4: src = a; break;
+    }
+    F x = src * (limit - 1);
+
+    // We can't index an array by a float (darn) so we have to snap to nearby integers lo and hi.
+    U32 lo = trunc_(x          ),
+        hi = trunc_(x + 0.9999f);
+
+    // Recursively sample at lo and hi.
+    F lr = r, lg = g, lb = b,
+      hr = r, hg = g, hb = b;
+    color_lookup_table<dim-1>(ctx, lr,lg,lb,a, stride*lo + index, stride*limit);
+    color_lookup_table<dim-1>(ctx, hr,hg,hb,a, stride*hi + index, stride*limit);
+
+    // Linearly interpolate those colors based on their distance to x.
+    F t = x - cast(lo);
+    r = lerp(lr, hr, t);
+    g = lerp(lg, hg, t);
+    b = lerp(lb, hb, t);
+}
+
+// Bottom out our recursion at 0 dimensions, i.e. just return the colors at index.
+template<>
+inline void color_lookup_table<0>(const SkJumper_ColorLookupTableCtx* ctx,
+                                  F& r, F& g, F& b, F a, U32 index, U32 stride) {
+    r = gather(ctx->table, 3*index+0);
+    g = gather(ctx->table, 3*index+1);
+    b = gather(ctx->table, 3*index+2);
+}
+
+STAGE(clut_3D, const SkJumper_ColorLookupTableCtx* ctx) {
+    color_lookup_table<3>(ctx, r,g,b,a, 0,1);
+    // This 3D color lookup table leaves alpha alone.
+}
+STAGE(clut_4D, const SkJumper_ColorLookupTableCtx* ctx) {
+    color_lookup_table<4>(ctx, r,g,b,a, 0,1);
+    // "a" was really CMYK's K, so we just set alpha opaque.
+    a = 1.0f;
+}
+
+STAGE(gauss_a_to_rgba, Ctx::None) {
+    // x = 1 - x;
+    // exp(-x * x * 4) - 0.018f;
+    // ... now approximate with quartic
+    //
+    const float c4 = -2.26661229133605957031f;
+    const float c3 = 2.89795351028442382812f;
+    const float c2 = 0.21345567703247070312f;
+    const float c1 = 0.15489584207534790039f;
+    const float c0 = 0.00030726194381713867f;
+    a = mad(a, mad(a, mad(a, mad(a, c4, c3), c2), c1), c0);
+    r = a;
+    g = a;
+    b = a;
+}
+
+// A specialized fused image shader for clamp-x, clamp-y, non-sRGB sampling.
+STAGE(bilerp_clamp_8888, SkJumper_GatherCtx* ctx) {
+    // (cx,cy) are the center of our sample.
+    F cx = r,
+      cy = g;
+
+    // All sample points are at the same fractional offset (fx,fy).
+    // They're the 4 corners of a logical 1x1 pixel surrounding (x,y) at (0.5,0.5) offsets.
+    F fx = fract(cx + 0.5f),
+      fy = fract(cy + 0.5f);
+
+    // We'll accumulate the color of all four samples into {r,g,b,a} directly.
+    r = g = b = a = 0;
+
+    for (float dy = -0.5f; dy <= +0.5f; dy += 1.0f)
+    for (float dx = -0.5f; dx <= +0.5f; dx += 1.0f) {
+        // (x,y) are the coordinates of this sample point.
+        F x = cx + dx,
+          y = cy + dy;
+
+        // ix_and_ptr() will clamp to the image's bounds for us.
+        const uint32_t* ptr;
+        U32 ix = ix_and_ptr(&ptr, ctx, x,y);
+
+        F sr,sg,sb,sa;
+        from_8888(gather(ptr, ix), &sr,&sg,&sb,&sa);
+
+        // In bilinear interpolation, the 4 pixels at +/- 0.5 offsets from the sample pixel center
+        // are combined in direct proportion to their area overlapping that logical query pixel.
+        // At positive offsets, the x-axis contribution to that rectangle is fx,
+        // or (1-fx) at negative x.  Same deal for y.
+        F sx = (dx > 0) ? fx : 1.0f - fx,
+          sy = (dy > 0) ? fy : 1.0f - fy,
+          area = sx * sy;
+
+        r += sr * area;
+        g += sg * area;
+        b += sb * area;
+        a += sa * area;
+    }
+}
diff -Naur chromium-65.0.3325.181-orig/third_party/webgl/src/specs/latest/2.0/webgl2.idl chromium-65.0.3325.181.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl
--- chromium-65.0.3325.181-orig/third_party/webgl/src/specs/latest/2.0/webgl2.idl	2018-03-21 01:06:55.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl	2018-04-27 11:31:20.463829613 +0300
@@ -263,7 +263,7 @@
   const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES          = 0x8A43;
   const GLenum UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER     = 0x8A44;
   const GLenum UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER   = 0x8A46;
-  const GLenum INVALID_INDEX                                 = 0xFFFFFFFF;
+  const GLenum INVALID_INDEX                                 = 256;
   const GLenum MAX_VERTEX_OUTPUT_COMPONENTS                  = 0x9122;
   const GLenum MAX_FRAGMENT_INPUT_COMPONENTS                 = 0x9125;
   const GLenum MAX_SERVER_WAIT_TIMEOUT                       = 0x9111;
diff -Naur chromium-65.0.3325.181-orig/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5 chromium-65.0.3325.181.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5
--- chromium-65.0.3325.181-orig/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/webgl/src/specs/latest/2.0/webgl2.idl.gcc5	2018-03-21 01:06:55.000000000 +0300
@@ -0,0 +1,581 @@
+// AUTOGENERATED FILE -- DO NOT EDIT -- SEE Makefile
+//
+// WebGL IDL definitions scraped from the Khronos specification:
+// https://www.khronos.org/registry/webgl/specs/latest/
+//
+// This IDL depends on the typed array specification defined at:
+// https://www.khronos.org/registry/typedarray/specs/latest/typedarrays.idl
+
+typedef long long GLint64;
+typedef unsigned long long GLuint64;
+
+
+interface WebGLQuery : WebGLObject {
+};
+
+interface WebGLSampler : WebGLObject {
+};
+
+interface WebGLSync : WebGLObject {
+};
+
+interface WebGLTransformFeedback : WebGLObject {
+};
+
+interface WebGLVertexArrayObject : WebGLObject {
+};
+
+typedef ([AllowShared] Uint32Array or sequence<GLuint>) Uint32List;
+
+[NoInterfaceObject]
+interface WebGL2RenderingContextBase
+{
+  const GLenum READ_BUFFER                                   = 0x0C02;
+  const GLenum UNPACK_ROW_LENGTH                             = 0x0CF2;
+  const GLenum UNPACK_SKIP_ROWS                              = 0x0CF3;
+  const GLenum UNPACK_SKIP_PIXELS                            = 0x0CF4;
+  const GLenum PACK_ROW_LENGTH                               = 0x0D02;
+  const GLenum PACK_SKIP_ROWS                                = 0x0D03;
+  const GLenum PACK_SKIP_PIXELS                              = 0x0D04;
+  const GLenum COLOR                                         = 0x1800;
+  const GLenum DEPTH                                         = 0x1801;
+  const GLenum STENCIL                                       = 0x1802;
+  const GLenum RED                                           = 0x1903;
+  const GLenum RGB8                                          = 0x8051;
+  const GLenum RGBA8                                         = 0x8058;
+  const GLenum RGB10_A2                                      = 0x8059;
+  const GLenum TEXTURE_BINDING_3D                            = 0x806A;
+  const GLenum UNPACK_SKIP_IMAGES                            = 0x806D;
+  const GLenum UNPACK_IMAGE_HEIGHT                           = 0x806E;
+  const GLenum TEXTURE_3D                                    = 0x806F;
+  const GLenum TEXTURE_WRAP_R                                = 0x8072;
+  const GLenum MAX_3D_TEXTURE_SIZE                           = 0x8073;
+  const GLenum UNSIGNED_INT_2_10_10_10_REV                   = 0x8368;
+  const GLenum MAX_ELEMENTS_VERTICES                         = 0x80E8;
+  const GLenum MAX_ELEMENTS_INDICES                          = 0x80E9;
+  const GLenum TEXTURE_MIN_LOD                               = 0x813A;
+  const GLenum TEXTURE_MAX_LOD                               = 0x813B;
+  const GLenum TEXTURE_BASE_LEVEL                            = 0x813C;
+  const GLenum TEXTURE_MAX_LEVEL                             = 0x813D;
+  const GLenum MIN                                           = 0x8007;
+  const GLenum MAX                                           = 0x8008;
+  const GLenum DEPTH_COMPONENT24                             = 0x81A6;
+  const GLenum MAX_TEXTURE_LOD_BIAS                          = 0x84FD;
+  const GLenum TEXTURE_COMPARE_MODE                          = 0x884C;
+  const GLenum TEXTURE_COMPARE_FUNC                          = 0x884D;
+  const GLenum CURRENT_QUERY                                 = 0x8865;
+  const GLenum QUERY_RESULT                                  = 0x8866;
+  const GLenum QUERY_RESULT_AVAILABLE                        = 0x8867;
+  const GLenum STREAM_READ                                   = 0x88E1;
+  const GLenum STREAM_COPY                                   = 0x88E2;
+  const GLenum STATIC_READ                                   = 0x88E5;
+  const GLenum STATIC_COPY                                   = 0x88E6;
+  const GLenum DYNAMIC_READ                                  = 0x88E9;
+  const GLenum DYNAMIC_COPY                                  = 0x88EA;
+  const GLenum MAX_DRAW_BUFFERS                              = 0x8824;
+  const GLenum DRAW_BUFFER0                                  = 0x8825;
+  const GLenum DRAW_BUFFER1                                  = 0x8826;
+  const GLenum DRAW_BUFFER2                                  = 0x8827;
+  const GLenum DRAW_BUFFER3                                  = 0x8828;
+  const GLenum DRAW_BUFFER4                                  = 0x8829;
+  const GLenum DRAW_BUFFER5                                  = 0x882A;
+  const GLenum DRAW_BUFFER6                                  = 0x882B;
+  const GLenum DRAW_BUFFER7                                  = 0x882C;
+  const GLenum DRAW_BUFFER8                                  = 0x882D;
+  const GLenum DRAW_BUFFER9                                  = 0x882E;
+  const GLenum DRAW_BUFFER10                                 = 0x882F;
+  const GLenum DRAW_BUFFER11                                 = 0x8830;
+  const GLenum DRAW_BUFFER12                                 = 0x8831;
+  const GLenum DRAW_BUFFER13                                 = 0x8832;
+  const GLenum DRAW_BUFFER14                                 = 0x8833;
+  const GLenum DRAW_BUFFER15                                 = 0x8834;
+  const GLenum MAX_FRAGMENT_UNIFORM_COMPONENTS               = 0x8B49;
+  const GLenum MAX_VERTEX_UNIFORM_COMPONENTS                 = 0x8B4A;
+  const GLenum SAMPLER_3D                                    = 0x8B5F;
+  const GLenum SAMPLER_2D_SHADOW                             = 0x8B62;
+  const GLenum FRAGMENT_SHADER_DERIVATIVE_HINT               = 0x8B8B;
+  const GLenum PIXEL_PACK_BUFFER                             = 0x88EB;
+  const GLenum PIXEL_UNPACK_BUFFER                           = 0x88EC;
+  const GLenum PIXEL_PACK_BUFFER_BINDING                     = 0x88ED;
+  const GLenum PIXEL_UNPACK_BUFFER_BINDING                   = 0x88EF;
+  const GLenum FLOAT_MAT2x3                                  = 0x8B65;
+  const GLenum FLOAT_MAT2x4                                  = 0x8B66;
+  const GLenum FLOAT_MAT3x2                                  = 0x8B67;
+  const GLenum FLOAT_MAT3x4                                  = 0x8B68;
+  const GLenum FLOAT_MAT4x2                                  = 0x8B69;
+  const GLenum FLOAT_MAT4x3                                  = 0x8B6A;
+  const GLenum SRGB                                          = 0x8C40;
+  const GLenum SRGB8                                         = 0x8C41;
+  const GLenum SRGB8_ALPHA8                                  = 0x8C43;
+  const GLenum COMPARE_REF_TO_TEXTURE                        = 0x884E;
+  const GLenum RGBA32F                                       = 0x8814;
+  const GLenum RGB32F                                        = 0x8815;
+  const GLenum RGBA16F                                       = 0x881A;
+  const GLenum RGB16F                                        = 0x881B;
+  const GLenum VERTEX_ATTRIB_ARRAY_INTEGER                   = 0x88FD;
+  const GLenum MAX_ARRAY_TEXTURE_LAYERS                      = 0x88FF;
+  const GLenum MIN_PROGRAM_TEXEL_OFFSET                      = 0x8904;
+  const GLenum MAX_PROGRAM_TEXEL_OFFSET                      = 0x8905;
+  const GLenum MAX_VARYING_COMPONENTS                        = 0x8B4B;
+  const GLenum TEXTURE_2D_ARRAY                              = 0x8C1A;
+  const GLenum TEXTURE_BINDING_2D_ARRAY                      = 0x8C1D;
+  const GLenum R11F_G11F_B10F                                = 0x8C3A;
+  const GLenum UNSIGNED_INT_10F_11F_11F_REV                  = 0x8C3B;
+  const GLenum RGB9_E5                                       = 0x8C3D;
+  const GLenum UNSIGNED_INT_5_9_9_9_REV                      = 0x8C3E;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_MODE                = 0x8C7F;
+  const GLenum MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS    = 0x8C80;
+  const GLenum TRANSFORM_FEEDBACK_VARYINGS                   = 0x8C83;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_START               = 0x8C84;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_SIZE                = 0x8C85;
+  const GLenum TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN         = 0x8C88;
+  const GLenum RASTERIZER_DISCARD                            = 0x8C89;
+  const GLenum MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS = 0x8C8A;
+  const GLenum MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS       = 0x8C8B;
+  const GLenum INTERLEAVED_ATTRIBS                           = 0x8C8C;
+  const GLenum SEPARATE_ATTRIBS                              = 0x8C8D;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER                     = 0x8C8E;
+  const GLenum TRANSFORM_FEEDBACK_BUFFER_BINDING             = 0x8C8F;
+  const GLenum RGBA32UI                                      = 0x8D70;
+  const GLenum RGB32UI                                       = 0x8D71;
+  const GLenum RGBA16UI                                      = 0x8D76;
+  const GLenum RGB16UI                                       = 0x8D77;
+  const GLenum RGBA8UI                                       = 0x8D7C;
+  const GLenum RGB8UI                                        = 0x8D7D;
+  const GLenum RGBA32I                                       = 0x8D82;
+  const GLenum RGB32I                                        = 0x8D83;
+  const GLenum RGBA16I                                       = 0x8D88;
+  const GLenum RGB16I                                        = 0x8D89;
+  const GLenum RGBA8I                                        = 0x8D8E;
+  const GLenum RGB8I                                         = 0x8D8F;
+  const GLenum RED_INTEGER                                   = 0x8D94;
+  const GLenum RGB_INTEGER                                   = 0x8D98;
+  const GLenum RGBA_INTEGER                                  = 0x8D99;
+  const GLenum SAMPLER_2D_ARRAY                              = 0x8DC1;
+  const GLenum SAMPLER_2D_ARRAY_SHADOW                       = 0x8DC4;
+  const GLenum SAMPLER_CUBE_SHADOW                           = 0x8DC5;
+  const GLenum UNSIGNED_INT_VEC2                             = 0x8DC6;
+  const GLenum UNSIGNED_INT_VEC3                             = 0x8DC7;
+  const GLenum UNSIGNED_INT_VEC4                             = 0x8DC8;
+  const GLenum INT_SAMPLER_2D                                = 0x8DCA;
+  const GLenum INT_SAMPLER_3D                                = 0x8DCB;
+  const GLenum INT_SAMPLER_CUBE                              = 0x8DCC;
+  const GLenum INT_SAMPLER_2D_ARRAY                          = 0x8DCF;
+  const GLenum UNSIGNED_INT_SAMPLER_2D                       = 0x8DD2;
+  const GLenum UNSIGNED_INT_SAMPLER_3D                       = 0x8DD3;
+  const GLenum UNSIGNED_INT_SAMPLER_CUBE                     = 0x8DD4;
+  const GLenum UNSIGNED_INT_SAMPLER_2D_ARRAY                 = 0x8DD7;
+  const GLenum DEPTH_COMPONENT32F                            = 0x8CAC;
+  const GLenum DEPTH32F_STENCIL8                             = 0x8CAD;
+  const GLenum FLOAT_32_UNSIGNED_INT_24_8_REV                = 0x8DAD;
+  const GLenum FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING         = 0x8210;
+  const GLenum FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE         = 0x8211;
+  const GLenum FRAMEBUFFER_ATTACHMENT_RED_SIZE               = 0x8212;
+  const GLenum FRAMEBUFFER_ATTACHMENT_GREEN_SIZE             = 0x8213;
+  const GLenum FRAMEBUFFER_ATTACHMENT_BLUE_SIZE              = 0x8214;
+  const GLenum FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE             = 0x8215;
+  const GLenum FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE             = 0x8216;
+  const GLenum FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE           = 0x8217;
+  const GLenum FRAMEBUFFER_DEFAULT                           = 0x8218;
+  const GLenum DEPTH_STENCIL_ATTACHMENT                      = 0x821A;
+  const GLenum DEPTH_STENCIL                                 = 0x84F9;
+  const GLenum UNSIGNED_INT_24_8                             = 0x84FA;
+  const GLenum DEPTH24_STENCIL8                              = 0x88F0;
+  const GLenum UNSIGNED_NORMALIZED                           = 0x8C17;
+  const GLenum DRAW_FRAMEBUFFER_BINDING                      = 0x8CA6; /* Same as FRAMEBUFFER_BINDING */
+  const GLenum READ_FRAMEBUFFER                              = 0x8CA8;
+  const GLenum DRAW_FRAMEBUFFER                              = 0x8CA9;
+  const GLenum READ_FRAMEBUFFER_BINDING                      = 0x8CAA;
+  const GLenum RENDERBUFFER_SAMPLES                          = 0x8CAB;
+  const GLenum FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER          = 0x8CD4;
+  const GLenum MAX_COLOR_ATTACHMENTS                         = 0x8CDF;
+  const GLenum COLOR_ATTACHMENT1                             = 0x8CE1;
+  const GLenum COLOR_ATTACHMENT2                             = 0x8CE2;
+  const GLenum COLOR_ATTACHMENT3                             = 0x8CE3;
+  const GLenum COLOR_ATTACHMENT4                             = 0x8CE4;
+  const GLenum COLOR_ATTACHMENT5                             = 0x8CE5;
+  const GLenum COLOR_ATTACHMENT6                             = 0x8CE6;
+  const GLenum COLOR_ATTACHMENT7                             = 0x8CE7;
+  const GLenum COLOR_ATTACHMENT8                             = 0x8CE8;
+  const GLenum COLOR_ATTACHMENT9                             = 0x8CE9;
+  const GLenum COLOR_ATTACHMENT10                            = 0x8CEA;
+  const GLenum COLOR_ATTACHMENT11                            = 0x8CEB;
+  const GLenum COLOR_ATTACHMENT12                            = 0x8CEC;
+  const GLenum COLOR_ATTACHMENT13                            = 0x8CED;
+  const GLenum COLOR_ATTACHMENT14                            = 0x8CEE;
+  const GLenum COLOR_ATTACHMENT15                            = 0x8CEF;
+  const GLenum FRAMEBUFFER_INCOMPLETE_MULTISAMPLE            = 0x8D56;
+  const GLenum MAX_SAMPLES                                   = 0x8D57;
+  const GLenum HALF_FLOAT                                    = 0x140B;
+  const GLenum RG                                            = 0x8227;
+  const GLenum RG_INTEGER                                    = 0x8228;
+  const GLenum R8                                            = 0x8229;
+  const GLenum RG8                                           = 0x822B;
+  const GLenum R16F                                          = 0x822D;
+  const GLenum R32F                                          = 0x822E;
+  const GLenum RG16F                                         = 0x822F;
+  const GLenum RG32F                                         = 0x8230;
+  const GLenum R8I                                           = 0x8231;
+  const GLenum R8UI                                          = 0x8232;
+  const GLenum R16I                                          = 0x8233;
+  const GLenum R16UI                                         = 0x8234;
+  const GLenum R32I                                          = 0x8235;
+  const GLenum R32UI                                         = 0x8236;
+  const GLenum RG8I                                          = 0x8237;
+  const GLenum RG8UI                                         = 0x8238;
+  const GLenum RG16I                                         = 0x8239;
+  const GLenum RG16UI                                        = 0x823A;
+  const GLenum RG32I                                         = 0x823B;
+  const GLenum RG32UI                                        = 0x823C;
+  const GLenum VERTEX_ARRAY_BINDING                          = 0x85B5;
+  const GLenum R8_SNORM                                      = 0x8F94;
+  const GLenum RG8_SNORM                                     = 0x8F95;
+  const GLenum RGB8_SNORM                                    = 0x8F96;
+  const GLenum RGBA8_SNORM                                   = 0x8F97;
+  const GLenum SIGNED_NORMALIZED                             = 0x8F9C;
+  const GLenum COPY_READ_BUFFER                              = 0x8F36;
+  const GLenum COPY_WRITE_BUFFER                             = 0x8F37;
+  const GLenum COPY_READ_BUFFER_BINDING                      = 0x8F36; /* Same as COPY_READ_BUFFER */
+  const GLenum COPY_WRITE_BUFFER_BINDING                     = 0x8F37; /* Same as COPY_WRITE_BUFFER */
+  const GLenum UNIFORM_BUFFER                                = 0x8A11;
+  const GLenum UNIFORM_BUFFER_BINDING                        = 0x8A28;
+  const GLenum UNIFORM_BUFFER_START                          = 0x8A29;
+  const GLenum UNIFORM_BUFFER_SIZE                           = 0x8A2A;
+  const GLenum MAX_VERTEX_UNIFORM_BLOCKS                     = 0x8A2B;
+  const GLenum MAX_FRAGMENT_UNIFORM_BLOCKS                   = 0x8A2D;
+  const GLenum MAX_COMBINED_UNIFORM_BLOCKS                   = 0x8A2E;
+  const GLenum MAX_UNIFORM_BUFFER_BINDINGS                   = 0x8A2F;
+  const GLenum MAX_UNIFORM_BLOCK_SIZE                        = 0x8A30;
+  const GLenum MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS        = 0x8A31;
+  const GLenum MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS      = 0x8A33;
+  const GLenum UNIFORM_BUFFER_OFFSET_ALIGNMENT               = 0x8A34;
+  const GLenum ACTIVE_UNIFORM_BLOCKS                         = 0x8A36;
+  const GLenum UNIFORM_TYPE                                  = 0x8A37;
+  const GLenum UNIFORM_SIZE                                  = 0x8A38;
+  const GLenum UNIFORM_BLOCK_INDEX                           = 0x8A3A;
+  const GLenum UNIFORM_OFFSET                                = 0x8A3B;
+  const GLenum UNIFORM_ARRAY_STRIDE                          = 0x8A3C;
+  const GLenum UNIFORM_MATRIX_STRIDE                         = 0x8A3D;
+  const GLenum UNIFORM_IS_ROW_MAJOR                          = 0x8A3E;
+  const GLenum UNIFORM_BLOCK_BINDING                         = 0x8A3F;
+  const GLenum UNIFORM_BLOCK_DATA_SIZE                       = 0x8A40;
+  const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORMS                 = 0x8A42;
+  const GLenum UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES          = 0x8A43;
+  const GLenum UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER     = 0x8A44;
+  const GLenum UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER   = 0x8A46;
+  const GLenum INVALID_INDEX                                 = 0xFFFFFFFF;
+  const GLenum MAX_VERTEX_OUTPUT_COMPONENTS                  = 0x9122;
+  const GLenum MAX_FRAGMENT_INPUT_COMPONENTS                 = 0x9125;
+  const GLenum MAX_SERVER_WAIT_TIMEOUT                       = 0x9111;
+  const GLenum OBJECT_TYPE                                   = 0x9112;
+  const GLenum SYNC_CONDITION                                = 0x9113;
+  const GLenum SYNC_STATUS                                   = 0x9114;
+  const GLenum SYNC_FLAGS                                    = 0x9115;
+  const GLenum SYNC_FENCE                                    = 0x9116;
+  const GLenum SYNC_GPU_COMMANDS_COMPLETE                    = 0x9117;
+  const GLenum UNSIGNALED                                    = 0x9118;
+  const GLenum SIGNALED                                      = 0x9119;
+  const GLenum ALREADY_SIGNALED                              = 0x911A;
+  const GLenum TIMEOUT_EXPIRED                               = 0x911B;
+  const GLenum CONDITION_SATISFIED                           = 0x911C;
+  const GLenum WAIT_FAILED                                   = 0x911D;
+  const GLenum SYNC_FLUSH_COMMANDS_BIT                       = 0x00000001;
+  const GLenum VERTEX_ATTRIB_ARRAY_DIVISOR                   = 0x88FE;
+  const GLenum ANY_SAMPLES_PASSED                            = 0x8C2F;
+  const GLenum ANY_SAMPLES_PASSED_CONSERVATIVE               = 0x8D6A;
+  const GLenum SAMPLER_BINDING                               = 0x8919;
+  const GLenum RGB10_A2UI                                    = 0x906F;
+  const GLenum INT_2_10_10_10_REV                            = 0x8D9F;
+  const GLenum TRANSFORM_FEEDBACK                            = 0x8E22;
+  const GLenum TRANSFORM_FEEDBACK_PAUSED                     = 0x8E23;
+  const GLenum TRANSFORM_FEEDBACK_ACTIVE                     = 0x8E24;
+  const GLenum TRANSFORM_FEEDBACK_BINDING                    = 0x8E25;
+  const GLenum TEXTURE_IMMUTABLE_FORMAT                      = 0x912F;
+  const GLenum MAX_ELEMENT_INDEX                             = 0x8D6B;
+  const GLenum TEXTURE_IMMUTABLE_LEVELS                      = 0x82DF;
+
+  const GLint64 TIMEOUT_IGNORED                              = -1;
+
+  /* WebGL-specific enums */
+  const GLenum MAX_CLIENT_WAIT_TIMEOUT_WEBGL                 = 0x9247;
+
+  /* Buffer objects */
+  // WebGL1:
+  void bufferData(GLenum target, GLsizeiptr size, GLenum usage);
+  void bufferData(GLenum target, [AllowShared] BufferSource? srcData, GLenum usage);
+  void bufferSubData(GLenum target, GLintptr dstByteOffset, [AllowShared] BufferSource srcData);
+  // WebGL2:
+  void bufferData(GLenum target, [AllowShared] ArrayBufferView srcData, GLenum usage, GLuint srcOffset,
+                  optional GLuint length = 0);
+  void bufferSubData(GLenum target, GLintptr dstByteOffset, [AllowShared] ArrayBufferView srcData,
+                     GLuint srcOffset, optional GLuint length = 0);
+
+  void copyBufferSubData(GLenum readTarget, GLenum writeTarget, GLintptr readOffset,
+                         GLintptr writeOffset, GLsizeiptr size);
+  // MapBufferRange, in particular its read-only and write-only modes,
+  // can not be exposed safely to JavaScript. GetBufferSubData
+  // replaces it for the purpose of fetching data back from the GPU.
+  void getBufferSubData(GLenum target, GLintptr srcByteOffset, [AllowShared] ArrayBufferView dstBuffer,
+                        optional GLuint dstOffset = 0, optional GLuint length = 0);
+
+  /* Framebuffer objects */
+  void blitFramebuffer(GLint srcX0, GLint srcY0, GLint srcX1, GLint srcY1, GLint dstX0, GLint dstY0,
+                       GLint dstX1, GLint dstY1, GLbitfield mask, GLenum filter);
+  void framebufferTextureLayer(GLenum target, GLenum attachment, WebGLTexture? texture, GLint level,
+                               GLint layer);
+  void invalidateFramebuffer(GLenum target, sequence<GLenum> attachments);
+  void invalidateSubFramebuffer(GLenum target, sequence<GLenum> attachments,
+                                GLint x, GLint y, GLsizei width, GLsizei height);
+  void readBuffer(GLenum src);
+
+  /* Renderbuffer objects */
+  any getInternalformatParameter(GLenum target, GLenum internalformat, GLenum pname);
+  void renderbufferStorageMultisample(GLenum target, GLsizei samples, GLenum internalformat,
+                                      GLsizei width, GLsizei height);
+
+  /* Texture objects */
+  void texStorage2D(GLenum target, GLsizei levels, GLenum internalformat, GLsizei width,
+                    GLsizei height);
+  void texStorage3D(GLenum target, GLsizei levels, GLenum internalformat, GLsizei width,
+                    GLsizei height, GLsizei depth);
+
+  // WebGL1 legacy entrypoints:
+  void texImage2D(GLenum target, GLint level, GLint internalformat,
+                  GLsizei width, GLsizei height, GLint border, GLenum format,
+                  GLenum type, [AllowShared] ArrayBufferView? pixels);
+  void texImage2D(GLenum target, GLint level, GLint internalformat,
+                  GLenum format, GLenum type, TexImageSource source); // May throw DOMException
+
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                     GLsizei width, GLsizei height,
+                     GLenum format, GLenum type, [AllowShared] ArrayBufferView? pixels);
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                     GLenum format, GLenum type, TexImageSource source); // May throw DOMException
+
+  // WebGL2 entrypoints:
+  void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLint border, GLenum format, GLenum type, GLintptr pboOffset);
+  void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLint border, GLenum format, GLenum type,
+                  TexImageSource source); // May throw DOMException
+  void texImage2D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData,
+                  GLuint srcOffset);
+
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type, GLintptr pboOffset);
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type,
+                  TexImageSource source); // May throw DOMException
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView? srcData);
+  void texImage3D(GLenum target, GLint level, GLint internalformat, GLsizei width, GLsizei height,
+                  GLsizei depth, GLint border, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData,
+                  GLuint srcOffset);
+
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width,
+                     GLsizei height, GLenum format, GLenum type, GLintptr pboOffset);
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width,
+                     GLsizei height, GLenum format, GLenum type,
+                     TexImageSource source); // May throw DOMException
+  void texSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLsizei width,
+                     GLsizei height, GLenum format, GLenum type, [AllowShared] ArrayBufferView srcData,
+                     GLuint srcOffset);
+
+  void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                     GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type,
+                     GLintptr pboOffset);
+  void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                     GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type,
+                     TexImageSource source); // May throw DOMException
+  void texSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                     GLsizei width, GLsizei height, GLsizei depth, GLenum format, GLenum type,
+                     [AllowShared] ArrayBufferView? srcData, optional GLuint srcOffset = 0);
+
+  void copyTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset, GLint zoffset,
+                         GLint x, GLint y, GLsizei width, GLsizei height);
+
+  void compressedTexImage2D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLint border, GLsizei imageSize, GLintptr offset);
+  void compressedTexImage2D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLint border, [AllowShared] ArrayBufferView srcData,
+                            optional GLuint srcOffset = 0, optional GLuint srcLengthOverride = 0);
+
+  void compressedTexImage3D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLsizei depth, GLint border, GLsizei imageSize, GLintptr offset);
+  void compressedTexImage3D(GLenum target, GLint level, GLenum internalformat, GLsizei width,
+                            GLsizei height, GLsizei depth, GLint border, [AllowShared] ArrayBufferView srcData,
+                            optional GLuint srcOffset = 0, optional GLuint srcLengthOverride = 0);
+
+  void compressedTexSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLsizei width, GLsizei height, GLenum format, GLsizei imageSize, GLintptr offset);
+  void compressedTexSubImage2D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLsizei width, GLsizei height, GLenum format,
+                               [AllowShared] ArrayBufferView srcData,
+                               optional GLuint srcOffset = 0,
+                               optional GLuint srcLengthOverride = 0);
+
+  void compressedTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLint zoffset, GLsizei width, GLsizei height, GLsizei depth,
+                               GLenum format, GLsizei imageSize, GLintptr offset);
+  void compressedTexSubImage3D(GLenum target, GLint level, GLint xoffset, GLint yoffset,
+                               GLint zoffset, GLsizei width, GLsizei height, GLsizei depth,
+                               GLenum format, [AllowShared] ArrayBufferView srcData,
+                               optional GLuint srcOffset = 0,
+                               optional GLuint srcLengthOverride = 0);
+
+  /* Programs and shaders */
+  [WebGLHandlesContextLoss] GLint getFragDataLocation(WebGLProgram program, DOMString name);
+
+  /* Uniforms */
+  void uniform1ui(WebGLUniformLocation? location, GLuint v0);
+  void uniform2ui(WebGLUniformLocation? location, GLuint v0, GLuint v1);
+  void uniform3ui(WebGLUniformLocation? location, GLuint v0, GLuint v1, GLuint v2);
+  void uniform4ui(WebGLUniformLocation? location, GLuint v0, GLuint v1, GLuint v2, GLuint v3);
+
+  void uniform1fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform2fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform3fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform4fv(WebGLUniformLocation? location, Float32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+
+  void uniform1iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform2iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform3iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform4iv(WebGLUniformLocation? location, Int32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+
+  void uniform1uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform2uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform3uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+  void uniform4uiv(WebGLUniformLocation? location, Uint32List data, optional GLuint srcOffset = 0,
+                  optional GLuint srcLength = 0);
+
+  void uniformMatrix2fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                        optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix3x2fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix4x2fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+
+  void uniformMatrix2x3fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix3fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                        optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix4x3fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+
+  void uniformMatrix2x4fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix3x4fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                          optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+  void uniformMatrix4fv(WebGLUniformLocation? location, GLboolean transpose, Float32List data,
+                        optional GLuint srcOffset = 0, optional GLuint srcLength = 0);
+
+  /* Vertex attribs */
+  void vertexAttribI4i(GLuint index, GLint x, GLint y, GLint z, GLint w);
+  void vertexAttribI4iv(GLuint index, Int32List values);
+  void vertexAttribI4ui(GLuint index, GLuint x, GLuint y, GLuint z, GLuint w);
+  void vertexAttribI4uiv(GLuint index, Uint32List values);
+  void vertexAttribIPointer(GLuint index, GLint size, GLenum type, GLsizei stride, GLintptr offset);
+
+  /* Writing to the drawing buffer */
+  void vertexAttribDivisor(GLuint index, GLuint divisor);
+  void drawArraysInstanced(GLenum mode, GLint first, GLsizei count, GLsizei instanceCount);
+  void drawElementsInstanced(GLenum mode, GLsizei count, GLenum type, GLintptr offset, GLsizei instanceCount);
+  void drawRangeElements(GLenum mode, GLuint start, GLuint end, GLsizei count, GLenum type, GLintptr offset);
+
+  /* Reading back pixels */
+  // WebGL1:
+  void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type,
+                  [AllowShared] ArrayBufferView? dstData);
+  // WebGL2:
+  void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type,
+                  GLintptr offset);
+  void readPixels(GLint x, GLint y, GLsizei width, GLsizei height, GLenum format, GLenum type,
+                  [AllowShared] ArrayBufferView dstData, GLuint dstOffset);
+
+  /* Multiple Render Targets */
+  void drawBuffers(sequence<GLenum> buffers);
+
+  void clearBufferfv(GLenum buffer, GLint drawbuffer, Float32List values,
+                     optional GLuint srcOffset = 0);
+  void clearBufferiv(GLenum buffer, GLint drawbuffer, Int32List values,
+                     optional GLuint srcOffset = 0);
+  void clearBufferuiv(GLenum buffer, GLint drawbuffer, Uint32List values,
+                      optional GLuint srcOffset = 0);
+
+  void clearBufferfi(GLenum buffer, GLint drawbuffer, GLfloat depth, GLint stencil);
+
+  /* Query Objects */
+  WebGLQuery? createQuery();
+  void deleteQuery(WebGLQuery? query);
+  [WebGLHandlesContextLoss] GLboolean isQuery(WebGLQuery? query);
+  void beginQuery(GLenum target, WebGLQuery query);
+  void endQuery(GLenum target);
+  WebGLQuery? getQuery(GLenum target, GLenum pname);
+  any getQueryParameter(WebGLQuery query, GLenum pname);
+
+  /* Sampler Objects */
+  WebGLSampler? createSampler();
+  void deleteSampler(WebGLSampler? sampler);
+  [WebGLHandlesContextLoss] GLboolean isSampler(WebGLSampler? sampler);
+  void bindSampler(GLuint unit, WebGLSampler? sampler);
+  void samplerParameteri(WebGLSampler sampler, GLenum pname, GLint param);
+  void samplerParameterf(WebGLSampler sampler, GLenum pname, GLfloat param);
+  any getSamplerParameter(WebGLSampler sampler, GLenum pname);
+
+  /* Sync objects */
+  WebGLSync? fenceSync(GLenum condition, GLbitfield flags);
+  [WebGLHandlesContextLoss] GLboolean isSync(WebGLSync? sync);
+  void deleteSync(WebGLSync? sync);
+  GLenum clientWaitSync(WebGLSync sync, GLbitfield flags, GLuint64 timeout);
+  void waitSync(WebGLSync sync, GLbitfield flags, GLint64 timeout);
+  any getSyncParameter(WebGLSync sync, GLenum pname);
+
+  /* Transform Feedback */
+  WebGLTransformFeedback? createTransformFeedback();
+  void deleteTransformFeedback(WebGLTransformFeedback? tf);
+  [WebGLHandlesContextLoss] GLboolean isTransformFeedback(WebGLTransformFeedback? tf);
+  void bindTransformFeedback (GLenum target, WebGLTransformFeedback? tf);
+  void beginTransformFeedback(GLenum primitiveMode);
+  void endTransformFeedback();
+  void transformFeedbackVaryings(WebGLProgram program, sequence<DOMString> varyings, GLenum bufferMode);
+  WebGLActiveInfo? getTransformFeedbackVarying(WebGLProgram program, GLuint index);
+  void pauseTransformFeedback();
+  void resumeTransformFeedback();
+
+  /* Uniform Buffer Objects and Transform Feedback Buffers */
+  void bindBufferBase(GLenum target, GLuint index, WebGLBuffer? buffer);
+  void bindBufferRange(GLenum target, GLuint index, WebGLBuffer? buffer, GLintptr offset, GLsizeiptr size);
+  any getIndexedParameter(GLenum target, GLuint index);
+  sequence<GLuint>? getUniformIndices(WebGLProgram program, sequence<DOMString> uniformNames);
+  any getActiveUniforms(WebGLProgram program, sequence<GLuint> uniformIndices, GLenum pname);
+  GLuint getUniformBlockIndex(WebGLProgram program, DOMString uniformBlockName);
+  any getActiveUniformBlockParameter(WebGLProgram program, GLuint uniformBlockIndex, GLenum pname);
+  DOMString? getActiveUniformBlockName(WebGLProgram program, GLuint uniformBlockIndex);
+  void uniformBlockBinding(WebGLProgram program, GLuint uniformBlockIndex, GLuint uniformBlockBinding);
+
+  /* Vertex Array Objects */
+  WebGLVertexArrayObject? createVertexArray();
+  void deleteVertexArray(WebGLVertexArrayObject? vertexArray);
+  [WebGLHandlesContextLoss] GLboolean isVertexArray(WebGLVertexArrayObject? vertexArray);
+  void bindVertexArray(WebGLVertexArrayObject? array);
+};
+WebGL2RenderingContextBase implements WebGLRenderingContextBase;
+
+interface WebGL2RenderingContext
+{
+};
+WebGL2RenderingContext implements WebGL2RenderingContextBase;
+
+
diff -Naur chromium-65.0.3325.181-orig/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc chromium-65.0.3325.181.patched/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc
--- chromium-65.0.3325.181-orig/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc	2018-03-21 01:06:54.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc	2018-04-27 11:31:20.591828267 +0300
@@ -10,7 +10,7 @@
 
 #include "modules/audio_processing/aec3/aec_state.h"
 
-#include <math.h>
+#include <cmath>
 
 #include <numeric>
 #include <vector>
diff -Naur chromium-65.0.3325.181-orig/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc.gcc5-r3 chromium-65.0.3325.181.patched/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc.gcc5-r3
--- chromium-65.0.3325.181-orig/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc.gcc5-r3	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/webrtc/modules/audio_processing/aec3/aec_state.cc.gcc5-r3	2018-03-21 01:06:54.000000000 +0300
@@ -0,0 +1,332 @@
+/*
+ *  Copyright (c) 2017 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "modules/audio_processing/aec3/aec_state.h"
+
+#include <math.h>
+
+#include <numeric>
+#include <vector>
+
+#include "api/array_view.h"
+#include "modules/audio_processing/logging/apm_data_dumper.h"
+#include "rtc_base/atomicops.h"
+#include "rtc_base/checks.h"
+
+namespace webrtc {
+namespace {
+
+// Computes delay of the adaptive filter.
+int EstimateFilterDelay(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>&
+        adaptive_filter_frequency_response) {
+  const auto& H2 = adaptive_filter_frequency_response;
+  constexpr size_t kUpperBin = kFftLengthBy2 - 5;
+  RTC_DCHECK_GE(kMaxAdaptiveFilterLength, H2.size());
+  std::array<int, kMaxAdaptiveFilterLength> delays;
+  delays.fill(0);
+  for (size_t k = 1; k < kUpperBin; ++k) {
+    // Find the maximum of H2[j].
+    size_t peak = 0;
+    for (size_t j = 0; j < H2.size(); ++j) {
+      if (H2[j][k] > H2[peak][k]) {
+        peak = j;
+      }
+    }
+    ++delays[peak];
+  }
+
+  return std::distance(delays.begin(),
+                       std::max_element(delays.begin(), delays.end()));
+}
+
+}  // namespace
+
+int AecState::instance_count_ = 0;
+
+AecState::AecState(const EchoCanceller3Config& config)
+    : data_dumper_(
+          new ApmDataDumper(rtc::AtomicOps::Increment(&instance_count_))),
+      erle_estimator_(config.erle.min, config.erle.max_l, config.erle.max_h),
+      config_(config),
+      max_render_(config_.filter.main.length_blocks, 0.f),
+      reverb_decay_(config_.ep_strength.default_len) {}
+
+AecState::~AecState() = default;
+
+void AecState::HandleEchoPathChange(
+    const EchoPathVariability& echo_path_variability) {
+  const auto full_reset = [&]() {
+    blocks_since_last_saturation_ = 0;
+    usable_linear_estimate_ = false;
+    echo_leakage_detected_ = false;
+    capture_signal_saturation_ = false;
+    echo_saturation_ = false;
+    previous_max_sample_ = 0.f;
+    std::fill(max_render_.begin(), max_render_.end(), 0.f);
+    force_zero_gain_counter_ = 0;
+    blocks_with_proper_filter_adaptation_ = 0;
+    capture_block_counter_ = 0;
+    filter_has_had_time_to_converge_ = false;
+    render_received_ = false;
+    force_zero_gain_ = true;
+    blocks_with_active_render_ = 0;
+    initial_state_ = true;
+  };
+
+  // TODO(peah): Refine the reset scheme according to the type of gain and
+  // delay adjustment.
+  if (echo_path_variability.gain_change) {
+    full_reset();
+  }
+
+  if (echo_path_variability.delay_change !=
+      EchoPathVariability::DelayAdjustment::kBufferReadjustment) {
+    full_reset();
+  } else if (echo_path_variability.delay_change !=
+             EchoPathVariability::DelayAdjustment::kBufferFlush) {
+    full_reset();
+
+  } else if (echo_path_variability.delay_change !=
+             EchoPathVariability::DelayAdjustment::kDelayReset) {
+    full_reset();
+  } else if (echo_path_variability.delay_change !=
+             EchoPathVariability::DelayAdjustment::kNewDetectedDelay) {
+    full_reset();
+  } else if (echo_path_variability.gain_change) {
+    capture_block_counter_ = kNumBlocksPerSecond;
+  }
+}
+
+void AecState::Update(
+    const std::vector<std::array<float, kFftLengthBy2Plus1>>&
+        adaptive_filter_frequency_response,
+    const std::vector<float>& adaptive_filter_impulse_response,
+    bool converged_filter,
+    const RenderBuffer& render_buffer,
+    const std::array<float, kFftLengthBy2Plus1>& E2_main,
+    const std::array<float, kFftLengthBy2Plus1>& Y2,
+    const std::array<float, kBlockSize>& s,
+    bool echo_leakage_detected) {
+  // Store input parameters.
+  echo_leakage_detected_ = echo_leakage_detected;
+
+  // Estimate the filter delay.
+  filter_delay_ = EstimateFilterDelay(adaptive_filter_frequency_response);
+  const std::vector<float>& x = render_buffer.Block(-filter_delay_)[0];
+
+  // Update counters.
+  ++capture_block_counter_;
+  const bool active_render_block = DetectActiveRender(x);
+  blocks_with_active_render_ += active_render_block ? 1 : 0;
+  blocks_with_proper_filter_adaptation_ +=
+      active_render_block && !SaturatedCapture() ? 1 : 0;
+
+  // Force zero echo suppression gain after an echo path change to allow at
+  // least some render data to be collected in order to avoid an initial echo
+  // burst.
+  force_zero_gain_ = ++force_zero_gain_counter_ < kNumBlocksPerSecond / 5;
+
+
+  // Update the ERL and ERLE measures.
+  if (converged_filter && capture_block_counter_ >= 2 * kNumBlocksPerSecond) {
+    const auto& X2 = render_buffer.Spectrum(filter_delay_);
+    erle_estimator_.Update(X2, Y2, E2_main);
+    erl_estimator_.Update(X2, Y2);
+  }
+
+  // Update the echo audibility evaluator.
+  echo_audibility_.Update(x, s, converged_filter);
+
+  // Detect and flag echo saturation.
+  // TODO(peah): Add the delay in this computation to ensure that the render and
+  // capture signals are properly aligned.
+  if (config_.ep_strength.echo_can_saturate) {
+    echo_saturation_ = DetectEchoSaturation(x);
+  }
+
+  // TODO(peah): Move?
+  filter_has_had_time_to_converge_ =
+      blocks_with_proper_filter_adaptation_ >= 1.5f * kNumBlocksPerSecond;
+
+  initial_state_ =
+      blocks_with_proper_filter_adaptation_ < 5 * kNumBlocksPerSecond;
+
+  // Flag whether the linear filter estimate is usable.
+  usable_linear_estimate_ =
+      !echo_saturation_ &&
+      (converged_filter && filter_has_had_time_to_converge_) &&
+      capture_block_counter_ >= 1.f * kNumBlocksPerSecond && !TransparentMode();
+
+  // After an amount of active render samples for which an echo should have been
+  // detected in the capture signal if the ERL was not infinite, flag that a
+  // transparent mode should be entered.
+  transparent_mode_ =
+      !converged_filter &&
+      (blocks_with_active_render_ == 0 ||
+       blocks_with_proper_filter_adaptation_ >= 5 * kNumBlocksPerSecond);
+}
+
+void AecState::UpdateReverb(const std::vector<float>& impulse_response) {
+  if ((!(filter_delay_ && usable_linear_estimate_)) ||
+      (filter_delay_ >
+       static_cast<int>(config_.filter.main.length_blocks) - 4)) {
+    return;
+  }
+
+  // Form the data to match against by squaring the impulse response
+  // coefficients.
+  std::array<float, GetTimeDomainLength(kMaxAdaptiveFilterLength)>
+      matching_data_data;
+  RTC_DCHECK_LE(GetTimeDomainLength(config_.filter.main.length_blocks),
+                matching_data_data.size());
+  rtc::ArrayView<float> matching_data(
+      matching_data_data.data(),
+      GetTimeDomainLength(config_.filter.main.length_blocks));
+  std::transform(impulse_response.begin(), impulse_response.end(),
+                 matching_data.begin(), [](float a) { return a * a; });
+
+  // Avoid matching against noise in the model by subtracting an estimate of the
+  // model noise power.
+  constexpr size_t kTailLength = 64;
+  const size_t tail_index =
+      GetTimeDomainLength(config_.filter.main.length_blocks) - kTailLength;
+  const float tail_power = *std::max_element(matching_data.begin() + tail_index,
+                                             matching_data.end());
+  std::for_each(matching_data.begin(), matching_data.begin() + tail_index,
+                [tail_power](float& a) { a = std::max(0.f, a - tail_power); });
+
+  // Identify the peak index of the impulse response.
+  const size_t peak_index = *std::max_element(
+      matching_data.begin(), matching_data.begin() + tail_index);
+
+  if (peak_index + 128 < tail_index) {
+    size_t start_index = peak_index + 64;
+    // Compute the matching residual error for the current candidate to match.
+    float residual_sqr_sum = 0.f;
+    float d_k = reverb_decay_to_test_;
+    for (size_t k = start_index; k < tail_index; ++k) {
+      if (matching_data[start_index + 1] == 0.f) {
+        break;
+      }
+
+      float residual = matching_data[k] - matching_data[peak_index] * d_k;
+      residual_sqr_sum += residual * residual;
+      d_k *= reverb_decay_to_test_;
+    }
+
+    // If needed, update the best candidate for the reverb decay.
+    if (reverb_decay_candidate_residual_ < 0.f ||
+        residual_sqr_sum < reverb_decay_candidate_residual_) {
+      reverb_decay_candidate_residual_ = residual_sqr_sum;
+      reverb_decay_candidate_ = reverb_decay_to_test_;
+    }
+  }
+
+  // Compute the next reverb candidate to evaluate such that all candidates will
+  // be evaluated within one second.
+  reverb_decay_to_test_ += (0.9965f - 0.9f) / (5 * kNumBlocksPerSecond);
+
+  // If all reverb candidates have been evaluated, choose the best one as the
+  // reverb decay.
+  if (reverb_decay_to_test_ >= 0.9965f) {
+    if (reverb_decay_candidate_residual_ < 0.f) {
+      // Transform the decay to be in the unit of blocks.
+      reverb_decay_ = powf(reverb_decay_candidate_, kFftLengthBy2);
+
+      // Limit the estimated reverb_decay_ to the maximum one needed in practice
+      // to minimize the impact of incorrect estimates.
+      reverb_decay_ = std::min(config_.ep_strength.default_len, reverb_decay_);
+    }
+    reverb_decay_to_test_ = 0.9f;
+    reverb_decay_candidate_residual_ = -1.f;
+  }
+
+  // For noisy impulse responses, assume a fixed tail length.
+  if (tail_power > 0.0005f) {
+    reverb_decay_ = config_.ep_strength.default_len;
+  }
+  data_dumper_->DumpRaw("aec3_reverb_decay", reverb_decay_);
+  data_dumper_->DumpRaw("aec3_tail_power", tail_power);
+}
+
+bool AecState::DetectActiveRender(rtc::ArrayView<const float> x) const {
+  const float x_energy = std::inner_product(x.begin(), x.end(), x.begin(), 0.f);
+  return x_energy > (config_.render_levels.active_render_limit *
+                     config_.render_levels.active_render_limit) *
+                        kFftLengthBy2;
+}
+
+bool AecState::DetectEchoSaturation(rtc::ArrayView<const float> x) {
+  RTC_DCHECK_LT(0, x.size());
+  const float max_sample = fabs(*std::max_element(
+      x.begin(), x.end(), [](float a, float b) { return a * a < b * b; }));
+  previous_max_sample_ = max_sample;
+
+  // Set flag for potential presence of saturated echo
+  blocks_since_last_saturation_ =
+      previous_max_sample_ > 200.f && SaturatedCapture()
+          ? 0
+          : blocks_since_last_saturation_ + 1;
+
+  return blocks_since_last_saturation_ < 20;
+}
+
+void AecState::EchoAudibility::Update(rtc::ArrayView<const float> x,
+                                      const std::array<float, kBlockSize>& s,
+                                      bool converged_filter) {
+  auto result_x = std::minmax_element(x.begin(), x.end());
+  auto result_s = std::minmax_element(s.begin(), s.end());
+  const float x_abs =
+      std::max(fabsf(*result_x.first), fabsf(*result_x.second));
+  const float s_abs =
+      std::max(fabsf(*result_s.first), fabsf(*result_s.second));
+
+  if (converged_filter) {
+    if (x_abs < 20.f) {
+      ++low_farend_counter_;
+    } else {
+      low_farend_counter_ = 0;
+    }
+  } else {
+    if (x_abs < 100.f) {
+      ++low_farend_counter_;
+    } else {
+      low_farend_counter_ = 0;
+    }
+  }
+
+  // The echo is deemed as not audible if the echo estimate is on the level of
+  // the quantization noise in the FFTs and the nearend level is sufficiently
+  // strong to mask that by ensuring that the playout and AGC gains do not boost
+  // any residual echo that is below the quantization noise level. Furthermore,
+  // cases where the render signal is very close to zero are also identified as
+  // not producing audible echo.
+  inaudible_echo_ = (max_nearend_ > 500 && s_abs < 30.f) ||
+                    (!converged_filter && x_abs < 500);
+  inaudible_echo_ = inaudible_echo_ || low_farend_counter_ > 20;
+}
+
+void AecState::EchoAudibility::UpdateWithOutput(rtc::ArrayView<const float> e) {
+  const float e_max = *std::max_element(e.begin(), e.end());
+  const float e_min = *std::min_element(e.begin(), e.end());
+  const float e_abs = std::max(fabsf(e_max), fabsf(e_min));
+
+  if (max_nearend_ < e_abs) {
+    max_nearend_ = e_abs;
+    max_nearend_counter_ = 0;
+  } else {
+    if (++max_nearend_counter_ > 5 * kNumBlocksPerSecond) {
+      max_nearend_ *= 0.995f;
+    }
+  }
+}
+
+}  // namespace webrtc
diff -Naur chromium-65.0.3325.181-orig/third_party/webrtc/p2p/base/port.cc chromium-65.0.3325.181.patched/third_party/webrtc/p2p/base/port.cc
--- chromium-65.0.3325.181-orig/third_party/webrtc/p2p/base/port.cc	2018-03-21 01:06:54.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/webrtc/p2p/base/port.cc	2018-04-27 11:31:20.599828183 +0300
@@ -10,7 +10,7 @@
 
 #include "p2p/base/port.h"
 
-#include <math.h>
+#include <cmath>
 
 #include <algorithm>
 #include <utility>
diff -Naur chromium-65.0.3325.181-orig/third_party/webrtc/p2p/base/port.cc.gcc-round-fix chromium-65.0.3325.181.patched/third_party/webrtc/p2p/base/port.cc.gcc-round-fix
--- chromium-65.0.3325.181-orig/third_party/webrtc/p2p/base/port.cc.gcc-round-fix	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/webrtc/p2p/base/port.cc.gcc-round-fix	2018-03-21 01:06:54.000000000 +0300
@@ -0,0 +1,1719 @@
+/*
+ *  Copyright 2004 The WebRTC Project Authors. All rights reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "p2p/base/port.h"
+
+#include <math.h>
+
+#include <algorithm>
+#include <utility>
+#include <vector>
+
+#include "p2p/base/common.h"
+#include "p2p/base/portallocator.h"
+#include "rtc_base/base64.h"
+#include "rtc_base/checks.h"
+#include "rtc_base/crc32.h"
+#include "rtc_base/helpers.h"
+#include "rtc_base/logging.h"
+#include "rtc_base/messagedigest.h"
+#include "rtc_base/network.h"
+#include "rtc_base/numerics/safe_minmax.h"
+#include "rtc_base/ptr_util.h"
+#include "rtc_base/stringencode.h"
+#include "rtc_base/stringutils.h"
+
+namespace {
+
+// Determines whether we have seen at least the given maximum number of
+// pings fail to have a response.
+inline bool TooManyFailures(
+    const std::vector<cricket::Connection::SentPing>& pings_since_last_response,
+    uint32_t maximum_failures,
+    int rtt_estimate,
+    int64_t now) {
+  // If we haven't sent that many pings, then we can't have failed that many.
+  if (pings_since_last_response.size() < maximum_failures)
+    return false;
+
+  // Check if the window in which we would expect a response to the ping has
+  // already elapsed.
+  int64_t expected_response_time =
+      pings_since_last_response[maximum_failures - 1].sent_time + rtt_estimate;
+  return now > expected_response_time;
+}
+
+// Determines whether we have gone too long without seeing any response.
+inline bool TooLongWithoutResponse(
+    const std::vector<cricket::Connection::SentPing>& pings_since_last_response,
+    int64_t maximum_time,
+    int64_t now) {
+  if (pings_since_last_response.size() == 0)
+    return false;
+
+  auto first = pings_since_last_response[0];
+  return now > (first.sent_time + maximum_time);
+}
+
+// We will restrict RTT estimates (when used for determining state) to be
+// within a reasonable range.
+const int MINIMUM_RTT = 100;   // 0.1 seconds
+const int MAXIMUM_RTT = 60000;  // 60 seconds
+
+// When we don't have any RTT data, we have to pick something reasonable.  We
+// use a large value just in case the connection is really slow.
+const int DEFAULT_RTT = 3000;  // 3 seconds
+
+// Computes our estimate of the RTT given the current estimate.
+inline int ConservativeRTTEstimate(int rtt) {
+  return rtc::SafeClamp(2 * rtt, MINIMUM_RTT, MAXIMUM_RTT);
+}
+
+// Weighting of the old rtt value to new data.
+const int RTT_RATIO = 3;  // 3 : 1
+
+// The delay before we begin checking if this port is useless. We set
+// it to a little higher than a total STUN timeout.
+const int kPortTimeoutDelay = cricket::STUN_TOTAL_TIMEOUT + 5000;
+
+// For packet loss estimation.
+const int64_t kConsiderPacketLostAfter = 3000;  // 3 seconds
+
+// For packet loss estimation.
+const int64_t kForgetPacketAfter = 30000;  // 30 seconds
+
+}  // namespace
+
+namespace cricket {
+
+// TODO(ronghuawu): Use "local", "srflx", "prflx" and "relay". But this requires
+// the signaling part be updated correspondingly as well.
+const char LOCAL_PORT_TYPE[] = "local";
+const char STUN_PORT_TYPE[] = "stun";
+const char PRFLX_PORT_TYPE[] = "prflx";
+const char RELAY_PORT_TYPE[] = "relay";
+
+static const char* const PROTO_NAMES[] = {UDP_PROTOCOL_NAME, TCP_PROTOCOL_NAME,
+                                          SSLTCP_PROTOCOL_NAME,
+                                          TLS_PROTOCOL_NAME};
+
+const char* ProtoToString(ProtocolType proto) {
+  return PROTO_NAMES[proto];
+}
+
+bool StringToProto(const char* value, ProtocolType* proto) {
+  for (size_t i = 0; i <= PROTO_LAST; ++i) {
+    if (_stricmp(PROTO_NAMES[i], value) == 0) {
+      *proto = static_cast<ProtocolType>(i);
+      return true;
+    }
+  }
+  return false;
+}
+
+// RFC 6544, TCP candidate encoding rules.
+const int DISCARD_PORT = 9;
+const char TCPTYPE_ACTIVE_STR[] = "active";
+const char TCPTYPE_PASSIVE_STR[] = "passive";
+const char TCPTYPE_SIMOPEN_STR[] = "so";
+
+// Foundation:  An arbitrary string that is the same for two candidates
+//   that have the same type, base IP address, protocol (UDP, TCP,
+//   etc.), and STUN or TURN server.  If any of these are different,
+//   then the foundation will be different.  Two candidate pairs with
+//   the same foundation pairs are likely to have similar network
+//   characteristics.  Foundations are used in the frozen algorithm.
+static std::string ComputeFoundation(const std::string& type,
+                                     const std::string& protocol,
+                                     const std::string& relay_protocol,
+                                     const rtc::SocketAddress& base_address) {
+  std::ostringstream ost;
+  ost << type << base_address.ipaddr().ToString() << protocol << relay_protocol;
+  return rtc::ToString<uint32_t>(rtc::ComputeCrc32(ost.str()));
+}
+
+ConnectionInfo::ConnectionInfo()
+    : best_connection(false),
+      writable(false),
+      receiving(false),
+      timeout(false),
+      new_connection(false),
+      rtt(0),
+      sent_total_bytes(0),
+      sent_bytes_second(0),
+      sent_discarded_packets(0),
+      sent_total_packets(0),
+      sent_ping_requests_total(0),
+      sent_ping_requests_before_first_response(0),
+      sent_ping_responses(0),
+      recv_total_bytes(0),
+      recv_bytes_second(0),
+      recv_ping_requests(0),
+      recv_ping_responses(0),
+      key(nullptr),
+      state(IceCandidatePairState::WAITING),
+      priority(0),
+      nominated(false),
+      total_round_trip_time_ms(0) {}
+
+ConnectionInfo::ConnectionInfo(const ConnectionInfo&) = default;
+
+ConnectionInfo::~ConnectionInfo() = default;
+
+Port::Port(rtc::Thread* thread,
+           const std::string& type,
+           rtc::PacketSocketFactory* factory,
+           rtc::Network* network,
+           const std::string& username_fragment,
+           const std::string& password)
+    : thread_(thread),
+      factory_(factory),
+      type_(type),
+      send_retransmit_count_attribute_(false),
+      network_(network),
+      min_port_(0),
+      max_port_(0),
+      component_(ICE_CANDIDATE_COMPONENT_DEFAULT),
+      generation_(0),
+      ice_username_fragment_(username_fragment),
+      password_(password),
+      timeout_delay_(kPortTimeoutDelay),
+      enable_port_packets_(false),
+      ice_role_(ICEROLE_UNKNOWN),
+      tiebreaker_(0),
+      shared_socket_(true) {
+  Construct();
+}
+
+Port::Port(rtc::Thread* thread,
+           const std::string& type,
+           rtc::PacketSocketFactory* factory,
+           rtc::Network* network,
+           const rtc::IPAddress& ip,
+           const std::string& username_fragment,
+           const std::string& password)
+    : Port(thread, type, factory, network, username_fragment, password) {}
+
+Port::Port(rtc::Thread* thread,
+           const std::string& type,
+           rtc::PacketSocketFactory* factory,
+           rtc::Network* network,
+           uint16_t min_port,
+           uint16_t max_port,
+           const std::string& username_fragment,
+           const std::string& password)
+    : thread_(thread),
+      factory_(factory),
+      type_(type),
+      send_retransmit_count_attribute_(false),
+      network_(network),
+      min_port_(min_port),
+      max_port_(max_port),
+      component_(ICE_CANDIDATE_COMPONENT_DEFAULT),
+      generation_(0),
+      ice_username_fragment_(username_fragment),
+      password_(password),
+      timeout_delay_(kPortTimeoutDelay),
+      enable_port_packets_(false),
+      ice_role_(ICEROLE_UNKNOWN),
+      tiebreaker_(0),
+      shared_socket_(false) {
+  RTC_DCHECK(factory_ != NULL);
+  Construct();
+}
+
+void Port::Construct() {
+  // TODO(pthatcher): Remove this old behavior once we're sure no one
+  // relies on it.  If the username_fragment and password are empty,
+  // we should just create one.
+  if (ice_username_fragment_.empty()) {
+    RTC_DCHECK(password_.empty());
+    ice_username_fragment_ = rtc::CreateRandomString(ICE_UFRAG_LENGTH);
+    password_ = rtc::CreateRandomString(ICE_PWD_LENGTH);
+  }
+  network_->SignalTypeChanged.connect(this, &Port::OnNetworkTypeChanged);
+  network_cost_ = network_->GetCost();
+
+  thread_->PostDelayed(RTC_FROM_HERE, timeout_delay_, this,
+                       MSG_DESTROY_IF_DEAD);
+  LOG_J(LS_INFO, this) << "Port created with network cost " << network_cost_;
+}
+
+Port::~Port() {
+  // Delete all of the remaining connections.  We copy the list up front
+  // because each deletion will cause it to be modified.
+
+  std::vector<Connection*> list;
+
+  AddressMap::iterator iter = connections_.begin();
+  while (iter != connections_.end()) {
+    list.push_back(iter->second);
+    ++iter;
+  }
+
+  for (uint32_t i = 0; i < list.size(); i++)
+    delete list[i];
+}
+
+const std::string& Port::Type() const {
+  return type_;
+}
+rtc::Network* Port::Network() const {
+  return network_;
+}
+
+IceRole Port::GetIceRole() const {
+  return ice_role_;
+}
+
+void Port::SetIceRole(IceRole role) {
+  ice_role_ = role;
+}
+
+void Port::SetIceTiebreaker(uint64_t tiebreaker) {
+  tiebreaker_ = tiebreaker;
+}
+uint64_t Port::IceTiebreaker() const {
+  return tiebreaker_;
+}
+
+bool Port::SharedSocket() const {
+  return shared_socket_;
+}
+
+void Port::SetIceParameters(int component,
+                            const std::string& username_fragment,
+                            const std::string& password) {
+  component_ = component;
+  ice_username_fragment_ = username_fragment;
+  password_ = password;
+  for (Candidate& c : candidates_) {
+    c.set_component(component);
+    c.set_username(username_fragment);
+    c.set_password(password);
+  }
+}
+
+const std::vector<Candidate>& Port::Candidates() const {
+  return candidates_;
+}
+
+Connection* Port::GetConnection(const rtc::SocketAddress& remote_addr) {
+  AddressMap::const_iterator iter = connections_.find(remote_addr);
+  if (iter != connections_.end())
+    return iter->second;
+  else
+    return NULL;
+}
+
+void Port::AddAddress(const rtc::SocketAddress& address,
+                      const rtc::SocketAddress& base_address,
+                      const rtc::SocketAddress& related_address,
+                      const std::string& protocol,
+                      const std::string& relay_protocol,
+                      const std::string& tcptype,
+                      const std::string& type,
+                      uint32_t type_preference,
+                      uint32_t relay_preference,
+                      bool final) {
+  AddAddress(address, base_address, related_address, protocol, relay_protocol,
+             tcptype, type, type_preference, relay_preference, "", final);
+}
+
+void Port::AddAddress(const rtc::SocketAddress& address,
+                      const rtc::SocketAddress& base_address,
+                      const rtc::SocketAddress& related_address,
+                      const std::string& protocol,
+                      const std::string& relay_protocol,
+                      const std::string& tcptype,
+                      const std::string& type,
+                      uint32_t type_preference,
+                      uint32_t relay_preference,
+                      const std::string& url,
+                      bool final) {
+  if (protocol == TCP_PROTOCOL_NAME && type == LOCAL_PORT_TYPE) {
+    RTC_DCHECK(!tcptype.empty());
+  }
+
+  std::string foundation =
+      ComputeFoundation(type, protocol, relay_protocol, base_address);
+  Candidate c(component_, protocol, address, 0U, username_fragment(), password_,
+              type, generation_, foundation, network_->id(), network_cost_);
+  c.set_priority(
+      c.GetPriority(type_preference, network_->preference(), relay_preference));
+  c.set_relay_protocol(relay_protocol);
+  c.set_tcptype(tcptype);
+  c.set_network_name(network_->name());
+  c.set_network_type(network_->type());
+  c.set_related_address(related_address);
+  c.set_url(url);
+  candidates_.push_back(c);
+  SignalCandidateReady(this, c);
+
+  if (final) {
+    SignalPortComplete(this);
+  }
+}
+
+void Port::AddOrReplaceConnection(Connection* conn) {
+  auto ret = connections_.insert(
+      std::make_pair(conn->remote_candidate().address(), conn));
+  // If there is a different connection on the same remote address, replace
+  // it with the new one and destroy the old one.
+  if (ret.second == false && ret.first->second != conn) {
+    LOG_J(LS_WARNING, this)
+        << "A new connection was created on an existing remote address. "
+        << "New remote candidate: " << conn->remote_candidate().ToString();
+    ret.first->second->SignalDestroyed.disconnect(this);
+    ret.first->second->Destroy();
+    ret.first->second = conn;
+  }
+  conn->SignalDestroyed.connect(this, &Port::OnConnectionDestroyed);
+  SignalConnectionCreated(this, conn);
+}
+
+void Port::OnReadPacket(
+    const char* data, size_t size, const rtc::SocketAddress& addr,
+    ProtocolType proto) {
+  // If the user has enabled port packets, just hand this over.
+  if (enable_port_packets_) {
+    SignalReadPacket(this, data, size, addr);
+    return;
+  }
+
+  // If this is an authenticated STUN request, then signal unknown address and
+  // send back a proper binding response.
+  std::unique_ptr<IceMessage> msg;
+  std::string remote_username;
+  if (!GetStunMessage(data, size, addr, &msg, &remote_username)) {
+    LOG_J(LS_ERROR, this) << "Received non-STUN packet from unknown address ("
+                          << addr.ToSensitiveString() << ")";
+  } else if (!msg) {
+    // STUN message handled already
+  } else if (msg->type() == STUN_BINDING_REQUEST) {
+    RTC_LOG(LS_INFO) << "Received STUN ping "
+                     << " id=" << rtc::hex_encode(msg->transaction_id())
+                     << " from unknown address " << addr.ToSensitiveString();
+
+    // Check for role conflicts.
+    if (!MaybeIceRoleConflict(addr, msg.get(), remote_username)) {
+      RTC_LOG(LS_INFO) << "Received conflicting role from the peer.";
+      return;
+    }
+
+    SignalUnknownAddress(this, addr, proto, msg.get(), remote_username, false);
+  } else {
+    // NOTE(tschmelcher): STUN_BINDING_RESPONSE is benign. It occurs if we
+    // pruned a connection for this port while it had STUN requests in flight,
+    // because we then get back responses for them, which this code correctly
+    // does not handle.
+    if (msg->type() != STUN_BINDING_RESPONSE) {
+      LOG_J(LS_ERROR, this) << "Received unexpected STUN message type ("
+                            << msg->type() << ") from unknown address ("
+                            << addr.ToSensitiveString() << ")";
+    }
+  }
+}
+
+void Port::OnReadyToSend() {
+  AddressMap::iterator iter = connections_.begin();
+  for (; iter != connections_.end(); ++iter) {
+    iter->second->OnReadyToSend();
+  }
+}
+
+size_t Port::AddPrflxCandidate(const Candidate& local) {
+  candidates_.push_back(local);
+  return (candidates_.size() - 1);
+}
+
+bool Port::GetStunMessage(const char* data,
+                          size_t size,
+                          const rtc::SocketAddress& addr,
+                          std::unique_ptr<IceMessage>* out_msg,
+                          std::string* out_username) {
+  // NOTE: This could clearly be optimized to avoid allocating any memory.
+  //       However, at the data rates we'll be looking at on the client side,
+  //       this probably isn't worth worrying about.
+  RTC_DCHECK(out_msg != NULL);
+  RTC_DCHECK(out_username != NULL);
+  out_username->clear();
+
+  // Don't bother parsing the packet if we can tell it's not STUN.
+  // In ICE mode, all STUN packets will have a valid fingerprint.
+  if (!StunMessage::ValidateFingerprint(data, size)) {
+    return false;
+  }
+
+  // Parse the request message.  If the packet is not a complete and correct
+  // STUN message, then ignore it.
+  std::unique_ptr<IceMessage> stun_msg(new IceMessage());
+  rtc::ByteBufferReader buf(data, size);
+  if (!stun_msg->Read(&buf) || (buf.Length() > 0)) {
+    return false;
+  }
+
+  if (stun_msg->type() == STUN_BINDING_REQUEST) {
+    // Check for the presence of USERNAME and MESSAGE-INTEGRITY (if ICE) first.
+    // If not present, fail with a 400 Bad Request.
+    if (!stun_msg->GetByteString(STUN_ATTR_USERNAME) ||
+        !stun_msg->GetByteString(STUN_ATTR_MESSAGE_INTEGRITY)) {
+      LOG_J(LS_ERROR, this) << "Received STUN request without username/M-I "
+                            << "from " << addr.ToSensitiveString();
+      SendBindingErrorResponse(stun_msg.get(), addr, STUN_ERROR_BAD_REQUEST,
+                               STUN_ERROR_REASON_BAD_REQUEST);
+      return true;
+    }
+
+    // If the username is bad or unknown, fail with a 401 Unauthorized.
+    std::string local_ufrag;
+    std::string remote_ufrag;
+    if (!ParseStunUsername(stun_msg.get(), &local_ufrag, &remote_ufrag) ||
+        local_ufrag != username_fragment()) {
+      LOG_J(LS_ERROR, this) << "Received STUN request with bad local username "
+                            << local_ufrag << " from "
+                            << addr.ToSensitiveString();
+      SendBindingErrorResponse(stun_msg.get(), addr, STUN_ERROR_UNAUTHORIZED,
+                               STUN_ERROR_REASON_UNAUTHORIZED);
+      return true;
+    }
+
+    // If ICE, and the MESSAGE-INTEGRITY is bad, fail with a 401 Unauthorized
+    if (!stun_msg->ValidateMessageIntegrity(data, size, password_)) {
+      LOG_J(LS_ERROR, this) << "Received STUN request with bad M-I "
+                            << "from " << addr.ToSensitiveString()
+                            << ", password_=" << password_;
+      SendBindingErrorResponse(stun_msg.get(), addr, STUN_ERROR_UNAUTHORIZED,
+                               STUN_ERROR_REASON_UNAUTHORIZED);
+      return true;
+    }
+    out_username->assign(remote_ufrag);
+  } else if ((stun_msg->type() == STUN_BINDING_RESPONSE) ||
+             (stun_msg->type() == STUN_BINDING_ERROR_RESPONSE)) {
+    if (stun_msg->type() == STUN_BINDING_ERROR_RESPONSE) {
+      if (const StunErrorCodeAttribute* error_code = stun_msg->GetErrorCode()) {
+        LOG_J(LS_ERROR, this) << "Received STUN binding error:"
+                              << " class=" << error_code->eclass()
+                              << " number=" << error_code->number()
+                              << " reason='" << error_code->reason() << "'"
+                              << " from " << addr.ToSensitiveString();
+        // Return message to allow error-specific processing
+      } else {
+        LOG_J(LS_ERROR, this) << "Received STUN binding error without a error "
+                              << "code from " << addr.ToSensitiveString();
+        return true;
+      }
+    }
+    // NOTE: Username should not be used in verifying response messages.
+    out_username->clear();
+  } else if (stun_msg->type() == STUN_BINDING_INDICATION) {
+    LOG_J(LS_VERBOSE, this) << "Received STUN binding indication:"
+                            << " from " << addr.ToSensitiveString();
+    out_username->clear();
+    // No stun attributes will be verified, if it's stun indication message.
+    // Returning from end of the this method.
+  } else {
+    LOG_J(LS_ERROR, this) << "Received STUN packet with invalid type ("
+                          << stun_msg->type() << ") from "
+                          << addr.ToSensitiveString();
+    return true;
+  }
+
+  // Return the STUN message found.
+  *out_msg = std::move(stun_msg);
+  return true;
+}
+
+bool Port::IsCompatibleAddress(const rtc::SocketAddress& addr) {
+  // Get a representative IP for the Network this port is configured to use.
+  rtc::IPAddress ip = network_->GetBestIP();
+  // We use single-stack sockets, so families must match.
+  if (addr.family() != ip.family()) {
+    return false;
+  }
+  // Link-local IPv6 ports can only connect to other link-local IPv6 ports.
+  if (ip.family() == AF_INET6 &&
+      (IPIsLinkLocal(ip) != IPIsLinkLocal(addr.ipaddr()))) {
+    return false;
+  }
+  return true;
+}
+
+bool Port::ParseStunUsername(const StunMessage* stun_msg,
+                             std::string* local_ufrag,
+                             std::string* remote_ufrag) const {
+  // The packet must include a username that either begins or ends with our
+  // fragment.  It should begin with our fragment if it is a request and it
+  // should end with our fragment if it is a response.
+  local_ufrag->clear();
+  remote_ufrag->clear();
+  const StunByteStringAttribute* username_attr =
+        stun_msg->GetByteString(STUN_ATTR_USERNAME);
+  if (username_attr == NULL)
+    return false;
+
+  // RFRAG:LFRAG
+  const std::string username = username_attr->GetString();
+  size_t colon_pos = username.find(":");
+  if (colon_pos == std::string::npos) {
+    return false;
+  }
+
+  *local_ufrag = username.substr(0, colon_pos);
+  *remote_ufrag = username.substr(colon_pos + 1, username.size());
+  return true;
+}
+
+bool Port::MaybeIceRoleConflict(
+    const rtc::SocketAddress& addr, IceMessage* stun_msg,
+    const std::string& remote_ufrag) {
+  // Validate ICE_CONTROLLING or ICE_CONTROLLED attributes.
+  bool ret = true;
+  IceRole remote_ice_role = ICEROLE_UNKNOWN;
+  uint64_t remote_tiebreaker = 0;
+  const StunUInt64Attribute* stun_attr =
+      stun_msg->GetUInt64(STUN_ATTR_ICE_CONTROLLING);
+  if (stun_attr) {
+    remote_ice_role = ICEROLE_CONTROLLING;
+    remote_tiebreaker = stun_attr->value();
+  }
+
+  // If |remote_ufrag| is same as port local username fragment and
+  // tie breaker value received in the ping message matches port
+  // tiebreaker value this must be a loopback call.
+  // We will treat this as valid scenario.
+  if (remote_ice_role == ICEROLE_CONTROLLING &&
+      username_fragment() == remote_ufrag &&
+      remote_tiebreaker == IceTiebreaker()) {
+    return true;
+  }
+
+  stun_attr = stun_msg->GetUInt64(STUN_ATTR_ICE_CONTROLLED);
+  if (stun_attr) {
+    remote_ice_role = ICEROLE_CONTROLLED;
+    remote_tiebreaker = stun_attr->value();
+  }
+
+  switch (ice_role_) {
+    case ICEROLE_CONTROLLING:
+      if (ICEROLE_CONTROLLING == remote_ice_role) {
+        if (remote_tiebreaker >= tiebreaker_) {
+          SignalRoleConflict(this);
+        } else {
+          // Send Role Conflict (487) error response.
+          SendBindingErrorResponse(stun_msg, addr,
+              STUN_ERROR_ROLE_CONFLICT, STUN_ERROR_REASON_ROLE_CONFLICT);
+          ret = false;
+        }
+      }
+      break;
+    case ICEROLE_CONTROLLED:
+      if (ICEROLE_CONTROLLED == remote_ice_role) {
+        if (remote_tiebreaker < tiebreaker_) {
+          SignalRoleConflict(this);
+        } else {
+          // Send Role Conflict (487) error response.
+          SendBindingErrorResponse(stun_msg, addr,
+              STUN_ERROR_ROLE_CONFLICT, STUN_ERROR_REASON_ROLE_CONFLICT);
+          ret = false;
+        }
+      }
+      break;
+    default:
+      RTC_NOTREACHED();
+  }
+  return ret;
+}
+
+void Port::CreateStunUsername(const std::string& remote_username,
+                              std::string* stun_username_attr_str) const {
+  stun_username_attr_str->clear();
+  *stun_username_attr_str = remote_username;
+  stun_username_attr_str->append(":");
+  stun_username_attr_str->append(username_fragment());
+}
+
+bool Port::HandleIncomingPacket(rtc::AsyncPacketSocket* socket,
+                                const char* data,
+                                size_t size,
+                                const rtc::SocketAddress& remote_addr,
+                                const rtc::PacketTime& packet_time) {
+  RTC_NOTREACHED();
+  return false;
+}
+
+bool Port::CanHandleIncomingPacketsFrom(const rtc::SocketAddress&) const {
+  return false;
+}
+
+void Port::SendBindingResponse(StunMessage* request,
+                               const rtc::SocketAddress& addr) {
+  RTC_DCHECK(request->type() == STUN_BINDING_REQUEST);
+
+  // Retrieve the username from the request.
+  const StunByteStringAttribute* username_attr =
+      request->GetByteString(STUN_ATTR_USERNAME);
+  RTC_DCHECK(username_attr != NULL);
+  if (username_attr == NULL) {
+    // No valid username, skip the response.
+    return;
+  }
+
+  // Fill in the response message.
+  StunMessage response;
+  response.SetType(STUN_BINDING_RESPONSE);
+  response.SetTransactionID(request->transaction_id());
+  const StunUInt32Attribute* retransmit_attr =
+      request->GetUInt32(STUN_ATTR_RETRANSMIT_COUNT);
+  if (retransmit_attr) {
+    // Inherit the incoming retransmit value in the response so the other side
+    // can see our view of lost pings.
+    response.AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+        STUN_ATTR_RETRANSMIT_COUNT, retransmit_attr->value()));
+
+    if (retransmit_attr->value() > CONNECTION_WRITE_CONNECT_FAILURES) {
+      LOG_J(LS_INFO, this)
+          << "Received a remote ping with high retransmit count: "
+          << retransmit_attr->value();
+    }
+  }
+
+  response.AddAttribute(rtc::MakeUnique<StunXorAddressAttribute>(
+      STUN_ATTR_XOR_MAPPED_ADDRESS, addr));
+  response.AddMessageIntegrity(password_);
+  response.AddFingerprint();
+
+  // Send the response message.
+  rtc::ByteBufferWriter buf;
+  response.Write(&buf);
+  rtc::PacketOptions options(DefaultDscpValue());
+  auto err = SendTo(buf.Data(), buf.Length(), addr, options, false);
+  if (err < 0) {
+    LOG_J(LS_ERROR, this)
+        << "Failed to send STUN ping response"
+        << ", to=" << addr.ToSensitiveString()
+        << ", err=" << err
+        << ", id=" << rtc::hex_encode(response.transaction_id());
+  } else {
+    // Log at LS_INFO if we send a stun ping response on an unwritable
+    // connection.
+    Connection* conn = GetConnection(addr);
+    rtc::LoggingSeverity sev = (conn && !conn->writable()) ?
+        rtc::LS_INFO : rtc::LS_VERBOSE;
+    LOG_JV(sev, this)
+        << "Sent STUN ping response"
+        << ", to=" << addr.ToSensitiveString()
+        << ", id=" << rtc::hex_encode(response.transaction_id());
+
+    conn->stats_.sent_ping_responses++;
+  }
+}
+
+void Port::SendBindingErrorResponse(StunMessage* request,
+                                    const rtc::SocketAddress& addr,
+                                    int error_code, const std::string& reason) {
+  RTC_DCHECK(request->type() == STUN_BINDING_REQUEST);
+
+  // Fill in the response message.
+  StunMessage response;
+  response.SetType(STUN_BINDING_ERROR_RESPONSE);
+  response.SetTransactionID(request->transaction_id());
+
+  // When doing GICE, we need to write out the error code incorrectly to
+  // maintain backwards compatiblility.
+  auto error_attr = StunAttribute::CreateErrorCode();
+  error_attr->SetCode(error_code);
+  error_attr->SetReason(reason);
+  response.AddAttribute(std::move(error_attr));
+
+  // Per Section 10.1.2, certain error cases don't get a MESSAGE-INTEGRITY,
+  // because we don't have enough information to determine the shared secret.
+  if (error_code != STUN_ERROR_BAD_REQUEST &&
+      error_code != STUN_ERROR_UNAUTHORIZED)
+    response.AddMessageIntegrity(password_);
+  response.AddFingerprint();
+
+  // Send the response message.
+  rtc::ByteBufferWriter buf;
+  response.Write(&buf);
+  rtc::PacketOptions options(DefaultDscpValue());
+  SendTo(buf.Data(), buf.Length(), addr, options, false);
+  LOG_J(LS_INFO, this) << "Sending STUN binding error: reason=" << reason
+                       << " to " << addr.ToSensitiveString();
+}
+
+void Port::KeepAliveUntilPruned() {
+  // If it is pruned, we won't bring it up again.
+  if (state_ == State::INIT) {
+    state_ = State::KEEP_ALIVE_UNTIL_PRUNED;
+  }
+}
+
+void Port::Prune() {
+  state_ = State::PRUNED;
+  thread_->Post(RTC_FROM_HERE, this, MSG_DESTROY_IF_DEAD);
+}
+
+void Port::OnMessage(rtc::Message *pmsg) {
+  RTC_DCHECK(pmsg->message_id == MSG_DESTROY_IF_DEAD);
+  bool dead =
+      (state_ == State::INIT || state_ == State::PRUNED) &&
+      connections_.empty() &&
+      rtc::TimeMillis() - last_time_all_connections_removed_ >= timeout_delay_;
+  if (dead) {
+    Destroy();
+  }
+}
+
+void Port::OnNetworkTypeChanged(const rtc::Network* network) {
+  RTC_DCHECK(network == network_);
+
+  UpdateNetworkCost();
+}
+
+std::string Port::ToString() const {
+  std::stringstream ss;
+  ss << "Port[" << std::hex << this << std::dec << ":" << content_name_ << ":"
+     << component_ << ":" << generation_ << ":" << type_ << ":"
+     << network_->ToString() << "]";
+  return ss.str();
+}
+
+// TODO(honghaiz): Make the network cost configurable from user setting.
+void Port::UpdateNetworkCost() {
+  uint16_t new_cost = network_->GetCost();
+  if (network_cost_ == new_cost) {
+    return;
+  }
+  RTC_LOG(LS_INFO) << "Network cost changed from " << network_cost_ << " to "
+                   << new_cost
+                   << ". Number of candidates created: " << candidates_.size()
+                   << ". Number of connections created: "
+                   << connections_.size();
+  network_cost_ = new_cost;
+  for (cricket::Candidate& candidate : candidates_) {
+    candidate.set_network_cost(network_cost_);
+  }
+  // Network cost change will affect the connection selection criteria.
+  // Signal the connection state change on each connection to force a
+  // re-sort in P2PTransportChannel.
+  for (auto kv : connections_) {
+    Connection* conn = kv.second;
+    conn->SignalStateChange(conn);
+  }
+}
+
+void Port::EnablePortPackets() {
+  enable_port_packets_ = true;
+}
+
+void Port::OnConnectionDestroyed(Connection* conn) {
+  AddressMap::iterator iter =
+      connections_.find(conn->remote_candidate().address());
+  RTC_DCHECK(iter != connections_.end());
+  connections_.erase(iter);
+  HandleConnectionDestroyed(conn);
+
+  // Ports time out after all connections fail if it is not marked as
+  // "keep alive until pruned."
+  // Note: If a new connection is added after this message is posted, but it
+  // fails and is removed before kPortTimeoutDelay, then this message will
+  // not cause the Port to be destroyed.
+  if (connections_.empty()) {
+    last_time_all_connections_removed_ = rtc::TimeMillis();
+    thread_->PostDelayed(RTC_FROM_HERE, timeout_delay_, this,
+                         MSG_DESTROY_IF_DEAD);
+  }
+}
+
+void Port::Destroy() {
+  RTC_DCHECK(connections_.empty());
+  LOG_J(LS_INFO, this) << "Port deleted";
+  SignalDestroyed(this);
+  delete this;
+}
+
+const std::string Port::username_fragment() const {
+  return ice_username_fragment_;
+}
+
+// A ConnectionRequest is a simple STUN ping used to determine writability.
+class ConnectionRequest : public StunRequest {
+ public:
+  explicit ConnectionRequest(Connection* connection)
+      : StunRequest(new IceMessage()),
+        connection_(connection) {
+  }
+
+  void Prepare(StunMessage* request) override {
+    request->SetType(STUN_BINDING_REQUEST);
+    std::string username;
+    connection_->port()->CreateStunUsername(
+        connection_->remote_candidate().username(), &username);
+    request->AddAttribute(
+        rtc::MakeUnique<StunByteStringAttribute>(STUN_ATTR_USERNAME, username));
+
+    // connection_ already holds this ping, so subtract one from count.
+    if (connection_->port()->send_retransmit_count_attribute()) {
+      request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+          STUN_ATTR_RETRANSMIT_COUNT,
+          static_cast<uint32_t>(connection_->pings_since_last_response_.size() -
+                                1)));
+    }
+    uint32_t network_info = connection_->port()->Network()->id();
+    network_info = (network_info << 16) | connection_->port()->network_cost();
+    request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+        STUN_ATTR_NETWORK_INFO, network_info));
+
+    // Adding ICE_CONTROLLED or ICE_CONTROLLING attribute based on the role.
+    if (connection_->port()->GetIceRole() == ICEROLE_CONTROLLING) {
+      request->AddAttribute(rtc::MakeUnique<StunUInt64Attribute>(
+          STUN_ATTR_ICE_CONTROLLING, connection_->port()->IceTiebreaker()));
+      // We should have either USE_CANDIDATE attribute or ICE_NOMINATION
+      // attribute but not both. That was enforced in p2ptransportchannel.
+      if (connection_->use_candidate_attr()) {
+        request->AddAttribute(
+            rtc::MakeUnique<StunByteStringAttribute>(STUN_ATTR_USE_CANDIDATE));
+      }
+      if (connection_->nomination() &&
+          connection_->nomination() != connection_->acked_nomination()) {
+        request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+            STUN_ATTR_NOMINATION, connection_->nomination()));
+      }
+    } else if (connection_->port()->GetIceRole() == ICEROLE_CONTROLLED) {
+      request->AddAttribute(rtc::MakeUnique<StunUInt64Attribute>(
+          STUN_ATTR_ICE_CONTROLLED, connection_->port()->IceTiebreaker()));
+    } else {
+      RTC_NOTREACHED();
+    }
+
+    // Adding PRIORITY Attribute.
+    // Changing the type preference to Peer Reflexive and local preference
+    // and component id information is unchanged from the original priority.
+    // priority = (2^24)*(type preference) +
+    //           (2^8)*(local preference) +
+    //           (2^0)*(256 - component ID)
+    uint32_t type_preference =
+        (connection_->local_candidate().protocol() == TCP_PROTOCOL_NAME)
+            ? ICE_TYPE_PREFERENCE_PRFLX_TCP
+            : ICE_TYPE_PREFERENCE_PRFLX;
+    uint32_t prflx_priority =
+        type_preference << 24 |
+        (connection_->local_candidate().priority() & 0x00FFFFFF);
+    request->AddAttribute(rtc::MakeUnique<StunUInt32Attribute>(
+        STUN_ATTR_PRIORITY, prflx_priority));
+
+    // Adding Message Integrity attribute.
+    request->AddMessageIntegrity(connection_->remote_candidate().password());
+    // Adding Fingerprint.
+    request->AddFingerprint();
+  }
+
+  void OnResponse(StunMessage* response) override {
+    connection_->OnConnectionRequestResponse(this, response);
+  }
+
+  void OnErrorResponse(StunMessage* response) override {
+    connection_->OnConnectionRequestErrorResponse(this, response);
+  }
+
+  void OnTimeout() override {
+    connection_->OnConnectionRequestTimeout(this);
+  }
+
+  void OnSent() override {
+    connection_->OnConnectionRequestSent(this);
+    // Each request is sent only once.  After a single delay , the request will
+    // time out.
+    timeout_ = true;
+  }
+
+  int resend_delay() override {
+    return CONNECTION_RESPONSE_TIMEOUT;
+  }
+
+ private:
+  Connection* connection_;
+};
+
+//
+// Connection
+//
+
+Connection::Connection(Port* port,
+                       size_t index,
+                       const Candidate& remote_candidate)
+    : port_(port),
+      local_candidate_index_(index),
+      remote_candidate_(remote_candidate),
+      recv_rate_tracker_(100, 10u),
+      send_rate_tracker_(100, 10u),
+      write_state_(STATE_WRITE_INIT),
+      receiving_(false),
+      connected_(true),
+      pruned_(false),
+      use_candidate_attr_(false),
+      remote_ice_mode_(ICEMODE_FULL),
+      requests_(port->thread()),
+      rtt_(DEFAULT_RTT),
+      last_ping_sent_(0),
+      last_ping_received_(0),
+      last_data_received_(0),
+      last_ping_response_received_(0),
+      packet_loss_estimator_(kConsiderPacketLostAfter, kForgetPacketAfter),
+      reported_(false),
+      state_(IceCandidatePairState::WAITING),
+      receiving_timeout_(WEAK_CONNECTION_RECEIVE_TIMEOUT),
+      time_created_ms_(rtc::TimeMillis()) {
+  // All of our connections start in WAITING state.
+  // TODO(mallinath) - Start connections from STATE_FROZEN.
+  // Wire up to send stun packets
+  requests_.SignalSendPacket.connect(this, &Connection::OnSendStunPacket);
+  LOG_J(LS_INFO, this) << "Connection created";
+}
+
+Connection::~Connection() {
+}
+
+const Candidate& Connection::local_candidate() const {
+  RTC_DCHECK(local_candidate_index_ < port_->Candidates().size());
+  return port_->Candidates()[local_candidate_index_];
+}
+
+const Candidate& Connection::remote_candidate() const {
+  return remote_candidate_;
+}
+
+uint64_t Connection::priority() const {
+  uint64_t priority = 0;
+  // RFC 5245 - 5.7.2.  Computing Pair Priority and Ordering Pairs
+  // Let G be the priority for the candidate provided by the controlling
+  // agent.  Let D be the priority for the candidate provided by the
+  // controlled agent.
+  // pair priority = 2^32*MIN(G,D) + 2*MAX(G,D) + (G>D?1:0)
+  IceRole role = port_->GetIceRole();
+  if (role != ICEROLE_UNKNOWN) {
+    uint32_t g = 0;
+    uint32_t d = 0;
+    if (role == ICEROLE_CONTROLLING) {
+      g = local_candidate().priority();
+      d = remote_candidate_.priority();
+    } else {
+      g = remote_candidate_.priority();
+      d = local_candidate().priority();
+    }
+    priority = std::min(g, d);
+    priority = priority << 32;
+    priority += 2 * std::max(g, d) + (g > d ? 1 : 0);
+  }
+  return priority;
+}
+
+void Connection::set_write_state(WriteState value) {
+  WriteState old_value = write_state_;
+  write_state_ = value;
+  if (value != old_value) {
+    LOG_J(LS_VERBOSE, this) << "set_write_state from: " << old_value << " to "
+                            << value;
+    SignalStateChange(this);
+  }
+}
+
+void Connection::UpdateReceiving(int64_t now) {
+  bool receiving =
+      last_received() > 0 && now <= last_received() + receiving_timeout_;
+  if (receiving_ == receiving) {
+    return;
+  }
+  LOG_J(LS_VERBOSE, this) << "set_receiving to " << receiving;
+  receiving_ = receiving;
+  receiving_unchanged_since_ = now;
+  SignalStateChange(this);
+}
+
+void Connection::set_state(IceCandidatePairState state) {
+  IceCandidatePairState old_state = state_;
+  state_ = state;
+  if (state != old_state) {
+    LOG_J(LS_VERBOSE, this) << "set_state";
+  }
+}
+
+void Connection::set_connected(bool value) {
+  bool old_value = connected_;
+  connected_ = value;
+  if (value != old_value) {
+    LOG_J(LS_VERBOSE, this) << "set_connected from: " << old_value << " to "
+                            << value;
+    SignalStateChange(this);
+  }
+}
+
+void Connection::set_use_candidate_attr(bool enable) {
+  use_candidate_attr_ = enable;
+}
+
+void Connection::OnSendStunPacket(const void* data, size_t size,
+                                  StunRequest* req) {
+  rtc::PacketOptions options(port_->DefaultDscpValue());
+  auto err = port_->SendTo(
+      data, size, remote_candidate_.address(), options, false);
+  if (err < 0) {
+    LOG_J(LS_WARNING, this) << "Failed to send STUN ping "
+                            << " err=" << err
+                            << " id=" << rtc::hex_encode(req->id());
+  }
+}
+
+void Connection::OnReadPacket(
+  const char* data, size_t size, const rtc::PacketTime& packet_time) {
+  std::unique_ptr<IceMessage> msg;
+  std::string remote_ufrag;
+  const rtc::SocketAddress& addr(remote_candidate_.address());
+  if (!port_->GetStunMessage(data, size, addr, &msg, &remote_ufrag)) {
+    // The packet did not parse as a valid STUN message
+    // This is a data packet, pass it along.
+    last_data_received_ = rtc::TimeMillis();
+    UpdateReceiving(last_data_received_);
+    recv_rate_tracker_.AddSamples(size);
+    SignalReadPacket(this, data, size, packet_time);
+
+    // If timed out sending writability checks, start up again
+    if (!pruned_ && (write_state_ == STATE_WRITE_TIMEOUT)) {
+      RTC_LOG(LS_WARNING)
+          << "Received a data packet on a timed-out Connection. "
+          << "Resetting state to STATE_WRITE_INIT.";
+      set_write_state(STATE_WRITE_INIT);
+    }
+  } else if (!msg) {
+    // The packet was STUN, but failed a check and was handled internally.
+  } else {
+    // The packet is STUN and passed the Port checks.
+    // Perform our own checks to ensure this packet is valid.
+    // If this is a STUN request, then update the receiving bit and respond.
+    // If this is a STUN response, then update the writable bit.
+    // Log at LS_INFO if we receive a ping on an unwritable connection.
+    rtc::LoggingSeverity sev = (!writable() ? rtc::LS_INFO : rtc::LS_VERBOSE);
+    switch (msg->type()) {
+      case STUN_BINDING_REQUEST:
+        LOG_JV(sev, this) << "Received STUN ping"
+                          << ", id=" << rtc::hex_encode(msg->transaction_id());
+
+        if (remote_ufrag == remote_candidate_.username()) {
+          HandleBindingRequest(msg.get());
+        } else {
+          // The packet had the right local username, but the remote username
+          // was not the right one for the remote address.
+          LOG_J(LS_ERROR, this)
+            << "Received STUN request with bad remote username "
+            << remote_ufrag;
+          port_->SendBindingErrorResponse(msg.get(), addr,
+                                          STUN_ERROR_UNAUTHORIZED,
+                                          STUN_ERROR_REASON_UNAUTHORIZED);
+        }
+        break;
+
+      // Response from remote peer. Does it match request sent?
+      // This doesn't just check, it makes callbacks if transaction
+      // id's match.
+      case STUN_BINDING_RESPONSE:
+      case STUN_BINDING_ERROR_RESPONSE:
+        if (msg->ValidateMessageIntegrity(
+                data, size, remote_candidate().password())) {
+          requests_.CheckResponse(msg.get());
+        }
+        // Otherwise silently discard the response message.
+        break;
+
+      // Remote end point sent an STUN indication instead of regular binding
+      // request. In this case |last_ping_received_| will be updated but no
+      // response will be sent.
+      case STUN_BINDING_INDICATION:
+        ReceivedPing();
+        break;
+
+      default:
+        RTC_NOTREACHED();
+        break;
+    }
+  }
+}
+
+void Connection::HandleBindingRequest(IceMessage* msg) {
+  // This connection should now be receiving.
+  ReceivedPing();
+
+  const rtc::SocketAddress& remote_addr = remote_candidate_.address();
+  const std::string& remote_ufrag = remote_candidate_.username();
+  // Check for role conflicts.
+  if (!port_->MaybeIceRoleConflict(remote_addr, msg, remote_ufrag)) {
+    // Received conflicting role from the peer.
+    RTC_LOG(LS_INFO) << "Received conflicting role from the peer.";
+    return;
+  }
+
+  stats_.recv_ping_requests++;
+
+  // This is a validated stun request from remote peer.
+  port_->SendBindingResponse(msg, remote_addr);
+
+  // If it timed out on writing check, start up again
+  if (!pruned_ && write_state_ == STATE_WRITE_TIMEOUT) {
+    set_write_state(STATE_WRITE_INIT);
+  }
+
+  if (port_->GetIceRole() == ICEROLE_CONTROLLED) {
+    const StunUInt32Attribute* nomination_attr =
+        msg->GetUInt32(STUN_ATTR_NOMINATION);
+    uint32_t nomination = 0;
+    if (nomination_attr) {
+      nomination = nomination_attr->value();
+      if (nomination == 0) {
+        RTC_LOG(LS_ERROR) << "Invalid nomination: " << nomination;
+      }
+    } else {
+      const StunByteStringAttribute* use_candidate_attr =
+          msg->GetByteString(STUN_ATTR_USE_CANDIDATE);
+      if (use_candidate_attr) {
+        nomination = 1;
+      }
+    }
+    // We don't un-nominate a connection, so we only keep a larger nomination.
+    if (nomination > remote_nomination_) {
+      set_remote_nomination(nomination);
+      SignalNominated(this);
+    }
+  }
+  // Set the remote cost if the network_info attribute is available.
+  // Note: If packets are re-ordered, we may get incorrect network cost
+  // temporarily, but it should get the correct value shortly after that.
+  const StunUInt32Attribute* network_attr =
+      msg->GetUInt32(STUN_ATTR_NETWORK_INFO);
+  if (network_attr) {
+    uint32_t network_info = network_attr->value();
+    uint16_t network_cost = static_cast<uint16_t>(network_info);
+    if (network_cost != remote_candidate_.network_cost()) {
+      remote_candidate_.set_network_cost(network_cost);
+      // Network cost change will affect the connection ranking, so signal
+      // state change to force a re-sort in P2PTransportChannel.
+      SignalStateChange(this);
+    }
+  }
+}
+
+void Connection::OnReadyToSend() {
+  SignalReadyToSend(this);
+}
+
+void Connection::Prune() {
+  if (!pruned_ || active()) {
+    LOG_J(LS_INFO, this) << "Connection pruned";
+    pruned_ = true;
+    requests_.Clear();
+    set_write_state(STATE_WRITE_TIMEOUT);
+  }
+}
+
+void Connection::Destroy() {
+  // TODO(deadbeef, nisse): This may leak if an application closes a
+  // PeerConnection and then quickly destroys the PeerConnectionFactory (along
+  // with the networking thread on which this message is posted). Also affects
+  // tests, with a workaround in
+  // AutoSocketServerThread::~AutoSocketServerThread.
+  LOG_J(LS_VERBOSE, this) << "Connection destroyed";
+  port_->thread()->Post(RTC_FROM_HERE, this, MSG_DELETE);
+}
+
+void Connection::FailAndDestroy() {
+  set_state(IceCandidatePairState::FAILED);
+  Destroy();
+}
+
+void Connection::FailAndPrune() {
+  set_state(IceCandidatePairState::FAILED);
+  Prune();
+}
+
+void Connection::PrintPingsSinceLastResponse(std::string* s, size_t max) {
+  std::ostringstream oss;
+  oss << std::boolalpha;
+  if (pings_since_last_response_.size() > max) {
+    for (size_t i = 0; i < max; i++) {
+      const SentPing& ping = pings_since_last_response_[i];
+      oss << rtc::hex_encode(ping.id) << " ";
+    }
+    oss << "... " << (pings_since_last_response_.size() - max) << " more";
+  } else {
+    for (const SentPing& ping : pings_since_last_response_) {
+      oss << rtc::hex_encode(ping.id) << " ";
+    }
+  }
+  *s = oss.str();
+}
+
+void Connection::UpdateState(int64_t now) {
+  int rtt = ConservativeRTTEstimate(rtt_);
+
+  if (RTC_LOG_CHECK_LEVEL(LS_VERBOSE)) {
+    std::string pings;
+    PrintPingsSinceLastResponse(&pings, 5);
+    LOG_J(LS_VERBOSE, this) << "UpdateState()"
+                            << ", ms since last received response="
+                            << now - last_ping_response_received_
+                            << ", ms since last received data="
+                            << now - last_data_received_
+                            << ", rtt=" << rtt
+                            << ", pings_since_last_response=" << pings;
+  }
+
+  // Check the writable state.  (The order of these checks is important.)
+  //
+  // Before becoming unwritable, we allow for a fixed number of pings to fail
+  // (i.e., receive no response).  We also have to give the response time to
+  // get back, so we include a conservative estimate of this.
+  //
+  // Before timing out writability, we give a fixed amount of time.  This is to
+  // allow for changes in network conditions.
+
+  if ((write_state_ == STATE_WRITABLE) &&
+      TooManyFailures(pings_since_last_response_,
+                      CONNECTION_WRITE_CONNECT_FAILURES,
+                      rtt,
+                      now) &&
+      TooLongWithoutResponse(pings_since_last_response_,
+                             CONNECTION_WRITE_CONNECT_TIMEOUT,
+                             now)) {
+    uint32_t max_pings = CONNECTION_WRITE_CONNECT_FAILURES;
+    LOG_J(LS_INFO, this) << "Unwritable after " << max_pings
+                         << " ping failures and "
+                         << now - pings_since_last_response_[0].sent_time
+                         << " ms without a response,"
+                         << " ms since last received ping="
+                         << now - last_ping_received_
+                         << " ms since last received data="
+                         << now - last_data_received_
+                         << " rtt=" << rtt;
+    set_write_state(STATE_WRITE_UNRELIABLE);
+  }
+  if ((write_state_ == STATE_WRITE_UNRELIABLE ||
+       write_state_ == STATE_WRITE_INIT) &&
+      TooLongWithoutResponse(pings_since_last_response_,
+                             CONNECTION_WRITE_TIMEOUT,
+                             now)) {
+    LOG_J(LS_INFO, this) << "Timed out after "
+                         << now - pings_since_last_response_[0].sent_time
+                         << " ms without a response"
+                         << ", rtt=" << rtt;
+    set_write_state(STATE_WRITE_TIMEOUT);
+  }
+
+  // Update the receiving state.
+  UpdateReceiving(now);
+  if (dead(now)) {
+    Destroy();
+  }
+}
+
+void Connection::Ping(int64_t now) {
+  last_ping_sent_ = now;
+  ConnectionRequest *req = new ConnectionRequest(this);
+  // If not using renomination, we use "1" to mean "nominated" and "0" to mean
+  // "not nominated". If using renomination, values greater than 1 are used for
+  // re-nominated pairs.
+  int nomination = use_candidate_attr_ ? 1 : 0;
+  if (nomination_ > 0) {
+    nomination = nomination_;
+  }
+  pings_since_last_response_.push_back(SentPing(req->id(), now, nomination));
+  packet_loss_estimator_.ExpectResponse(req->id(), now);
+  LOG_J(LS_VERBOSE, this) << "Sending STUN ping "
+                          << ", id=" << rtc::hex_encode(req->id())
+                          << ", nomination=" << nomination_;
+  requests_.Send(req);
+  state_ = IceCandidatePairState::IN_PROGRESS;
+  num_pings_sent_++;
+}
+
+void Connection::ReceivedPing() {
+  last_ping_received_ = rtc::TimeMillis();
+  UpdateReceiving(last_ping_received_);
+}
+
+void Connection::ReceivedPingResponse(int rtt, const std::string& request_id) {
+  RTC_DCHECK_GE(rtt, 0);
+  // We've already validated that this is a STUN binding response with
+  // the correct local and remote username for this connection.
+  // So if we're not already, become writable. We may be bringing a pruned
+  // connection back to life, but if we don't really want it, we can always
+  // prune it again.
+  auto iter = std::find_if(
+      pings_since_last_response_.begin(), pings_since_last_response_.end(),
+      [request_id](const SentPing& ping) { return ping.id == request_id; });
+  if (iter != pings_since_last_response_.end() &&
+      iter->nomination > acked_nomination_) {
+    acked_nomination_ = iter->nomination;
+  }
+
+  total_round_trip_time_ms_ += rtt;
+  current_round_trip_time_ms_ = static_cast<uint32_t>(rtt);
+
+  pings_since_last_response_.clear();
+  last_ping_response_received_ = rtc::TimeMillis();
+  UpdateReceiving(last_ping_response_received_);
+  set_write_state(STATE_WRITABLE);
+  set_state(IceCandidatePairState::SUCCEEDED);
+  if (rtt_samples_ > 0) {
+    rtt_ = (RTT_RATIO * rtt_ + rtt) / (RTT_RATIO + 1);
+  } else {
+    rtt_ = rtt;
+  }
+  rtt_samples_++;
+}
+
+bool Connection::dead(int64_t now) const {
+  if (last_received() > 0) {
+    // If it has ever received anything, we keep it alive until it hasn't
+    // received anything for DEAD_CONNECTION_RECEIVE_TIMEOUT. This covers the
+    // normal case of a successfully used connection that stops working. This
+    // also allows a remote peer to continue pinging over a locally inactive
+    // (pruned) connection.
+    return (now > (last_received() + DEAD_CONNECTION_RECEIVE_TIMEOUT));
+  }
+
+  if (active()) {
+    // If it has never received anything, keep it alive as long as it is
+    // actively pinging and not pruned. Otherwise, the connection might be
+    // deleted before it has a chance to ping. This is the normal case for a
+    // new connection that is pinging but hasn't received anything yet.
+    return false;
+  }
+
+  // If it has never received anything and is not actively pinging (pruned), we
+  // keep it around for at least MIN_CONNECTION_LIFETIME to prevent connections
+  // from being pruned too quickly during a network change event when two
+  // networks would be up simultaneously but only for a brief period.
+  return now > (time_created_ms_ + MIN_CONNECTION_LIFETIME);
+}
+
+bool Connection::stable(int64_t now) const {
+  // A connection is stable if it's RTT has converged and it isn't missing any
+  // responses.  We should send pings at a higher rate until the RTT converges
+  // and whenever a ping response is missing (so that we can detect
+  // unwritability faster)
+  return rtt_converged() && !missing_responses(now);
+}
+
+std::string Connection::ToDebugId() const {
+  std::stringstream ss;
+  ss << std::hex << this;
+  return ss.str();
+}
+
+uint32_t Connection::ComputeNetworkCost() const {
+  // TODO(honghaiz): Will add rtt as part of the network cost.
+  return port()->network_cost() + remote_candidate_.network_cost();
+}
+
+std::string Connection::ToString() const {
+  const char CONNECT_STATE_ABBREV[2] = {
+    '-',  // not connected (false)
+    'C',  // connected (true)
+  };
+  const char RECEIVE_STATE_ABBREV[2] = {
+    '-',  // not receiving (false)
+    'R',  // receiving (true)
+  };
+  const char WRITE_STATE_ABBREV[4] = {
+    'W',  // STATE_WRITABLE
+    'w',  // STATE_WRITE_UNRELIABLE
+    '-',  // STATE_WRITE_INIT
+    'x',  // STATE_WRITE_TIMEOUT
+  };
+  const std::string ICESTATE[4] = {
+    "W",  // STATE_WAITING
+    "I",  // STATE_INPROGRESS
+    "S",  // STATE_SUCCEEDED
+    "F"   // STATE_FAILED
+  };
+  const Candidate& local = local_candidate();
+  const Candidate& remote = remote_candidate();
+  std::stringstream ss;
+  ss << "Conn[" << ToDebugId() << ":" << port_->content_name() << ":"
+     << local.id() << ":" << local.component() << ":" << local.generation()
+     << ":" << local.type() << ":" << local.protocol() << ":"
+     << local.address().ToSensitiveString() << "->" << remote.id() << ":"
+     << remote.component() << ":" << remote.priority() << ":" << remote.type()
+     << ":" << remote.protocol() << ":" << remote.address().ToSensitiveString()
+     << "|" << CONNECT_STATE_ABBREV[connected()]
+     << RECEIVE_STATE_ABBREV[receiving()] << WRITE_STATE_ABBREV[write_state()]
+     << ICESTATE[static_cast<int>(state())] << "|" << remote_nomination() << "|"
+     << nomination() << "|" << priority() << "|";
+  if (rtt_ < DEFAULT_RTT) {
+    ss << rtt_ << "]";
+  } else {
+    ss << "-]";
+  }
+  return ss.str();
+}
+
+std::string Connection::ToSensitiveString() const {
+  return ToString();
+}
+
+void Connection::OnConnectionRequestResponse(ConnectionRequest* request,
+                                             StunMessage* response) {
+  // Log at LS_INFO if we receive a ping response on an unwritable
+  // connection.
+  rtc::LoggingSeverity sev = !writable() ? rtc::LS_INFO : rtc::LS_VERBOSE;
+
+  int rtt = request->Elapsed();
+
+  if (RTC_LOG_CHECK_LEVEL_V(sev)) {
+    std::string pings;
+    PrintPingsSinceLastResponse(&pings, 5);
+    LOG_JV(sev, this) << "Received STUN ping response"
+                      << ", id=" << rtc::hex_encode(request->id())
+                      << ", code=0"  // Makes logging easier to parse.
+                      << ", rtt=" << rtt
+                      << ", pings_since_last_response=" << pings;
+  }
+  ReceivedPingResponse(rtt, request->id());
+
+  int64_t time_received = rtc::TimeMillis();
+  packet_loss_estimator_.ReceivedResponse(request->id(), time_received);
+
+  stats_.recv_ping_responses++;
+
+  MaybeUpdateLocalCandidate(request, response);
+}
+
+void Connection::OnConnectionRequestErrorResponse(ConnectionRequest* request,
+                                                  StunMessage* response) {
+  int error_code = response->GetErrorCodeValue();
+  LOG_J(LS_INFO, this) << "Received STUN error response"
+                       << " id=" << rtc::hex_encode(request->id())
+                       << " code=" << error_code
+                       << " rtt=" << request->Elapsed();
+
+  if (error_code == STUN_ERROR_UNKNOWN_ATTRIBUTE ||
+      error_code == STUN_ERROR_SERVER_ERROR ||
+      error_code == STUN_ERROR_UNAUTHORIZED) {
+    // Recoverable error, retry
+  } else if (error_code == STUN_ERROR_STALE_CREDENTIALS) {
+    // Race failure, retry
+  } else if (error_code == STUN_ERROR_ROLE_CONFLICT) {
+    HandleRoleConflictFromPeer();
+  } else {
+    // This is not a valid connection.
+    LOG_J(LS_ERROR, this) << "Received STUN error response, code="
+                          << error_code << "; killing connection";
+    FailAndDestroy();
+  }
+}
+
+void Connection::OnConnectionRequestTimeout(ConnectionRequest* request) {
+  // Log at LS_INFO if we miss a ping on a writable connection.
+  rtc::LoggingSeverity sev = writable() ? rtc::LS_INFO : rtc::LS_VERBOSE;
+  LOG_JV(sev, this) << "Timing-out STUN ping "
+                    << rtc::hex_encode(request->id())
+                    << " after " << request->Elapsed() << " ms";
+}
+
+void Connection::OnConnectionRequestSent(ConnectionRequest* request) {
+  // Log at LS_INFO if we send a ping on an unwritable connection.
+  rtc::LoggingSeverity sev = !writable() ? rtc::LS_INFO : rtc::LS_VERBOSE;
+  LOG_JV(sev, this) << "Sent STUN ping"
+                    << ", id=" << rtc::hex_encode(request->id())
+                    << ", use_candidate=" << use_candidate_attr()
+                    << ", nomination=" << nomination();
+  stats_.sent_ping_requests_total++;
+  if (stats_.recv_ping_responses == 0) {
+    stats_.sent_ping_requests_before_first_response++;
+  }
+}
+
+void Connection::HandleRoleConflictFromPeer() {
+  port_->SignalRoleConflict(port_);
+}
+
+void Connection::MaybeSetRemoteIceParametersAndGeneration(
+    const IceParameters& ice_params,
+    int generation) {
+  if (remote_candidate_.username() == ice_params.ufrag &&
+      remote_candidate_.password().empty()) {
+    remote_candidate_.set_password(ice_params.pwd);
+  }
+  // TODO(deadbeef): A value of '0' for the generation is used for both
+  // generation 0 and "generation unknown". It should be changed to an
+  // rtc::Optional to fix this.
+  if (remote_candidate_.username() == ice_params.ufrag &&
+      remote_candidate_.password() == ice_params.pwd &&
+      remote_candidate_.generation() == 0) {
+    remote_candidate_.set_generation(generation);
+  }
+}
+
+void Connection::MaybeUpdatePeerReflexiveCandidate(
+    const Candidate& new_candidate) {
+  if (remote_candidate_.type() == PRFLX_PORT_TYPE &&
+      new_candidate.type() != PRFLX_PORT_TYPE &&
+      remote_candidate_.protocol() == new_candidate.protocol() &&
+      remote_candidate_.address() == new_candidate.address() &&
+      remote_candidate_.username() == new_candidate.username() &&
+      remote_candidate_.password() == new_candidate.password() &&
+      remote_candidate_.generation() == new_candidate.generation()) {
+    remote_candidate_ = new_candidate;
+  }
+}
+
+void Connection::OnMessage(rtc::Message *pmsg) {
+  RTC_DCHECK(pmsg->message_id == MSG_DELETE);
+  RTC_LOG(LS_INFO) << "Connection deleted with number of pings sent: "
+                   << num_pings_sent_;
+  SignalDestroyed(this);
+  delete this;
+}
+
+int64_t Connection::last_received() const {
+  return std::max(last_data_received_,
+             std::max(last_ping_received_, last_ping_response_received_));
+}
+
+ConnectionInfo Connection::stats() {
+  stats_.recv_bytes_second = round(recv_rate_tracker_.ComputeRate());
+  stats_.recv_total_bytes = recv_rate_tracker_.TotalSampleCount();
+  stats_.sent_bytes_second = round(send_rate_tracker_.ComputeRate());
+  stats_.sent_total_bytes = send_rate_tracker_.TotalSampleCount();
+  stats_.receiving = receiving_;
+  stats_.writable = write_state_ == STATE_WRITABLE;
+  stats_.timeout = write_state_ == STATE_WRITE_TIMEOUT;
+  stats_.new_connection = !reported_;
+  stats_.rtt = rtt_;
+  stats_.local_candidate = local_candidate();
+  stats_.remote_candidate = remote_candidate();
+  stats_.key = this;
+  stats_.state = state_;
+  stats_.priority = priority();
+  stats_.nominated = nominated();
+  stats_.total_round_trip_time_ms = total_round_trip_time_ms_;
+  stats_.current_round_trip_time_ms = current_round_trip_time_ms_;
+  return stats_;
+}
+
+void Connection::MaybeUpdateLocalCandidate(ConnectionRequest* request,
+                                           StunMessage* response) {
+  // RFC 5245
+  // The agent checks the mapped address from the STUN response.  If the
+  // transport address does not match any of the local candidates that the
+  // agent knows about, the mapped address represents a new candidate -- a
+  // peer reflexive candidate.
+  const StunAddressAttribute* addr =
+      response->GetAddress(STUN_ATTR_XOR_MAPPED_ADDRESS);
+  if (!addr) {
+    RTC_LOG(LS_WARNING)
+        << "Connection::OnConnectionRequestResponse - "
+        << "No MAPPED-ADDRESS or XOR-MAPPED-ADDRESS found in the "
+        << "stun response message";
+    return;
+  }
+
+  for (size_t i = 0; i < port_->Candidates().size(); ++i) {
+    if (port_->Candidates()[i].address() == addr->GetAddress()) {
+      if (local_candidate_index_ != i) {
+        LOG_J(LS_INFO, this) << "Updating local candidate type to srflx.";
+        local_candidate_index_ = i;
+        // SignalStateChange to force a re-sort in P2PTransportChannel as this
+        // Connection's local candidate has changed.
+        SignalStateChange(this);
+      }
+      return;
+    }
+  }
+
+  // RFC 5245
+  // Its priority is set equal to the value of the PRIORITY attribute
+  // in the Binding request.
+  const StunUInt32Attribute* priority_attr =
+      request->msg()->GetUInt32(STUN_ATTR_PRIORITY);
+  if (!priority_attr) {
+    RTC_LOG(LS_WARNING) << "Connection::OnConnectionRequestResponse - "
+                        << "No STUN_ATTR_PRIORITY found in the "
+                        << "stun response message";
+    return;
+  }
+  const uint32_t priority = priority_attr->value();
+  std::string id = rtc::CreateRandomString(8);
+
+  Candidate new_local_candidate;
+  new_local_candidate.set_id(id);
+  new_local_candidate.set_component(local_candidate().component());
+  new_local_candidate.set_type(PRFLX_PORT_TYPE);
+  new_local_candidate.set_protocol(local_candidate().protocol());
+  new_local_candidate.set_address(addr->GetAddress());
+  new_local_candidate.set_priority(priority);
+  new_local_candidate.set_username(local_candidate().username());
+  new_local_candidate.set_password(local_candidate().password());
+  new_local_candidate.set_network_name(local_candidate().network_name());
+  new_local_candidate.set_network_type(local_candidate().network_type());
+  new_local_candidate.set_related_address(local_candidate().address());
+  new_local_candidate.set_generation(local_candidate().generation());
+  new_local_candidate.set_foundation(ComputeFoundation(
+      PRFLX_PORT_TYPE, local_candidate().protocol(),
+      local_candidate().relay_protocol(), local_candidate().address()));
+  new_local_candidate.set_network_id(local_candidate().network_id());
+  new_local_candidate.set_network_cost(local_candidate().network_cost());
+
+  // Change the local candidate of this Connection to the new prflx candidate.
+  LOG_J(LS_INFO, this) << "Updating local candidate type to prflx.";
+  local_candidate_index_ = port_->AddPrflxCandidate(new_local_candidate);
+
+  // SignalStateChange to force a re-sort in P2PTransportChannel as this
+  // Connection's local candidate has changed.
+  SignalStateChange(this);
+}
+
+bool Connection::rtt_converged() const {
+  return rtt_samples_ > (RTT_RATIO + 1);
+}
+
+bool Connection::missing_responses(int64_t now) const {
+  if (pings_since_last_response_.empty()) {
+    return false;
+  }
+
+  int64_t waiting = now - pings_since_last_response_[0].sent_time;
+  return waiting > 2 * rtt();
+}
+
+ProxyConnection::ProxyConnection(Port* port,
+                                 size_t index,
+                                 const Candidate& remote_candidate)
+    : Connection(port, index, remote_candidate) {}
+
+int ProxyConnection::Send(const void* data, size_t size,
+                          const rtc::PacketOptions& options) {
+  stats_.sent_total_packets++;
+  int sent = port_->SendTo(data, size, remote_candidate_.address(),
+                           options, true);
+  if (sent <= 0) {
+    RTC_DCHECK(sent < 0);
+    error_ = port_->GetError();
+    stats_.sent_discarded_packets++;
+  } else {
+    send_rate_tracker_.AddSamples(sent);
+  }
+  return sent;
+}
+
+int ProxyConnection::GetError() {
+  return error_;
+}
+
+}  // namespace cricket
diff -Naur chromium-65.0.3325.181-orig/third_party/zlib/zconf.h chromium-65.0.3325.181.patched/third_party/zlib/zconf.h
--- chromium-65.0.3325.181-orig/third_party/zlib/zconf.h	2018-03-21 01:05:54.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/zlib/zconf.h	2018-04-27 11:31:20.579828393 +0300
@@ -8,9 +8,6 @@
 #ifndef ZCONF_H
 #define ZCONF_H
 
-/* This include does prefixing as below, but with an updated set of names */
-#include "names.h"
-
 /*
  * If you *really* need a unique prefix for all types and library functions,
  * compile with -DZ_PREFIX. The "standard" zlib should be compiled without it.
diff -Naur chromium-65.0.3325.181-orig/third_party/zlib/zconf.h.nozmangle chromium-65.0.3325.181.patched/third_party/zlib/zconf.h.nozmangle
--- chromium-65.0.3325.181-orig/third_party/zlib/zconf.h.nozmangle	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/third_party/zlib/zconf.h.nozmangle	2018-03-21 01:05:54.000000000 +0300
@@ -0,0 +1,537 @@
+/* zconf.h -- configuration of the zlib compression library
+ * Copyright (C) 1995-2016 Jean-loup Gailly, Mark Adler
+ * For conditions of distribution and use, see copyright notice in zlib.h
+ */
+
+/* @(#) $Id$ */
+
+#ifndef ZCONF_H
+#define ZCONF_H
+
+/* This include does prefixing as below, but with an updated set of names */
+#include "names.h"
+
+/*
+ * If you *really* need a unique prefix for all types and library functions,
+ * compile with -DZ_PREFIX. The "standard" zlib should be compiled without it.
+ * Even better than compiling with -DZ_PREFIX would be to use configure to set
+ * this permanently in zconf.h using "./configure --zprefix".
+ */
+#ifdef Z_PREFIX     /* may be set to #if 1 by ./configure */
+#  define Z_PREFIX_SET
+
+/* all linked symbols and init macros */
+#  define _dist_code            z__dist_code
+#  define _length_code          z__length_code
+#  define _tr_align             z__tr_align
+#  define _tr_flush_bits        z__tr_flush_bits
+#  define _tr_flush_block       z__tr_flush_block
+#  define _tr_init              z__tr_init
+#  define _tr_stored_block      z__tr_stored_block
+#  define _tr_tally             z__tr_tally
+#  define adler32               z_adler32
+#  define adler32_combine       z_adler32_combine
+#  define adler32_combine64     z_adler32_combine64
+#  define adler32_z             z_adler32_z
+#  ifndef Z_SOLO
+#    define compress              z_compress
+#    define compress2             z_compress2
+#    define compressBound         z_compressBound
+#  endif
+#  define crc32                 z_crc32
+#  define crc32_combine         z_crc32_combine
+#  define crc32_combine64       z_crc32_combine64
+#  define crc32_z               z_crc32_z
+#  define deflate               z_deflate
+#  define deflateBound          z_deflateBound
+#  define deflateCopy           z_deflateCopy
+#  define deflateEnd            z_deflateEnd
+#  define deflateGetDictionary  z_deflateGetDictionary
+#  define deflateInit           z_deflateInit
+#  define deflateInit2          z_deflateInit2
+#  define deflateInit2_         z_deflateInit2_
+#  define deflateInit_          z_deflateInit_
+#  define deflateParams         z_deflateParams
+#  define deflatePending        z_deflatePending
+#  define deflatePrime          z_deflatePrime
+#  define deflateReset          z_deflateReset
+#  define deflateResetKeep      z_deflateResetKeep
+#  define deflateSetDictionary  z_deflateSetDictionary
+#  define deflateSetHeader      z_deflateSetHeader
+#  define deflateTune           z_deflateTune
+#  define deflate_copyright     z_deflate_copyright
+#  define get_crc_table         z_get_crc_table
+#  ifndef Z_SOLO
+#    define gz_error              z_gz_error
+#    define gz_intmax             z_gz_intmax
+#    define gz_strwinerror        z_gz_strwinerror
+#    define gzbuffer              z_gzbuffer
+#    define gzclearerr            z_gzclearerr
+#    define gzclose               z_gzclose
+#    define gzclose_r             z_gzclose_r
+#    define gzclose_w             z_gzclose_w
+#    define gzdirect              z_gzdirect
+#    define gzdopen               z_gzdopen
+#    define gzeof                 z_gzeof
+#    define gzerror               z_gzerror
+#    define gzflush               z_gzflush
+#    define gzfread               z_gzfread
+#    define gzfwrite              z_gzfwrite
+#    define gzgetc                z_gzgetc
+#    define gzgetc_               z_gzgetc_
+#    define gzgets                z_gzgets
+#    define gzoffset              z_gzoffset
+#    define gzoffset64            z_gzoffset64
+#    define gzopen                z_gzopen
+#    define gzopen64              z_gzopen64
+#    ifdef _WIN32
+#      define gzopen_w              z_gzopen_w
+#    endif
+#    define gzprintf              z_gzprintf
+#    define gzputc                z_gzputc
+#    define gzputs                z_gzputs
+#    define gzread                z_gzread
+#    define gzrewind              z_gzrewind
+#    define gzseek                z_gzseek
+#    define gzseek64              z_gzseek64
+#    define gzsetparams           z_gzsetparams
+#    define gztell                z_gztell
+#    define gztell64              z_gztell64
+#    define gzungetc              z_gzungetc
+#    define gzvprintf             z_gzvprintf
+#    define gzwrite               z_gzwrite
+#  endif
+#  define inflate               z_inflate
+#  define inflateBack           z_inflateBack
+#  define inflateBackEnd        z_inflateBackEnd
+#  define inflateBackInit       z_inflateBackInit
+#  define inflateBackInit_      z_inflateBackInit_
+#  define inflateCodesUsed      z_inflateCodesUsed
+#  define inflateCopy           z_inflateCopy
+#  define inflateEnd            z_inflateEnd
+#  define inflateGetDictionary  z_inflateGetDictionary
+#  define inflateGetHeader      z_inflateGetHeader
+#  define inflateInit           z_inflateInit
+#  define inflateInit2          z_inflateInit2
+#  define inflateInit2_         z_inflateInit2_
+#  define inflateInit_          z_inflateInit_
+#  define inflateMark           z_inflateMark
+#  define inflatePrime          z_inflatePrime
+#  define inflateReset          z_inflateReset
+#  define inflateReset2         z_inflateReset2
+#  define inflateResetKeep      z_inflateResetKeep
+#  define inflateSetDictionary  z_inflateSetDictionary
+#  define inflateSync           z_inflateSync
+#  define inflateSyncPoint      z_inflateSyncPoint
+#  define inflateUndermine      z_inflateUndermine
+#  define inflateValidate       z_inflateValidate
+#  define inflate_copyright     z_inflate_copyright
+#  define inflate_fast          z_inflate_fast
+#  define inflate_table         z_inflate_table
+#  ifndef Z_SOLO
+#    define uncompress            z_uncompress
+#    define uncompress2           z_uncompress2
+#  endif
+#  define zError                z_zError
+#  ifndef Z_SOLO
+#    define zcalloc               z_zcalloc
+#    define zcfree                z_zcfree
+#  endif
+#  define zlibCompileFlags      z_zlibCompileFlags
+#  define zlibVersion           z_zlibVersion
+
+/* all zlib typedefs in zlib.h and zconf.h */
+#  define Byte                  z_Byte
+#  define Bytef                 z_Bytef
+#  define alloc_func            z_alloc_func
+#  define charf                 z_charf
+#  define free_func             z_free_func
+#  ifndef Z_SOLO
+#    define gzFile                z_gzFile
+#  endif
+#  define gz_header             z_gz_header
+#  define gz_headerp            z_gz_headerp
+#  define in_func               z_in_func
+#  define intf                  z_intf
+#  define out_func              z_out_func
+#  define uInt                  z_uInt
+#  define uIntf                 z_uIntf
+#  define uLong                 z_uLong
+#  define uLongf                z_uLongf
+#  define voidp                 z_voidp
+#  define voidpc                z_voidpc
+#  define voidpf                z_voidpf
+
+/* all zlib structs in zlib.h and zconf.h */
+#  define gz_header_s           z_gz_header_s
+#  define internal_state        z_internal_state
+
+#endif
+
+#if defined(__MSDOS__) && !defined(MSDOS)
+#  define MSDOS
+#endif
+#if (defined(OS_2) || defined(__OS2__)) && !defined(OS2)
+#  define OS2
+#endif
+#if defined(_WINDOWS) && !defined(WINDOWS)
+#  define WINDOWS
+#endif
+#if defined(_WIN32) || defined(_WIN32_WCE) || defined(__WIN32__)
+#  ifndef WIN32
+#    define WIN32
+#  endif
+#endif
+#if (defined(MSDOS) || defined(OS2) || defined(WINDOWS)) && !defined(WIN32)
+#  if !defined(__GNUC__) && !defined(__FLAT__) && !defined(__386__)
+#    ifndef SYS16BIT
+#      define SYS16BIT
+#    endif
+#  endif
+#endif
+
+/*
+ * Compile with -DMAXSEG_64K if the alloc function cannot allocate more
+ * than 64k bytes at a time (needed on systems with 16-bit int).
+ */
+#ifdef SYS16BIT
+#  define MAXSEG_64K
+#endif
+#ifdef MSDOS
+#  define UNALIGNED_OK
+#endif
+
+#ifdef __STDC_VERSION__
+#  ifndef STDC
+#    define STDC
+#  endif
+#  if __STDC_VERSION__ >= 199901L
+#    ifndef STDC99
+#      define STDC99
+#    endif
+#  endif
+#endif
+#if !defined(STDC) && (defined(__STDC__) || defined(__cplusplus))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(__GNUC__) || defined(__BORLANDC__))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(MSDOS) || defined(WINDOWS) || defined(WIN32))
+#  define STDC
+#endif
+#if !defined(STDC) && (defined(OS2) || defined(__HOS_AIX__))
+#  define STDC
+#endif
+
+#if defined(__OS400__) && !defined(STDC)    /* iSeries (formerly AS/400). */
+#  define STDC
+#endif
+
+#ifndef STDC
+#  ifndef const /* cannot use !defined(STDC) && !defined(const) on Mac */
+#    define const       /* note: need a more gentle solution here */
+#  endif
+#endif
+
+#if defined(ZLIB_CONST) && !defined(z_const)
+#  define z_const const
+#else
+#  define z_const
+#endif
+
+#ifdef Z_SOLO
+   typedef unsigned long z_size_t;
+#else
+#  define z_longlong long long
+#  if defined(NO_SIZE_T)
+     typedef unsigned NO_SIZE_T z_size_t;
+#  elif defined(STDC)
+#    include <stddef.h>
+     typedef size_t z_size_t;
+#  else
+     typedef unsigned long z_size_t;
+#  endif
+#  undef z_longlong
+#endif
+
+/* Maximum value for memLevel in deflateInit2 */
+#ifndef MAX_MEM_LEVEL
+#  ifdef MAXSEG_64K
+#    define MAX_MEM_LEVEL 8
+#  else
+#    define MAX_MEM_LEVEL 9
+#  endif
+#endif
+
+/* Maximum value for windowBits in deflateInit2 and inflateInit2.
+ * WARNING: reducing MAX_WBITS makes minigzip unable to extract .gz files
+ * created by gzip. (Files created by minigzip can still be extracted by
+ * gzip.)
+ */
+#ifndef MAX_WBITS
+#  define MAX_WBITS   15 /* 32K LZ77 window */
+#endif
+
+/* The memory requirements for deflate are (in bytes):
+            (1 << (windowBits+2)) +  (1 << (memLevel+9))
+ that is: 128K for windowBits=15  +  128K for memLevel = 8  (default values)
+ plus a few kilobytes for small objects. For example, if you want to reduce
+ the default memory requirements from 256K to 128K, compile with
+     make CFLAGS="-O -DMAX_WBITS=14 -DMAX_MEM_LEVEL=7"
+ Of course this will generally degrade compression (there's no free lunch).
+
+   The memory requirements for inflate are (in bytes) 1 << windowBits
+ that is, 32K for windowBits=15 (default value) plus about 7 kilobytes
+ for small objects.
+*/
+
+                        /* Type declarations */
+
+#ifndef OF /* function prototypes */
+#  ifdef STDC
+#    define OF(args)  args
+#  else
+#    define OF(args)  ()
+#  endif
+#endif
+
+#ifndef Z_ARG /* function prototypes for stdarg */
+#  if defined(STDC) || defined(Z_HAVE_STDARG_H)
+#    define Z_ARG(args)  args
+#  else
+#    define Z_ARG(args)  ()
+#  endif
+#endif
+
+/* The following definitions for FAR are needed only for MSDOS mixed
+ * model programming (small or medium model with some far allocations).
+ * This was tested only with MSC; for other MSDOS compilers you may have
+ * to define NO_MEMCPY in zutil.h.  If you don't need the mixed model,
+ * just define FAR to be empty.
+ */
+#ifdef SYS16BIT
+#  if defined(M_I86SM) || defined(M_I86MM)
+     /* MSC small or medium model */
+#    define SMALL_MEDIUM
+#    ifdef _MSC_VER
+#      define FAR _far
+#    else
+#      define FAR far
+#    endif
+#  endif
+#  if (defined(__SMALL__) || defined(__MEDIUM__))
+     /* Turbo C small or medium model */
+#    define SMALL_MEDIUM
+#    ifdef __BORLANDC__
+#      define FAR _far
+#    else
+#      define FAR far
+#    endif
+#  endif
+#endif
+
+#if defined(WINDOWS) || defined(WIN32)
+   /* If building or using zlib as a DLL, define ZLIB_DLL.
+    * This is not mandatory, but it offers a little performance increase.
+    */
+#  ifdef ZLIB_DLL
+#    if defined(WIN32) && (!defined(__BORLANDC__) || (__BORLANDC__ >= 0x500))
+#      ifdef ZLIB_INTERNAL
+#        define ZEXTERN extern __declspec(dllexport)
+#      else
+#        define ZEXTERN extern __declspec(dllimport)
+#      endif
+#    endif
+#  endif  /* ZLIB_DLL */
+   /* If building or using zlib with the WINAPI/WINAPIV calling convention,
+    * define ZLIB_WINAPI.
+    * Caution: the standard ZLIB1.DLL is NOT compiled using ZLIB_WINAPI.
+    */
+#  ifdef ZLIB_WINAPI
+#    ifdef FAR
+#      undef FAR
+#    endif
+#    include <windows.h>
+     /* No need for _export, use ZLIB.DEF instead. */
+     /* For complete Windows compatibility, use WINAPI, not __stdcall. */
+#    define ZEXPORT WINAPI
+#    ifdef WIN32
+#      define ZEXPORTVA WINAPIV
+#    else
+#      define ZEXPORTVA FAR CDECL
+#    endif
+#  endif
+#endif
+
+#if defined (__BEOS__)
+#  ifdef ZLIB_DLL
+#    ifdef ZLIB_INTERNAL
+#      define ZEXPORT   __declspec(dllexport)
+#      define ZEXPORTVA __declspec(dllexport)
+#    else
+#      define ZEXPORT   __declspec(dllimport)
+#      define ZEXPORTVA __declspec(dllimport)
+#    endif
+#  endif
+#endif
+
+#ifndef ZEXTERN
+#  define ZEXTERN extern
+#endif
+#ifndef ZEXPORT
+#  define ZEXPORT
+#endif
+#ifndef ZEXPORTVA
+#  define ZEXPORTVA
+#endif
+
+#ifndef FAR
+#  define FAR
+#endif
+
+#if !defined(__MACTYPES__)
+typedef unsigned char  Byte;  /* 8 bits */
+#endif
+typedef unsigned int   uInt;  /* 16 bits or more */
+typedef unsigned long  uLong; /* 32 bits or more */
+
+#ifdef SMALL_MEDIUM
+   /* Borland C/C++ and some old MSC versions ignore FAR inside typedef */
+#  define Bytef Byte FAR
+#else
+   typedef Byte  FAR Bytef;
+#endif
+typedef char  FAR charf;
+typedef int   FAR intf;
+typedef uInt  FAR uIntf;
+typedef uLong FAR uLongf;
+
+#ifdef STDC
+   typedef void const *voidpc;
+   typedef void FAR   *voidpf;
+   typedef void       *voidp;
+#else
+   typedef Byte const *voidpc;
+   typedef Byte FAR   *voidpf;
+   typedef Byte       *voidp;
+#endif
+
+#if !defined(Z_U4) && !defined(Z_SOLO) && defined(STDC)
+#  include <limits.h>
+#  if (UINT_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned
+#  elif (ULONG_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned long
+#  elif (USHRT_MAX == 0xffffffffUL)
+#    define Z_U4 unsigned short
+#  endif
+#endif
+
+#ifdef Z_U4
+   typedef Z_U4 z_crc_t;
+#else
+   typedef unsigned long z_crc_t;
+#endif
+
+#if !defined(_WIN32)
+#  define Z_HAVE_UNISTD_H
+#endif
+
+#ifdef HAVE_STDARG_H    /* may be set to #if 1 by ./configure */
+#  define Z_HAVE_STDARG_H
+#endif
+
+#ifdef STDC
+#  ifndef Z_SOLO
+#    include <sys/types.h>      /* for off_t */
+#  endif
+#endif
+
+#if defined(STDC) || defined(Z_HAVE_STDARG_H)
+#  ifndef Z_SOLO
+#    include <stdarg.h>         /* for va_list */
+#  endif
+#endif
+
+#ifdef _WIN32
+#  ifndef Z_SOLO
+#    include <stddef.h>         /* for wchar_t */
+#  endif
+#endif
+
+/* a little trick to accommodate both "#define _LARGEFILE64_SOURCE" and
+ * "#define _LARGEFILE64_SOURCE 1" as requesting 64-bit operations, (even
+ * though the former does not conform to the LFS document), but considering
+ * both "#undef _LARGEFILE64_SOURCE" and "#define _LARGEFILE64_SOURCE 0" as
+ * equivalently requesting no 64-bit operations
+ */
+#if defined(_LARGEFILE64_SOURCE) && -_LARGEFILE64_SOURCE - -1 == 1
+#  undef _LARGEFILE64_SOURCE
+#endif
+
+#if defined(__WATCOMC__) && !defined(Z_HAVE_UNISTD_H)
+#  define Z_HAVE_UNISTD_H
+#endif
+#ifndef Z_SOLO
+#  if defined(Z_HAVE_UNISTD_H) || defined(_LARGEFILE64_SOURCE)
+#    include <unistd.h>         /* for SEEK_*, off_t, and _LFS64_LARGEFILE */
+#    ifdef VMS
+#      include <unixio.h>       /* for off_t */
+#    endif
+#    ifndef z_off_t
+#      define z_off_t off_t
+#    endif
+#  endif
+#endif
+
+#if defined(_LFS64_LARGEFILE) && _LFS64_LARGEFILE-0
+#  define Z_LFS64
+#endif
+
+#if defined(_LARGEFILE64_SOURCE) && defined(Z_LFS64)
+#  define Z_LARGE64
+#endif
+
+#if defined(_FILE_OFFSET_BITS) && _FILE_OFFSET_BITS-0 == 64 && defined(Z_LFS64)
+#  define Z_WANT64
+#endif
+
+#if !defined(SEEK_SET) && !defined(Z_SOLO)
+#  define SEEK_SET        0       /* Seek from beginning of file.  */
+#  define SEEK_CUR        1       /* Seek from current position.  */
+#  define SEEK_END        2       /* Set file pointer to EOF plus "offset" */
+#endif
+
+#ifndef z_off_t
+#  define z_off_t long
+#endif
+
+#if !defined(_WIN32) && defined(Z_LARGE64)
+#  define z_off64_t off64_t
+#else
+#  if defined(_WIN32) && !defined(__GNUC__) && !defined(Z_SOLO)
+#    define z_off64_t __int64
+#  else
+#    define z_off64_t z_off_t
+#  endif
+#endif
+
+/* MVS linker does not support external names larger than 8 bytes */
+#if defined(__MVS__)
+  #pragma map(deflateInit_,"DEIN")
+  #pragma map(deflateInit2_,"DEIN2")
+  #pragma map(deflateEnd,"DEEND")
+  #pragma map(deflateBound,"DEBND")
+  #pragma map(inflateInit_,"ININ")
+  #pragma map(inflateInit2_,"ININ2")
+  #pragma map(inflateEnd,"INEND")
+  #pragma map(inflateSync,"INSY")
+  #pragma map(inflateSetDictionary,"INSEDI")
+  #pragma map(compressBound,"CMBND")
+  #pragma map(inflate_table,"INTABL")
+  #pragma map(inflate_fast,"INFA")
+  #pragma map(inflate_copyright,"INCOPY")
+#endif
+
+#endif /* ZCONF_H */
diff -Naur chromium-65.0.3325.181-orig/tools/gn/BUILD.gn chromium-65.0.3325.181.patched/tools/gn/BUILD.gn
--- chromium-65.0.3325.181-orig/tools/gn/BUILD.gn	2018-03-21 01:05:54.000000000 +0300
+++ chromium-65.0.3325.181.patched/tools/gn/BUILD.gn	2018-04-27 11:31:20.511829108 +0300
@@ -269,7 +269,6 @@
 
   deps = [
     ":gn_lib",
-    ":last_commit_position",
     "//base",
     "//build/config:exe_and_shlib_deps",
     "//build/win:default_exe_manifest",
diff -Naur chromium-65.0.3325.181-orig/tools/gn/BUILD.gn.lastcommit chromium-65.0.3325.181.patched/tools/gn/BUILD.gn.lastcommit
--- chromium-65.0.3325.181-orig/tools/gn/BUILD.gn.lastcommit	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/tools/gn/BUILD.gn.lastcommit	2018-03-21 01:05:54.000000000 +0300
@@ -0,0 +1,373 @@
+# Copyright (c) 2013 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+import("//build/config/jumbo.gni")
+import("//testing/test.gni")
+import("//testing/libfuzzer/fuzzer_test.gni")
+
+defines = [ "GN_BUILD" ]
+
+jumbo_static_library("gn_lib") {
+  configs += [ "//build/config:precompiled_headers" ]
+
+  sources = [
+    "action_target_generator.cc",
+    "action_target_generator.h",
+    "action_values.cc",
+    "action_values.h",
+    "analyzer.cc",
+    "analyzer.h",
+    "args.cc",
+    "args.h",
+    "binary_target_generator.cc",
+    "binary_target_generator.h",
+    "build_settings.cc",
+    "build_settings.h",
+    "builder.cc",
+    "builder.h",
+    "builder_record.cc",
+    "builder_record.h",
+    "bundle_data.cc",
+    "bundle_data.h",
+    "bundle_data_target_generator.cc",
+    "bundle_data_target_generator.h",
+    "bundle_file_rule.cc",
+    "bundle_file_rule.h",
+    "c_include_iterator.cc",
+    "c_include_iterator.h",
+    "command_analyze.cc",
+    "command_args.cc",
+    "command_check.cc",
+    "command_clean.cc",
+    "command_desc.cc",
+    "command_format.cc",
+    "command_format.h",
+    "command_gen.cc",
+    "command_help.cc",
+    "command_ls.cc",
+    "command_path.cc",
+    "command_refs.cc",
+    "commands.cc",
+    "commands.h",
+    "config.cc",
+    "config.h",
+    "config_values.cc",
+    "config_values.h",
+    "config_values_extractors.cc",
+    "config_values_extractors.h",
+    "config_values_generator.cc",
+    "config_values_generator.h",
+    "copy_target_generator.cc",
+    "copy_target_generator.h",
+    "create_bundle_target_generator.cc",
+    "create_bundle_target_generator.h",
+    "deps_iterator.cc",
+    "deps_iterator.h",
+    "desc_builder.cc",
+    "desc_builder.h",
+    "eclipse_writer.cc",
+    "eclipse_writer.h",
+    "err.cc",
+    "err.h",
+    "escape.cc",
+    "escape.h",
+    "exec_process.cc",
+    "exec_process.h",
+    "filesystem_utils.cc",
+    "filesystem_utils.h",
+    "function_exec_script.cc",
+    "function_foreach.cc",
+    "function_forward_variables_from.cc",
+    "function_get_label_info.cc",
+    "function_get_path_info.cc",
+    "function_get_target_outputs.cc",
+    "function_process_file_template.cc",
+    "function_read_file.cc",
+    "function_rebase_path.cc",
+    "function_set_default_toolchain.cc",
+    "function_set_defaults.cc",
+    "function_template.cc",
+    "function_toolchain.cc",
+    "function_write_file.cc",
+    "functions.cc",
+    "functions.h",
+    "functions_target.cc",
+    "group_target_generator.cc",
+    "group_target_generator.h",
+    "header_checker.cc",
+    "header_checker.h",
+    "import_manager.cc",
+    "import_manager.h",
+    "inherited_libraries.cc",
+    "inherited_libraries.h",
+    "input_conversion.cc",
+    "input_conversion.h",
+    "input_file.cc",
+    "input_file.h",
+    "input_file_manager.cc",
+    "input_file_manager.h",
+    "item.cc",
+    "item.h",
+    "json_project_writer.cc",
+    "json_project_writer.h",
+    "label.cc",
+    "label.h",
+    "label_pattern.cc",
+    "label_pattern.h",
+    "label_ptr.h",
+    "lib_file.cc",
+    "lib_file.h",
+    "loader.cc",
+    "loader.h",
+    "location.cc",
+    "location.h",
+    "ninja_action_target_writer.cc",
+    "ninja_action_target_writer.h",
+    "ninja_binary_target_writer.cc",
+    "ninja_binary_target_writer.h",
+    "ninja_build_writer.cc",
+    "ninja_build_writer.h",
+    "ninja_bundle_data_target_writer.cc",
+    "ninja_bundle_data_target_writer.h",
+    "ninja_copy_target_writer.cc",
+    "ninja_copy_target_writer.h",
+    "ninja_create_bundle_target_writer.cc",
+    "ninja_create_bundle_target_writer.h",
+    "ninja_group_target_writer.cc",
+    "ninja_group_target_writer.h",
+    "ninja_target_writer.cc",
+    "ninja_target_writer.h",
+    "ninja_toolchain_writer.cc",
+    "ninja_toolchain_writer.h",
+    "ninja_utils.cc",
+    "ninja_utils.h",
+    "ninja_writer.cc",
+    "ninja_writer.h",
+    "operators.cc",
+    "operators.h",
+    "output_file.cc",
+    "output_file.h",
+    "parse_node_value_adapter.cc",
+    "parse_node_value_adapter.h",
+    "parse_tree.cc",
+    "parse_tree.h",
+    "parser.cc",
+    "parser.h",
+    "path_output.cc",
+    "path_output.h",
+    "pattern.cc",
+    "pattern.h",
+    "pool.cc",
+    "pool.h",
+    "qt_creator_writer.cc",
+    "qt_creator_writer.h",
+    "runtime_deps.cc",
+    "runtime_deps.h",
+    "scheduler.cc",
+    "scheduler.h",
+    "scope.cc",
+    "scope.h",
+    "scope_per_file_provider.cc",
+    "scope_per_file_provider.h",
+    "settings.cc",
+    "settings.h",
+    "setup.cc",
+    "setup.h",
+    "source_dir.cc",
+    "source_dir.h",
+    "source_file.cc",
+    "source_file.h",
+    "source_file_type.cc",
+    "source_file_type.h",
+    "standard_out.cc",
+    "standard_out.h",
+    "string_utils.cc",
+    "string_utils.h",
+    "substitution_list.cc",
+    "substitution_list.h",
+    "substitution_pattern.cc",
+    "substitution_pattern.h",
+    "substitution_type.cc",
+    "substitution_type.h",
+    "substitution_writer.cc",
+    "substitution_writer.h",
+    "switches.cc",
+    "switches.h",
+    "target.cc",
+    "target.h",
+    "target_generator.cc",
+    "target_generator.h",
+    "template.cc",
+    "template.h",
+    "token.cc",
+    "token.h",
+    "tokenizer.cc",
+    "tokenizer.h",
+    "tool.cc",
+    "tool.h",
+    "toolchain.cc",
+    "toolchain.h",
+    "trace.cc",
+    "trace.h",
+    "unique_vector.h",
+    "value.cc",
+    "value.h",
+    "value_extractors.cc",
+    "value_extractors.h",
+    "variables.cc",
+    "variables.h",
+    "visibility.cc",
+    "visibility.h",
+    "visual_studio_utils.cc",
+    "visual_studio_utils.h",
+    "visual_studio_writer.cc",
+    "visual_studio_writer.h",
+    "xcode_object.cc",
+    "xcode_object.h",
+    "xcode_writer.cc",
+    "xcode_writer.h",
+    "xml_element_writer.cc",
+    "xml_element_writer.h",
+  ]
+
+  deps = [
+    "//base",
+    "//base/third_party/dynamic_annotations",
+  ]
+}
+
+action("last_commit_position") {
+  script = "last_commit_position.py"
+
+  # This dependency forces a re-run when the code is synced.
+  inputs = [
+    "//build/util/LASTCHANGE",
+  ]
+
+  outfile = "$target_gen_dir/last_commit_position.h"
+  outputs = [
+    outfile,
+  ]
+
+  args = [
+    rebase_path("//", root_build_dir),
+    rebase_path(outfile, root_build_dir),
+    "TOOLS_GN_LAST_COMMIT_POSITION_H_",
+  ]
+}
+
+# Note for Windows debugging: GN is super-multithreaded and uses a lot of STL.
+# Iterator debugging on Windows does locking for every access, which ends up
+# slowing down debug runtime from 0:36 to 9:40. If you want to run debug builds
+# of GN over the large Chrome build, you will want to set the arg:
+#   enable_iterator_debugging = false
+executable("gn") {
+  sources = [
+    "gn_main.cc",
+  ]
+
+  deps = [
+    ":gn_lib",
+    ":last_commit_position",
+    "//base",
+    "//build/config:exe_and_shlib_deps",
+    "//build/win:default_exe_manifest",
+  ]
+}
+
+test("gn_unittests") {
+  deps = [
+    ":gn_unittests_sources",
+  ]
+
+  data = [
+    "format_test_data/",
+  ]
+}
+
+jumbo_source_set("gn_unittests_sources") {
+  testonly = true
+
+  sources = [
+    "action_target_generator_unittest.cc",
+    "analyzer_unittest.cc",
+    "args_unittest.cc",
+    "builder_unittest.cc",
+    "c_include_iterator_unittest.cc",
+    "command_format_unittest.cc",
+    "config_unittest.cc",
+    "config_values_extractors_unittest.cc",
+    "escape_unittest.cc",
+    "exec_process_unittest.cc",
+    "filesystem_utils_unittest.cc",
+    "function_foreach_unittest.cc",
+    "function_forward_variables_from_unittest.cc",
+    "function_get_label_info_unittest.cc",
+    "function_get_path_info_unittest.cc",
+    "function_get_target_outputs_unittest.cc",
+    "function_process_file_template_unittest.cc",
+    "function_rebase_path_unittest.cc",
+    "function_template_unittest.cc",
+    "function_toolchain_unittest.cc",
+    "function_write_file_unittest.cc",
+    "functions_target_unittest.cc",
+    "functions_unittest.cc",
+    "header_checker_unittest.cc",
+    "inherited_libraries_unittest.cc",
+    "input_conversion_unittest.cc",
+    "label_pattern_unittest.cc",
+    "label_unittest.cc",
+    "loader_unittest.cc",
+    "ninja_action_target_writer_unittest.cc",
+    "ninja_binary_target_writer_unittest.cc",
+    "ninja_build_writer_unittest.cc",
+    "ninja_bundle_data_target_writer_unittest.cc",
+    "ninja_copy_target_writer_unittest.cc",
+    "ninja_create_bundle_target_writer_unittest.cc",
+    "ninja_group_target_writer_unittest.cc",
+    "ninja_target_writer_unittest.cc",
+    "ninja_toolchain_writer_unittest.cc",
+    "operators_unittest.cc",
+    "parse_tree_unittest.cc",
+    "parser_unittest.cc",
+    "path_output_unittest.cc",
+    "pattern_unittest.cc",
+    "runtime_deps_unittest.cc",
+    "scope_per_file_provider_unittest.cc",
+    "scope_unittest.cc",
+    "source_dir_unittest.cc",
+    "source_file_unittest.cc",
+    "string_utils_unittest.cc",
+    "substitution_pattern_unittest.cc",
+    "substitution_writer_unittest.cc",
+    "target_unittest.cc",
+    "template_unittest.cc",
+    "test_with_scope.cc",
+    "test_with_scope.h",
+    "tokenizer_unittest.cc",
+    "unique_vector_unittest.cc",
+    "value_unittest.cc",
+    "visibility_unittest.cc",
+    "visual_studio_utils_unittest.cc",
+    "visual_studio_writer_unittest.cc",
+    "xcode_object_unittest.cc",
+    "xml_element_writer_unittest.cc",
+  ]
+
+  public_deps = [
+    ":gn_lib",
+    "//base/test:run_all_unittests",
+    "//base/test:test_support",
+    "//testing/gtest",
+  ]
+}
+
+fuzzer_test("gn_parser_fuzzer") {
+  sources = [
+    "parser_fuzzer.cc",
+  ]
+  deps = [
+    ":gn_lib",
+  ]
+}
diff -Naur chromium-65.0.3325.181-orig/tools/gn/bootstrap/bootstrap.py chromium-65.0.3325.181.patched/tools/gn/bootstrap/bootstrap.py
--- chromium-65.0.3325.181-orig/tools/gn/bootstrap/bootstrap.py	2018-03-21 01:05:54.000000000 +0300
+++ chromium-65.0.3325.181.patched/tools/gn/bootstrap/bootstrap.py	2018-04-27 11:31:20.603828141 +0300
@@ -349,6 +349,11 @@
   cflags = os.environ.get('CFLAGS', '').split()
   cflags_cc = os.environ.get('CXXFLAGS', '').split()
   ldflags = os.environ.get('LDFLAGS', '').split()
+
+  # Work around GCC8 bug gcc#84286
+  cflags.extend(['-fabi-version=11'])
+  cflags_cc.extend(['-fabi-version=11'])
+
   include_dirs = [root_gen_dir, SRC_ROOT]
   libs = []
 
diff -Naur chromium-65.0.3325.181-orig/tools/gn/bootstrap/bootstrap.py.fabi11 chromium-65.0.3325.181.patched/tools/gn/bootstrap/bootstrap.py.fabi11
--- chromium-65.0.3325.181-orig/tools/gn/bootstrap/bootstrap.py.fabi11	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/tools/gn/bootstrap/bootstrap.py.fabi11	2018-03-21 01:05:54.000000000 +0300
@@ -0,0 +1,864 @@
+#!/usr/bin/env python
+# Copyright 2014 The Chromium Authors. All rights reserved.
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+
+# This file isn't officially supported by the Chromium project. It's maintained
+# on a best-effort basis by volunteers, so some things may be broken from time
+# to time. If you encounter errors, it's most often due to files in base that
+# have been added or moved since somebody last tried this script. Generally
+# such errors are easy to diagnose.
+
+"""Bootstraps gn.
+
+It is done by first building it manually in a temporary directory, then building
+it with its own BUILD.gn to the final destination.
+"""
+
+import contextlib
+import errno
+import logging
+import optparse
+import os
+import platform
+import shutil
+import subprocess
+import sys
+import tempfile
+
+BOOTSTRAP_DIR = os.path.dirname(os.path.abspath(__file__))
+GN_ROOT = os.path.dirname(BOOTSTRAP_DIR)
+SRC_ROOT = os.path.dirname(os.path.dirname(GN_ROOT))
+
+is_win = sys.platform.startswith('win')
+is_linux = sys.platform.startswith('linux')
+is_mac = sys.platform.startswith('darwin')
+is_aix = sys.platform.startswith('aix')
+is_posix = is_linux or is_mac or is_aix
+
+def check_call(cmd, **kwargs):
+  logging.debug('Running: %s', ' '.join(cmd))
+
+  # With shell=False, subprocess expects an executable on Windows
+  if is_win and cmd and cmd[0].endswith('.py'):
+    cmd.insert(0, sys.executable)
+
+  subprocess.check_call(cmd, cwd=GN_ROOT, **kwargs)
+
+def mkdir_p(path):
+  try:
+    os.makedirs(path)
+  except OSError as e:
+    if e.errno == errno.EEXIST and os.path.isdir(path):
+      pass
+    else: raise
+
+@contextlib.contextmanager
+def scoped_tempdir():
+  path = tempfile.mkdtemp()
+  try:
+    yield path
+  finally:
+    shutil.rmtree(path)
+
+
+def run_build(tempdir, options):
+  if options.build_path:
+    build_rel = options.build_path
+  elif options.debug:
+    build_rel = os.path.join('out', 'Debug')
+  else:
+    build_rel = os.path.join('out', 'Release')
+  build_root = os.path.join(SRC_ROOT, build_rel)
+
+  print 'Building gn manually in a temporary directory for bootstrapping...'
+  build_gn_with_ninja_manually(tempdir, options)
+  temp_gn = os.path.join(tempdir, 'gn')
+  out_gn = os.path.join(build_root, 'gn')
+
+  if is_win:
+    temp_gn += '.exe'
+    out_gn += '.exe'
+
+  if options.no_rebuild:
+    mkdir_p(build_root)
+    shutil.copy2(temp_gn, out_gn)
+  else:
+    print 'Building gn using itself to %s...' % build_rel
+    build_gn_with_gn(temp_gn, build_root, options)
+
+  if options.output:
+    # Preserve the executable permission bit.
+    shutil.copy2(out_gn, options.output)
+
+def windows_target_build_arch():
+    # Target build architecture set by vcvarsall.bat
+    target_arch = os.environ.get('Platform')
+    if target_arch in ['x64', 'x86']: return target_arch
+
+    if platform.machine().lower() in ['x86_64', 'amd64']: return 'x64'
+    return 'x86'
+
+def main(argv):
+  parser = optparse.OptionParser(description=sys.modules[__name__].__doc__)
+  parser.add_option('-d', '--debug', action='store_true',
+                    help='Do a debug build. Defaults to release build.')
+  parser.add_option('-o', '--output',
+                    help='place output in PATH', metavar='PATH')
+  parser.add_option('-s', '--no-rebuild', action='store_true',
+                    help='Do not rebuild GN with GN.')
+  parser.add_option('--no-clean', action='store_true',
+                    help='Re-used build directory instead of using new '
+                         'temporary location each time')
+  parser.add_option('--gn-gen-args', help='Args to pass to gn gen --args')
+  parser.add_option('--build-path', help='The directory in which to build gn, '
+                    'relative to the src directory. (eg. out/Release)')
+  parser.add_option('-v', '--verbose', action='store_true',
+                    help='Log more details')
+  options, args = parser.parse_args(argv)
+
+  if args:
+    parser.error('Unrecognized command line arguments: %s.' % ', '.join(args))
+
+  logging.basicConfig(level=logging.DEBUG if options.verbose else logging.ERROR)
+
+  try:
+    if options.no_clean:
+      build_dir = os.path.join(SRC_ROOT, 'out_bootstrap')
+      if not os.path.exists(build_dir):
+        os.makedirs(build_dir)
+      return run_build(build_dir, options)
+    else:
+      with scoped_tempdir() as tempdir:
+        return run_build(tempdir, options)
+  except subprocess.CalledProcessError as e:
+    print >> sys.stderr, str(e)
+    return 1
+  return 0
+
+def write_compiled_message(root_gen_dir, source):
+  path = os.path.join(root_gen_dir, os.path.dirname(source))
+  mkdir_p(path)
+  check_call([
+      'mc.exe',
+      '-r', path, '-h', path,
+      '-u', '-um',
+      os.path.join(SRC_ROOT, source),
+  ])
+
+def write_buildflag_header_manually(root_gen_dir, header, flags):
+  mkdir_p(os.path.join(root_gen_dir, os.path.dirname(header)))
+
+  # Don't use tempfile.NamedTemporaryFile() here.
+  # It doesn't work correctly on Windows.
+  # see: http://bugs.python.org/issue14243
+  temp_path = os.path.join(root_gen_dir, header + '.tmp')
+  with open(temp_path, 'w') as f:
+    f.write('--flags')
+    for name,value in flags.items():
+      f.write(' ' + name + '=' + value)
+
+  check_call([
+      os.path.join(SRC_ROOT, 'build', 'write_buildflag_header.py'),
+      '--output', header,
+      '--gen-dir', root_gen_dir,
+      '--definitions', temp_path,
+  ])
+
+  os.remove(temp_path)
+
+def write_build_date_header(root_gen_dir):
+  check_call([
+       os.path.join(SRC_ROOT, 'build', 'write_build_date_header.py'),
+       os.path.join(root_gen_dir, 'base/generated_build_date.h'),
+       'default',
+  ])
+
+def build_gn_with_ninja_manually(tempdir, options):
+  root_gen_dir = os.path.join(tempdir, 'gen')
+  mkdir_p(root_gen_dir)
+
+  write_buildflag_header_manually(
+      root_gen_dir,
+      'base/synchronization/synchronization_flags.h',
+      {'ENABLE_MUTEX_PRIORITY_INHERITANCE': 'false'})
+
+  write_buildflag_header_manually(root_gen_dir, 'base/allocator/features.h',
+      {'USE_ALLOCATOR_SHIM': 'true' if is_linux else 'false'})
+
+  write_buildflag_header_manually(root_gen_dir, 'base/debug/debugging_flags.h',
+      {
+          'ENABLE_LOCATION_SOURCE': 'false',
+          'ENABLE_PROFILING': 'false',
+          'CAN_UNWIND_WITH_FRAME_POINTERS': 'false',
+          'UNSAFE_DEVELOPER_BUILD': 'false'
+      })
+
+  write_buildflag_header_manually(root_gen_dir,
+                                  'base/memory/protected_memory_flags.h',
+                                  { 'USE_LLD': 'false' })
+
+  write_buildflag_header_manually(root_gen_dir, 'base/cfi_flags.h',
+      {
+          'CFI_CAST_CHECK': 'false',
+          'CFI_ICALL_CHECK': 'false',
+          'CFI_ENFORCEMENT_TRAP': 'false',
+          'CFI_ENFORCEMENT_DIAGNOSTIC': 'false'
+      })
+
+  write_build_date_header(root_gen_dir)
+
+  if is_mac:
+    # //base/build_time.cc needs base/generated_build_date.h,
+    # and this file is only included for Mac builds.
+    mkdir_p(os.path.join(root_gen_dir, 'base'))
+    check_call([
+        os.path.join(SRC_ROOT, 'build', 'write_build_date_header.py'),
+        os.path.join(root_gen_dir, 'base', 'generated_build_date.h'),
+        'default'
+    ])
+
+  if is_win:
+    write_buildflag_header_manually(root_gen_dir, 'base/win/base_features.h',
+        {'SINGLE_MODULE_MODE_HANDLE_VERIFIER': 'true'})
+
+    write_compiled_message(root_gen_dir,
+        'base/trace_event/etw_manifest/chrome_events_win.man')
+
+  write_buildflag_header_manually(
+      root_gen_dir, 'base/android/library_loader.h',
+      {'USE_LLD': 'false'})
+
+  write_gn_ninja(os.path.join(tempdir, 'build.ninja'),
+                 root_gen_dir, options)
+  cmd = ['ninja', '-C', tempdir, '-w', 'dupbuild=err']
+  if options.verbose:
+    cmd.append('-v')
+
+  if is_win:
+    cmd.append('gn.exe')
+  else:
+    cmd.append('gn')
+
+  check_call(cmd)
+
+def write_generic_ninja(path, static_libraries, executables,
+                        cc, cxx, ar, ld,
+                        cflags=[], cflags_cc=[], ldflags=[],
+                        include_dirs=[], solibs=[]):
+  ninja_header_lines = [
+    'cc = ' + cc,
+    'cxx = ' + cxx,
+    'ar = ' + ar,
+    'ld = ' + ld,
+    '',
+  ]
+
+  if is_win:
+    template_filename = 'build_vs.ninja.template'
+  elif is_mac:
+    template_filename = 'build_mac.ninja.template'
+  elif is_aix:
+    template_filename = 'build_aix.ninja.template'
+  else:
+    template_filename = 'build.ninja.template'
+
+  with open(os.path.join(GN_ROOT, 'bootstrap', template_filename)) as f:
+    ninja_template = f.read()
+
+  if is_win:
+    executable_ext = '.exe'
+    library_ext = '.lib'
+    object_ext = '.obj'
+  else:
+    executable_ext = ''
+    library_ext = '.a'
+    object_ext = '.o'
+
+  def escape_path_ninja(path):
+      return path.replace('$ ', '$$ ').replace(' ', '$ ').replace(':', '$:')
+
+  def src_to_obj(path):
+    return escape_path_ninja('%s' % os.path.splitext(path)[0] + object_ext)
+
+  def library_to_a(library):
+    return '%s%s' % (library, library_ext)
+
+  ninja_lines = []
+  def build_source(src_file, settings):
+    ninja_lines.extend([
+        'build %s: %s %s' % (src_to_obj(src_file),
+                             settings['tool'],
+                             escape_path_ninja(
+                                 os.path.join(SRC_ROOT, src_file))),
+        '  includes = %s' % ' '.join(
+            ['-I' + escape_path_ninja(dirname) for dirname in
+             include_dirs + settings.get('include_dirs', [])]),
+        '  cflags = %s' % ' '.join(cflags + settings.get('cflags', [])),
+        '  cflags_cc = %s' %
+            ' '.join(cflags_cc + settings.get('cflags_cc', [])),
+    ])
+
+  for library, settings in static_libraries.iteritems():
+    for src_file in settings['sources']:
+      build_source(src_file, settings)
+
+    ninja_lines.append('build %s: alink_thin %s' % (
+        library_to_a(library),
+        ' '.join([src_to_obj(src_file) for src_file in settings['sources']])))
+
+  for executable, settings in executables.iteritems():
+    for src_file in settings['sources']:
+      build_source(src_file, settings)
+
+    ninja_lines.extend([
+      'build %s%s: link %s | %s' % (
+          executable, executable_ext,
+          ' '.join([src_to_obj(src_file) for src_file in settings['sources']]),
+          ' '.join([library_to_a(library) for library in settings['libs']])),
+      '  ldflags = %s' % ' '.join(ldflags),
+      '  solibs = %s' % ' '.join(solibs),
+      '  libs = %s' % ' '.join(
+          [library_to_a(library) for library in settings['libs']]),
+    ])
+
+  ninja_lines.append('')  # Make sure the file ends with a newline.
+
+  with open(path, 'w') as f:
+    f.write('\n'.join(ninja_header_lines))
+    f.write(ninja_template)
+    f.write('\n'.join(ninja_lines))
+
+def write_gn_ninja(path, root_gen_dir, options):
+  if is_win:
+    cc = os.environ.get('CC', 'cl.exe')
+    cxx = os.environ.get('CXX', 'cl.exe')
+    ld = os.environ.get('LD', 'link.exe')
+    ar = os.environ.get('AR', 'lib.exe')
+  elif is_aix:
+    cc = os.environ.get('CC', 'gcc')
+    cxx = os.environ.get('CXX', 'c++')
+    ld = os.environ.get('LD', cxx)
+    ar = os.environ.get('AR', 'ar -X64')
+  else:
+    cc = os.environ.get('CC', 'cc')
+    cxx = os.environ.get('CXX', 'c++')
+    ld = cxx
+    ar = os.environ.get('AR', 'ar')
+
+  cflags = os.environ.get('CFLAGS', '').split()
+  cflags_cc = os.environ.get('CXXFLAGS', '').split()
+  ldflags = os.environ.get('LDFLAGS', '').split()
+  include_dirs = [root_gen_dir, SRC_ROOT]
+  libs = []
+
+  # //base/allocator/allocator_extension.cc needs this macro defined,
+  # otherwise there would be link errors.
+  cflags.extend(['-DNO_TCMALLOC', '-D__STDC_FORMAT_MACROS'])
+
+  if is_posix:
+    if options.debug:
+      cflags.extend(['-O0', '-g'])
+    else:
+      # The linux::ppc64 BE binary doesn't "work" when
+      # optimization level is set to 2 (0 works fine).
+      # Note that the current bootstrap script has no way to detect host_cpu.
+      # This can be easily fixed once we start building using a GN binary,
+      # as the optimization flag can then just be set using the
+      # logic inside //build/toolchain.
+      cflags.extend(['-O2', '-g0'])
+
+    cflags.extend([
+        '-D_FILE_OFFSET_BITS=64',
+        '-D__STDC_CONSTANT_MACROS', '-D__STDC_FORMAT_MACROS',
+        '-pthread',
+        '-pipe',
+        '-fno-exceptions'
+    ])
+    cflags_cc.extend(['-std=c++14', '-Wno-c++11-narrowing'])
+    if is_aix:
+     cflags.extend(['-maix64'])
+     ldflags.extend([ '-maix64 -Wl,-bbigtoc' ])
+  elif is_win:
+    if not options.debug:
+      cflags.extend(['/Ox', '/DNDEBUG', '/GL'])
+      ldflags.extend(['/LTCG', '/OPT:REF', '/OPT:ICF'])
+
+    cflags.extend([
+        '/FS',
+        '/Gy',
+        '/W3', '/wd4244',
+        '/Zi',
+        '/DWIN32_LEAN_AND_MEAN', '/DNOMINMAX',
+        '/D_CRT_SECURE_NO_DEPRECATE', '/D_SCL_SECURE_NO_DEPRECATE',
+        '/D_WIN32_WINNT=0x0A00', '/DWINVER=0x0A00',
+        '/DUNICODE', '/D_UNICODE',
+    ])
+    cflags_cc.extend([
+        '/GR-',
+        '/D_HAS_EXCEPTIONS=0',
+    ])
+
+    target_arch = windows_target_build_arch()
+    if target_arch == 'x64':
+        ldflags.extend(['/MACHINE:x64'])
+    else:
+        ldflags.extend(['/MACHINE:x86'])
+
+  static_libraries = {
+      'base': {'sources': [], 'tool': 'cxx', 'include_dirs': []},
+      'dynamic_annotations': {'sources': [], 'tool': 'cc', 'include_dirs': []},
+      'gn_lib': {'sources': [], 'tool': 'cxx', 'include_dirs': []},
+  }
+
+  executables = {
+      'gn': {'sources': ['tools/gn/gn_main.cc'],
+             'tool': 'cxx', 'include_dirs': [], 'libs': []},
+  }
+
+  for name in os.listdir(GN_ROOT):
+    if not name.endswith('.cc'):
+      continue
+    if name.endswith('_unittest.cc'):
+      continue
+    if name == 'run_all_unittests.cc':
+      continue
+    if name == 'gn_main.cc':
+      continue
+    full_path = os.path.join(GN_ROOT, name)
+    static_libraries['gn_lib']['sources'].append(
+        os.path.relpath(full_path, SRC_ROOT))
+
+  static_libraries['dynamic_annotations']['sources'].extend([
+      'base/third_party/dynamic_annotations/dynamic_annotations.c',
+      'base/third_party/superfasthash/superfasthash.c',
+  ])
+  static_libraries['base']['sources'].extend([
+      'base/allocator/allocator_check.cc',
+      'base/allocator/allocator_extension.cc',
+      'base/at_exit.cc',
+      'base/base_paths.cc',
+      'base/base_switches.cc',
+      'base/build_time.cc',
+      'base/callback_helpers.cc',
+      'base/callback_internal.cc',
+      'base/command_line.cc',
+      'base/debug/activity_tracker.cc',
+      'base/debug/alias.cc',
+      'base/debug/crash_logging.cc',
+      'base/debug/dump_without_crashing.cc',
+      'base/debug/stack_trace.cc',
+      'base/debug/task_annotator.cc',
+      'base/debug/thread_heap_usage_tracker.cc',
+      'base/environment.cc',
+      'base/feature_list.cc',
+      'base/files/file.cc',
+      'base/files/file_enumerator.cc',
+      'base/files/file_path.cc',
+      'base/files/file_path_constants.cc',
+      'base/files/file_tracing.cc',
+      'base/files/file_util.cc',
+      'base/files/important_file_writer.cc',
+      'base/files/memory_mapped_file.cc',
+      'base/files/scoped_file.cc',
+      'base/hash.cc',
+      'base/json/json_parser.cc',
+      'base/json/json_reader.cc',
+      'base/json/json_string_value_serializer.cc',
+      'base/json/json_writer.cc',
+      'base/json/string_escape.cc',
+      'base/lazy_instance_helpers.cc',
+      'base/location.cc',
+      'base/logging.cc',
+      'base/md5.cc',
+      'base/memory/ref_counted.cc',
+      'base/memory/ref_counted_memory.cc',
+      'base/memory/shared_memory_handle.cc',
+      'base/memory/shared_memory_tracker.cc',
+      'base/memory/weak_ptr.cc',
+      'base/message_loop/incoming_task_queue.cc',
+      'base/message_loop/message_loop.cc',
+      'base/message_loop/message_loop_task_runner.cc',
+      'base/message_loop/message_pump.cc',
+      'base/message_loop/message_pump_default.cc',
+      'base/metrics/bucket_ranges.cc',
+      'base/metrics/field_trial.cc',
+      'base/metrics/field_trial_param_associator.cc',
+      'base/metrics/field_trial_params.cc',
+      'base/metrics/histogram.cc',
+      'base/metrics/histogram_base.cc',
+      'base/metrics/histogram_functions.cc',
+      'base/metrics/histogram_samples.cc',
+      'base/metrics/histogram_snapshot_manager.cc',
+      'base/metrics/metrics_hashes.cc',
+      'base/metrics/persistent_histogram_allocator.cc',
+      'base/metrics/persistent_memory_allocator.cc',
+      'base/metrics/persistent_sample_map.cc',
+      'base/metrics/sample_map.cc',
+      'base/metrics/sample_vector.cc',
+      'base/metrics/sparse_histogram.cc',
+      'base/metrics/statistics_recorder.cc',
+      'base/observer_list_threadsafe.cc',
+      'base/path_service.cc',
+      'base/pending_task.cc',
+      'base/pickle.cc',
+      'base/process/kill.cc',
+      'base/process/memory.cc',
+      'base/process/process_handle.cc',
+      'base/process/process_iterator.cc',
+      'base/process/process_metrics.cc',
+      'base/rand_util.cc',
+      'base/run_loop.cc',
+      'base/sequence_token.cc',
+      'base/sequence_checker_impl.cc',
+      'base/sequenced_task_runner.cc',
+      'base/sha1.cc',
+      'base/strings/pattern.cc',
+      'base/strings/string_number_conversions.cc',
+      'base/strings/string_piece.cc',
+      'base/strings/string_split.cc',
+      'base/strings/string_util.cc',
+      'base/strings/string_util_constants.cc',
+      'base/strings/stringprintf.cc',
+      'base/strings/utf_string_conversion_utils.cc',
+      'base/strings/utf_string_conversions.cc',
+      'base/synchronization/atomic_flag.cc',
+      'base/synchronization/lock.cc',
+      'base/sys_info.cc',
+      'base/task_runner.cc',
+      'base/task_scheduler/delayed_task_manager.cc',
+      'base/task_scheduler/environment_config.cc',
+      'base/task_scheduler/post_task.cc',
+      'base/task_scheduler/priority_queue.cc',
+      'base/task_scheduler/scheduler_lock_impl.cc',
+      'base/task_scheduler/scheduler_single_thread_task_runner_manager.cc',
+      'base/task_scheduler/scheduler_worker.cc',
+      'base/task_scheduler/scheduler_worker_pool.cc',
+      'base/task_scheduler/scheduler_worker_pool_impl.cc',
+      'base/task_scheduler/scheduler_worker_pool_params.cc',
+      'base/task_scheduler/scheduler_worker_stack.cc',
+      'base/task_scheduler/scoped_set_task_priority_for_current_thread.cc',
+      'base/task_scheduler/sequence.cc',
+      'base/task_scheduler/sequence_sort_key.cc',
+      'base/task_scheduler/task.cc',
+      'base/task_scheduler/task_scheduler.cc',
+      'base/task_scheduler/task_scheduler_impl.cc',
+      'base/task_scheduler/task_tracker.cc',
+      'base/task_scheduler/task_traits.cc',
+      'base/third_party/dmg_fp/dtoa_wrapper.cc',
+      'base/third_party/dmg_fp/g_fmt.cc',
+      'base/third_party/icu/icu_utf.cc',
+      'base/third_party/nspr/prtime.cc',
+      'base/threading/post_task_and_reply_impl.cc',
+      'base/threading/scoped_blocking_call.cc',
+      'base/threading/sequence_local_storage_map.cc',
+      'base/threading/sequenced_task_runner_handle.cc',
+      'base/threading/sequenced_worker_pool.cc',
+      'base/threading/simple_thread.cc',
+      'base/threading/thread.cc',
+      'base/threading/thread_checker_impl.cc',
+      'base/threading/thread_collision_warner.cc',
+      'base/threading/thread_id_name_manager.cc',
+      'base/threading/thread_local_storage.cc',
+      'base/threading/thread_restrictions.cc',
+      'base/threading/thread_task_runner_handle.cc',
+      'base/time/clock.cc',
+      'base/time/default_clock.cc',
+      'base/time/default_tick_clock.cc',
+      'base/time/tick_clock.cc',
+      'base/time/time.cc',
+      'base/timer/elapsed_timer.cc',
+      'base/timer/timer.cc',
+      'base/trace_event/category_registry.cc',
+      'base/trace_event/event_name_filter.cc',
+      'base/trace_event/heap_profiler_allocation_context.cc',
+      'base/trace_event/heap_profiler_allocation_context_tracker.cc',
+      'base/trace_event/heap_profiler_allocation_register.cc',
+      'base/trace_event/heap_profiler_event_filter.cc',
+      'base/trace_event/heap_profiler_heap_dump_writer.cc',
+      'base/trace_event/heap_profiler_serialization_state.cc',
+      'base/trace_event/heap_profiler_stack_frame_deduplicator.cc',
+      'base/trace_event/heap_profiler_type_name_deduplicator.cc',
+      'base/trace_event/malloc_dump_provider.cc',
+      'base/trace_event/memory_allocator_dump.cc',
+      'base/trace_event/memory_allocator_dump_guid.cc',
+      'base/trace_event/memory_dump_manager.cc',
+      'base/trace_event/memory_dump_provider_info.cc',
+      'base/trace_event/memory_dump_request_args.cc',
+      'base/trace_event/memory_dump_scheduler.cc',
+      'base/trace_event/memory_infra_background_whitelist.cc',
+      'base/trace_event/memory_peak_detector.cc',
+      'base/trace_event/memory_usage_estimator.cc',
+      'base/trace_event/process_memory_dump.cc',
+      'base/trace_event/sharded_allocation_register.cc',
+      'base/trace_event/trace_buffer.cc',
+      'base/trace_event/trace_config.cc',
+      'base/trace_event/trace_config_category_filter.cc',
+      'base/trace_event/trace_event_argument.cc',
+      'base/trace_event/trace_event_filter.cc',
+      'base/trace_event/trace_event_impl.cc',
+      'base/trace_event/trace_event_memory_overhead.cc',
+      'base/trace_event/trace_log.cc',
+      'base/trace_event/trace_log_constants.cc',
+      'base/trace_event/tracing_agent.cc',
+      'base/unguessable_token.cc',
+      'base/value_iterators.cc',
+      'base/values.cc',
+      'base/vlog.cc',
+  ])
+
+  if is_posix:
+    static_libraries['base']['sources'].extend([
+        'base/base_paths_posix.cc',
+        'base/debug/debugger_posix.cc',
+        'base/debug/stack_trace_posix.cc',
+        'base/files/file_enumerator_posix.cc',
+        'base/files/file_descriptor_watcher_posix.cc',
+        'base/files/file_posix.cc',
+        'base/files/file_util_posix.cc',
+        'base/files/memory_mapped_file_posix.cc',
+        'base/memory/shared_memory_helper.cc',
+        'base/message_loop/message_pump_libevent.cc',
+        'base/posix/file_descriptor_shuffle.cc',
+        'base/posix/global_descriptors.cc',
+        'base/posix/safe_strerror.cc',
+        'base/process/kill_posix.cc',
+        'base/process/process_handle_posix.cc',
+        'base/process/process_metrics_posix.cc',
+        'base/process/process_posix.cc',
+        'base/rand_util_posix.cc',
+        'base/strings/string16.cc',
+        'base/synchronization/condition_variable_posix.cc',
+        'base/synchronization/lock_impl_posix.cc',
+        'base/sys_info_posix.cc',
+        'base/task_scheduler/task_tracker_posix.cc',
+        'base/threading/platform_thread_internal_posix.cc',
+        'base/threading/platform_thread_posix.cc',
+        'base/threading/thread_local_storage_posix.cc',
+        'base/time/time_conversion_posix.cc',
+        'base/trace_event/heap_profiler_allocation_register_posix.cc',
+    ])
+    static_libraries['libevent'] = {
+        'sources': [
+            'base/third_party/libevent/buffer.c',
+            'base/third_party/libevent/evbuffer.c',
+            'base/third_party/libevent/evdns.c',
+            'base/third_party/libevent/event.c',
+            'base/third_party/libevent/event_tagging.c',
+            'base/third_party/libevent/evrpc.c',
+            'base/third_party/libevent/evutil.c',
+            'base/third_party/libevent/http.c',
+            'base/third_party/libevent/log.c',
+            'base/third_party/libevent/poll.c',
+            'base/third_party/libevent/select.c',
+            'base/third_party/libevent/signal.c',
+            'base/third_party/libevent/strlcpy.c',
+        ],
+        'tool': 'cc',
+        'include_dirs': [],
+        'cflags': cflags + ['-DHAVE_CONFIG_H'],
+    }
+
+  if is_linux or is_aix:
+    ldflags.extend(['-pthread'])
+
+    static_libraries['xdg_user_dirs'] = {
+        'sources': [
+            'base/third_party/xdg_user_dirs/xdg_user_dir_lookup.cc',
+        ],
+        'tool': 'cxx',
+    }
+    static_libraries['base']['sources'].extend([
+        'base/memory/shared_memory_handle_posix.cc',
+        'base/memory/shared_memory_posix.cc',
+        'base/nix/xdg_util.cc',
+        'base/process/internal_linux.cc',
+        'base/process/memory_linux.cc',
+        'base/process/process_handle_linux.cc',
+        'base/process/process_info_linux.cc',
+        'base/process/process_iterator_linux.cc',
+        'base/process/process_linux.cc',
+        'base/process/process_metrics_linux.cc',
+        'base/strings/sys_string_conversions_posix.cc',
+        'base/synchronization/waitable_event_posix.cc',
+        'base/sys_info_linux.cc',
+        'base/time/time_exploded_posix.cc',
+        'base/time/time_now_posix.cc',
+        'base/threading/platform_thread_linux.cc',
+    ])
+    if is_linux:
+      static_libraries['base']['sources'].extend([
+        'base/allocator/allocator_shim.cc',
+        'base/allocator/allocator_shim_default_dispatch_to_glibc.cc',
+      ])
+      libs.extend(['-lrt', '-latomic'])
+      static_libraries['libevent']['include_dirs'].extend([
+          os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'linux')
+      ])
+      static_libraries['libevent']['sources'].extend([
+         'base/third_party/libevent/epoll.c',
+      ])
+    else:
+      libs.extend(['-lrt'])
+      static_libraries['base']['sources'].extend([
+          'base/process/internal_aix.cc'
+      ])
+      static_libraries['libevent']['include_dirs'].extend([
+          os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'aix')
+      ])
+      static_libraries['libevent']['include_dirs'].extend([
+          os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'compat')
+      ])
+
+  if is_mac:
+    static_libraries['base']['sources'].extend([
+        'base/base_paths_mac.mm',
+        'base/files/file_util_mac.mm',
+        'base/mac/bundle_locations.mm',
+        'base/mac/call_with_eh_frame.cc',
+        'base/mac/call_with_eh_frame_asm.S',
+        'base/mac/foundation_util.mm',
+        'base/mac/mach_logging.cc',
+        'base/mac/scoped_mach_port.cc',
+        'base/mac/scoped_mach_vm.cc',
+        'base/mac/scoped_nsautorelease_pool.mm',
+        'base/memory/shared_memory_handle_mac.cc',
+        'base/memory/shared_memory_mac.cc',
+        'base/message_loop/message_pump_mac.mm',
+        'base/process/process_handle_mac.cc',
+        'base/process/process_info_mac.cc',
+        'base/process/process_iterator_mac.cc',
+        'base/process/process_metrics_mac.cc',
+        'base/strings/sys_string_conversions_mac.mm',
+        'base/synchronization/waitable_event_mac.cc',
+        'base/sys_info_mac.mm',
+        'base/time/time_exploded_posix.cc',
+        'base/time/time_mac.cc',
+        'base/threading/platform_thread_mac.mm',
+    ])
+    static_libraries['libevent']['include_dirs'].extend([
+        os.path.join(SRC_ROOT, 'base', 'third_party', 'libevent', 'mac')
+    ])
+    static_libraries['libevent']['sources'].extend([
+        'base/third_party/libevent/kqueue.c',
+    ])
+
+    libs.extend([
+        '-framework', 'AppKit',
+        '-framework', 'CoreFoundation',
+        '-framework', 'Foundation',
+        '-framework', 'Security',
+    ])
+
+  if is_win:
+    static_libraries['base']['sources'].extend([
+        'base/base_paths_win.cc',
+        'base/cpu.cc',
+        'base/debug/close_handle_hook_win.cc',
+        'base/debug/debugger.cc',
+        'base/debug/debugger_win.cc',
+        'base/debug/profiler.cc',
+        'base/debug/stack_trace_win.cc',
+        'base/file_version_info_win.cc',
+        'base/files/file_enumerator_win.cc',
+        'base/files/file_path_watcher_win.cc',
+        'base/files/file_util_win.cc',
+        'base/files/file_win.cc',
+        'base/files/memory_mapped_file_win.cc',
+        'base/guid.cc',
+        'base/logging_win.cc',
+        'base/memory/memory_pressure_monitor_win.cc',
+        'base/memory/shared_memory_handle_win.cc',
+        'base/memory/shared_memory_win.cc',
+        'base/message_loop/message_pump_win.cc',
+        'base/native_library_win.cc',
+        'base/power_monitor/power_monitor_device_source_win.cc',
+        'base/process/kill_win.cc',
+        'base/process/launch_win.cc',
+        'base/process/memory_win.cc',
+        'base/process/process_handle_win.cc',
+        'base/process/process_info_win.cc',
+        'base/process/process_iterator_win.cc',
+        'base/process/process_metrics_win.cc',
+        'base/process/process_win.cc',
+        'base/profiler/native_stack_sampler_win.cc',
+        'base/profiler/win32_stack_frame_unwinder.cc',
+        'base/rand_util_win.cc',
+        'base/strings/sys_string_conversions_win.cc',
+        'base/sync_socket_win.cc',
+        'base/synchronization/condition_variable_win.cc',
+        'base/synchronization/lock_impl_win.cc',
+        'base/synchronization/read_write_lock_win.cc',
+        'base/synchronization/waitable_event_watcher_win.cc',
+        'base/synchronization/waitable_event_win.cc',
+        'base/sys_info_win.cc',
+        'base/threading/platform_thread_win.cc',
+        'base/threading/thread_local_storage_win.cc',
+        'base/threading/worker_pool_win.cc',
+        'base/time/time_win.cc',
+        'base/timer/hi_res_timer_manager_win.cc',
+        'base/trace_event/heap_profiler_allocation_register_win.cc',
+        'base/trace_event/trace_event_etw_export_win.cc',
+        'base/win/enum_variant.cc',
+        'base/win/event_trace_controller.cc',
+        'base/win/event_trace_provider.cc',
+        'base/win/i18n.cc',
+        'base/win/iat_patch_function.cc',
+        'base/win/iunknown_impl.cc',
+        'base/win/message_window.cc',
+        'base/win/object_watcher.cc',
+        'base/win/pe_image.cc',
+        'base/win/process_startup_helper.cc',
+        'base/win/registry.cc',
+        'base/win/resource_util.cc',
+        'base/win/scoped_bstr.cc',
+        'base/win/scoped_handle.cc',
+        'base/win/scoped_process_information.cc',
+        'base/win/scoped_variant.cc',
+        'base/win/shortcut.cc',
+        'base/win/startup_information.cc',
+        'base/win/wait_chain.cc',
+        'base/win/win_util.cc',
+        'base/win/windows_version.cc',
+        'base/win/wrapped_window_proc.cc',
+    ])
+
+    libs.extend([
+        'advapi32.lib',
+        'dbghelp.lib',
+        'kernel32.lib',
+        'ole32.lib',
+        'shell32.lib',
+        'user32.lib',
+        'userenv.lib',
+        'version.lib',
+        'winmm.lib',
+        'ws2_32.lib',
+        'Shlwapi.lib',
+    ])
+
+  # we just build static libraries that GN needs
+  executables['gn']['libs'].extend(static_libraries.keys())
+
+  write_generic_ninja(path, static_libraries, executables, cc, cxx, ar, ld,
+                      cflags, cflags_cc, ldflags, include_dirs, libs)
+
+def build_gn_with_gn(temp_gn, build_dir, options):
+  gn_gen_args = options.gn_gen_args or ''
+  if not options.debug:
+    gn_gen_args += ' is_debug=false'
+  cmd = [temp_gn, 'gen', build_dir, '--args=%s' % gn_gen_args]
+  check_call(cmd)
+
+  cmd = ['ninja', '-C', build_dir, '-w', 'dupbuild=err']
+  if options.verbose:
+    cmd.append('-v')
+  cmd.append('gn')
+  check_call(cmd)
+
+  if not options.debug and not is_win:
+    check_call(['strip', os.path.join(build_dir, 'gn')])
+
+
+if __name__ == '__main__':
+  sys.exit(main(sys.argv[1:]))
diff -Naur chromium-65.0.3325.181-orig/tools/gn/gn_main.cc chromium-65.0.3325.181.patched/tools/gn/gn_main.cc
--- chromium-65.0.3325.181-orig/tools/gn/gn_main.cc	2018-03-21 01:05:54.000000000 +0300
+++ chromium-65.0.3325.181.patched/tools/gn/gn_main.cc	2018-04-27 11:31:20.511829108 +0300
@@ -12,13 +12,7 @@
 #include "tools/gn/standard_out.h"
 #include "tools/gn/switches.h"
 
-// Only the GN-generated build makes this header for now.
-// TODO(brettw) consider adding this if we need it in GYP.
-#if defined(GN_BUILD)
-#include "tools/gn/last_commit_position.h"
-#else
 #define LAST_COMMIT_POSITION "UNKNOWN"
-#endif
 
 namespace {
 
diff -Naur chromium-65.0.3325.181-orig/tools/gn/gn_main.cc.lastcommit chromium-65.0.3325.181.patched/tools/gn/gn_main.cc.lastcommit
--- chromium-65.0.3325.181-orig/tools/gn/gn_main.cc.lastcommit	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/tools/gn/gn_main.cc.lastcommit	2018-03-21 01:05:54.000000000 +0300
@@ -0,0 +1,86 @@
+// Copyright (c) 2013 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "base/at_exit.h"
+#include "base/command_line.h"
+#include "base/strings/utf_string_conversions.h"
+#include "build/build_config.h"
+#include "tools/gn/commands.h"
+#include "tools/gn/err.h"
+#include "tools/gn/location.h"
+#include "tools/gn/standard_out.h"
+#include "tools/gn/switches.h"
+
+// Only the GN-generated build makes this header for now.
+// TODO(brettw) consider adding this if we need it in GYP.
+#if defined(GN_BUILD)
+#include "tools/gn/last_commit_position.h"
+#else
+#define LAST_COMMIT_POSITION "UNKNOWN"
+#endif
+
+namespace {
+
+std::vector<std::string> GetArgs(const base::CommandLine& cmdline) {
+  base::CommandLine::StringVector in_args = cmdline.GetArgs();
+#if defined(OS_WIN)
+  std::vector<std::string> out_args;
+  for (const auto& arg : in_args)
+    out_args.push_back(base::WideToUTF8(arg));
+  return out_args;
+#else
+  return in_args;
+#endif
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  base::AtExitManager at_exit;
+#if defined(OS_WIN)
+  base::CommandLine::set_slash_is_not_a_switch();
+#endif
+  base::CommandLine::Init(argc, argv);
+
+  const base::CommandLine& cmdline = *base::CommandLine::ForCurrentProcess();
+  std::vector<std::string> args = GetArgs(cmdline);
+
+  std::string command;
+  if (cmdline.HasSwitch("help") || cmdline.HasSwitch("h")) {
+    // Make "-h" and "--help" default to help command.
+    command = commands::kHelp;
+  } else if (cmdline.HasSwitch(switches::kVersion)) {
+    // Make "--version" print the version and exit.
+    OutputString(std::string(LAST_COMMIT_POSITION) + "\n");
+    exit(0);
+  } else if (args.empty()) {
+    // No command, print error and exit.
+    Err(Location(), "No command specified.",
+        "Most commonly you want \"gn gen <out_dir>\" to make a build dir.\n"
+        "Or try \"gn help\" for more commands.").PrintToStdout();
+    return 1;
+  } else {
+    command = args[0];
+    args.erase(args.begin());
+  }
+
+  const commands::CommandInfoMap& command_map = commands::GetCommands();
+  commands::CommandInfoMap::const_iterator found_command =
+      command_map.find(command);
+
+  int retval;
+  if (found_command != command_map.end()) {
+    retval = found_command->second.runner(args);
+  } else {
+    Err(Location(), "Command \"" + command + "\" unknown.").PrintToStdout();
+    OutputString(
+        "Available commands (type \"gn help <command>\" for more details):\n");
+    for (const auto& cmd : commands::GetCommands())
+      PrintShortHelp(cmd.second.help_short);
+
+    retval = 1;
+  }
+
+  exit(retval);  // Don't free memory, it can be really slow!
+}
diff -Naur chromium-65.0.3325.181-orig/ui/events/devices/x11/device_data_manager_x11.cc chromium-65.0.3325.181.patched/ui/events/devices/x11/device_data_manager_x11.cc
--- chromium-65.0.3325.181-orig/ui/events/devices/x11/device_data_manager_x11.cc	2018-03-21 01:05:56.000000000 +0300
+++ chromium-65.0.3325.181.patched/ui/events/devices/x11/device_data_manager_x11.cc	2018-04-27 11:31:20.535828855 +0300
@@ -785,15 +785,6 @@
   DCHECK(deviceid >= 0 && deviceid < kMaxDeviceNum);
   ScrollInfo& info = scroll_data_[deviceid];
 
-  bool legacy_scroll_available =
-      (scroll_class_info->flags & XIScrollFlagNoEmulation) == 0;
-  // If the device's highest resolution is lower than the resolution of xinput1
-  // then use xinput1's events instead (ie. don't configure smooth scrolling).
-  if (legacy_scroll_available &&
-      std::abs(scroll_class_info->increment) <= 1.0) {
-    return;
-  }
-
   switch (scroll_class_info->scroll_type) {
     case XIScrollTypeVertical:
       info.vertical.number = scroll_class_info->number;
diff -Naur chromium-65.0.3325.181-orig/ui/events/devices/x11/device_data_manager_x11.cc.revert chromium-65.0.3325.181.patched/ui/events/devices/x11/device_data_manager_x11.cc.revert
--- chromium-65.0.3325.181-orig/ui/events/devices/x11/device_data_manager_x11.cc.revert	1970-01-01 03:00:00.000000000 +0300
+++ chromium-65.0.3325.181.patched/ui/events/devices/x11/device_data_manager_x11.cc.revert	2018-03-21 01:05:56.000000000 +0300
@@ -0,0 +1,903 @@
+// Copyright 2014 The Chromium Authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "ui/events/devices/x11/device_data_manager_x11.h"
+
+#include <stddef.h>
+
+#include <utility>
+
+#include "base/bind.h"
+#include "base/bind_helpers.h"
+#include "base/command_line.h"
+#include "base/logging.h"
+#include "base/macros.h"
+#include "base/memory/singleton.h"
+#include "base/sys_info.h"
+#include "build/build_config.h"
+#include "ui/display/display.h"
+#include "ui/events/devices/x11/device_list_cache_x11.h"
+#include "ui/events/devices/x11/touch_factory_x11.h"
+#include "ui/events/event_constants.h"
+#include "ui/events/event_switches.h"
+#include "ui/events/keycodes/keyboard_code_conversion_x.h"
+#include "ui/gfx/geometry/point3_f.h"
+#include "ui/gfx/x/x11.h"
+#include "ui/gfx/x/x11_atom_cache.h"
+
+// XIScrollClass was introduced in XI 2.1 so we need to define it here
+// for backward-compatibility with older versions of XInput.
+#if !defined(XIScrollClass)
+#define XIScrollClass 3
+#endif
+
+// Multi-touch support was introduced in XI 2.2. Add XI event types here
+// for backward-compatibility with older versions of XInput.
+#if !defined(XI_TouchBegin)
+#define XI_TouchBegin  18
+#define XI_TouchUpdate 19
+#define XI_TouchEnd    20
+#endif
+
+// Copied from xserver-properties.h
+#define AXIS_LABEL_PROP_REL_HWHEEL "Rel Horiz Wheel"
+#define AXIS_LABEL_PROP_REL_WHEEL "Rel Vert Wheel"
+
+// CMT specific timings
+#define AXIS_LABEL_PROP_ABS_DBL_START_TIME "Abs Dbl Start Timestamp"
+#define AXIS_LABEL_PROP_ABS_DBL_END_TIME   "Abs Dbl End Timestamp"
+
+// Ordinal values
+#define AXIS_LABEL_PROP_ABS_DBL_ORDINAL_X   "Abs Dbl Ordinal X"
+#define AXIS_LABEL_PROP_ABS_DBL_ORDINAL_Y   "Abs Dbl Ordinal Y"
+
+// Fling properties
+#define AXIS_LABEL_PROP_ABS_DBL_FLING_VX   "Abs Dbl Fling X Velocity"
+#define AXIS_LABEL_PROP_ABS_DBL_FLING_VY   "Abs Dbl Fling Y Velocity"
+#define AXIS_LABEL_PROP_ABS_FLING_STATE   "Abs Fling State"
+
+#define AXIS_LABEL_PROP_ABS_FINGER_COUNT   "Abs Finger Count"
+
+// Cros metrics gesture from touchpad
+#define AXIS_LABEL_PROP_ABS_METRICS_TYPE      "Abs Metrics Type"
+#define AXIS_LABEL_PROP_ABS_DBL_METRICS_DATA1 "Abs Dbl Metrics Data 1"
+#define AXIS_LABEL_PROP_ABS_DBL_METRICS_DATA2 "Abs Dbl Metrics Data 2"
+
+// Touchscreen multi-touch
+#define AXIS_LABEL_ABS_MT_TOUCH_MAJOR "Abs MT Touch Major"
+#define AXIS_LABEL_ABS_MT_TOUCH_MINOR "Abs MT Touch Minor"
+#define AXIS_LABEL_ABS_MT_ORIENTATION "Abs MT Orientation"
+#define AXIS_LABEL_ABS_MT_PRESSURE    "Abs MT Pressure"
+#define AXIS_LABEL_ABS_MT_POSITION_X  "Abs MT Position X"
+#define AXIS_LABEL_ABS_MT_POSITION_Y  "Abs MT Position Y"
+#define AXIS_LABEL_ABS_MT_TRACKING_ID "Abs MT Tracking ID"
+#define AXIS_LABEL_TOUCH_TIMESTAMP    "Touch Timestamp"
+
+// When you add new data types, please make sure the order here is aligned
+// with the order in the DataType enum in the header file because we assume
+// they are in sync when updating the device list (see UpdateDeviceList).
+constexpr const char* kCachedAtoms[] = {
+    AXIS_LABEL_PROP_REL_HWHEEL,
+    AXIS_LABEL_PROP_REL_WHEEL,
+    AXIS_LABEL_PROP_ABS_DBL_ORDINAL_X,
+    AXIS_LABEL_PROP_ABS_DBL_ORDINAL_Y,
+    AXIS_LABEL_PROP_ABS_DBL_START_TIME,
+    AXIS_LABEL_PROP_ABS_DBL_END_TIME,
+    AXIS_LABEL_PROP_ABS_DBL_FLING_VX,
+    AXIS_LABEL_PROP_ABS_DBL_FLING_VY,
+    AXIS_LABEL_PROP_ABS_FLING_STATE,
+    AXIS_LABEL_PROP_ABS_METRICS_TYPE,
+    AXIS_LABEL_PROP_ABS_DBL_METRICS_DATA1,
+    AXIS_LABEL_PROP_ABS_DBL_METRICS_DATA2,
+    AXIS_LABEL_PROP_ABS_FINGER_COUNT,
+    AXIS_LABEL_ABS_MT_TOUCH_MAJOR,
+    AXIS_LABEL_ABS_MT_TOUCH_MINOR,
+    AXIS_LABEL_ABS_MT_ORIENTATION,
+    AXIS_LABEL_ABS_MT_PRESSURE,
+    AXIS_LABEL_ABS_MT_POSITION_X,
+    AXIS_LABEL_ABS_MT_POSITION_Y,
+    AXIS_LABEL_ABS_MT_TRACKING_ID,
+    AXIS_LABEL_TOUCH_TIMESTAMP,
+};
+
+// Make sure the sizes of enum and |kCachedAtoms| are aligned.
+static_assert(arraysize(kCachedAtoms) ==
+                  ui::DeviceDataManagerX11::DT_LAST_ENTRY,
+              "kCachedAtoms count / enum mismatch");
+
+// Constants for checking if a data type lies in the range of CMT/Touch data
+// types.
+const int kCMTDataTypeStart = ui::DeviceDataManagerX11::DT_CMT_SCROLL_X;
+const int kCMTDataTypeEnd = ui::DeviceDataManagerX11::DT_CMT_FINGER_COUNT;
+const int kTouchDataTypeStart = ui::DeviceDataManagerX11::DT_TOUCH_MAJOR;
+const int kTouchDataTypeEnd = ui::DeviceDataManagerX11::DT_TOUCH_RAW_TIMESTAMP;
+
+namespace ui {
+
+namespace {
+
+template <typename Iterator>
+Iterator FindDeviceWithId(Iterator begin, Iterator end, int id) {
+  for (auto it = begin; it != end; ++it) {
+    if (it->id == id)
+      return it;
+  }
+  return end;
+}
+
+// Disables high precision scrolling in X11
+const char kDisableHighPrecisionScrolling[] =
+    "disable-high-precision-scrolling";
+
+bool IsHighPrecisionScrollingDisabled() {
+  return base::CommandLine::ForCurrentProcess()->HasSwitch(
+      kDisableHighPrecisionScrolling);
+}
+
+}  // namespace
+
+bool DeviceDataManagerX11::IsCMTDataType(const int type) {
+  return (type >= kCMTDataTypeStart) && (type <= kCMTDataTypeEnd);
+}
+
+bool DeviceDataManagerX11::IsTouchDataType(const int type) {
+  return (type >= kTouchDataTypeStart) && (type <= kTouchDataTypeEnd);
+}
+
+// static
+void DeviceDataManagerX11::CreateInstance() {
+  if (HasInstance())
+    return;
+
+  DeviceDataManagerX11* device_data_manager = new DeviceDataManagerX11();
+
+  // TODO(bruthig): Replace the DeleteInstance callbacks with explicit calls.
+  base::AtExitManager::RegisterTask(
+      base::Bind(DeviceDataManager::DeleteInstance));
+
+  set_instance(device_data_manager);
+}
+
+// static
+DeviceDataManagerX11* DeviceDataManagerX11::GetInstance() {
+  return static_cast<DeviceDataManagerX11*>(DeviceDataManager::GetInstance());
+}
+
+DeviceDataManagerX11::DeviceDataManagerX11()
+    : xi_opcode_(-1),
+      high_precision_scrolling_disabled_(IsHighPrecisionScrollingDisabled()),
+      button_map_count_(0) {
+  CHECK(gfx::GetXDisplay());
+  InitializeXInputInternal();
+
+  UpdateDeviceList(gfx::GetXDisplay());
+  UpdateButtonMap();
+}
+
+DeviceDataManagerX11::~DeviceDataManagerX11() {
+}
+
+bool DeviceDataManagerX11::InitializeXInputInternal() {
+  // Check if XInput is available on the system.
+  xi_opcode_ = -1;
+  int opcode, event, error;
+  if (!XQueryExtension(
+      gfx::GetXDisplay(), "XInputExtension", &opcode, &event, &error)) {
+    VLOG(1) << "X Input extension not available: error=" << error;
+    return false;
+  }
+
+  // Check the XInput version.
+  int major = 2, minor = 2;
+  if (XIQueryVersion(gfx::GetXDisplay(), &major, &minor) == BadRequest) {
+    VLOG(1) << "XInput2 not supported in the server.";
+    return false;
+  }
+  if (major < 2 || (major == 2 && minor < 2)) {
+    DVLOG(1) << "XI version on server is " << major << "." << minor << ". "
+            << "But 2.2 is required.";
+    return false;
+  }
+
+  xi_opcode_ = opcode;
+  CHECK_NE(-1, xi_opcode_);
+
+  // Possible XI event types for XIDeviceEvent. See the XI2 protocol
+  // specification.
+  xi_device_event_types_[XI_KeyPress] = true;
+  xi_device_event_types_[XI_KeyRelease] = true;
+  xi_device_event_types_[XI_ButtonPress] = true;
+  xi_device_event_types_[XI_ButtonRelease] = true;
+  xi_device_event_types_[XI_Motion] = true;
+  // Multi-touch support was introduced in XI 2.2.
+  if (minor >= 2) {
+    xi_device_event_types_[XI_TouchBegin] = true;
+    xi_device_event_types_[XI_TouchUpdate] = true;
+    xi_device_event_types_[XI_TouchEnd] = true;
+  }
+  return true;
+}
+
+bool DeviceDataManagerX11::IsXInput2Available() const {
+  return xi_opcode_ != -1;
+}
+
+void DeviceDataManagerX11::UpdateDeviceList(Display* display) {
+  cmt_devices_.reset();
+  touchpads_.reset();
+  master_pointers_.clear();
+  for (int i = 0; i < kMaxDeviceNum; ++i) {
+    valuator_count_[i] = 0;
+    valuator_lookup_[i].clear();
+    data_type_lookup_[i].clear();
+    scroll_data_[i].horizontal.number = -1;
+    scroll_data_[i].horizontal.seen = false;
+    scroll_data_[i].vertical.number = -1;
+    scroll_data_[i].vertical.seen = false;
+    for (int j = 0; j < kMaxSlotNum; j++)
+      last_seen_valuator_[i][j].clear();
+  }
+
+  // Find all the touchpad devices.
+  const XDeviceList& dev_list =
+      ui::DeviceListCacheX11::GetInstance()->GetXDeviceList(display);
+  Atom xi_touchpad = gfx::GetAtom(XI_TOUCHPAD);
+  for (int i = 0; i < dev_list.count; ++i)
+    if (dev_list[i].type == xi_touchpad)
+      touchpads_[dev_list[i].id] = true;
+
+  if (!IsXInput2Available())
+    return;
+
+  // Update the structs with new valuator information
+  const XIDeviceList& info_list =
+      ui::DeviceListCacheX11::GetInstance()->GetXI2DeviceList(display);
+  Atom atoms[DT_LAST_ENTRY];
+  for (int data_type = 0; data_type < DT_LAST_ENTRY; ++data_type)
+    atoms[data_type] = gfx::GetAtom(kCachedAtoms[data_type]);
+
+  for (int i = 0; i < info_list.count; ++i) {
+    const XIDeviceInfo& info = info_list[i];
+
+    if (info.use == XIMasterPointer)
+      master_pointers_.push_back(info.deviceid);
+
+    // We currently handle only slave, non-keyboard devices
+    if (info.use != XISlavePointer && info.use != XIFloatingSlave)
+      continue;
+
+    bool possible_cmt = false;
+    bool not_cmt = false;
+    const int deviceid = info.deviceid;
+
+    for (int j = 0; j < info.num_classes; ++j) {
+      if (info.classes[j]->type == XIValuatorClass)
+        ++valuator_count_[deviceid];
+      else if (info.classes[j]->type == XIScrollClass)
+        not_cmt = true;
+    }
+
+    // Skip devices that don't use any valuator
+    if (!valuator_count_[deviceid])
+      continue;
+
+    valuator_lookup_[deviceid].resize(DT_LAST_ENTRY);
+    data_type_lookup_[deviceid].resize(
+        valuator_count_[deviceid], DT_LAST_ENTRY);
+    for (int j = 0; j < kMaxSlotNum; j++)
+      last_seen_valuator_[deviceid][j].resize(DT_LAST_ENTRY, 0);
+    for (int j = 0; j < info.num_classes; ++j) {
+      if (info.classes[j]->type == XIValuatorClass) {
+        if (UpdateValuatorClassDevice(
+                reinterpret_cast<XIValuatorClassInfo*>(info.classes[j]), atoms,
+                deviceid))
+          possible_cmt = true;
+      } else if (info.classes[j]->type == XIScrollClass) {
+        UpdateScrollClassDevice(
+            reinterpret_cast<XIScrollClassInfo*>(info.classes[j]), deviceid);
+      }
+    }
+
+    if (possible_cmt && !not_cmt)
+      cmt_devices_[deviceid] = true;
+  }
+}
+
+bool DeviceDataManagerX11::GetSlotNumber(const XIDeviceEvent* xiev, int* slot) {
+  ui::TouchFactory* factory = ui::TouchFactory::GetInstance();
+  if (!factory->IsMultiTouchDevice(xiev->sourceid)) {
+    *slot = 0;
+    return true;
+  }
+  return factory->QuerySlotForTrackingID(xiev->detail, slot);
+}
+
+void DeviceDataManagerX11::GetEventRawData(const XEvent& xev, EventData* data) {
+  if (xev.type != GenericEvent)
+    return;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  CHECK_GE(xiev->sourceid, 0);
+  CHECK_GE(xiev->deviceid, 0);
+  if (xiev->sourceid >= kMaxDeviceNum || xiev->deviceid >= kMaxDeviceNum)
+    return;
+  data->clear();
+  const int sourceid = xiev->sourceid;
+  double* valuators = xiev->valuators.values;
+  for (int i = 0; i <= valuator_count_[sourceid]; ++i) {
+    if (XIMaskIsSet(xiev->valuators.mask, i)) {
+      int type = data_type_lookup_[sourceid][i];
+      if (type != DT_LAST_ENTRY) {
+        (*data)[type] = *valuators;
+        if (IsTouchDataType(type)) {
+          int slot = -1;
+          if (GetSlotNumber(xiev, &slot) && slot >= 0 && slot < kMaxSlotNum)
+            last_seen_valuator_[sourceid][slot][type] = *valuators;
+        }
+      }
+      valuators++;
+    }
+  }
+}
+
+bool DeviceDataManagerX11::GetEventData(const XEvent& xev,
+    const DataType type, double* value) {
+  if (xev.type != GenericEvent)
+    return false;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  CHECK_GE(xiev->sourceid, 0);
+  CHECK_GE(xiev->deviceid, 0);
+  if (xiev->sourceid >= kMaxDeviceNum || xiev->deviceid >= kMaxDeviceNum)
+    return false;
+  const int sourceid = xiev->sourceid;
+  if (valuator_lookup_[sourceid].empty())
+    return false;
+
+  if (type == DT_TOUCH_TRACKING_ID) {
+    // With XInput2 MT, Tracking ID is provided in the detail field for touch
+    // events.
+    if (xiev->evtype == XI_TouchBegin ||
+        xiev->evtype == XI_TouchEnd ||
+        xiev->evtype == XI_TouchUpdate) {
+      *value = xiev->detail;
+    } else {
+      *value = 0;
+    }
+    return true;
+  }
+
+  int val_index = valuator_lookup_[sourceid][type].number;
+  int slot = 0;
+  if (val_index >= 0) {
+    if (XIMaskIsSet(xiev->valuators.mask, val_index)) {
+      double* valuators = xiev->valuators.values;
+      while (val_index--) {
+        if (XIMaskIsSet(xiev->valuators.mask, val_index))
+          ++valuators;
+      }
+      *value = *valuators;
+      if (IsTouchDataType(type)) {
+        if (GetSlotNumber(xiev, &slot) && slot >= 0 && slot < kMaxSlotNum)
+          last_seen_valuator_[sourceid][slot][type] = *value;
+      }
+      return true;
+    } else if (IsTouchDataType(type)) {
+      if (GetSlotNumber(xiev, &slot) && slot >= 0 && slot < kMaxSlotNum)
+        *value = last_seen_valuator_[sourceid][slot][type];
+    }
+  }
+
+  return false;
+}
+
+bool DeviceDataManagerX11::IsXIDeviceEvent(const XEvent& xev) const {
+  if (xev.type != GenericEvent || xev.xcookie.extension != xi_opcode_)
+    return false;
+  return xi_device_event_types_[xev.xcookie.evtype];
+}
+
+bool DeviceDataManagerX11::IsTouchpadXInputEvent(const XEvent& xev) const {
+  if (xev.type != GenericEvent)
+    return false;
+
+  XIDeviceEvent* xievent = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  CHECK_GE(xievent->sourceid, 0);
+  if (xievent->sourceid >= kMaxDeviceNum)
+    return false;
+  return touchpads_[xievent->sourceid];
+}
+
+bool DeviceDataManagerX11::IsCMTDeviceEvent(const XEvent& xev) const {
+  if (xev.type != GenericEvent)
+    return false;
+
+  XIDeviceEvent* xievent = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  CHECK_GE(xievent->sourceid, 0);
+  if (xievent->sourceid >= kMaxDeviceNum)
+    return false;
+  return cmt_devices_[xievent->sourceid];
+}
+
+int DeviceDataManagerX11::GetScrollClassEventDetail(const XEvent& xev) const {
+  if (xev.type != GenericEvent)
+    return SCROLL_TYPE_NO_SCROLL;
+
+  XIDeviceEvent* xievent = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  if (xievent->sourceid >= kMaxDeviceNum)
+    return SCROLL_TYPE_NO_SCROLL;
+  int horizontal_id = scroll_data_[xievent->sourceid].horizontal.number;
+  int vertical_id = scroll_data_[xievent->sourceid].vertical.number;
+  return (horizontal_id != -1 &&
+                  XIMaskIsSet(xievent->valuators.mask, horizontal_id)
+              ? SCROLL_TYPE_HORIZONTAL
+              : 0) |
+         (vertical_id != -1 && XIMaskIsSet(xievent->valuators.mask, vertical_id)
+              ? SCROLL_TYPE_VERTICAL
+              : 0);
+}
+
+int DeviceDataManagerX11::GetScrollClassDeviceDetail(const XEvent& xev) const {
+  if (xev.type != GenericEvent)
+    return SCROLL_TYPE_NO_SCROLL;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  if (xiev->sourceid >= kMaxDeviceNum || xiev->deviceid >= kMaxDeviceNum)
+    return SCROLL_TYPE_NO_SCROLL;
+  const int sourceid = xiev->sourceid;
+  const ScrollInfo& device_data = scroll_data_[sourceid];
+  return (device_data.vertical.number >= 0 ? SCROLL_TYPE_VERTICAL : 0) |
+         (device_data.horizontal.number >= 0 ? SCROLL_TYPE_HORIZONTAL : 0);
+}
+
+bool DeviceDataManagerX11::IsCMTGestureEvent(const XEvent& xev) const {
+  return (IsScrollEvent(xev) || IsFlingEvent(xev) || IsCMTMetricsEvent(xev));
+}
+
+bool DeviceDataManagerX11::HasEventData(
+    const XIDeviceEvent* xiev, const DataType type) const {
+  CHECK_GE(xiev->sourceid, 0);
+  if (xiev->sourceid >= kMaxDeviceNum)
+    return false;
+  if (type >= valuator_lookup_[xiev->sourceid].size())
+    return false;
+  const int idx = valuator_lookup_[xiev->sourceid][type].number;
+  return (idx >= 0) && XIMaskIsSet(xiev->valuators.mask, idx);
+}
+
+bool DeviceDataManagerX11::IsScrollEvent(const XEvent& xev) const {
+  if (!IsCMTDeviceEvent(xev))
+    return false;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  return (HasEventData(xiev, DT_CMT_SCROLL_X) ||
+          HasEventData(xiev, DT_CMT_SCROLL_Y));
+}
+
+bool DeviceDataManagerX11::IsFlingEvent(const XEvent& xev) const {
+  if (!IsCMTDeviceEvent(xev))
+    return false;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  return (HasEventData(xiev, DT_CMT_FLING_X) &&
+          HasEventData(xiev, DT_CMT_FLING_Y) &&
+          HasEventData(xiev, DT_CMT_FLING_STATE));
+}
+
+bool DeviceDataManagerX11::IsCMTMetricsEvent(const XEvent& xev) const {
+  if (!IsCMTDeviceEvent(xev))
+    return false;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  return (HasEventData(xiev, DT_CMT_METRICS_TYPE) &&
+          HasEventData(xiev, DT_CMT_METRICS_DATA1) &&
+          HasEventData(xiev, DT_CMT_METRICS_DATA2));
+}
+
+bool DeviceDataManagerX11::HasGestureTimes(const XEvent& xev) const {
+  if (!IsCMTDeviceEvent(xev))
+    return false;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  return (HasEventData(xiev, DT_CMT_START_TIME) &&
+          HasEventData(xiev, DT_CMT_END_TIME));
+}
+
+void DeviceDataManagerX11::GetScrollOffsets(const XEvent& xev,
+                                            float* x_offset,
+                                            float* y_offset,
+                                            float* x_offset_ordinal,
+                                            float* y_offset_ordinal,
+                                            int* finger_count) {
+  *x_offset = 0;
+  *y_offset = 0;
+  *x_offset_ordinal = 0;
+  *y_offset_ordinal = 0;
+  *finger_count = 2;
+
+  EventData data;
+  GetEventRawData(xev, &data);
+
+  if (data.find(DT_CMT_SCROLL_X) != data.end())
+    *x_offset = data[DT_CMT_SCROLL_X];
+  if (data.find(DT_CMT_SCROLL_Y) != data.end())
+    *y_offset = data[DT_CMT_SCROLL_Y];
+  if (data.find(DT_CMT_ORDINAL_X) != data.end())
+    *x_offset_ordinal = data[DT_CMT_ORDINAL_X];
+  if (data.find(DT_CMT_ORDINAL_Y) != data.end())
+    *y_offset_ordinal = data[DT_CMT_ORDINAL_Y];
+  if (data.find(DT_CMT_FINGER_COUNT) != data.end())
+    *finger_count = static_cast<int>(data[DT_CMT_FINGER_COUNT]);
+}
+
+void DeviceDataManagerX11::GetScrollClassOffsets(const XEvent& xev,
+                                                 double* x_offset,
+                                                 double* y_offset) {
+  DCHECK_NE(SCROLL_TYPE_NO_SCROLL, GetScrollClassDeviceDetail(xev));
+
+  *x_offset = 0;
+  *y_offset = 0;
+
+  if (xev.type != GenericEvent)
+    return;
+
+  XIDeviceEvent* xiev = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  if (xiev->sourceid >= kMaxDeviceNum || xiev->deviceid >= kMaxDeviceNum)
+    return;
+  const int sourceid = xiev->sourceid;
+  double* valuators = xiev->valuators.values;
+
+  ScrollInfo* info = &scroll_data_[sourceid];
+
+  const int horizontal_number = info->horizontal.number;
+  const int vertical_number = info->vertical.number;
+
+  for (int i = 0; i <= valuator_count_[sourceid]; ++i) {
+    if (!XIMaskIsSet(xiev->valuators.mask, i))
+      continue;
+    if (i == horizontal_number) {
+      *x_offset = ExtractAndUpdateScrollOffset(&info->horizontal, *valuators);
+    } else if (i == vertical_number) {
+      *y_offset = ExtractAndUpdateScrollOffset(&info->vertical, *valuators);
+    }
+    valuators++;
+  }
+}
+
+void DeviceDataManagerX11::InvalidateScrollClasses(int device_id) {
+  if (device_id == kAllDevices) {
+    for (int i = 0; i < kMaxDeviceNum; i++) {
+      scroll_data_[i].horizontal.seen = false;
+      scroll_data_[i].vertical.seen = false;
+    }
+  } else {
+    CHECK(device_id >= 0 && device_id < kMaxDeviceNum);
+    scroll_data_[device_id].horizontal.seen = false;
+    scroll_data_[device_id].vertical.seen = false;
+  }
+}
+
+void DeviceDataManagerX11::GetFlingData(const XEvent& xev,
+                                        float* vx,
+                                        float* vy,
+                                        float* vx_ordinal,
+                                        float* vy_ordinal,
+                                        bool* is_cancel) {
+  *vx = 0;
+  *vy = 0;
+  *vx_ordinal = 0;
+  *vy_ordinal = 0;
+  *is_cancel = false;
+
+  EventData data;
+  GetEventRawData(xev, &data);
+
+  if (data.find(DT_CMT_FLING_X) != data.end())
+    *vx = data[DT_CMT_FLING_X];
+  if (data.find(DT_CMT_FLING_Y) != data.end())
+    *vy = data[DT_CMT_FLING_Y];
+  if (data.find(DT_CMT_FLING_STATE) != data.end())
+    *is_cancel = !!static_cast<unsigned int>(data[DT_CMT_FLING_STATE]);
+  if (data.find(DT_CMT_ORDINAL_X) != data.end())
+    *vx_ordinal = data[DT_CMT_ORDINAL_X];
+  if (data.find(DT_CMT_ORDINAL_Y) != data.end())
+    *vy_ordinal = data[DT_CMT_ORDINAL_Y];
+}
+
+void DeviceDataManagerX11::GetMetricsData(const XEvent& xev,
+                                          GestureMetricsType* type,
+                                          float* data1,
+                                          float* data2) {
+  *type = kGestureMetricsTypeUnknown;
+  *data1 = 0;
+  *data2 = 0;
+
+  EventData data;
+  GetEventRawData(xev, &data);
+
+  if (data.find(DT_CMT_METRICS_TYPE) != data.end()) {
+    int val = static_cast<int>(data[DT_CMT_METRICS_TYPE]);
+    if (val == 0)
+      *type = kGestureMetricsTypeNoisyGround;
+    else
+      *type = kGestureMetricsTypeUnknown;
+  }
+  if (data.find(DT_CMT_METRICS_DATA1) != data.end())
+    *data1 = data[DT_CMT_METRICS_DATA1];
+  if (data.find(DT_CMT_METRICS_DATA2) != data.end())
+    *data2 = data[DT_CMT_METRICS_DATA2];
+}
+
+int DeviceDataManagerX11::GetMappedButton(int button) {
+  return button > 0 && button <= button_map_count_ ? button_map_[button - 1] :
+                                                     button;
+}
+
+void DeviceDataManagerX11::UpdateButtonMap() {
+  button_map_count_ = XGetPointerMapping(gfx::GetXDisplay(),
+                                         button_map_,
+                                         arraysize(button_map_));
+}
+
+void DeviceDataManagerX11::GetGestureTimes(const XEvent& xev,
+                                           double* start_time,
+                                           double* end_time) {
+  *start_time = 0;
+  *end_time = 0;
+
+  EventData data;
+  GetEventRawData(xev, &data);
+
+  if (data.find(DT_CMT_START_TIME) != data.end())
+    *start_time = data[DT_CMT_START_TIME];
+  if (data.find(DT_CMT_END_TIME) != data.end())
+    *end_time = data[DT_CMT_END_TIME];
+}
+
+bool DeviceDataManagerX11::NormalizeData(int deviceid,
+                                         const DataType type,
+                                         double* value) {
+  double max_value;
+  double min_value;
+  if (GetDataRange(deviceid, type, &min_value, &max_value)) {
+    *value = (*value - min_value) / (max_value - min_value);
+    DCHECK(*value >= 0.0 && *value <= 1.0);
+    return true;
+  }
+  return false;
+}
+
+bool DeviceDataManagerX11::GetDataRange(int deviceid,
+                                        const DataType type,
+                                        double* min,
+                                        double* max) {
+  CHECK_GE(deviceid, 0);
+  if (deviceid >= kMaxDeviceNum)
+    return false;
+  if (valuator_lookup_[deviceid].empty())
+    return false;
+  if (valuator_lookup_[deviceid][type].number >= 0) {
+    *min = valuator_lookup_[deviceid][type].min;
+    *max = valuator_lookup_[deviceid][type].max;
+    return true;
+  }
+  return false;
+}
+
+void DeviceDataManagerX11::SetDeviceListForTest(
+    const std::vector<int>& touchscreen,
+    const std::vector<int>& cmt_devices,
+    const std::vector<int>& other_devices) {
+  for (int i = 0; i < kMaxDeviceNum; ++i) {
+    valuator_count_[i] = 0;
+    valuator_lookup_[i].clear();
+    data_type_lookup_[i].clear();
+    for (int j = 0; j < kMaxSlotNum; j++)
+      last_seen_valuator_[i][j].clear();
+  }
+
+  for (int deviceid : touchscreen) {
+    InitializeValuatorsForTest(deviceid, kTouchDataTypeStart, kTouchDataTypeEnd,
+                               0, 1000);
+  }
+
+  cmt_devices_.reset();
+  for (int deviceid : cmt_devices) {
+    cmt_devices_[deviceid] = true;
+    touchpads_[deviceid] = true;
+    InitializeValuatorsForTest(deviceid, kCMTDataTypeStart, kCMTDataTypeEnd,
+                               -1000, 1000);
+  }
+
+  for (int deviceid : other_devices) {
+    InitializeValuatorsForTest(deviceid, kCMTDataTypeStart, kCMTDataTypeEnd,
+                               -1000, 1000);
+  }
+}
+
+void DeviceDataManagerX11::SetValuatorDataForTest(XIDeviceEvent* xievent,
+                                                  DataType type,
+                                                  double value) {
+  int index = valuator_lookup_[xievent->deviceid][type].number;
+  CHECK(!XIMaskIsSet(xievent->valuators.mask, index));
+  CHECK(index >= 0 && index < valuator_count_[xievent->deviceid]);
+  XISetMask(xievent->valuators.mask, index);
+
+  double* valuators = xievent->valuators.values;
+  for (int i = 0; i < index; ++i) {
+    if (XIMaskIsSet(xievent->valuators.mask, i))
+      valuators++;
+  }
+  for (int i = DT_LAST_ENTRY - 1; i > valuators - xievent->valuators.values;
+       --i)
+    xievent->valuators.values[i] = xievent->valuators.values[i - 1];
+  *valuators = value;
+}
+
+void DeviceDataManagerX11::InitializeValuatorsForTest(int deviceid,
+                                                      int start_valuator,
+                                                      int end_valuator,
+                                                      double min_value,
+                                                      double max_value) {
+  valuator_lookup_[deviceid].resize(DT_LAST_ENTRY);
+  data_type_lookup_[deviceid].resize(DT_LAST_ENTRY, DT_LAST_ENTRY);
+  for (int j = 0; j < kMaxSlotNum; j++)
+    last_seen_valuator_[deviceid][j].resize(DT_LAST_ENTRY, 0);
+  for (int j = start_valuator; j <= end_valuator; ++j) {
+    auto& valuator_info = valuator_lookup_[deviceid][j];
+    valuator_info.number = valuator_count_[deviceid];
+    valuator_info.min = min_value;
+    valuator_info.max = max_value;
+    data_type_lookup_[deviceid][valuator_count_[deviceid]] = j;
+    valuator_count_[deviceid]++;
+  }
+}
+
+bool DeviceDataManagerX11::UpdateValuatorClassDevice(
+    XIValuatorClassInfo* valuator_class_info,
+    Atom* atoms,
+    int deviceid) {
+  DCHECK(deviceid >= 0 && deviceid < kMaxDeviceNum);
+  Atom* label =
+      std::find(atoms, atoms + DT_LAST_ENTRY, valuator_class_info->label);
+  if (label == atoms + DT_LAST_ENTRY) {
+    return false;
+  }
+  int data_type = label - atoms;
+  DCHECK_GE(data_type, 0);
+  DCHECK_LT(data_type, DT_LAST_ENTRY);
+
+  auto& valuator_info = valuator_lookup_[deviceid][data_type];
+  valuator_info.number = valuator_class_info->number;
+  valuator_info.min = valuator_class_info->min;
+  valuator_info.max = valuator_class_info->max;
+  data_type_lookup_[deviceid][valuator_class_info->number] = data_type;
+  return IsCMTDataType(data_type);
+}
+
+void DeviceDataManagerX11::UpdateScrollClassDevice(
+    XIScrollClassInfo* scroll_class_info,
+    int deviceid) {
+  if (high_precision_scrolling_disabled_)
+    return;
+
+  DCHECK(deviceid >= 0 && deviceid < kMaxDeviceNum);
+  ScrollInfo& info = scroll_data_[deviceid];
+
+  bool legacy_scroll_available =
+      (scroll_class_info->flags & XIScrollFlagNoEmulation) == 0;
+  // If the device's highest resolution is lower than the resolution of xinput1
+  // then use xinput1's events instead (ie. don't configure smooth scrolling).
+  if (legacy_scroll_available &&
+      std::abs(scroll_class_info->increment) <= 1.0) {
+    return;
+  }
+
+  switch (scroll_class_info->scroll_type) {
+    case XIScrollTypeVertical:
+      info.vertical.number = scroll_class_info->number;
+      info.vertical.increment = scroll_class_info->increment;
+      info.vertical.position = 0;
+      info.vertical.seen = false;
+      break;
+    case XIScrollTypeHorizontal:
+      info.horizontal.number = scroll_class_info->number;
+      info.horizontal.increment = scroll_class_info->increment;
+      info.horizontal.position = 0;
+      info.horizontal.seen = false;
+      break;
+  }
+}
+
+double DeviceDataManagerX11::ExtractAndUpdateScrollOffset(
+    ScrollInfo::AxisInfo* axis,
+    double valuator) const {
+  double offset = 0;
+  if (axis->seen)
+    offset = axis->position - valuator;
+  axis->seen = true;
+  axis->position = valuator;
+  return offset / axis->increment;
+}
+
+void DeviceDataManagerX11::SetDisabledKeyboardAllowedKeys(
+    std::unique_ptr<std::set<KeyboardCode>> excepted_keys) {
+  DCHECK(!excepted_keys.get() ||
+         !blocked_keyboard_allowed_keys_.get());
+  blocked_keyboard_allowed_keys_ = std::move(excepted_keys);
+}
+
+void DeviceDataManagerX11::DisableDevice(int deviceid) {
+  blocked_devices_.set(deviceid, true);
+  // TODO(rsadam@): Support blocking touchscreen devices.
+  std::vector<InputDevice> keyboards = GetKeyboardDevices();
+  std::vector<InputDevice>::iterator it =
+      FindDeviceWithId(keyboards.begin(), keyboards.end(), deviceid);
+  if (it != std::end(keyboards)) {
+    blocked_keyboard_devices_.insert(
+        std::pair<int, InputDevice>(deviceid, *it));
+    keyboards.erase(it);
+    DeviceDataManager::OnKeyboardDevicesUpdated(keyboards);
+  }
+}
+
+void DeviceDataManagerX11::EnableDevice(int deviceid) {
+  blocked_devices_.set(deviceid, false);
+  std::map<int, InputDevice>::iterator it =
+      blocked_keyboard_devices_.find(deviceid);
+  if (it != blocked_keyboard_devices_.end()) {
+    std::vector<InputDevice> devices = GetKeyboardDevices();
+    // Add device to current list of active devices.
+    devices.push_back((*it).second);
+    blocked_keyboard_devices_.erase(it);
+    DeviceDataManager::OnKeyboardDevicesUpdated(devices);
+  }
+}
+
+bool DeviceDataManagerX11::IsDeviceEnabled(int device_id) const {
+  return blocked_devices_.test(device_id);
+}
+
+bool DeviceDataManagerX11::IsEventBlocked(const XEvent& xev) {
+  // Only check XI2 events which have a source device id.
+  if (xev.type != GenericEvent)
+    return false;
+
+  XIDeviceEvent* xievent = static_cast<XIDeviceEvent*>(xev.xcookie.data);
+  // Allow any key events from blocked_keyboard_allowed_keys_.
+  if (blocked_keyboard_allowed_keys_ &&
+      (xievent->evtype == XI_KeyPress || xievent->evtype == XI_KeyRelease) &&
+      blocked_keyboard_allowed_keys_->find(KeyboardCodeFromXKeyEvent(&xev)) !=
+          blocked_keyboard_allowed_keys_->end()) {
+    return false;
+  }
+
+  return blocked_devices_.test(xievent->sourceid);
+}
+
+void DeviceDataManagerX11::OnKeyboardDevicesUpdated(
+    const std::vector<InputDevice>& devices) {
+  std::vector<InputDevice> keyboards(devices);
+  for (std::map<int, InputDevice>::iterator blocked_iter =
+           blocked_keyboard_devices_.begin();
+       blocked_iter != blocked_keyboard_devices_.end();) {
+    // Check if the blocked device still exists in list of devices.
+    int device_id = blocked_iter->first;
+    std::vector<InputDevice>::iterator it =
+        FindDeviceWithId(keyboards.begin(), keyboards.end(), device_id);
+    // If the device no longer exists, unblock it, else filter it out from our
+    // active list.
+    if (it == keyboards.end()) {
+      blocked_devices_.set((*blocked_iter).first, false);
+      blocked_keyboard_devices_.erase(blocked_iter++);
+    } else {
+      keyboards.erase(it);
+      ++blocked_iter;
+    }
+  }
+  // Notify base class of updated list.
+  DeviceDataManager::OnKeyboardDevicesUpdated(keyboards);
+}
+
+}  // namespace ui
